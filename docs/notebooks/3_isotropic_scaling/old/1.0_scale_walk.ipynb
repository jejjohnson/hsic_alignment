{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isotropic Scaling Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Synopsis\n",
    "\n",
    "In this experiment, I will be looking at how the isotropic scaling effects the HSIC score for the HSIC and KA algorithms. In theory, because we are trying to find one parameter shared between the two kernel functions, there should be problems when the scale of one distribution is larger than another. It's a drawback of the method and it motivates the need to use two different parameters for the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# Insert path to model directory,.\n",
    "cwd = os.getcwd()\n",
    "path = f\"{cwd}/../../src\"\n",
    "sys.path.insert(0, path)\n",
    "\n",
    "import warnings\n",
    "import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "# toy datasets\n",
    "from data.toy import generate_dependence_data, generate_isotropic_data\n",
    "\n",
    "# Kernel Dependency measure\n",
    "from models.train_models import get_gamma_init\n",
    "from models.train_models import get_hsic\n",
    "from models.kernel import estimate_sigma, sigma_to_gamma, gamma_to_sigma, get_param_grid\n",
    "from models.ite_algorithms import run_rbig_models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Plotting\n",
    "from visualization.distribution import plot_scorer\n",
    "from visualization.scaling import plot_scorer_scale, plot_scorer_scale_norm\n",
    "\n",
    "\n",
    "# experiment helpers\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting Procedures\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# plt.style.use(['fivethirtyeight', 'seaborn-poster'])\n",
    "warnings.filterwarnings('ignore') # get rid of annoying warnings\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seaborn-dark-palette',\n",
       " 'classic',\n",
       " 'ggplot',\n",
       " 'seaborn-dark',\n",
       " 'seaborn-pastel',\n",
       " 'seaborn-bright',\n",
       " 'seaborn-deep',\n",
       " 'tableau-colorblind10',\n",
       " 'seaborn-talk',\n",
       " 'fast',\n",
       " 'seaborn-ticks',\n",
       " 'seaborn-white',\n",
       " 'bmh',\n",
       " 'fivethirtyeight',\n",
       " 'seaborn-muted',\n",
       " '_classic_test',\n",
       " 'grayscale',\n",
       " 'seaborn-darkgrid',\n",
       " 'seaborn-poster',\n",
       " 'seaborn',\n",
       " 'seaborn-whitegrid',\n",
       " 'dark_background',\n",
       " 'seaborn-paper',\n",
       " 'seaborn-colorblind',\n",
       " 'seaborn-notebook',\n",
       " 'Solarize_Light2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this experiment is to measure how the Mutual information (MI) changes related to the HSIC score of different methods when we change the data and preprocessing conditions (normalization and scale). We change the nature of the data via the scale of the data received and whether or not we do a normalization procedure before we submit the datasets to our HSIC algorithms. Each HSIC method will give us a score and we can calculate the Mutual information\n",
    "\n",
    "**Free Params**\n",
    "\n",
    "* Number of Trials (`seed`)\n",
    "    * 1:10\n",
    "* Scale or not scaled (`scale`)\n",
    "* Normalized | Not Normalized (`normalize`)\n",
    "* HSIC Algorithm (`method`)\n",
    "    * HSIC, KA, cKA\n",
    "* Dataset (`dataset`)\n",
    "    * Linear, Sinusoidal, Circle, Random\n",
    "* Amount of Noise (`noise` List)\n",
    "    * log space \n",
    "\n",
    "**Measurements**\n",
    "\n",
    "* Mutual Information (`mi`)\n",
    "* HSIC score (`score`)\n",
    "* Time for execution (`time`)\n",
    "\n",
    "**Fixed Parameters**\n",
    "\n",
    "* Number of points (`num_points`)\n",
    "* Noise for X points (`noise_x`)\n",
    "* Noise for Y points (`noise_y`)\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01      , 0.01668101, 0.02782559, 0.04641589, 0.07742637,\n",
       "       0.12915497, 0.21544347, 0.35938137, 0.59948425, 1.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-2, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataParams:\n",
    "    dataset = 'line'\n",
    "    num_points = 500\n",
    "    noise_y = 0.1\n",
    "    alpha = 1.0\n",
    "    beta = 1.0\n",
    "\n",
    "class ExpParams:\n",
    "    dataset = ['line', 'sine', 'circ', 'rand']\n",
    "    seed = np.linspace(1,10,10)\n",
    "    scale = np.logspace(-2, 2, 10)\n",
    "    normalized = [True, False]\n",
    "    noise = np.logspace(-3, 1, 10)\n",
    "    method = ['hsic', 'tka', 'ctka']\n",
    "    gamma_method = [\n",
    "        ('median', 0.2, None),\n",
    "        ('median', 0.4, None),\n",
    "        ('median', 0.5, None),\n",
    "        ('median', 0.6, None),\n",
    "        ('median', 0.8, None),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Type, Optional\n",
    "\n",
    "def get_gamma_name(gamma_method: Tuple[str,str,str])-> str:\n",
    "    if gamma_method[1] is None and gamma_method[2] is None:\n",
    "        gamma_name = gamma_method[0]\n",
    "    elif gamma_method[1] is not None and gamma_method[2] is None:\n",
    "        gamma_name = f\"{gamma_method[0]}_p{gamma_method[1]}\"\n",
    "    elif gamma_method[1] is None and gamma_method[2] is not None:\n",
    "        gamma_name = f\"{gamma_method[0]}_s{gamma_method[2]}\"\n",
    "    elif gamma_method[1] is not None and gamma_method[2] is not None:\n",
    "        gamma_name = f\"{gamma_method[0]}_s{gamma_method[1]}_s{gamma_method[2]}\"\n",
    "    else:\n",
    "        raise ValueError('Unrecognized Combination...')\n",
    "    return gamma_name\n",
    "\n",
    "def plot_data(X: np.ndarray, Y: np.ndarray):\n",
    "    fig, ax = plt.subplots(nrows=1, figsize=(7, 5))\n",
    "\n",
    "    ax.scatter(X, Y, color='red')\n",
    "    # plt.legend(fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleExperiment:\n",
    "    def __init__(self, data_params, exp_params):\n",
    "        self.data_params = data_params\n",
    "        self.exp_params = exp_params\n",
    "        \n",
    "    def _get_data(self, dataset: str, noise: float, seed: int)-> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Gathers the raw dependence data\"\"\"\n",
    "        # get dataset\n",
    "        X, Y = generate_dependence_data(\n",
    "            dataset=dataset,\n",
    "            num_points=10_000, #self.data_params.num_points,\n",
    "            seed=seed,\n",
    "            noise_x=noise,\n",
    "            noise_y=noise,\n",
    "            alpha=self.data_params.alpha,\n",
    "            beta=self.data_params.beta\n",
    "        )\n",
    "        return X, Y\n",
    "    \n",
    "    def _apply_noise(self, X: np.ndarray, Y: np.ndarray, noise: float, seed: int)-> Tuple[np.ndarray, np.ndarray]:\n",
    "        \n",
    "        rng = check_random_state(seed)\n",
    "        \n",
    "        X += rng.randn(X.shape[0], X.shape[1])\n",
    "#         Y += rng.randn(Y.shape)\n",
    "        \n",
    "        \n",
    "        return X, Y\n",
    "    def _apply_scaling(self, X: np.ndarray, scale: float)-> np.ndarray:\n",
    "        \"\"\"The scaling step in our experiment\"\"\"\n",
    "        # apply scaling\n",
    "        return scale * X\n",
    "    \n",
    "    def _apply_normalization(self, X: np.ndarray, Y: np.ndarray, normalize: bool)-> np.ndarray:\n",
    "        \"\"\"The normalization step in our experiment.\"\"\"\n",
    "        # apply normalization\n",
    "        if normalize == True:\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "#             Y = StandardScaler().fit_transform(Y)\n",
    "        elif normalize == False:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized boolean value for normalize {normalize}')\n",
    "        return X, Y\n",
    "    \n",
    "    def _apply_mi_estimate(self, X: np.ndarray, Y: np.ndarray)-> float:\n",
    "        \"\"\"Apply Mutual Information estimator. \n",
    "        We choose to use RBIG as our estimator.\"\"\"\n",
    "        # estimate mutual information\n",
    "        mi, _ = run_rbig_models(X, Y, measure='mi', verbose=None)\n",
    "        \n",
    "        return mi\n",
    "    \n",
    "    def _apply_hsic_estimate(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        Y: np.ndarray, \n",
    "        method: str, \n",
    "        gamma_init: Tuple[str, Optional[float], Optional[float]])-> float:\n",
    "        \"\"\"Apply HSIC estimator using one of the 3 algorithms:\n",
    "        * HSIC\n",
    "        * KA\n",
    "        * cKA\n",
    "        \"\"\"\n",
    "        # initialize the gamma parameter\n",
    "        gamma_init = get_gamma_init(X, Y, gamma_init[0], gamma_init[1], gamma_init[2])\n",
    "        \n",
    "        # get hsic_value\n",
    "        hsic_value = get_hsic(X, Y, method, gamma_init, maximum=False)\n",
    "        \n",
    "        return hsic_value\n",
    "    \n",
    "    def _experiment_step(\n",
    "        self,\n",
    "        results_df: pd.DataFrame,\n",
    "        dataset: str,\n",
    "        noise: float, seed: int,\n",
    "        scale: float,\n",
    "        normalize: bool,\n",
    "        method: str,\n",
    "        gamma_init: Tuple[str, Optional[float], Optional[float]]\n",
    "    )-> pd.DataFrame:\n",
    "        \n",
    "        # Step I - Extract Data\n",
    "        X, Y = self._get_data(dataset=dataset, noise=noise, seed=seed)\n",
    "        \n",
    "#         # Step I.1 - Apply Noise\n",
    "#         X, Y = self._apply_noise(X=X, Y=Y, noise=noise, seed=seed)\n",
    "        \n",
    "        # Step II - Apply Scaling\n",
    "        X = self._apply_scaling(X=X, scale=scale)\n",
    "\n",
    "        # Step III - Apply Normalization\n",
    "        X, Y = self._apply_normalization(X=X, Y=Y, normalize=normalize)\n",
    "\n",
    "        # Step IV - Estimate mutual information\n",
    "        mi = self._apply_mi_estimate(X, Y)\n",
    "\n",
    "        # Step IV - Estimate HSIC value\n",
    "        hsic_value = self._apply_hsic_estimate(X, Y, method, gamma_init)\n",
    "        \n",
    "        # Step V - Save Results to dataframe\n",
    "        results_df = results_df.append({\n",
    "            'normalized': normalize,\n",
    "            'trial': seed,\n",
    "            'dataset': dataset,\n",
    "            'scale': scale,\n",
    "            'scorer': method,\n",
    "            'gamma_method': get_gamma_name(gamma_init),\n",
    "            'hsic_value': hsic_value,\n",
    "            \"mi\": mi,\n",
    "            \"noise\": noise,\n",
    "        }, ignore_index=True)\n",
    "        return results_df\n",
    "    \n",
    "    def run_experiment(self):\n",
    "        \n",
    "        \n",
    "        results_df = pd.DataFrame()\n",
    "#         print(self.exp_params.seed)\n",
    "        \n",
    "        # Loop Through Free Parameters\n",
    "        for iseed in self.exp_params.seed:\n",
    "#             print(iseed)\n",
    "            for idataset in self.exp_params.dataset:\n",
    "                for inoise in self.exp_params.noise: \n",
    "                    for iscale in self.exp_params.scale:\n",
    "                        for inormalize in self.exp_params.normalized:\n",
    "                            for igamma in self.exp_params.gamma_method:\n",
    "                                for imethod in self.exp_params.method:\n",
    "                                    results_df = self._experiment_step(\n",
    "                                        results_df=results_df,\n",
    "                                        dataset=idataset,\n",
    "                                        noise=inoise, \n",
    "                                        seed=iseed,\n",
    "                                        scale=iscale,\n",
    "                                        normalize=inormalize,\n",
    "                                        method=imethod,\n",
    "                                        gamma_init=igamma\n",
    "                                    )\n",
    "        return results_df\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Run - Full Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI (RBIG): 1.8373\n",
      "HSIC score (ctka): 0.0749\n"
     ]
    }
   ],
   "source": [
    "# Initialize Experiment class\n",
    "exp_class = ScaleExperiment(DataParams, ExpParams, )\n",
    "\n",
    "# ========================================\n",
    "# Step I - Extract data\n",
    "# ========================================\n",
    "dataset = 'circ'\n",
    "noise = 0.000\n",
    "seed = 1\n",
    "\n",
    "X, Y = exp_class._get_data(dataset=dataset, noise=noise, seed=seed)\n",
    "\n",
    "# plot_data(X,Y)\n",
    "# ========================================\n",
    "# Step II - Apply Scaling\n",
    "# ========================================\n",
    "scale = 1.\n",
    "\n",
    "X = exp_class._apply_scaling(X=X, scale=scale)\n",
    "# plot_data(X,Y)\n",
    "\n",
    "# ========================================\n",
    "# Step III - Apply Normalization\n",
    "# ========================================\n",
    "normalize = False\n",
    "\n",
    "X, Y = exp_class._apply_normalization(X=X, Y=Y, normalize=normalize)\n",
    "\n",
    "# plot_data(X,Y)\n",
    "\n",
    "# ========================================\n",
    "# Step IV - Estimate mutual information\n",
    "# ========================================\n",
    "mi = exp_class._apply_mi_estimate(X, Y)\n",
    "\n",
    "print(f'MI (RBIG): {mi:.4f}')\n",
    "\n",
    "# ========================================\n",
    "# Step V - Estimate HSIC value\n",
    "# ========================================\n",
    "method = 'ctka'\n",
    "gamma_init = ('median', 0.5, None)\n",
    "\n",
    "hsic_value = exp_class._apply_hsic_estimate(X, Y, method, gamma_init)\n",
    "\n",
    "print(f'HSIC score ({method}): {hsic_value:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Run - Experimental Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_experiment_step() missing 1 required positional argument: 'results_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bada97fe429c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgamma_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: _experiment_step() missing 1 required positional argument: 'results_df'"
     ]
    }
   ],
   "source": [
    "# Initialize Experiment class\n",
    "exp_class = ScaleExperiment(DataParams, ExpParams, )\n",
    "\n",
    "\n",
    "results_df = exp_class._experiment_step(\n",
    "    dataset=dataset, noise=noise, seed=seed,\n",
    "    scale=scale,\n",
    "    normalize=normalize,\n",
    "    method=method,\n",
    "    gamma_init=gamma_init\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Run - Full Experiment Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataParams:\n",
    "    dataset = 'line'\n",
    "    num_points = 1_000\n",
    "    noise_y = 0.00\n",
    "    alpha = 1.0\n",
    "    beta = 1.0\n",
    "\n",
    "class ExpParams:\n",
    "    dataset = ['line', 'sine', 'circ', 'rand']\n",
    "    seed = np.linspace(1,10,10, dtype=int)\n",
    "    scale = np.logspace(-2, 2, 10)\n",
    "    normalized = [True, False]\n",
    "    noise = [0.01]\n",
    "    method = ['hsic', 'tka', 'ctka']\n",
    "    gamma_method = [\n",
    "        ('median', 0.5, None),\n",
    "    ]\n",
    "\n",
    "# Initialize Experiment class\n",
    "exp_class = ScaleExperiment(DataParams, ExpParams, )\n",
    "\n",
    "results_df = exp_class.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-it4dnn]",
   "language": "python",
   "name": "conda-env-.conda-it4dnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
