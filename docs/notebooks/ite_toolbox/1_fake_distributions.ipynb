{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Distributions\n",
    "\n",
    "In this notebook, I will walk through some of the distributions we used in order to generate some fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "cwd = os.getcwd()\n",
    "sys.path.insert(0, f'{cwd}/../../src')\n",
    "sys.path.insert(0, f'{cwd}/../../src/itetoolbox')\n",
    "\n",
    "import numpy as np\n",
    "import ite\n",
    "from sklearn.utils import check_random_state\n",
    "from data.toy import entropy_marginal\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Distribution\n",
    "\n",
    "$$x \\sim \\mathcal{U}(a, b)$$\n",
    "\n",
    "where $a,b$ are the support for the distribution.\n",
    "\n",
    "We can measure the entropy as:\n",
    "\n",
    "$$H(x) = \\ln(b-a)$$\n",
    "\n",
    "Additionally, if we want to measure the entropy of $x$ that is generated by some random transformation $A$ then we have:\n",
    "\n",
    "\n",
    "$$H(Ax) = \\ln(b-a)+ \\ln \\left| A \\right|$$\n",
    "\n",
    "where $|\\cdot|$ is the determinant operator.\n",
    "\n",
    "**Multivariate Uniform Distribution**\n",
    "\n",
    "**Note**: I saw in the code that they do the prod of the support and then calculate the log function. Because every dimension is independent so we can perhaps just sum them. But I'm not sure about the product. ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.69314718)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = -1\n",
    "b = 1\n",
    "loc = -1\n",
    "scale = (b-a)\n",
    "uni_var = stats.uniform.rvs(loc=loc, scale=scale, size=(10, 2), random_state=123)\n",
    "\n",
    "stats.uniform.entropy(loc=a, scale=(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2571675347021572\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "d_dimensions = 2\n",
    "\n",
    "support_a = -np.random.rand(1, d_dimensions)\n",
    "support_b = np.random.rand(1, d_dimensions)\n",
    "\n",
    "# random rotation matrix\n",
    "A = np.random.rand(d_dimensions, d_dimensions)\n",
    "\n",
    "# Compute entropy of uniform dist\n",
    "H_uni = np.log(np.prod(support_b - support_a))\n",
    "\n",
    "# computer entropy of linear transformation\n",
    "H_A = np.linalg.slogdet(A)[1]\n",
    "\n",
    "print(H_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H = \\frac{1}{2} \\log\\left( 2 \\pi \\exp(1)\\right)^{D} \\left| \\Sigma \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "cov = np.array([[1, 0.9], [0.9, 1]])\n",
    "print(cov.shape)\n",
    "mu = [0.0, 0.0]\n",
    "seed = 123\n",
    "n_samples = 100,\n",
    "d_dimensions = 2\n",
    "\n",
    "norm_dist = stats.multivariate_normal(mean=mu, cov=cov, seed=seed)\n",
    "\n",
    "# norm_dist.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.stats._multivariate.multivariate_normal_frozen at 0x7f5d3b091a58>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirichlet Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parameter vector 'a' must be one dimensional, but a.shape = ().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-67b2f0e5f6c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdiri_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirichlet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/it4dnn/lib/python3.6/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, alpha, size, random_state)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m         \"\"\"\n\u001b[0;32m-> 1559\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dirichlet_check_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1560\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirichlet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/it4dnn/lib/python3.6/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36m_dirichlet_check_parameters\u001b[0;34m(alpha)\u001b[0m\n\u001b[1;32m   1230\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         raise ValueError(\"Parameter vector 'a' must be one dimensional, \"\n\u001b[0;32m-> 1232\u001b[0;31m                          \"but a.shape = %s.\" % (alpha.shape, ))\n\u001b[0m\u001b[1;32m   1233\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parameter vector 'a' must be one dimensional, but a.shape = ()."
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "seed = 123\n",
    "\n",
    "diri_dist = stats.dirichlet.rvs(alpha=alpha, size=(3,1), random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Student Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution\n",
    "\n",
    "\n",
    "**Multivariate**\n",
    "\n",
    "$$\\frac{\\Gamma \\left[ \\frac{(\\nu + p)}{2} \\right]}\n",
    "{\\Gamma \\left(\\frac{\\nu}{2} \\right)\\nu^{\\frac{p}{2}} \\pi^{\\frac{p}{2}} \\left|\\Sigma \\right|^{\\frac{1}{2}}} \n",
    "\\left[  1 + \\frac{1}{\\nu} (x - \\mu)^\\top \\Sigma^{-1}(x - \\mu)\n",
    "\\right]^{- \\frac{(\\nu + p}{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "**Entropy**\n",
    "\n",
    "The differential entropy of the multivariate student-t distribution when the covariance matrix is the identity.\n",
    "\n",
    "$$h = \n",
    "- \\log \\frac{\\Gamma \\left( \\frac{\\nu + d}{2} \\right)}{\\Gamma \\left( \\frac{\\nu}{2} \\right)(\\nu \\pi)^{d/2}} +\n",
    "\\left( \\frac{\\nu + d}{2} \\right)\n",
    "\\left( \\Psi \\left(\\frac{\\nu + d}{2} \\right) \n",
    "- \\Psi\\left( \\frac{\\nu}{2} \\right)\\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $\\Psi$ is the digamma function\n",
    "* $\\Gamma$ is the gamma function\n",
    "\n",
    "If we have the case where we have a covariance matrix $\\Sigma$, we can use the relationship:\n",
    "\n",
    "$$y = \\mu + Lx$$\n",
    "\n",
    "where: \n",
    "* $x$ is the standard Student-t random vector\n",
    "* $\\mu$ is the mean\n",
    "* $\\Sigma=LL^\\top$ is the covariance matrix\n",
    "\n",
    "We know the properties of differential entropy yields the following equation:\n",
    "\n",
    "$$h(Ax) = h(x) + \\log |A|$$\n",
    "\n",
    "So we can rewrite the Student-t distribution with a mean $\\mu$ and a covariance matrix $\\Sigma$ as the additive product of the original distribution with a covariance $I$ and the change of variables:\n",
    "\n",
    "$$h(x) = h_{\\Sigma=I} + \\frac{1}{2} \\log |\\Sigma|$$\n",
    "\n",
    "**Source**\n",
    "\n",
    "* [StackOverFlow](https://math.stackexchange.com/questions/2272184/differential-entropy-of-the-multivariate-student-t-distribution)\n",
    "* [Wiki](https://en.wikipedia.org/wiki/Student%27s_t-distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Class Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistData:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_samples: int=1000,\n",
    "        d_dimensions: int=3,\n",
    "        distribution: str=\"gauss\",\n",
    "        mu: float=0.0,\n",
    "        sigma: float=1.0,\n",
    "        weight: float=2.0,\n",
    "        bias: float=0.5,\n",
    "        nu: float=1.0,\n",
    "        gauss_state: int=123,\n",
    "        dim_state: int=111,\n",
    "        trans_state: int=123,\n",
    "    )-> None:\n",
    "        self.n_samples = n_samples\n",
    "        self.d_dimensions = d_dimensions\n",
    "        self.distribution = distribution\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "        self.nu = nu\n",
    "        self.gauss = check_random_state(gauss_state)\n",
    "        self.dim_state = check_random_state(dim_state)\n",
    "        self.trans_state = check_random_state(trans_state)\n",
    "\n",
    "    def data(self):\n",
    "\n",
    "        if self.distribution == \"gauss\":\n",
    "\n",
    "            # generate data Gaussian data\n",
    "            self.samples = self.mu + self.sigma * self.gauss.randn(self.n_samples, self.d_dimensions)\n",
    "            \n",
    "            # random rotation (uniformly distributed)\n",
    "            self.A = self.trans_state.rand(self.d_dimensions, self.d_dimensions)\n",
    "            \n",
    "            # output data\n",
    "            self.X = self.samples @ self.A\n",
    "        \n",
    "        elif self.distribution == 'linear':\n",
    "            \n",
    "            # generate data from normal dist\n",
    "            self.samples= self.mu + self.sigma * self.gauss.randn(self.n_samples, self.d_dimensions)\n",
    "            \n",
    "            # random rotation (uniformly distributed)\n",
    "            d_rot = self.dim_state.randn(1, self.d_dimensions)\n",
    "            \n",
    "            # linear transformation on all dimensions\n",
    "            for idim in range(self.d_dimensions):\n",
    "                exponent = self.weight * d_rot[:, idim] + self.bias\n",
    "                self.samples[:, idim] = np.sign(self.samples[:, idim]) * np.abs(self.samples[:, idim])**exponent\n",
    "            \n",
    "            # random rotation (uniformly distributed)\n",
    "            self.A = self.trans_state.rand(self.d_dimensions, self.d_dimensions)\n",
    "            self.X = self.samples @ self.A\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized distribution...\")\n",
    "\n",
    "        return self.X\n",
    "    \n",
    "    def entropy(self):\n",
    "        \n",
    "        if self.distribution == \"gauss\":\n",
    "            \n",
    "            # calculate entropy\n",
    "            return entropy_marginal(self.X).sum() + np.linalg.slogdet(self.A)[1]\n",
    "        \n",
    "        if self.distribution == \"linear\":\n",
    "            \n",
    "            # calculate entropy\n",
    "            return entropy_marginal(self.X).sum() + np.linalg.slogdet(self.A)[1]\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized distribution...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution I - Rotated Gaussian Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 518.0578\n"
     ]
    }
   ],
   "source": [
    "random_state = 123\n",
    "mu = 0.0\n",
    "sigma = 1.0\n",
    "n_samples = 10000\n",
    "d_dimensions = 100\n",
    "distribution = 'gauss'\n",
    "\n",
    "# initialize class\n",
    "clf_datadist = DistData(\n",
    "    n_samples=n_samples,\n",
    "    mu = mu,\n",
    "    sigma = sigma,\n",
    "    d_dimensions=d_dimensions\n",
    "    \n",
    ")\n",
    "\n",
    "# generate samples\n",
    "X = clf_datadist.data()\n",
    "\n",
    "# calculate entropy\n",
    "H_x = clf_datadist.entropy()\n",
    "\n",
    "print(f\"Entropy: {H_x:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution II - Rotated Linear Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 4602.8497\n"
     ]
    }
   ],
   "source": [
    "random_state = 123\n",
    "mu = 0.0\n",
    "sigma = 1.0\n",
    "n_samples = 10000\n",
    "d_dimensions = 100\n",
    "distribution = 'linear'\n",
    "\n",
    "# initialize class\n",
    "clf_datadist = DistData(\n",
    "    n_samples=n_samples,\n",
    "    mu = mu,\n",
    "    sigma = sigma,\n",
    "    d_dimensions=d_dimensions,\n",
    "    distribution=distribution\n",
    "    \n",
    ")\n",
    "\n",
    "# generate samples\n",
    "X = clf_datadist.data()\n",
    "\n",
    "# calculate entropy\n",
    "H_x = clf_datadist.entropy()\n",
    "\n",
    "print(f\"Entropy: {H_x:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-it4dnn]",
   "language": "python",
   "name": "conda-env-.conda-it4dnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
