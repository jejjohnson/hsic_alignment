{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough - Gamma n Mutual Infor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Insert path to model directory,.\n",
    "cwd = os.getcwd()\n",
    "path = f\"{cwd}/../../src\"\n",
    "sys.path.insert(0, path)\n",
    "\n",
    "# Insert path to package,.\n",
    "pysim_path = f\"/home/emmanuel/code/pysim/\"\n",
    "sys.path.insert(0, pysim_path)\n",
    "\n",
    "import warnings\n",
    "from typing import Optional, Tuple\n",
    "import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "# toy datasets\n",
    "from data.distribution import DataParams, Inputs\n",
    "\n",
    "# Kernel Dependency measure\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from models.dependence import HSICModel\n",
    "from pysim.kernel.utils import estimate_sigma\n",
    "\n",
    "# RBIG IT measures\n",
    "# from models.ite_algorithms import run_rbig_models\n",
    "\n",
    "# Plotting\n",
    "from visualization.distribution import plot_scorer\n",
    "\n",
    "# experiment helpers\n",
    "from experiments.utils import dict_product, run_parallel_step\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting Procedures\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(['seaborn-talk'])\n",
    "warnings.filterwarnings('ignore') # get rid of annoying warnings\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore') # get rid of annoying warnings\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/projects/2019_hsic_align/notebooks/4_distributions\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/mutual_info/\"\n",
    "RES_PATH = \"/home/emmanuel/projects/2019_hsic_align/data/results/distributions/mutual_info/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the holder for the parameters\n",
    "parameters = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case I - HSIC Estimator\n",
    "\n",
    "In this first part, we have 3 cases of HSIC as a combination of a centered kernel and whether or not we normalize the covariance term. The 3 \"scorers\" are as follows:\n",
    "\n",
    "\n",
    "1. **HSIC**\n",
    "\n",
    "$$HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F$$\n",
    "\n",
    "> In this case, the kernels are **centered**, but the score is **not normalized**.\n",
    "\n",
    "\n",
    "2. **Kernel Alignment** (KA) \n",
    "\n",
    "$$TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F}$$\n",
    "\n",
    "> In this case, the kernels are **not centered** but the score is **normalized**.\n",
    "\n",
    "3. **cTKA**\n",
    "\n",
    "$$cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F}$$\n",
    "\n",
    "> In this case, the kernels are **centered** and the score is **normalized**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hsic(\n",
    "    X: np.ndarray, \n",
    "    Y: np.ndarray, \n",
    "    scorer: str, \n",
    "    sigma_X: Optional[float]=None, \n",
    "    sigma_Y: Optional[float]=None\n",
    ") -> float:\n",
    "    \"\"\"Estimates the HSIC value given some data, sigma and\n",
    "    the score.\"\"\"\n",
    "    # init hsic model class\n",
    "    \n",
    "    hsic_model = HSICModel()\n",
    "    # hsic model params\n",
    "    if sigma_X is not None:\n",
    "        \n",
    "        hsic_model.kernel_X = RBF(sigma_X)\n",
    "        hsic_model.kernel_Y = RBF(sigma_Y)\n",
    "\n",
    "    # get hsic score\n",
    "    hsic_val = hsic_model.get_score(X, Y, scorer)\n",
    "    \n",
    "    return hsic_val\n",
    "\n",
    "# parameters\n",
    "parameters['scorer'] = ['hsic', 'ka', 'cka'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case II - Sigma Estimator\n",
    "\n",
    "For this parameter, we are interested in estimating a few things:\n",
    "\n",
    "1. We want to know which estimator to choose from.\n",
    "\n",
    "Kernel methods are great if the parameters of the kernel are correct. In supervised scenarios, we can simply learn the appropriate kernel parameters that best fit our data given some criteria. In unsupervised settings, we generally do not know which parameters to choose from. But there are many different ways to choose the parameters as every lab/researcher has their own method that \"they swear by\". I will choose some of the most common ones: \n",
    "\n",
    "* Silverman\n",
    "* Scott\n",
    "* Mean Distance\n",
    "* Median Distance\n",
    "* Median Distance with the $k^{th}$ sample (or percent) of that distance matrix.\n",
    "\n",
    "#### Case III - Sigma Application\n",
    "\n",
    "2. We want to know the how we are applying the length scale.\n",
    "\n",
    "We have three cases to consider:\n",
    "\n",
    "* One length scale for both datasets\n",
    "* One length scale per dataset\n",
    "* One length scale per dataset per dimension\n",
    "\n",
    "This is important as it could turn a good estimator into a bad estimator. Scott and Silverman work very well for univariate distributions but not very well for multivariate distributions. So if we have one scott/silverman estimate per feature, then this estimator might be a lot better and yield much better results. For the case of the RBF kernel, having one length scale per dimension corresponds to the ARD Kernel which assigns a length scale (or relevance values) per feature. We don't typically use the ARD kernel for kernel methods that we cannot optimize using some gradient function due to how expensive it is. But in this case, it isn't so expensive because we are choosing not to optimizing anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigma(\n",
    "    X: np.ndarray, \n",
    "    Y: np.ndarray, \n",
    "    method: str='silverman', \n",
    "    percent: Optional[float]=None,\n",
    "    per_dimension: bool=False, \n",
    "    separate_scales: bool=False\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # sigma parameters\n",
    "    subsample = None\n",
    "    random_state = 123\n",
    "    \n",
    "    sigma_X = estimate_sigma(\n",
    "        X, \n",
    "        subsample=subsample,\n",
    "        method=method,\n",
    "        percent=percent,\n",
    "        random_state=random_state,\n",
    "        per_dimension=per_dimension\n",
    "    )\n",
    "    \n",
    "    sigma_Y = estimate_sigma(\n",
    "        Y, \n",
    "        subsample=subsample,\n",
    "        method=method,\n",
    "        percent=percent,\n",
    "        random_state=random_state,\n",
    "        per_dimension=per_dimension\n",
    "    )\n",
    "    \n",
    "    if separate_scales is False:\n",
    "        sigma_Y = sigma_X = np.mean([sigma_X, sigma_Y])\n",
    "    \n",
    "    return sigma_X, sigma_Y\n",
    "\n",
    "# Parameters for the estimators\n",
    "parameters['sigma_estimator'] = [\n",
    "#     ('silverman',None),\n",
    "#     ('scott', None),\n",
    "    *[('median', x) for x in np.arange(0.1, 1.0, 0.1, dtype=np.float64)]\n",
    "]\n",
    "parameters['separate_scales'] = [True, False]\n",
    "parameters['per_dimension'] = [True, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case IV - Standardize or not Standardize\n",
    "\n",
    "This is a simple case but it can have drastic changes in the results of estimating the length scale. In ML, we tend to standardize our datasets because the algorithms do better with predictions with the ranges are contained. Datasets with massive values for certain features could have adverse affects on the representation and the predictions. The formula is given by:\n",
    "\n",
    "$$\\bar{x} = \\frac{x - \\mu_x}{\\sigma_x}$$\n",
    "\n",
    "**Note**: this is scaling per feature and not per sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('median', 0.1),\n",
       " ('median', 0.2),\n",
       " ('median', 0.30000000000000004),\n",
       " ('median', 0.4),\n",
       " ('median', 0.5),\n",
       " ('median', 0.6),\n",
       " ('median', 0.7000000000000001),\n",
       " ('median', 0.8),\n",
       " ('median', 0.9)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[('median', i) for i in np.arange(0.1, 1.0, 0.1, dtype=np.float64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Tuple, Optional\n",
    "\n",
    "def standardize_data(\n",
    "    X: np.ndarray, \n",
    "    Y: np.ndarray, \n",
    "    standardize: bool=False\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    Y = StandardScaler().fit_transform(Y)\n",
    "    return X, Y\n",
    "\n",
    "# experimental parameters\n",
    "parameters['standardize'] = [True, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case V - Multivariate Datasets\n",
    "\n",
    "For this experiment, we have generated samples for two sets of multivariate distributions: the Gaussian and the T-Student. We have varied the parameters so that we get a variety of samples, dimensions and the amount of similarity (that we can analytically calculate) between them. \n",
    "\n",
    "For example, we can take a Gaussian distribution with a covariance and generate a similar Gaussian distribution with the same number of samples and variance with a covariance. We know the cross-covariance between them and the self-covariances, so we can analytically calculate the mutual information between the two. MI is absolute which is the dependence or similarity between the two datasets. Now, we will see how the HSIC scores will do versus this variation of dataset size and shape. \n",
    "\n",
    "We have the following parameters:\n",
    "\n",
    "* Samples - [500, 1K, 5K, 10K, 30K, 50K]\n",
    "* Dimensions - [ 2, 3, 10, 50, 100]\n",
    "* trials - `1:5`\n",
    "* IT measures - Mutual Information\n",
    "* Distributions - [Gaussian, T-Student]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example parameters for the dataset\n",
    "data_params = {}\n",
    "data_params['dataset'] = ['gauss'] \n",
    "data_params['std'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] \n",
    "data_params['nu'] = [1]\n",
    "data_params['trial'] = [1, 2, 3, 4, 5]\n",
    "data_params['samples'] = [50, 100, 500, 1_000, 5_000]\n",
    "data_params['dimensions'] = [2, 3, 10, 50, 100]\n",
    "\n",
    "# example parameters function\n",
    "example_params = DataParams()\n",
    "\n",
    "# generates a named tuple containing the inputs and the MI \n",
    "inputs = example_params.generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "We have a lot of parameters. So we are going to run everything in parallel so that we can save time. We will do this by giving the cartesian product of our nD list of parameters. This will give us a list of tuples where each entry is a set of parameters to evaluate. The length of this list will be the total number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Params: 216 1375\n"
     ]
    }
   ],
   "source": [
    "# create a list of all param combinations\n",
    "parameters_list = list(dict_product(parameters))\n",
    "data_params_list = list(dict_product(data_params))\n",
    "n_params, n_data_params = len(parameters_list), len(data_params_list)\n",
    "print('# of Params:', n_params, n_data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Params: 216\n"
     ]
    }
   ],
   "source": [
    "# create a list of all param combinations\n",
    "parameters_list = list(dict_product(parameters))\n",
    "n_params = len(parameters_list)\n",
    "print('# of Params:', n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict \n",
    "\n",
    "def step(params: Dict, data_params: Dict, inputs):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ====================\n",
    "        # Sigma Estimator\n",
    "        # ====================\n",
    "\n",
    "        # estimate sigma\n",
    "        sigma_X, sigma_Y = get_sigma(\n",
    "            X=inputs.X, Y=inputs.Y, \n",
    "            method=params['sigma_estimator'][0], \n",
    "            percent=params['sigma_estimator'][1], \n",
    "            per_dimension=params['per_dimension'],\n",
    "            separate_scales=params['separate_scales']\n",
    "        )\n",
    "        \n",
    "        # ====================\n",
    "        # HSIC Model\n",
    "        # ====================\n",
    "        # get hsic score\n",
    "        score = get_hsic(\n",
    "            inputs.X, inputs.Y, \n",
    "            params['scorer'], \n",
    "            sigma_X, sigma_Y\n",
    "        )\n",
    "        \n",
    "        # ====================\n",
    "        # Results\n",
    "        # ====================\n",
    "\n",
    "        # append results to dataframe\n",
    "        results_df = pd.DataFrame({\n",
    "            # Data Params\n",
    "            'dataset': [data_params['dataset']],\n",
    "            'trial': [data_params['trial']],\n",
    "            'std': [data_params['std']],\n",
    "            'nu': [data_params['nu']],\n",
    "            'samples' : [data_params['samples']],\n",
    "            'dimensions' : [data_params['dimensions']],\n",
    "            # Standardize params\n",
    "            'standardize': [params['standardize']],\n",
    "            # Sigma type params\n",
    "            'per_dimension': [params['per_dimension']],\n",
    "            'separate_scales': [params['separate_scales']],\n",
    "            # Gamma Params\n",
    "            'sigma_method': [params['sigma_estimator'][0]],\n",
    "            'sigma_percent': [params['sigma_estimator'][1]],\n",
    "            'sigma_X': [sigma_X],\n",
    "            'sigma_Y': [sigma_Y],\n",
    "            # HSIC Params\n",
    "            'scorer': [params['scorer']],\n",
    "            'score': [score],\n",
    "            'mutual_info': [inputs.mutual_info]\n",
    "        })\n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'gauss', 'std': 1, 'nu': 1, 'trial': 1, 'samples': 50, 'dimensions': 2}\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "\n",
    "for iparam in data_params_list:\n",
    "    print(iparam)\n",
    "\n",
    "    # ================\n",
    "    # DATA\n",
    "    # ================    \n",
    "    dist_data = DataParams(\n",
    "        dataset=iparam['dataset'],\n",
    "        trial = iparam['trial'],\n",
    "        std = iparam['std'],\n",
    "        nu = iparam['nu'],\n",
    "        samples = iparam['samples'],\n",
    "        dimensions = iparam['dimensions'],\n",
    "    )\n",
    "    \n",
    "    # generate data\n",
    "    inputs = dist_data.generate_data()\n",
    "    \n",
    "    # step through function\n",
    "\n",
    "\n",
    "    step_df = step(parameters_list[0], iparam, inputs)\n",
    "    results_df = pd.concat([results_df, step_df])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>trial</th>\n",
       "      <th>std</th>\n",
       "      <th>nu</th>\n",
       "      <th>samples</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>standardize</th>\n",
       "      <th>per_dimension</th>\n",
       "      <th>separate_scales</th>\n",
       "      <th>sigma_method</th>\n",
       "      <th>sigma_percent</th>\n",
       "      <th>sigma_X</th>\n",
       "      <th>sigma_Y</th>\n",
       "      <th>scorer</th>\n",
       "      <th>score</th>\n",
       "      <th>mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gauss</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>median</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.1686566316684468, 0.14612229488391992]</td>\n",
       "      <td>[0.1589719949193001, 0.1680410083908699]</td>\n",
       "      <td>hsic</td>\n",
       "      <td>0.019091</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  trial  std  nu  samples  dimensions  standardize  per_dimension  \\\n",
       "0   gauss      1    1   1       50           2         True           True   \n",
       "\n",
       "   separate_scales sigma_method  sigma_percent  \\\n",
       "0             True       median            0.1   \n",
       "\n",
       "                                     sigma_X  \\\n",
       "0  [0.1686566316684468, 0.14612229488391992]   \n",
       "\n",
       "                                    sigma_Y scorer     score  mutual_info  \n",
       "0  [0.1589719949193001, 0.1680410083908699]   hsic  0.019091          0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 23/1375 [14:15<64:21:20, 171.36s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f090242f5241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# step through function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     step_df = run_parallel_step(\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mexp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/utils.py\u001b[0m in \u001b[0;36mrun_parallel_step\u001b[0;34m(exp_step, parameters, n_jobs, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# loop through parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     results = Parallel(n_jobs=n_jobs, verbose=verbose)(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     )\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "verbose = 0\n",
    "n_jobs = 16\n",
    "\n",
    "results_df = pd.DataFrame({})\n",
    "\n",
    "\n",
    "for iparam in tqdm(data_params_list, total=len(data_params_list)):\n",
    "#     print(iparam)\n",
    "\n",
    "    # ================\n",
    "    # DATA\n",
    "    # ================    \n",
    "    dist_data = DataParams(\n",
    "        dataset=iparam['dataset'],\n",
    "        trial = iparam['trial'],\n",
    "        std = iparam['std'],\n",
    "        nu = iparam['nu'],\n",
    "        samples = iparam['samples'],\n",
    "        dimensions = iparam['dimensions'],\n",
    "    )\n",
    "    \n",
    "    # generate data\n",
    "    inputs = dist_data.generate_data()\n",
    "    \n",
    "    # step through function\n",
    "\n",
    "    step_df = run_parallel_step(\n",
    "        exp_step=step, \n",
    "        parameters=parameters_list,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=verbose,\n",
    "        data_params=iparam,\n",
    "        inputs=inputs\n",
    "    )\n",
    "    results_df = pd.concat([results_df, pd.concat(step_df, ignore_index=True)])\n",
    "#     res_test_df\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>trial</th>\n",
       "      <th>std</th>\n",
       "      <th>nu</th>\n",
       "      <th>samples</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>standardize</th>\n",
       "      <th>per_dimension</th>\n",
       "      <th>separate_scales</th>\n",
       "      <th>sigma_method</th>\n",
       "      <th>sigma_percent</th>\n",
       "      <th>sigma_X</th>\n",
       "      <th>sigma_Y</th>\n",
       "      <th>scorer</th>\n",
       "      <th>score</th>\n",
       "      <th>mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>gauss</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>median</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.88461</td>\n",
       "      <td>2.80248</td>\n",
       "      <td>cka</td>\n",
       "      <td>0.044423</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>gauss</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>median</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.99481</td>\n",
       "      <td>1.99481</td>\n",
       "      <td>cka</td>\n",
       "      <td>0.064728</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>gauss</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>median</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.99481</td>\n",
       "      <td>1.99481</td>\n",
       "      <td>cka</td>\n",
       "      <td>0.064728</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>gauss</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>median</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.84355</td>\n",
       "      <td>2.84355</td>\n",
       "      <td>cka</td>\n",
       "      <td>0.044155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>gauss</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>median</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.84355</td>\n",
       "      <td>2.84355</td>\n",
       "      <td>cka</td>\n",
       "      <td>0.044155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset  trial  std  nu  samples  dimensions  standardize  per_dimension  \\\n",
       "211   gauss      1    1   1       50           2        False          False   \n",
       "212   gauss      1    1   1       50           2         True           True   \n",
       "213   gauss      1    1   1       50           2        False           True   \n",
       "214   gauss      1    1   1       50           2         True          False   \n",
       "215   gauss      1    1   1       50           2        False          False   \n",
       "\n",
       "     separate_scales sigma_method  sigma_percent  sigma_X  sigma_Y scorer  \\\n",
       "211             True       median            0.9  2.88461  2.80248    cka   \n",
       "212            False       median            0.9  1.99481  1.99481    cka   \n",
       "213            False       median            0.9  1.99481  1.99481    cka   \n",
       "214            False       median            0.9  2.84355  2.84355    cka   \n",
       "215            False       median            0.9  2.84355  2.84355    cka   \n",
       "\n",
       "        score  mutual_info  \n",
       "211  0.044423          0.0  \n",
       "212  0.064728          0.0  \n",
       "213  0.064728          0.0  \n",
       "214  0.044155          0.0  \n",
       "215  0.044155          0.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/emmanuel/projects/2019_hsic_align/data/results/distributions/mutual_info/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{FIG_PATH}/test.csv', 'a') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/emmanuel/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/emmanuel/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/emmanuel/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/emmanuel/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py\", line 255, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/emmanuel/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py\", line 255, in <listcomp>\n    return [func(*args, **kwargs)\nTypeError: step() missing 2 required positional arguments: 'data_params' and 'inputs'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: step() missing 2 required positional arguments: 'data_params' and 'inputs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-344f5c665a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m results = run_parallel_step(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mexp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/utils.py\u001b[0m in \u001b[0;36mrun_parallel_step\u001b[0;34m(exp_step, parameters, n_jobs, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# loop through parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     results = Parallel(n_jobs=n_jobs, verbose=verbose)(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     )\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    578\u001b[0m         \"\"\"\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                 \u001b[0mqmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0mcq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hsic_align/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "verbose = 1\n",
    "n_jobs = 16\n",
    "\n",
    "results = run_parallel_step(\n",
    "    exp_step=step, \n",
    "    parameters=parameters_list,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-hsic_align]",
   "language": "python",
   "name": "conda-env-.conda-hsic_align-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
