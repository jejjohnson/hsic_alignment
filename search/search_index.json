{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Kernel Parameter Estimation \u00b6 Motivation \u00b6 What is Similarity? Why HSIC? The differences between HSIC The Problems with high-dimensional data Research Questions \u00b6 Demo Notebook See this notebook for a full break down of each research question and why it's important and possibly difficult. 1. Which Scorer should we use? \u00b6 We are looking at different \"HSIC scorers\" because they all vary in terms of whether they center the kernel matrix or if they normalize the score via the norm of the individual kernels. Different Scorers HSIC \\text{HSIC} = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F \\text{HSIC} = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F Notice : we have the centered kernels, K_xH K_xH and no normalization. Kernel Alignment \\text{KA} = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} \\text{KA} = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} Notice : We have the uncentered kernels and a normalization factor. Centered Kernel Alignment \\text{cKA} = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} \\text{cKA} = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} Notice : We have the centered kernels and a normalization factor. 2. Which Estimator should we use? \u00b6 Example Estimators Scott \\text{scott} = N^{- \\frac{1}{D + 4}} \\text{scott} = N^{- \\frac{1}{D + 4}} Notice : This method doesn't take into account the data size. Silverman \\text{silverman} = \\left( \\frac{N * (D+2)}{4} \\right)^{- \\frac{1}{D + 4}} \\text{silverman} = \\left( \\frac{N * (D+2)}{4} \\right)^{- \\frac{1}{D + 4}} Notice : This method doesn't take into account the data size. Median/Mean Distance The heuristic is the 'mean distance between the points of the domain'. The full formula is: \\nu = \\sqrt{\\frac{H_n}{2}} \\nu = \\sqrt{\\frac{H_n}{2}} where H_n = \\text{Med}\\left\\{ ||X_{n,i} - X_{n,j}||^2 | 1 \\leq i < j \\leq n \\right\\} H_n = \\text{Med}\\left\\{ ||X_{n,i} - X_{n,j}||^2 | 1 \\leq i < j \\leq n \\right\\} and \\text{Med} \\text{Med} is the empirical median. We can also use the Mean as well. We can obtain this by: Calculating the squareform euclidean distance of all points in our dataset Order them in increasing order Set H_n H_n to be the central element if n(n-1)/2 n(n-1)/2 is odd or the mean if n(n-1)/2 n(n-1)/2 is even. Note : some authors just use \\sqrt{H_n} \\sqrt{H_n} . Median Kth Distance This is a distance measure that is new to me. It is the median/mean of the distances to the k-th k-th neighbour of the dataset. So essentially, we take the same as the median except we take the kth kth -distance for each data-point and take the median of that. Calculate the squareform of the matrix Sort the matrix in ascending order Take the kth distance Take the median or mean of this columns 3. Should we use different length scales or the same? \u00b6 Details RBF Kernel K(\\mathbf{x,y}) = \\exp\\left(-\\frac{\\left|\\left|\\mathbf{x} - \\mathbf{y}\\right|\\right|^2_2}{2\\sigma^2}\\right) K(\\mathbf{x,y}) = \\exp\\left(-\\frac{\\left|\\left|\\mathbf{x} - \\mathbf{y}\\right|\\right|^2_2}{2\\sigma^2}\\right) We can estimate 1 sigma per dataset \\sigma_X,\\sigma_Y \\sigma_X,\\sigma_Y or just 1 sigma \\sigma_{XY} \\sigma_{XY} . ARD Kernel K(\\mathbf{x,y}) = \\exp\\left(-\\frac{1}{2}\\left|\\left|\\frac{\\mathbf{x}}{\\sigma_d} - \\frac{\\mathbf{y}}{\\sigma_d}\\right|\\right|^2_2\\right) K(\\mathbf{x,y}) = \\exp\\left(-\\frac{1}{2}\\left|\\left|\\frac{\\mathbf{x}}{\\sigma_d} - \\frac{\\mathbf{y}}{\\sigma_d}\\right|\\right|^2_2\\right) We can estimate 1 sigma per dataset per dimension \\sigma_{X_d}, \\sigma_{Y_d} \\sigma_{X_d}, \\sigma_{Y_d} . 4. Should we standardize our data? \u00b6 \\bar{\\mathbf{x}} = \\frac{\\mathbf{x} - \\mu_\\mathbf{x}}{\\sigma_\\mathbf{x}} \\bar{\\mathbf{x}} = \\frac{\\mathbf{x} - \\mu_\\mathbf{x}}{\\sigma_\\mathbf{x}} 5. Summary of Parameters \u00b6 Options Standardize Yes / No Parameter Estimator Mean, Median, Silverman, etc Center Kernel Yes / No Normalized Score Yes / No Experiments \u00b6 Walk-Throughs \u00b6 This is the walk-through where I go step by step and show how I implemented everything. This is mainly for code review purposes but it also has some nuggets. 1.0 - Estimating Sigma In this notebook, I show how one can estimate sigma using different heuristics in the literature. 2.0 - Estimating HSIC I show how we can estimate HSIC using some of the main methods in the literature. 3.0 - Multivariate Distribution I show how we can apply this to large multivariate data and create a large scale parameter search 3.1 - Best Parameters This is part II where I show some preliminary results for which methods are better. 5.0 - Fitting Mutual Information I show how the centered kernel alignment best approximates the Gaussian distribution. Parameter Grid - 1D Data \u00b6 Notebook Parameter Grid - nD Data \u00b6 Demo Notebook Fitting Mutual Information Mutual Information vs HSIC scores \u00b6 Demo Notebook Fitting Mutual Information Results \u00b6 Take-Home Message I \u00b6 The median distance seems to be fairly robust in settings with different samples and dimensions. Scott and Silverman should probably avoided if you are not going to estimate the the parameter per feature. Take-Home Message II \u00b6 It appears that the centered kernel alignment (CKA) method is the most consistent when we compare the score versus the mutual information of known distributions. HSIC has some consistency but not entirely. The KA algorithm has no consistency whatsoever; avoid using this method for unsupervised problems.","title":"Overview"},{"location":"#kernel-parameter-estimation","text":"","title":"Kernel Parameter Estimation"},{"location":"#motivation","text":"What is Similarity? Why HSIC? The differences between HSIC The Problems with high-dimensional data","title":"Motivation"},{"location":"#research-questions","text":"Demo Notebook See this notebook for a full break down of each research question and why it's important and possibly difficult.","title":"Research Questions"},{"location":"#1-which-scorer-should-we-use","text":"We are looking at different \"HSIC scorers\" because they all vary in terms of whether they center the kernel matrix or if they normalize the score via the norm of the individual kernels. Different Scorers HSIC \\text{HSIC} = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F \\text{HSIC} = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F Notice : we have the centered kernels, K_xH K_xH and no normalization. Kernel Alignment \\text{KA} = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} \\text{KA} = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} Notice : We have the uncentered kernels and a normalization factor. Centered Kernel Alignment \\text{cKA} = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} \\text{cKA} = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} Notice : We have the centered kernels and a normalization factor.","title":"1. Which Scorer should we use?"},{"location":"#2-which-estimator-should-we-use","text":"Example Estimators Scott \\text{scott} = N^{- \\frac{1}{D + 4}} \\text{scott} = N^{- \\frac{1}{D + 4}} Notice : This method doesn't take into account the data size. Silverman \\text{silverman} = \\left( \\frac{N * (D+2)}{4} \\right)^{- \\frac{1}{D + 4}} \\text{silverman} = \\left( \\frac{N * (D+2)}{4} \\right)^{- \\frac{1}{D + 4}} Notice : This method doesn't take into account the data size. Median/Mean Distance The heuristic is the 'mean distance between the points of the domain'. The full formula is: \\nu = \\sqrt{\\frac{H_n}{2}} \\nu = \\sqrt{\\frac{H_n}{2}} where H_n = \\text{Med}\\left\\{ ||X_{n,i} - X_{n,j}||^2 | 1 \\leq i < j \\leq n \\right\\} H_n = \\text{Med}\\left\\{ ||X_{n,i} - X_{n,j}||^2 | 1 \\leq i < j \\leq n \\right\\} and \\text{Med} \\text{Med} is the empirical median. We can also use the Mean as well. We can obtain this by: Calculating the squareform euclidean distance of all points in our dataset Order them in increasing order Set H_n H_n to be the central element if n(n-1)/2 n(n-1)/2 is odd or the mean if n(n-1)/2 n(n-1)/2 is even. Note : some authors just use \\sqrt{H_n} \\sqrt{H_n} . Median Kth Distance This is a distance measure that is new to me. It is the median/mean of the distances to the k-th k-th neighbour of the dataset. So essentially, we take the same as the median except we take the kth kth -distance for each data-point and take the median of that. Calculate the squareform of the matrix Sort the matrix in ascending order Take the kth distance Take the median or mean of this columns","title":"2. Which Estimator should we use?"},{"location":"#3-should-we-use-different-length-scales-or-the-same","text":"Details RBF Kernel K(\\mathbf{x,y}) = \\exp\\left(-\\frac{\\left|\\left|\\mathbf{x} - \\mathbf{y}\\right|\\right|^2_2}{2\\sigma^2}\\right) K(\\mathbf{x,y}) = \\exp\\left(-\\frac{\\left|\\left|\\mathbf{x} - \\mathbf{y}\\right|\\right|^2_2}{2\\sigma^2}\\right) We can estimate 1 sigma per dataset \\sigma_X,\\sigma_Y \\sigma_X,\\sigma_Y or just 1 sigma \\sigma_{XY} \\sigma_{XY} . ARD Kernel K(\\mathbf{x,y}) = \\exp\\left(-\\frac{1}{2}\\left|\\left|\\frac{\\mathbf{x}}{\\sigma_d} - \\frac{\\mathbf{y}}{\\sigma_d}\\right|\\right|^2_2\\right) K(\\mathbf{x,y}) = \\exp\\left(-\\frac{1}{2}\\left|\\left|\\frac{\\mathbf{x}}{\\sigma_d} - \\frac{\\mathbf{y}}{\\sigma_d}\\right|\\right|^2_2\\right) We can estimate 1 sigma per dataset per dimension \\sigma_{X_d}, \\sigma_{Y_d} \\sigma_{X_d}, \\sigma_{Y_d} .","title":"3. Should we use different length scales or the same?"},{"location":"#4-should-we-standardize-our-data","text":"\\bar{\\mathbf{x}} = \\frac{\\mathbf{x} - \\mu_\\mathbf{x}}{\\sigma_\\mathbf{x}} \\bar{\\mathbf{x}} = \\frac{\\mathbf{x} - \\mu_\\mathbf{x}}{\\sigma_\\mathbf{x}}","title":"4. Should we standardize our data?"},{"location":"#5-summary-of-parameters","text":"Options Standardize Yes / No Parameter Estimator Mean, Median, Silverman, etc Center Kernel Yes / No Normalized Score Yes / No","title":"5. Summary of Parameters"},{"location":"#experiments","text":"","title":"Experiments"},{"location":"#walk-throughs","text":"This is the walk-through where I go step by step and show how I implemented everything. This is mainly for code review purposes but it also has some nuggets. 1.0 - Estimating Sigma In this notebook, I show how one can estimate sigma using different heuristics in the literature. 2.0 - Estimating HSIC I show how we can estimate HSIC using some of the main methods in the literature. 3.0 - Multivariate Distribution I show how we can apply this to large multivariate data and create a large scale parameter search 3.1 - Best Parameters This is part II where I show some preliminary results for which methods are better. 5.0 - Fitting Mutual Information I show how the centered kernel alignment best approximates the Gaussian distribution.","title":"Walk-Throughs"},{"location":"#parameter-grid-1d-data","text":"Notebook","title":"Parameter Grid - 1D Data"},{"location":"#parameter-grid-nd-data","text":"Demo Notebook Fitting Mutual Information","title":"Parameter Grid - nD Data"},{"location":"#mutual-information-vs-hsic-scores","text":"Demo Notebook Fitting Mutual Information","title":"Mutual Information vs HSIC scores"},{"location":"#results","text":"","title":"Results"},{"location":"#take-home-message-i","text":"The median distance seems to be fairly robust in settings with different samples and dimensions. Scott and Silverman should probably avoided if you are not going to estimate the the parameter per feature.","title":"Take-Home Message I"},{"location":"#take-home-message-ii","text":"It appears that the centered kernel alignment (CKA) method is the most consistent when we compare the score versus the mutual information of known distributions. HSIC has some consistency but not entirely. The KA algorithm has no consistency whatsoever; avoid using this method for unsupervised problems.","title":"Take-Home Message II"},{"location":"notebooks/1_1D_parameter/1.0_motivation/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Demo I - Different Cases \u00b6 In this document, I will be looking at the motivation behind this study and why we would like to pursue this further. import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) # toy datasets from data.toy import generate_dependence_data from data.distribution import DataParams from dataclasses import dataclass # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from models.dependence import HSICModel from pysim.kernel.utils import get_init_gammas , get_gamma_grid , estimate_sigma import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-talk' ]) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/1d_dataset/demo/\" Estimating Sigma & HSIC \u00b6 def standardize_data ( X , Y , standardize : bool = False ): X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) return X , Y def get_sigma ( X , Y , method : str = 'silverman' , per_dimension : bool = False , separate_scales : bool = False ): # sigma parameters subsample = None percent = 0.20 random_state = 123 sigma_X = estimate_sigma ( X , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) sigma_Y = estimate_sigma ( Y , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) if separate_scales : sigma_X = np . mean ([ sigma_X , sigma_Y ]) sigma_Y = np . mean ([ sigma_X , sigma_Y ]) return sigma_X , sigma_Y def get_hsic ( X , Y , scorer : str , sigma_X = None , sigma_Y = None ): # init hsic model class hsic_model = HSICModel () # hsic model params if sigma_X is not None : hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( X , Y , scorer ) return hsic_val Data I - 1D Dataset \u00b6 # data params dataset = 'sine' num_points = 1000 seed = 123 noise = 0.1 # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise , noise_y = noise ) # plot fig , ax = plt . subplots () ax . scatter ( X [: 100 ,:], Y [: 100 ,:]) plt . tight_layout () fig . savefig ( FIG_PATH + f \"demo_ { dataset } .png\" ) plt . show () Let's take a simple 1D distribution: a sine curve. It is clear that there is a nonlinear relationship between them that cannot be captured (well) by linear methods. We are interested in looking at the dependence between X X and Y Y . We have the HSIC family of methods: HSIC, kernel alignment and centered kernel alignment. They are all very similar but there are some subtle differences. We will highlight them as we go through the overview. Let's take a generic approach and use the default HSIC, KA and CKA methods to try and estimate the dependence between X,Y X,Y . If we run the algorithm, we get the following results. Question I - Which Algorithm? \u00b6 results_df = pd . DataFrame () method = 'scott' per_dimension = False separate_scales = False # sigma_X, sigma_y = get_sigma( # X, Y, # method=method, # per_dimension=per_dimension, # separate_scales=separate_scales # ) method = 'default' sigma_X , sigma_Y = None , None scorer = 'hsic' results_df = results_df . append ( pd . DataFrame ({ \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q1' ]),) print ( results_df . to_markdown ()) | | hsic | ka | cka | |:---|----------:|---------:|---------:| | Q1 | 0.0582356 | 0.688475 | 0.588434 | Notice how all of the values are slightly difference. This is because of the composition of the methods. We can highlight the differences with a simple table. | **Method** | **Centered Kernel** | **Normalized** | | ------------------------- | ------------------- | -------------- | | HSIC | Yes | No | | Kernel Alignment | No | Yes | | Centered Kernel Alignment | Yes | No | So each method has a slightly different formulation but they are mostly the same. So now the next question is: how do we estimate the parameters of the kernel used? Well the default is simply \\sigma=1.0 \\sigma=1.0 but we know that this won't do as the kernel depends on the parameters of the kernel. In this case we are using the most commonly used kernel: the Radial Basis Function (RBF). Since this is a 1D example, I will use some generic estimators called the \"Silverman Rule\" and \"Scott Rule\". These are very commonly found in packages like scipy.stats.gaussian_kde or statsmodels.nonparametric.bandwidth . They are mostly used for the Kernel Density Estimation (KDE) where we need a decent parameter to approximate the kernel to get a decent density estimate. So what happens with the methods and the results? Question II - Which Parameter Estimator? \u00b6 methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = True results_df = pd . DataFrame () for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = per_dimension , separate_scales = separate_scales ) results_df = results_df . append ( pd . DataFrame ({ # \"sigma_x\": [sigma_X], # \"sigma_y\": [sigma_Y], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q2' ]),) print ( results_df . to_markdown ()) | | Estimator | hsic | ka | cka | |:---|:------------|----------:|---------:|---------:| | Q2 | scott | 0.0575482 | 0.660478 | 0.530685 | | Q2 | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q2 | median | 0.066173 | 0.702005 | 0.556274 | Question III - How do we estimate the length scale? \u00b6 Use the same length scale? Use different length scales? Use a length scale per dimension (D>1) methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] results_df = pd . DataFrame () for iscaler in separate_scales : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = per_dimension , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ # \"sigma_x\": [sigma_X], \"separate\" : [ iscaler ], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q3' ]),) print ( results_df . to_markdown ()) | | separate | Estimator | hsic | ka | cka | |:---|:-----------|:------------|----------:|---------:|---------:| | Q3 | True | scott | 0.0575482 | 0.660478 | 0.530685 | | Q3 | True | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q3 | True | median | 0.066173 | 0.702005 | 0.556274 | | Q3 | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q3 | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q3 | False | median | 0.0728568 | 0.739607 | 0.620757 | Question IV - Standardize Data? \u00b6 We could also standardize our data... This could actually change the size of each of the features which could eliminate the need to apply separate length scales. standardize = [ True , False ] methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] results_df = pd . DataFrame () for istandard in standardize : X_ , Y_ = standardize_data ( X , Y , istandard ) for iscaler in separate_scales : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X_ , Y_ , method = imethod , per_dimension = per_dimension , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"separate\" : [ iscaler ], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X_ , Y_ , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X_ , Y_ , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X_ , Y_ , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q4' ]),) print ( results_df . to_markdown ()) | | standardize | separate | Estimator | hsic | ka | cka | |:---|:--------------|:-----------|:------------|----------:|---------:|---------:| | Q4 | True | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | True | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q4 | False | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | False | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | False | median | 0.0728568 | 0.739607 | 0.620757 | Now we see that the values you get are quite different for all methods. What happens if we use different sigmas? Verdict \u00b6 Well, hard to say as it depends on the parameters. Every researcher I've met who dealt with kernel methods seems to have a suggestion that they swear by but I never know who to follow. My thoughts is that we should use dedicated sigma values per dataset however, that still leaves us with other methods that we may want to try. So we're going to repeat the same experiment but with a 2D dataset and we will see that the difficult will increase again. 2D Example \u00b6 For this experiment, we're going to take two 2D datasets each generated from a T-Student distribution. We will apply the same sequence as we did above and we will end the section by adding another option for picking the parameters. # initialize Data Params class dataset = 'tstudent' samples = 1_000 dimensions = 2 std = 5 nu = 8 trial = 1 standardize = False # initialize params example_params = DataParams ( dataset = dataset , samples = samples , dimensions = dimensions , std = std , nu = nu , trial = trial , standardize = standardize ) # generate some parameters inputs = example_params . generate_data () sns . jointplot ( x = inputs . X , y = inputs . Y ) plt . tight_layout () plt . savefig ( FIG_PATH + f \"demo_ { dataset } .png\" ) Fig I : An example 2D T-Student distribution. Question III (Revisited) - Different Length Scales? \u00b6 Now we can revisit this question because we actually could estimate a different length scale depending upon the dimensionality. One problem with scott or Silverman's method is that it takes into account the entire dataset instead of having one estimate per feature. methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] separate_dimensions = [ True , False ] results_df = pd . DataFrame () for iscaler in separate_scales : for idim in separate_dimensions : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = idim , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"Separate Dimensions\" : [ idim ], \"Separate Length Scales\" : [ iscaler ], 'Param Estimator' : [ imethod ], \"HSIC\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"KA\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"CKA\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q3' ]),) print ( results_df . to_markdown ()) | | standardize | Separate Dimensions | Separate Length Scales | Param Estimator | HSIC | KA | CKA | |:---|:--------------|:----------------------|:-------------------------|:------------------|----------:|---------:|---------:| | Q3 | False | True | True | scott | 0.0575482 | 0.660478 | 0.530685 | | Q3 | False | True | True | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q3 | False | True | True | median | 0.066173 | 0.702005 | 0.556274 | | Q3 | False | False | True | scott | 0.0575482 | 0.660478 | 0.530685 | | Q3 | False | False | True | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q3 | False | False | True | median | 0.066173 | 0.702005 | 0.556274 | | Q3 | False | True | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q3 | False | True | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q3 | False | True | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q3 | False | False | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q3 | False | False | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q3 | False | False | False | median | 0.0728568 | 0.739607 | 0.620757 | Q1-Q4 \u00b6 So now, let's look at all questions for the 2D data distribution standardize = [ True , False ] methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] separate_dimensions = [ True , False ] results_df = pd . DataFrame () for istandard in standardize : X_ , Y_ = standardize_data ( X , Y , istandard ) for iscaler in separate_scales : for idim in separate_dimensions : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X_ , Y_ , method = imethod , per_dimension = idim , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"Separate Dimensions\" : [ idim ], \"Separate Length Scales\" : [ iscaler ], 'Param Estimator' : [ imethod ], \"HSIC\" : [ get_hsic ( X_ , Y_ , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"KA\" : [ get_hsic ( X_ , Y_ , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"CKA\" : [ get_hsic ( X_ , Y_ , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q4' ]),) print ( results_df . to_markdown ()) | | standardize | Separate Dimensions | Separate Length Scales | Param Estimator | HSIC | KA | CKA | |:---|:--------------|:----------------------|:-------------------------|:------------------|----------:|---------:|---------:| | Q4 | True | True | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | True | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | True | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | True | False | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | False | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | False | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | True | True | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | True | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | True | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q4 | True | False | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | False | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | False | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q4 | False | True | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | True | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | True | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | False | False | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | False | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | False | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | False | True | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | True | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | True | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q4 | False | False | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | False | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | False | False | median | 0.0728568 | 0.739607 | 0.620757 | Verdict \u00b6 For the distributions, it seemed to be a little more consistent but with higher dimensions and more samples, these estimators start to fail. But then, we still don't have good alternative estimators. What Now? \u00b6 I will be looking at the following: Options Standardize Yes / No Parameter Estimator Mean, Median, Silverman, etc Center Kernel Yes / No Normalized Score Yes / No","title":"1.0 motivation"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#demo-i-different-cases","text":"In this document, I will be looking at the motivation behind this study and why we would like to pursue this further. import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) # toy datasets from data.toy import generate_dependence_data from data.distribution import DataParams from dataclasses import dataclass # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from models.dependence import HSICModel from pysim.kernel.utils import get_init_gammas , get_gamma_grid , estimate_sigma import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-talk' ]) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/1d_dataset/demo/\"","title":"Demo I - Different Cases"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#estimating-sigma-hsic","text":"def standardize_data ( X , Y , standardize : bool = False ): X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) return X , Y def get_sigma ( X , Y , method : str = 'silverman' , per_dimension : bool = False , separate_scales : bool = False ): # sigma parameters subsample = None percent = 0.20 random_state = 123 sigma_X = estimate_sigma ( X , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) sigma_Y = estimate_sigma ( Y , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) if separate_scales : sigma_X = np . mean ([ sigma_X , sigma_Y ]) sigma_Y = np . mean ([ sigma_X , sigma_Y ]) return sigma_X , sigma_Y def get_hsic ( X , Y , scorer : str , sigma_X = None , sigma_Y = None ): # init hsic model class hsic_model = HSICModel () # hsic model params if sigma_X is not None : hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( X , Y , scorer ) return hsic_val","title":"Estimating Sigma &amp; HSIC"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#data-i-1d-dataset","text":"# data params dataset = 'sine' num_points = 1000 seed = 123 noise = 0.1 # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise , noise_y = noise ) # plot fig , ax = plt . subplots () ax . scatter ( X [: 100 ,:], Y [: 100 ,:]) plt . tight_layout () fig . savefig ( FIG_PATH + f \"demo_ { dataset } .png\" ) plt . show () Let's take a simple 1D distribution: a sine curve. It is clear that there is a nonlinear relationship between them that cannot be captured (well) by linear methods. We are interested in looking at the dependence between X X and Y Y . We have the HSIC family of methods: HSIC, kernel alignment and centered kernel alignment. They are all very similar but there are some subtle differences. We will highlight them as we go through the overview. Let's take a generic approach and use the default HSIC, KA and CKA methods to try and estimate the dependence between X,Y X,Y . If we run the algorithm, we get the following results.","title":"Data I - 1D Dataset"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#question-i-which-algorithm","text":"results_df = pd . DataFrame () method = 'scott' per_dimension = False separate_scales = False # sigma_X, sigma_y = get_sigma( # X, Y, # method=method, # per_dimension=per_dimension, # separate_scales=separate_scales # ) method = 'default' sigma_X , sigma_Y = None , None scorer = 'hsic' results_df = results_df . append ( pd . DataFrame ({ \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q1' ]),) print ( results_df . to_markdown ()) | | hsic | ka | cka | |:---|----------:|---------:|---------:| | Q1 | 0.0582356 | 0.688475 | 0.588434 | Notice how all of the values are slightly difference. This is because of the composition of the methods. We can highlight the differences with a simple table. | **Method** | **Centered Kernel** | **Normalized** | | ------------------------- | ------------------- | -------------- | | HSIC | Yes | No | | Kernel Alignment | No | Yes | | Centered Kernel Alignment | Yes | No | So each method has a slightly different formulation but they are mostly the same. So now the next question is: how do we estimate the parameters of the kernel used? Well the default is simply \\sigma=1.0 \\sigma=1.0 but we know that this won't do as the kernel depends on the parameters of the kernel. In this case we are using the most commonly used kernel: the Radial Basis Function (RBF). Since this is a 1D example, I will use some generic estimators called the \"Silverman Rule\" and \"Scott Rule\". These are very commonly found in packages like scipy.stats.gaussian_kde or statsmodels.nonparametric.bandwidth . They are mostly used for the Kernel Density Estimation (KDE) where we need a decent parameter to approximate the kernel to get a decent density estimate. So what happens with the methods and the results?","title":"Question I - Which Algorithm?"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#question-ii-which-parameter-estimator","text":"methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = True results_df = pd . DataFrame () for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = per_dimension , separate_scales = separate_scales ) results_df = results_df . append ( pd . DataFrame ({ # \"sigma_x\": [sigma_X], # \"sigma_y\": [sigma_Y], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q2' ]),) print ( results_df . to_markdown ()) | | Estimator | hsic | ka | cka | |:---|:------------|----------:|---------:|---------:| | Q2 | scott | 0.0575482 | 0.660478 | 0.530685 | | Q2 | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q2 | median | 0.066173 | 0.702005 | 0.556274 |","title":"Question II - Which Parameter Estimator?"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#question-iii-how-do-we-estimate-the-length-scale","text":"Use the same length scale? Use different length scales? Use a length scale per dimension (D>1) methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] results_df = pd . DataFrame () for iscaler in separate_scales : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = per_dimension , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ # \"sigma_x\": [sigma_X], \"separate\" : [ iscaler ], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q3' ]),) print ( results_df . to_markdown ()) | | separate | Estimator | hsic | ka | cka | |:---|:-----------|:------------|----------:|---------:|---------:| | Q3 | True | scott | 0.0575482 | 0.660478 | 0.530685 | | Q3 | True | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q3 | True | median | 0.066173 | 0.702005 | 0.556274 | | Q3 | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q3 | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q3 | False | median | 0.0728568 | 0.739607 | 0.620757 |","title":"Question III - How do we estimate the length scale?"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#question-iv-standardize-data","text":"We could also standardize our data... This could actually change the size of each of the features which could eliminate the need to apply separate length scales. standardize = [ True , False ] methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] results_df = pd . DataFrame () for istandard in standardize : X_ , Y_ = standardize_data ( X , Y , istandard ) for iscaler in separate_scales : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X_ , Y_ , method = imethod , per_dimension = per_dimension , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"separate\" : [ iscaler ], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X_ , Y_ , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X_ , Y_ , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X_ , Y_ , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q4' ]),) print ( results_df . to_markdown ()) | | standardize | separate | Estimator | hsic | ka | cka | |:---|:--------------|:-----------|:------------|----------:|---------:|---------:| | Q4 | True | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | True | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q4 | False | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | False | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | False | median | 0.0728568 | 0.739607 | 0.620757 | Now we see that the values you get are quite different for all methods. What happens if we use different sigmas?","title":"Question IV - Standardize Data?"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#verdict","text":"Well, hard to say as it depends on the parameters. Every researcher I've met who dealt with kernel methods seems to have a suggestion that they swear by but I never know who to follow. My thoughts is that we should use dedicated sigma values per dataset however, that still leaves us with other methods that we may want to try. So we're going to repeat the same experiment but with a 2D dataset and we will see that the difficult will increase again.","title":"Verdict"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#2d-example","text":"For this experiment, we're going to take two 2D datasets each generated from a T-Student distribution. We will apply the same sequence as we did above and we will end the section by adding another option for picking the parameters. # initialize Data Params class dataset = 'tstudent' samples = 1_000 dimensions = 2 std = 5 nu = 8 trial = 1 standardize = False # initialize params example_params = DataParams ( dataset = dataset , samples = samples , dimensions = dimensions , std = std , nu = nu , trial = trial , standardize = standardize ) # generate some parameters inputs = example_params . generate_data () sns . jointplot ( x = inputs . X , y = inputs . Y ) plt . tight_layout () plt . savefig ( FIG_PATH + f \"demo_ { dataset } .png\" ) Fig I : An example 2D T-Student distribution.","title":"2D Example"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#question-iii-revisited-different-length-scales","text":"Now we can revisit this question because we actually could estimate a different length scale depending upon the dimensionality. One problem with scott or Silverman's method is that it takes into account the entire dataset instead of having one estimate per feature. methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] separate_dimensions = [ True , False ] results_df = pd . DataFrame () for iscaler in separate_scales : for idim in separate_dimensions : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = idim , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"Separate Dimensions\" : [ idim ], \"Separate Length Scales\" : [ iscaler ], 'Param Estimator' : [ imethod ], \"HSIC\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"KA\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"CKA\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q3' ]),) print ( results_df . to_markdown ()) | | standardize | Separate Dimensions | Separate Length Scales | Param Estimator | HSIC | KA | CKA | |:---|:--------------|:----------------------|:-------------------------|:------------------|----------:|---------:|---------:| | Q3 | False | True | True | scott | 0.0575482 | 0.660478 | 0.530685 | | Q3 | False | True | True | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q3 | False | True | True | median | 0.066173 | 0.702005 | 0.556274 | | Q3 | False | False | True | scott | 0.0575482 | 0.660478 | 0.530685 | | Q3 | False | False | True | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q3 | False | False | True | median | 0.066173 | 0.702005 | 0.556274 | | Q3 | False | True | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q3 | False | True | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q3 | False | True | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q3 | False | False | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q3 | False | False | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q3 | False | False | False | median | 0.0728568 | 0.739607 | 0.620757 |","title":"Question III (Revisited) - Different Length Scales?"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#q1-q4","text":"So now, let's look at all questions for the 2D data distribution standardize = [ True , False ] methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] separate_dimensions = [ True , False ] results_df = pd . DataFrame () for istandard in standardize : X_ , Y_ = standardize_data ( X , Y , istandard ) for iscaler in separate_scales : for idim in separate_dimensions : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X_ , Y_ , method = imethod , per_dimension = idim , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"Separate Dimensions\" : [ idim ], \"Separate Length Scales\" : [ iscaler ], 'Param Estimator' : [ imethod ], \"HSIC\" : [ get_hsic ( X_ , Y_ , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"KA\" : [ get_hsic ( X_ , Y_ , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"CKA\" : [ get_hsic ( X_ , Y_ , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q4' ]),) print ( results_df . to_markdown ()) | | standardize | Separate Dimensions | Separate Length Scales | Param Estimator | HSIC | KA | CKA | |:---|:--------------|:----------------------|:-------------------------|:------------------|----------:|---------:|---------:| | Q4 | True | True | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | True | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | True | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | True | False | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | False | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | False | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | True | True | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | True | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | True | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q4 | True | False | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | False | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | False | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q4 | False | True | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | True | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | True | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | False | False | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | False | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | False | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | False | True | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | True | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | True | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q4 | False | False | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | False | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | False | False | median | 0.0728568 | 0.739607 | 0.620757 |","title":"Q1-Q4"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#verdict_1","text":"For the distributions, it seemed to be a little more consistent but with higher dimensions and more samples, these estimators start to fail. But then, we still don't have good alternative estimators.","title":"Verdict"},{"location":"notebooks/1_1D_parameter/1.0_motivation/#what-now","text":"I will be looking at the following: Options Standardize Yes / No Parameter Estimator Mean, Median, Silverman, etc Center Kernel Yes / No Normalized Score Yes / No","title":"What Now?"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Parameter Space - 1D Example \u00b6 import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) import warnings from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.toy import generate_dependence_data from data.distribution import DataParams from features.utils import dict_product # Kernel Dependency measure from sklearn.gaussian_process.kernels import RBF from pysim.kernel.hsic import HSIC from pysim.kernel.utils import estimate_sigma , get_sigma_grid #GammaParam, SigmaParam # RBIG IT measures from models.dependence import HSICModel # Plotting from visualization.distribution import plot_scorer # experiment helpers from tqdm import tqdm from experiments.utils import dict_product , run_parallel_step # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-paper' ]) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline % load_ext autoreload % autoreload 2 Useful Functions \u00b6 I've broken down the components so that it's easier to pass appropriate parameters. The main functions as as follows: Standardize Data yes or no Get Sigma Handles the ways to estimate the parameter per dimension per dataset (x and/or y) estimator (median, mean, silverman, scott, etc) Get HSIC scorer Handles the HSIC method (hsic, ka, cka) from typing import Optional , Tuple def standardize_data ( X : np . ndarray , Y : np . ndarray , standardize : bool = False ) -> Tuple [ np . ndarray , np . ndarray ]: X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) return X , Y def get_sigma ( X : np . ndarray , Y : np . ndarray , method : str = 'silverman' , percent : Optional [ float ] = None , per_dimension : bool = False , separate_scales : bool = False ) -> Tuple [ np . ndarray , np . ndarray ]: # sigma parameters subsample = None random_state = 123 sigma_X = estimate_sigma ( X , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) sigma_Y = estimate_sigma ( Y , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) if separate_scales : sigma_X = np . mean ([ sigma_X , sigma_Y ]) sigma_Y = np . mean ([ sigma_X , sigma_Y ]) return sigma_X , sigma_Y def get_hsic ( X : np . ndarray , Y : np . ndarray , scorer : str , sigma_X : Optional [ float ] = None , sigma_Y : Optional [ float ] = None ) -> float : # init hsic model class hsic_model = HSICModel () # hsic model params if sigma_X is not None : hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( X , Y , scorer ) return hsic_val def plot_toy_data ( X , Y , subsample : Optional [ int ] = None ): # plot fig , ax = plt . subplots () ax . scatter ( X [: subsample ,:], Y [: subsample ,:]) return fig , ax Datasets \u00b6 For this experiment, we will be looking at 4 simple 1D datasets: Line Sine Circle Random datasets = [ 'line' , 'sine' , 'circle' , 'random' ] num_points = 1_000 seed = 123 noise = 0.1 for idataset in datasets : # get dataset X , Y = generate_dependence_data ( dataset = idataset , num_points = num_points , seed = seed , noise_x = noise , noise_y = noise ) fig , ax = plot_toy_data ( X , Y , 100 ) ax . get_xaxis () . set_visible ( False ) ax . get_yaxis () . set_visible ( False ) plt . tight_layout () # fig.savefig(FIG_PATH + f\"demo_{idataset}.png\") plt . show () Research Questions \u00b6 Which Algorithm? Which Parameter Estimator? Standardize or Not? Part I - The Sigma Space \u00b6 Experiment \u00b6 For this first part, we want to look a the entire \\sigma \\sigma space for the RBF kernel. We will vary the \\sigma \\sigma parameter and use 20 grid poinnts for both X X and Y Y . Since we're dealing with 1D data, we will not have to worry about per dimension estimates. Free Parameters Dataset (sine, line, circle, random) Scorer (hsic, cka, ka) Sigma X,Y (grid space) We fix all other parameters as they are not necessary for this first step. sigma_grid , sigma_X (<function __main__.sigma_grid(sigma_X, factor=4, n_grid_points=20)>, 0.32917944341805494) sigma_grid ( sigma_X , factor = 2 ) array([3.29179443e-03, 5.34513923e-03, 8.67931275e-03, 1.40932662e-02, 2.28843178e-02, 3.71590229e-02, 6.03379570e-02, 9.79753711e-02, 1.59090129e-01, 2.58326850e-01, 4.19465131e-01, 6.81117722e-01, 1.10598311e+00, 1.79586965e+00, 2.91609137e+00, 4.73508134e+00, 7.68871493e+00, 1.24847565e+01, 2.02724571e+01, 3.29179443e+01]) def sigma_grid ( sigma_X , factor = 2 , n_grid_points = 20 ): return np . logspace ( np . log10 ( sigma_X * 10 ** ( - factor )), np . log10 ( sigma_X * 10 ** ( factor )), n_grid_points ) # experimental parameters n_grid_points = 40 # sigma_grid = np.logspace(-3, 3, n_grid_points) # initialize sigma (use the median) sigma_X , sigma_Y = get_sigma ( X , Y , method = 'mean' ) print ( sigma_X , sigma_Y ) # create a grid sigma_X_grid = sigma_grid ( sigma_X , factor = 3 , n_grid_points = n_grid_points ) sigma_Y_grid = sigma_grid ( sigma_Y , factor = 3 , n_grid_points = n_grid_points ) # create a parameter grid parameters = { \"dataset\" : [ 'sine' , 'line' , 'random' , 'circle' ], \"scorer\" : [ 'hsic' , 'ka' , 'cka' ], \"sigma_X\" : np . copy ( sigma_X_grid ), \"sigma_Y\" : np . copy ( sigma_Y_grid ), } # Get a list of all parameters parameters = list ( dict_product ( parameters )) # check # of parameters n_params = len ( parameters ) print ( f \"Number of params: { n_params } \" ) print ( f \"First set of params: \\n { parameters [ 0 ] } \" ) 0.32917944341805494 0.3439255265652333 Number of params: 19200 First set of params: {'dataset': 'sine', 'scorer': 'hsic', 'sigma_X': 0.00032917944341805485, 'sigma_Y': 0.00034392552656523323} This made a list of dictionary values with every possible combination of the parameters we listed. Now if we call the first element of this list, we can pass these parameters into our HSIC function to calculate the score. This allows us to do the calculations in parallel instead of looping through every single combination. Now, we need to make an experimental step function. This function will be the HSIC function that called within the parallel loop. I want it to also return a pd.DataFrame with the columns holding the parameters. This will make things easier for us to keep track of things as well as plot our results. from typing import Dict def step ( params : Dict , X : np . ndarray , Y : np . ndarray ) -> pd . DataFrame : # get dataset X , Y = generate_dependence_data ( dataset = params [ 'dataset' ], num_points = 1_000 , seed = 123 , noise_x = 0.1 , noise_y = 0.1 ) # calculate the hsic value score = get_hsic ( X , Y , params [ 'scorer' ], params [ 'sigma_X' ], params [ 'sigma_Y' ]) # create a dataframe with the results and params results_df = pd . DataFrame ({ 'dataset' : [ params [ 'dataset' ]], 'scorer' : [ params [ 'scorer' ]], 'sigma_X' : [ params [ 'sigma_X' ]], 'sigma_Y' : [ params [ 'sigma_Y' ]], 'score' : score , },) return results_df # test the result res_test = step ( parameters [ 0 ], X , Y ) # quick test res_keys = [ 'dataset' , 'scorer' , 'sigma_X' , 'sigma_Y' , 'score' ] assert res_keys == res_test . columns . tolist () # print out results res_test . head () . to_markdown () '| | dataset | scorer | sigma_X | sigma_Y | score |\\n|---:|:----------|:---------|------------:|------------:|------------:|\\n| 0 | sine | hsic | 0.000329179 | 0.000343926 | 0.000997738 |' Now we can loop through and calculate the hsic value for each of the \\sigma \\sigma -parameters that we have enlisted. And we will do it in parallel to save time. I'm on a server with 28 cores free so best believe I will be using all of them... verbose = 1 n_jobs = - 1 results = run_parallel_step ( exp_step = step , parameters = parameters , n_jobs = n_jobs , verbose = verbose , X = X , Y = Y ) [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 2.0s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 5.6s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 10.5s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 15.1s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 20.7s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 29.9s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 40.6s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 48.7s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 1.5min [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 1.8min [Parallel(n_jobs=-1)]: Done 19145 out of 19200 | elapsed: 2.0min remaining: 0.3s [Parallel(n_jobs=-1)]: Done 19200 out of 19200 | elapsed: 2.0min finished # test (number of results = n parameters) assert n_params == len ( results ) results_df = pd . concat ( results , ignore_index = True ) results_df . head () . to_markdown () '| | dataset | scorer | sigma_X | sigma_Y | score |\\n|---:|:----------|:---------|------------:|------------:|------------:|\\n| 0 | sine | hsic | 0.000329179 | 0.000343926 | 0.000997738 |\\n| 1 | sine | hsic | 0.000329179 | 0.000490129 | 0.000997927 |\\n| 2 | sine | hsic | 0.000329179 | 0.000698484 | 0.000998668 |\\n| 3 | sine | hsic | 0.000329179 | 0.000995412 | 0.000999668 |\\n| 4 | sine | hsic | 0.000329179 | 0.00141856 | 0.00100054 |' Visualization - Heatmap \u00b6 To visualize the space, I will use a heatmap with the X,Y-axes for the \\sigma \\sigma -parameter and a colorbar to display the actual values we obtain. Note : The HSIC method has an infinite range whereas the CKA and KA methods will have a range between 0 and 1. In my personal experience, I've yet to see HSIC values go past 0.11 so I will use that as an upper bound for the visualization. Plot Function \u00b6 def plot_gamma_grid ( grid_df : pd . DataFrame , scorer : str , dataset : str , ax : Optional = None ): if ax is None : fig , ax = plt . subplots ( figsize = ( 8 , 6.5 )) # =========================================== # Plot Gridded DataFrame # =========================================== # subset hsic method grid_df_ = grid_df [ grid_df [ 'scorer' ] == scorer ] . drop ( 'scorer' , axis = 1 ) # subset dataset grid_df_ = grid_df_ [ grid_df_ [ 'dataset' ] == dataset ] . drop ( 'dataset' , axis = 1 ) # create a heatmap grid_df_ = pd . pivot_table ( grid_df_ , values = 'score' , index = [ 'sigma_Y' ], columns = 'sigma_X' ) # print(grid_df_) # min max if scorer == 'hsic' : vmax = 0.11 else : vmax = 1.0 # heatmap_data.columns = np.sqrt(1 / 2 * heatmap_data.columns.values) # heatmap_data.index = np.sqrt(1 / 2 * heatmap_data.index.values) pts = sns . heatmap ( data = grid_df_ , xticklabels = grid_df_ . columns . values . round ( decimals = 2 ), yticklabels = grid_df_ . index . values . round ( decimals = 2 ), vmin = 0 , vmax = vmax , ax = ax ) return fig , ax Line Dataset \u00b6 scorers = results_df [ 'scorer' ] . unique () . tolist () idataset = 'line' for iscorer in scorers : fig , ax = plot_gamma_grid ( results_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show () We see that the HSIC method is different that the CKA and KA. There is an \"absolutely maximum\" value that is present whereas the CKA and KA methods seem to have values that where they find maximum dependence. It's also interpretable because they are both at 1. Sine Dataset \u00b6 idataset = 'sine' for iscorer in scorers : fig , ax = plot_gamma_grid ( results_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show () The HSIC and the CKA method both show a decrease in the estimate for dependence for all values. The KA does not and looks very similar to the Line dataset. Circle Dataset \u00b6 idataset = 'circle' for iscorer in scorers : fig , ax = plot_gamma_grid ( results_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show () Yet another decrease in the score for the HSIC and the CKA and the KA is still very similar to the line and the sine dataset. The shapes of HSIC and CKA also seem to be more similar relatively speaking. Random Dataset \u00b6 idataset = 'random' for iscorer in scorers : fig , ax = plot_gamma_grid ( results_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show () We can see that the \\sigma \\sigma -space for the random values makes sense for the HSIC and the CKA but not the KA. There should be absolutely no dependence whatsoever. Part II - Specific Methods \u00b6 In the above section, we showed the full parameter space. But what happens if we just look at specific ways to estimate the sigma? For th Free Parameters : Dataset (sine, line, circle, random) Scorer (hsic, cka, ka) Sigma Estimator (mean, median, silverman, scott) Experiment \u00b6 # initialize sigma (use the median) sigma_X , sigma_Y = get_sigma ( X , Y , method = 'mean' ) # create a parameter grid parameters = { \"dataset\" : [ 'sine' , 'line' , 'random' , 'circle' ], \"scorer\" : [ 'hsic' , 'ka' , 'cka' ], \"estimator\" : [ 'mean' , 'median' , 'mean' ] } # Get a list of all parameters parameters = list ( dict_product ( parameters )) # check # of parameters n_params = len ( parameters ) print ( f \"Number of params: { n_params } \" ) print ( f \"First set of params: \\n { parameters [ 0 ] } \" ) Number of params: 36 First set of params: {'dataset': 'sine', 'scorer': 'hsic', 'estimator': 'mean'} from typing import Dict def step ( params : Dict , X : np . ndarray , Y : np . ndarray ) -> pd . DataFrame : # get dataset X , Y = generate_dependence_data ( dataset = params [ 'dataset' ], num_points = 1_000 , seed = 123 , noise_x = 0.1 , noise_y = 0.1 ) # estimate sigma sigma_X , sigma_Y = get_sigma ( X , Y , method = params [ 'estimator' ]) # calculate the hsic value score = get_hsic ( X , Y , params [ 'scorer' ], sigma_X , sigma_Y ) # create a dataframe with the results and params results_df = pd . DataFrame ({ 'dataset' : [ params [ 'dataset' ]], 'scorer' : [ params [ 'scorer' ]], 'estimator' : [ params [ 'estimator' ]], 'sigma_X' : [ sigma_X ], 'sigma_Y' : [ sigma_Y ], 'score' : score , },) return results_df # test the result res_test = step ( parameters [ 0 ], X , Y ) # quick test res_keys = [ 'dataset' , 'scorer' , 'estimator' , 'sigma_X' , 'sigma_Y' , 'score' ] assert res_keys == res_test . columns . tolist (), f 'Not true: { res_test . columns . tolist () } ' # print out results res_test . head () . to_markdown () '| | dataset | scorer | estimator | sigma_X | sigma_Y | score |\\n|---:|:----------|:---------|:------------|----------:|----------:|----------:|\\n| 0 | sine | hsic | mean | 0.329179 | 0.820625 | 0.0661783 |' verbose = 1 n_jobs = 1 results = run_parallel_step ( exp_step = step , parameters = parameters , n_jobs = n_jobs , verbose = verbose , X = X , Y = Y ) [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. [Parallel(n_jobs=1)]: Done 36 out of 36 | elapsed: 4.3s finished # test (number of results = n parameters) assert n_params == len ( results ) results_est_df = pd . concat ( results , ignore_index = True ) results_est_df . head () . to_markdown () '| | dataset | scorer | estimator | sigma_X | sigma_Y | score |\\n|---:|:----------|:---------|:------------|----------:|----------:|----------:|\\n| 0 | sine | hsic | mean | 0.329179 | 0.820625 | 0.0661783 |\\n| 1 | sine | hsic | median | 0.289021 | 0.72562 | 0.0770415 |\\n| 2 | sine | hsic | mean | 0.329179 | 0.820625 | 0.0661783 |\\n| 3 | sine | ka | mean | 0.329179 | 0.820625 | 0.91219 |\\n| 4 | sine | ka | median | 0.289021 | 0.72562 | 0.896967 |' Visualization - Standard Estimators \u00b6 def plot_all_params ( grid_df : pd . DataFrame , params_df : Optional [ pd . DataFrame ] = None , scorer : str = 'hsc' , dataset : str = 'sine' , ): fig , ax = plt . subplots ( figsize = ( 6 , 5 )) # =========================================== # Plot Gridded DataFrame # =========================================== # subset hsic method grid_df_ = grid_df [ grid_df [ 'scorer' ] == scorer ] . drop ( 'scorer' , axis = 1 ) # subset dataset grid_df_ = grid_df_ [ grid_df_ [ 'dataset' ] == dataset ] . drop ( 'dataset' , axis = 1 ) # create a heatmap grid_df_ = pd . pivot_table ( grid_df_ , values = 'score' , index = [ 'sigma_Y' ], columns = 'sigma_X' ) # print(grid_df_) # min max if scorer == 'hsic' : vmax = 0.11 vmin = grid_df_ . values . min () else : vmax = 1.0 vmin = grid_df_ . values . min () # print(vmin) # heatmap_data.columns = np.sqrt(1 / 2 * heatmap_data.columns.values) # heatmap_data.index = np.sqrt(1 / 2 * heatmap_data.index.values) X , Y = np . meshgrid ( grid_df_ . index . values , grid_df_ . columns . values , ) pts = ax . pcolormesh ( X , Y , grid_df_ . values , #vmin=0, vmax=vmax, cmap = 'Reds' , vmin = 0 , vmax = vmax , # norm=colors.LogNorm(vmin=vmin, vmax=vmax) ) # colorbar fig . colorbar ( pts , ax = ax ) # ax = sns.heatmap( # data=grid_df_, # xticklabels=grid_df_.columns.values.round(decimals=2), # yticklabels=grid_df_.index.values.round(decimals=2), # vmin=0, vmax=vmax # ) # =========================================== # Plot Params # =========================================== if params_df is not None : params_df_ = params_df [ params_df [ 'dataset' ] == dataset ] # subset hsic method params_df_ = params_df_ [ params_df_ [ 'scorer' ] == scorer ] # plot X estimators = [ ( 'median' , 'black' ), ( 'mean' , 'green' ), ( 'silverman' , 'blue' ), ( 'scott' , 'red' ), ] for iest , icolor in estimators : # Plot X # print( # params_df_[params_df_['estimator'] == iest].sigma_X, # params_df_[params_df_['estimator'] == iest].sigma_Y # ) ax . scatter ( params_df_ [ params_df_ [ 'estimator' ] == iest ] . sigma_X , params_df_ [ params_df_ [ 'estimator' ] == iest ] . sigma_Y , s = 500 , c = icolor , label = f \" { iest . capitalize () } X\" , zorder = 3 , marker = '.' ) # Plot Y # # ax.scatter( # # , # # params_df[params_df['estimator'] == iest].score, # # s=300, c=icolor, label=f\"{iest.capitalize()} Y\", zorder=3, marker='.') ax . legend () return fig , ax Line Dataset \u00b6 scorers = results_df [ 'scorer' ] . unique () . tolist () idataset = 'line' for iscorer in scorers : fig , ax = plot_all_params ( results_df , results_est_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) plt . xscale ( 'log' , basex = 10 ) plt . yscale ( 'log' , basey = 10 ) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show () Sine Dataset \u00b6 scorers = results_df [ 'scorer' ] . unique () . tolist () idataset = 'sine' for iscorer in scorers : fig , ax = plot_all_params ( results_df , results_est_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) plt . xscale ( 'log' , basex = 10 ) plt . yscale ( 'log' , basey = 10 ) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show () Circle Dataset \u00b6 scorers = results_df [ 'scorer' ] . unique () . tolist () idataset = 'circle' for iscorer in scorers : fig , ax = plot_all_params ( results_df , results_est_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) plt . xscale ( 'log' , basex = 10 ) plt . yscale ( 'log' , basey = 10 ) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show () Random Dataset \u00b6 scorers = results_df [ 'scorer' ] . unique () . tolist () idataset = 'random' for iscorer in scorers : fig , ax = plot_all_params ( results_df , results_est_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) plt . xscale ( 'log' , basex = 10 ) plt . yscale ( 'log' , basey = 10 ) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show ()","title":"2.0 preliminary exp"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#parameter-space-1d-example","text":"import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) import warnings from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.toy import generate_dependence_data from data.distribution import DataParams from features.utils import dict_product # Kernel Dependency measure from sklearn.gaussian_process.kernels import RBF from pysim.kernel.hsic import HSIC from pysim.kernel.utils import estimate_sigma , get_sigma_grid #GammaParam, SigmaParam # RBIG IT measures from models.dependence import HSICModel # Plotting from visualization.distribution import plot_scorer # experiment helpers from tqdm import tqdm from experiments.utils import dict_product , run_parallel_step # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-paper' ]) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline % load_ext autoreload % autoreload 2","title":"Parameter Space - 1D Example"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#useful-functions","text":"I've broken down the components so that it's easier to pass appropriate parameters. The main functions as as follows: Standardize Data yes or no Get Sigma Handles the ways to estimate the parameter per dimension per dataset (x and/or y) estimator (median, mean, silverman, scott, etc) Get HSIC scorer Handles the HSIC method (hsic, ka, cka) from typing import Optional , Tuple def standardize_data ( X : np . ndarray , Y : np . ndarray , standardize : bool = False ) -> Tuple [ np . ndarray , np . ndarray ]: X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) return X , Y def get_sigma ( X : np . ndarray , Y : np . ndarray , method : str = 'silverman' , percent : Optional [ float ] = None , per_dimension : bool = False , separate_scales : bool = False ) -> Tuple [ np . ndarray , np . ndarray ]: # sigma parameters subsample = None random_state = 123 sigma_X = estimate_sigma ( X , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) sigma_Y = estimate_sigma ( Y , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) if separate_scales : sigma_X = np . mean ([ sigma_X , sigma_Y ]) sigma_Y = np . mean ([ sigma_X , sigma_Y ]) return sigma_X , sigma_Y def get_hsic ( X : np . ndarray , Y : np . ndarray , scorer : str , sigma_X : Optional [ float ] = None , sigma_Y : Optional [ float ] = None ) -> float : # init hsic model class hsic_model = HSICModel () # hsic model params if sigma_X is not None : hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( X , Y , scorer ) return hsic_val def plot_toy_data ( X , Y , subsample : Optional [ int ] = None ): # plot fig , ax = plt . subplots () ax . scatter ( X [: subsample ,:], Y [: subsample ,:]) return fig , ax","title":"Useful Functions"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#datasets","text":"For this experiment, we will be looking at 4 simple 1D datasets: Line Sine Circle Random datasets = [ 'line' , 'sine' , 'circle' , 'random' ] num_points = 1_000 seed = 123 noise = 0.1 for idataset in datasets : # get dataset X , Y = generate_dependence_data ( dataset = idataset , num_points = num_points , seed = seed , noise_x = noise , noise_y = noise ) fig , ax = plot_toy_data ( X , Y , 100 ) ax . get_xaxis () . set_visible ( False ) ax . get_yaxis () . set_visible ( False ) plt . tight_layout () # fig.savefig(FIG_PATH + f\"demo_{idataset}.png\") plt . show ()","title":"Datasets"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#research-questions","text":"Which Algorithm? Which Parameter Estimator? Standardize or Not?","title":"Research Questions"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#part-i-the-sigma-space","text":"","title":"Part I - The Sigma Space"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#experiment","text":"For this first part, we want to look a the entire \\sigma \\sigma space for the RBF kernel. We will vary the \\sigma \\sigma parameter and use 20 grid poinnts for both X X and Y Y . Since we're dealing with 1D data, we will not have to worry about per dimension estimates. Free Parameters Dataset (sine, line, circle, random) Scorer (hsic, cka, ka) Sigma X,Y (grid space) We fix all other parameters as they are not necessary for this first step. sigma_grid , sigma_X (<function __main__.sigma_grid(sigma_X, factor=4, n_grid_points=20)>, 0.32917944341805494) sigma_grid ( sigma_X , factor = 2 ) array([3.29179443e-03, 5.34513923e-03, 8.67931275e-03, 1.40932662e-02, 2.28843178e-02, 3.71590229e-02, 6.03379570e-02, 9.79753711e-02, 1.59090129e-01, 2.58326850e-01, 4.19465131e-01, 6.81117722e-01, 1.10598311e+00, 1.79586965e+00, 2.91609137e+00, 4.73508134e+00, 7.68871493e+00, 1.24847565e+01, 2.02724571e+01, 3.29179443e+01]) def sigma_grid ( sigma_X , factor = 2 , n_grid_points = 20 ): return np . logspace ( np . log10 ( sigma_X * 10 ** ( - factor )), np . log10 ( sigma_X * 10 ** ( factor )), n_grid_points ) # experimental parameters n_grid_points = 40 # sigma_grid = np.logspace(-3, 3, n_grid_points) # initialize sigma (use the median) sigma_X , sigma_Y = get_sigma ( X , Y , method = 'mean' ) print ( sigma_X , sigma_Y ) # create a grid sigma_X_grid = sigma_grid ( sigma_X , factor = 3 , n_grid_points = n_grid_points ) sigma_Y_grid = sigma_grid ( sigma_Y , factor = 3 , n_grid_points = n_grid_points ) # create a parameter grid parameters = { \"dataset\" : [ 'sine' , 'line' , 'random' , 'circle' ], \"scorer\" : [ 'hsic' , 'ka' , 'cka' ], \"sigma_X\" : np . copy ( sigma_X_grid ), \"sigma_Y\" : np . copy ( sigma_Y_grid ), } # Get a list of all parameters parameters = list ( dict_product ( parameters )) # check # of parameters n_params = len ( parameters ) print ( f \"Number of params: { n_params } \" ) print ( f \"First set of params: \\n { parameters [ 0 ] } \" ) 0.32917944341805494 0.3439255265652333 Number of params: 19200 First set of params: {'dataset': 'sine', 'scorer': 'hsic', 'sigma_X': 0.00032917944341805485, 'sigma_Y': 0.00034392552656523323} This made a list of dictionary values with every possible combination of the parameters we listed. Now if we call the first element of this list, we can pass these parameters into our HSIC function to calculate the score. This allows us to do the calculations in parallel instead of looping through every single combination. Now, we need to make an experimental step function. This function will be the HSIC function that called within the parallel loop. I want it to also return a pd.DataFrame with the columns holding the parameters. This will make things easier for us to keep track of things as well as plot our results. from typing import Dict def step ( params : Dict , X : np . ndarray , Y : np . ndarray ) -> pd . DataFrame : # get dataset X , Y = generate_dependence_data ( dataset = params [ 'dataset' ], num_points = 1_000 , seed = 123 , noise_x = 0.1 , noise_y = 0.1 ) # calculate the hsic value score = get_hsic ( X , Y , params [ 'scorer' ], params [ 'sigma_X' ], params [ 'sigma_Y' ]) # create a dataframe with the results and params results_df = pd . DataFrame ({ 'dataset' : [ params [ 'dataset' ]], 'scorer' : [ params [ 'scorer' ]], 'sigma_X' : [ params [ 'sigma_X' ]], 'sigma_Y' : [ params [ 'sigma_Y' ]], 'score' : score , },) return results_df # test the result res_test = step ( parameters [ 0 ], X , Y ) # quick test res_keys = [ 'dataset' , 'scorer' , 'sigma_X' , 'sigma_Y' , 'score' ] assert res_keys == res_test . columns . tolist () # print out results res_test . head () . to_markdown () '| | dataset | scorer | sigma_X | sigma_Y | score |\\n|---:|:----------|:---------|------------:|------------:|------------:|\\n| 0 | sine | hsic | 0.000329179 | 0.000343926 | 0.000997738 |' Now we can loop through and calculate the hsic value for each of the \\sigma \\sigma -parameters that we have enlisted. And we will do it in parallel to save time. I'm on a server with 28 cores free so best believe I will be using all of them... verbose = 1 n_jobs = - 1 results = run_parallel_step ( exp_step = step , parameters = parameters , n_jobs = n_jobs , verbose = verbose , X = X , Y = Y ) [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 2.0s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 5.6s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 10.5s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 15.1s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 20.7s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 29.9s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 40.6s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 48.7s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 1.5min [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 1.8min [Parallel(n_jobs=-1)]: Done 19145 out of 19200 | elapsed: 2.0min remaining: 0.3s [Parallel(n_jobs=-1)]: Done 19200 out of 19200 | elapsed: 2.0min finished # test (number of results = n parameters) assert n_params == len ( results ) results_df = pd . concat ( results , ignore_index = True ) results_df . head () . to_markdown () '| | dataset | scorer | sigma_X | sigma_Y | score |\\n|---:|:----------|:---------|------------:|------------:|------------:|\\n| 0 | sine | hsic | 0.000329179 | 0.000343926 | 0.000997738 |\\n| 1 | sine | hsic | 0.000329179 | 0.000490129 | 0.000997927 |\\n| 2 | sine | hsic | 0.000329179 | 0.000698484 | 0.000998668 |\\n| 3 | sine | hsic | 0.000329179 | 0.000995412 | 0.000999668 |\\n| 4 | sine | hsic | 0.000329179 | 0.00141856 | 0.00100054 |'","title":"Experiment"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#visualization-heatmap","text":"To visualize the space, I will use a heatmap with the X,Y-axes for the \\sigma \\sigma -parameter and a colorbar to display the actual values we obtain. Note : The HSIC method has an infinite range whereas the CKA and KA methods will have a range between 0 and 1. In my personal experience, I've yet to see HSIC values go past 0.11 so I will use that as an upper bound for the visualization.","title":"Visualization - Heatmap"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#plot-function","text":"def plot_gamma_grid ( grid_df : pd . DataFrame , scorer : str , dataset : str , ax : Optional = None ): if ax is None : fig , ax = plt . subplots ( figsize = ( 8 , 6.5 )) # =========================================== # Plot Gridded DataFrame # =========================================== # subset hsic method grid_df_ = grid_df [ grid_df [ 'scorer' ] == scorer ] . drop ( 'scorer' , axis = 1 ) # subset dataset grid_df_ = grid_df_ [ grid_df_ [ 'dataset' ] == dataset ] . drop ( 'dataset' , axis = 1 ) # create a heatmap grid_df_ = pd . pivot_table ( grid_df_ , values = 'score' , index = [ 'sigma_Y' ], columns = 'sigma_X' ) # print(grid_df_) # min max if scorer == 'hsic' : vmax = 0.11 else : vmax = 1.0 # heatmap_data.columns = np.sqrt(1 / 2 * heatmap_data.columns.values) # heatmap_data.index = np.sqrt(1 / 2 * heatmap_data.index.values) pts = sns . heatmap ( data = grid_df_ , xticklabels = grid_df_ . columns . values . round ( decimals = 2 ), yticklabels = grid_df_ . index . values . round ( decimals = 2 ), vmin = 0 , vmax = vmax , ax = ax ) return fig , ax","title":"Plot Function"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#line-dataset","text":"scorers = results_df [ 'scorer' ] . unique () . tolist () idataset = 'line' for iscorer in scorers : fig , ax = plot_gamma_grid ( results_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show () We see that the HSIC method is different that the CKA and KA. There is an \"absolutely maximum\" value that is present whereas the CKA and KA methods seem to have values that where they find maximum dependence. It's also interpretable because they are both at 1.","title":"Line Dataset"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#sine-dataset","text":"idataset = 'sine' for iscorer in scorers : fig , ax = plot_gamma_grid ( results_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show () The HSIC and the CKA method both show a decrease in the estimate for dependence for all values. The KA does not and looks very similar to the Line dataset.","title":"Sine Dataset"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#circle-dataset","text":"idataset = 'circle' for iscorer in scorers : fig , ax = plot_gamma_grid ( results_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show () Yet another decrease in the score for the HSIC and the CKA and the KA is still very similar to the line and the sine dataset. The shapes of HSIC and CKA also seem to be more similar relatively speaking.","title":"Circle Dataset"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#random-dataset","text":"idataset = 'random' for iscorer in scorers : fig , ax = plot_gamma_grid ( results_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show () We can see that the \\sigma \\sigma -space for the random values makes sense for the HSIC and the CKA but not the KA. There should be absolutely no dependence whatsoever.","title":"Random Dataset"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#part-ii-specific-methods","text":"In the above section, we showed the full parameter space. But what happens if we just look at specific ways to estimate the sigma? For th Free Parameters : Dataset (sine, line, circle, random) Scorer (hsic, cka, ka) Sigma Estimator (mean, median, silverman, scott)","title":"Part II - Specific Methods"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#experiment_1","text":"# initialize sigma (use the median) sigma_X , sigma_Y = get_sigma ( X , Y , method = 'mean' ) # create a parameter grid parameters = { \"dataset\" : [ 'sine' , 'line' , 'random' , 'circle' ], \"scorer\" : [ 'hsic' , 'ka' , 'cka' ], \"estimator\" : [ 'mean' , 'median' , 'mean' ] } # Get a list of all parameters parameters = list ( dict_product ( parameters )) # check # of parameters n_params = len ( parameters ) print ( f \"Number of params: { n_params } \" ) print ( f \"First set of params: \\n { parameters [ 0 ] } \" ) Number of params: 36 First set of params: {'dataset': 'sine', 'scorer': 'hsic', 'estimator': 'mean'} from typing import Dict def step ( params : Dict , X : np . ndarray , Y : np . ndarray ) -> pd . DataFrame : # get dataset X , Y = generate_dependence_data ( dataset = params [ 'dataset' ], num_points = 1_000 , seed = 123 , noise_x = 0.1 , noise_y = 0.1 ) # estimate sigma sigma_X , sigma_Y = get_sigma ( X , Y , method = params [ 'estimator' ]) # calculate the hsic value score = get_hsic ( X , Y , params [ 'scorer' ], sigma_X , sigma_Y ) # create a dataframe with the results and params results_df = pd . DataFrame ({ 'dataset' : [ params [ 'dataset' ]], 'scorer' : [ params [ 'scorer' ]], 'estimator' : [ params [ 'estimator' ]], 'sigma_X' : [ sigma_X ], 'sigma_Y' : [ sigma_Y ], 'score' : score , },) return results_df # test the result res_test = step ( parameters [ 0 ], X , Y ) # quick test res_keys = [ 'dataset' , 'scorer' , 'estimator' , 'sigma_X' , 'sigma_Y' , 'score' ] assert res_keys == res_test . columns . tolist (), f 'Not true: { res_test . columns . tolist () } ' # print out results res_test . head () . to_markdown () '| | dataset | scorer | estimator | sigma_X | sigma_Y | score |\\n|---:|:----------|:---------|:------------|----------:|----------:|----------:|\\n| 0 | sine | hsic | mean | 0.329179 | 0.820625 | 0.0661783 |' verbose = 1 n_jobs = 1 results = run_parallel_step ( exp_step = step , parameters = parameters , n_jobs = n_jobs , verbose = verbose , X = X , Y = Y ) [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. [Parallel(n_jobs=1)]: Done 36 out of 36 | elapsed: 4.3s finished # test (number of results = n parameters) assert n_params == len ( results ) results_est_df = pd . concat ( results , ignore_index = True ) results_est_df . head () . to_markdown () '| | dataset | scorer | estimator | sigma_X | sigma_Y | score |\\n|---:|:----------|:---------|:------------|----------:|----------:|----------:|\\n| 0 | sine | hsic | mean | 0.329179 | 0.820625 | 0.0661783 |\\n| 1 | sine | hsic | median | 0.289021 | 0.72562 | 0.0770415 |\\n| 2 | sine | hsic | mean | 0.329179 | 0.820625 | 0.0661783 |\\n| 3 | sine | ka | mean | 0.329179 | 0.820625 | 0.91219 |\\n| 4 | sine | ka | median | 0.289021 | 0.72562 | 0.896967 |'","title":"Experiment"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#visualization-standard-estimators","text":"def plot_all_params ( grid_df : pd . DataFrame , params_df : Optional [ pd . DataFrame ] = None , scorer : str = 'hsc' , dataset : str = 'sine' , ): fig , ax = plt . subplots ( figsize = ( 6 , 5 )) # =========================================== # Plot Gridded DataFrame # =========================================== # subset hsic method grid_df_ = grid_df [ grid_df [ 'scorer' ] == scorer ] . drop ( 'scorer' , axis = 1 ) # subset dataset grid_df_ = grid_df_ [ grid_df_ [ 'dataset' ] == dataset ] . drop ( 'dataset' , axis = 1 ) # create a heatmap grid_df_ = pd . pivot_table ( grid_df_ , values = 'score' , index = [ 'sigma_Y' ], columns = 'sigma_X' ) # print(grid_df_) # min max if scorer == 'hsic' : vmax = 0.11 vmin = grid_df_ . values . min () else : vmax = 1.0 vmin = grid_df_ . values . min () # print(vmin) # heatmap_data.columns = np.sqrt(1 / 2 * heatmap_data.columns.values) # heatmap_data.index = np.sqrt(1 / 2 * heatmap_data.index.values) X , Y = np . meshgrid ( grid_df_ . index . values , grid_df_ . columns . values , ) pts = ax . pcolormesh ( X , Y , grid_df_ . values , #vmin=0, vmax=vmax, cmap = 'Reds' , vmin = 0 , vmax = vmax , # norm=colors.LogNorm(vmin=vmin, vmax=vmax) ) # colorbar fig . colorbar ( pts , ax = ax ) # ax = sns.heatmap( # data=grid_df_, # xticklabels=grid_df_.columns.values.round(decimals=2), # yticklabels=grid_df_.index.values.round(decimals=2), # vmin=0, vmax=vmax # ) # =========================================== # Plot Params # =========================================== if params_df is not None : params_df_ = params_df [ params_df [ 'dataset' ] == dataset ] # subset hsic method params_df_ = params_df_ [ params_df_ [ 'scorer' ] == scorer ] # plot X estimators = [ ( 'median' , 'black' ), ( 'mean' , 'green' ), ( 'silverman' , 'blue' ), ( 'scott' , 'red' ), ] for iest , icolor in estimators : # Plot X # print( # params_df_[params_df_['estimator'] == iest].sigma_X, # params_df_[params_df_['estimator'] == iest].sigma_Y # ) ax . scatter ( params_df_ [ params_df_ [ 'estimator' ] == iest ] . sigma_X , params_df_ [ params_df_ [ 'estimator' ] == iest ] . sigma_Y , s = 500 , c = icolor , label = f \" { iest . capitalize () } X\" , zorder = 3 , marker = '.' ) # Plot Y # # ax.scatter( # # , # # params_df[params_df['estimator'] == iest].score, # # s=300, c=icolor, label=f\"{iest.capitalize()} Y\", zorder=3, marker='.') ax . legend () return fig , ax","title":"Visualization - Standard Estimators"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#line-dataset_1","text":"scorers = results_df [ 'scorer' ] . unique () . tolist () idataset = 'line' for iscorer in scorers : fig , ax = plot_all_params ( results_df , results_est_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) plt . xscale ( 'log' , basex = 10 ) plt . yscale ( 'log' , basey = 10 ) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show ()","title":"Line Dataset"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#sine-dataset_1","text":"scorers = results_df [ 'scorer' ] . unique () . tolist () idataset = 'sine' for iscorer in scorers : fig , ax = plot_all_params ( results_df , results_est_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) plt . xscale ( 'log' , basex = 10 ) plt . yscale ( 'log' , basey = 10 ) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show ()","title":"Sine Dataset"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#circle-dataset_1","text":"scorers = results_df [ 'scorer' ] . unique () . tolist () idataset = 'circle' for iscorer in scorers : fig , ax = plot_all_params ( results_df , results_est_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) plt . xscale ( 'log' , basex = 10 ) plt . yscale ( 'log' , basey = 10 ) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show ()","title":"Circle Dataset"},{"location":"notebooks/1_1D_parameter/2.0_preliminary_exp/#random-dataset_1","text":"scorers = results_df [ 'scorer' ] . unique () . tolist () idataset = 'random' for iscorer in scorers : fig , ax = plot_all_params ( results_df , results_est_df , scorer = iscorer , dataset = idataset ) # ax.legend(ncol=1, fontsize=15) plt . xscale ( 'log' , basex = 10 ) plt . yscale ( 'log' , basey = 10 ) ax . set_xlabel ( r '$\\sigma_X$' , fontsize = 20 ) ax . set_ylabel ( r '$\\sigma_Y$' , fontsize = 20 ) ax . set_title ( f ' { iscorer . upper () } Score, { idataset . capitalize () } ' , fontsize = 20 ) plt . tight_layout () plt . show ()","title":"Random Dataset"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Comparing HSIC versus Mutual Information measures \u00b6 In this notebook, we will be exploring how we can estimate the HSIC parmaeter for different distributions and look at how it compares to MI measures. Normally the procedure for calculating HSIC is as follows: Calculate kernel matrices for X and Y Center both kernel matrices Find the Frobenius norm between the kernel matrices This works well but there is no certain way to estimate the parameter for each of the kernel matrices. There is another paper that is called the Kernel Tangent Alignment (KTA). This method is different as it is calculated like so: Calculate the kernel matrices for X and Y Find the Frobenius norm between the kernel matrices Normalize the value by the Frobenius norm of X and Y individually This works in a similar way to the HSIC method. The difference is that you do the normalization procedure. The final algorithm is the Centered Kernel Tangent Alignment (cKTA) method which is a combination of the previous two methods. The algorithm is as follows: Calculate the kernel matrices for X and Y Center both kernel matrices Find the Frobenius norm between the kernel matrices Normalize the value by the Frobenius norm of X and Y individually As you can see, it would appear that this method is the most complete in the sense that it incorporates all steps to ensure that our data is sufficiently scaled to a way that is directly comparable. This notebook will attempt to see which of these methods provides a good estimate for a sigma value for the kernel matrices and how do their output values compare to mutual information measures. Covariance vs Correlation \u00b6 The above methods can be put into perspective of the difference between covariance measures and correlation meausres. In this section, I will explain why that is so. We can write out the full definitions for covariance and correlation. The definition of covariance is: \\text{cov}_{XY}=\\sigma_{XY}=E\\left[(X - \\mu_X)(Y - \\mu_Y) \\right] \\text{cov}_{XY}=\\sigma_{XY}=E\\left[(X - \\mu_X)(Y - \\mu_Y) \\right] The definition of correlation is: \\text{corr}_{XY}=\\rho_{XY}=\\frac{\\sigma_{XY}}{\\sigma_X \\sigma_Y} \\text{corr}_{XY}=\\rho_{XY}=\\frac{\\sigma_{XY}}{\\sigma_X \\sigma_Y} The correlation measure is dimensionless whereas the covariance is in units obtained by multiplying the units of the two variables. Source : Wikipedia on Covariance and correlation Wikipedia on Correlation and dependence Code \u00b6 import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload Experiment Class \u00b6 The entire experiment is contained within this class. It features the fixed param, the free params, all the methods with the preprocessing and loading, and the hsic methods. class ExperimentKTA : def __init__ ( self , seed = 123 , n_trials = 10 , hsic_points = 1000 , n_noise = 10 , n_gamma = 50 , factor = 2 , mi_points = 100_000 , sigma_est = 'silverman' , save_path = None , save_name = 'test' ): # fixed experimental params self . seed = seed self . hsic_points = hsic_points self . n_noise = n_noise self . n_gamma = n_gamma self . factor = factor self . mi_points = mi_points self . sigma_est = sigma_est self . n_trials = n_trials self . save_path = save_path self . save_name = save_name # free experimental params self . noise_params = np . logspace ( - 3 , -. 3 , n_noise ) self . func_params = [ 'line' , 'sine' , 'circ' , 'rand' , ] self . scorers = [ 'hsic' , 'tka' , 'ctka' , ] self . seeds = [ i for i in range ( 1 , n_trials + 1 )] # saved dataframe pass def run_experiment ( self ): # initialize results dataframe self . results_df = self . generate_results_df () # Loop through functions for ifunction in self . func_params : print ( f \"Function: { ifunction } \" ) # Loop through noise parameters for inoise in self . noise_params : # Loop through random seeds for iseed in self . seeds : # generate data for MI measure X , Y = self . _generate_data ( inoise , ifunction , iseed , dataset = 'mi' ) # calculate MI mi_score , _ = run_rbig_models ( X , Y , measure = 'mi' , verbose = None , random_state = self . seed ) # ======================= # HSIC MEASURES # ======================= # initialize sigma init_sigma , sigma_params = self . _estimate_sigmas ( X , Y ) # convert to gamma init_gamma = sigma_to_gamma ( init_sigma ) gamma_params = sigma_to_gamma ( sigma_params ) # Loop through HSIC scoring methods for hsic_method in self . scorers : # Loop through gamma parameters for igamma in gamma_params : # generate data for MI measure X , Y = self . _generate_data ( inoise , ifunction , iseed , dataset = 'hsic' ) # Calculate HSIC hsic_score = self . _get_hsic ( X , Y , igamma , None , hsic_method ) # append results to results dataframe self . results_df = self . append_results ( self . results_df , ifunction , iseed , inoise , init_gamma , igamma , hsic_method , hsic_score , mi_score ) # save results to csv self . save_data ( self . results_df ) return self def _generate_data ( self , noise , function , seed , dataset = 'hsic' ): if dataset == 'hsic' : num_points = self . hsic_points elif dataset == 'mi' : num_points = self . mi_points else : raise ValueError ( f 'Unrecoginized dataset: { dataset } ' ) # get dataset X , Y = generate_dependence_data ( dataset = function , num_points = num_points , seed = seed , noise_x = noise , noise_y = noise ) return X , Y def _estimate_sigmas ( self , X , Y ): # estimate initialize sigma sigma_x = estimate_sigma ( X , method = self . sigma_est ) sigma_y = estimate_sigma ( Y , method = self . sigma_est ) # init overall sigma is mean between two init_sigma = np . mean ([ sigma_x , sigma_y ]) # get parameter grid sigmas = get_param_grid ( init_sigma , self . factor , self . n_gamma ) # convert to gammas return init_sigma , sigmas def _get_hsic ( self , X , Y , gamma , subsample , scorer ): # initialize hsic clf_hsic = HSIC ( gamma = gamma , scorer = scorer , subsample = subsample ) # calculate HSIC value clf_hsic . fit ( X , Y ) # return HSIC score return clf_hsic . score ( X ) def generate_results_df ( self ): return pd . DataFrame ( columns = [ 'trial' , 'function' , 'noise' , 'init_gamma' , 'gamma' , 'scorer' , 'value' , 'mi' , ]) def append_results ( self , results_df , function , trial , noise , init_gamma , gamma , hsic_method , hsic_score , mi_score ): # append data return results_df . append ({ 'function' : function , 'trial' : trial , 'noise' : noise , 'init_gamma' : init_gamma , 'gamma' : gamma , 'scorer' : hsic_method , 'value' : hsic_score , 'mi' : mi_score }, ignore_index = True ) def load_data ( self ): pass def save_data ( self , results_df ): results_df . to_csv ( f \" { self . save_path }{ self . save_name } .csv\" ) Experiment Run \u00b6 # experimental params seed = 123 # reproducibility n_trials = 1 # number of trials hsic_points = 10_000 # number of points used for HSIC mi_points = 10_000 # number of points used for MI n_noise = 50 # number of points in noise param grid n_gamma = 50 # number of points in gamma param grid factor = 1 # log factor for gamma param grid bounds sigma_est = 'mean' # sigma initialization save_path = f ' { cwd } /../../results/hsic/' save_name = 'trial_v2_s10k' # initialize experiment class clf_exp = ExperimentKTA ( seed = seed , n_trials = n_trials , hsic_points = hsic_points , factor = factor , mi_points = mi_points , sigma_est = sigma_est , n_noise = n_noise , n_gamma = n_gamma , save_path = save_path , save_name = save_name , ) # run full experiment clf_exp . run_experiment () Function: line projects / 2019 _hsic_align / results / hsic Example \u00b6 Visualize the Results \u00b6 Figure I - Mutual Information & Noise \u00b6 This first figure is to demonstrate how the mutual information compares with the amount of noise for each of the functions Linear , Sinusoidal , Circular , and Random . res_noise = results_df [ 'noise' ] . unique () . tolist () res_gammas = results_df [ 'gamma' ] . unique () . tolist () res_lines = results_df [ 'function' ] . unique () . tolist () fig , ax = plt . subplots () ax . scatter ( results_df [ results_df [ 'function' ] == 'line' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'line' ][ 'mi' ], label = 'Line' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'sine' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'sine' ][ 'mi' ], label = 'Sine' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'circ' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'circ' ][ 'mi' ], label = 'Circle' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'rand' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'rand' ][ 'mi' ], label = 'Random' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . set_xlabel ( 'Noise, $\\sigma_y$' ) ax . set_ylabel ( 'Mutual Information, MI$(X,Y)$' ) # ax.set_xscale('log') plt . legend () ax . set_title ( 'Experimental Parameter Space' ) plt . show () Line This has the most amount of MI with little noise but log-linearly decreases as we increase the noise. Sine This has the 2 nd most amount of MI with little noise. It also decreases as wee increase the noise. Curiously, we find that it has more MI than the linear function at some point around 10^{-2} 10^{-2} amount of noise. It could be due to the amount of structure still present within the sine function. Circle The circle has less MI overall than the linear and sine function and also decreases with added noise. Random There is no mutual information between them no matter how much more noise we inject. Plot Function \u00b6 def plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ): save_path = f ' { cwd } /../../results/hsic/figures/' # Set Title stuff if function == 'line' : title = 'Linear Function' elif function == 'sine' : title = 'Sine Function' elif function == 'circ' : title = 'Circle Function' elif function == 'rand' : title = 'Random Function' else : raise ValueError ( f 'Unrecognized function: { line } ' ) sub_results_df = results_df [ results_df [ 'function' ] == function ] free_params = [ # 'gamma', 'function' ] fixed_params = [ 'gamma' , 'value' , 'method' , 'mi' ] groups = sub_results_df . groupby ( free_params ) hue = 'gamma' fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 3 )) for iparams , idata in groups : # Plot I - HSIC pts = ax . scatter ( x = idata [ idata [ 'scorer' ] == hsic_method ][ 'value' ], y = idata [ idata [ 'scorer' ] == hsic_method ][ 'mi' ], c = idata [ idata [ 'scorer' ] == hsic_method ][ 'gamma' ], s = 20 , cmap = 'Spectral' , norm = matplotlib . colors . LogNorm () ) ax . set_xlabel ( hsic_method . upper () ) ax . set_ylabel ( 'Mutual Information' ) fig . colorbar ( pts , ax = ax , label = 'Gamma' ) # ax[0].get_legend().remove() # ax[1].get_legend().remove() # ax[2].get_legend().remove() ax . set_yscale ( 'log' ) ax . set_title ( title ) plt . tight_layout () plt . show () fig . savefig ( f \" { save_path } trialv1_ { function } _ { hsic_method } .png\" ) return None Figure II - MI vs Gamma vs HSIC (Linear Function) \u00b6 plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'ctka' ) Observation I : The scaling The scales for HSIC method is different than the other two methods. Both KTA and cKTA are bounded at 1 whereas HSIC is only bounded at 0. Or at least from what we can see from the graphs given. It's a slightly different interpretation in the sense that c/KTA will model if they are the same whereas HSIC models if they are Observation II : The shape of the parameter space We can see in the figures above that each of the HSIC estimators have different overall shapes. The HSIC has a minimum of 0 always but the others have a minimum of 1. KTA has a maximum of 1 always but cKTA's maximum changes as more noise is inputed into the system. I would say that the shapes for the maximum values for HSIC and the minimum values of c/KTA are similar with respect to the amount of noise but HSIC is inverted than the others. Observation III : Reasonable values for minimum noise The c/KTA methods have values close to 1 for almost all gamma values until the MI goes to about 3. After that, the values spread out more. HSIC has a large range of values that can be found but it seems that only with noise do the range of values decrease. Case II - Sine \u00b6 plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'ctka' ) This is a bit trickier. The HSIC seems to be similar. But the other two functions change. It appears that there is a maximum for the HSIC and the cKTA but not for the KTA. Yeet I think the max of the cKTA corresponds to the same values as the KTA. Case III - Circle \u00b6 plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'ctka' ) This is the trickiest case. The HSIC still has a maximum value. But again, the correspondence to meaning doesn't work with the HSIC value scaling. The CTKA and the KTA both don't seem to have a maximum for higher values of MI. Case IV - Random \u00b6 plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'ctka' ) Completely random makes sense. However, the KTA is troubling because the range spans from 0.3 to 1.0 and there is no 0 included... Both the HSIC and the cKTA's range of gamma values seem reasonable.","title":"1 explore exp"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#comparing-hsic-versus-mutual-information-measures","text":"In this notebook, we will be exploring how we can estimate the HSIC parmaeter for different distributions and look at how it compares to MI measures. Normally the procedure for calculating HSIC is as follows: Calculate kernel matrices for X and Y Center both kernel matrices Find the Frobenius norm between the kernel matrices This works well but there is no certain way to estimate the parameter for each of the kernel matrices. There is another paper that is called the Kernel Tangent Alignment (KTA). This method is different as it is calculated like so: Calculate the kernel matrices for X and Y Find the Frobenius norm between the kernel matrices Normalize the value by the Frobenius norm of X and Y individually This works in a similar way to the HSIC method. The difference is that you do the normalization procedure. The final algorithm is the Centered Kernel Tangent Alignment (cKTA) method which is a combination of the previous two methods. The algorithm is as follows: Calculate the kernel matrices for X and Y Center both kernel matrices Find the Frobenius norm between the kernel matrices Normalize the value by the Frobenius norm of X and Y individually As you can see, it would appear that this method is the most complete in the sense that it incorporates all steps to ensure that our data is sufficiently scaled to a way that is directly comparable. This notebook will attempt to see which of these methods provides a good estimate for a sigma value for the kernel matrices and how do their output values compare to mutual information measures.","title":"Comparing HSIC versus Mutual Information measures"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#covariance-vs-correlation","text":"The above methods can be put into perspective of the difference between covariance measures and correlation meausres. In this section, I will explain why that is so. We can write out the full definitions for covariance and correlation. The definition of covariance is: \\text{cov}_{XY}=\\sigma_{XY}=E\\left[(X - \\mu_X)(Y - \\mu_Y) \\right] \\text{cov}_{XY}=\\sigma_{XY}=E\\left[(X - \\mu_X)(Y - \\mu_Y) \\right] The definition of correlation is: \\text{corr}_{XY}=\\rho_{XY}=\\frac{\\sigma_{XY}}{\\sigma_X \\sigma_Y} \\text{corr}_{XY}=\\rho_{XY}=\\frac{\\sigma_{XY}}{\\sigma_X \\sigma_Y} The correlation measure is dimensionless whereas the covariance is in units obtained by multiplying the units of the two variables. Source : Wikipedia on Covariance and correlation Wikipedia on Correlation and dependence","title":"Covariance vs Correlation"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#code","text":"import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload","title":"Code"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#experiment-class","text":"The entire experiment is contained within this class. It features the fixed param, the free params, all the methods with the preprocessing and loading, and the hsic methods. class ExperimentKTA : def __init__ ( self , seed = 123 , n_trials = 10 , hsic_points = 1000 , n_noise = 10 , n_gamma = 50 , factor = 2 , mi_points = 100_000 , sigma_est = 'silverman' , save_path = None , save_name = 'test' ): # fixed experimental params self . seed = seed self . hsic_points = hsic_points self . n_noise = n_noise self . n_gamma = n_gamma self . factor = factor self . mi_points = mi_points self . sigma_est = sigma_est self . n_trials = n_trials self . save_path = save_path self . save_name = save_name # free experimental params self . noise_params = np . logspace ( - 3 , -. 3 , n_noise ) self . func_params = [ 'line' , 'sine' , 'circ' , 'rand' , ] self . scorers = [ 'hsic' , 'tka' , 'ctka' , ] self . seeds = [ i for i in range ( 1 , n_trials + 1 )] # saved dataframe pass def run_experiment ( self ): # initialize results dataframe self . results_df = self . generate_results_df () # Loop through functions for ifunction in self . func_params : print ( f \"Function: { ifunction } \" ) # Loop through noise parameters for inoise in self . noise_params : # Loop through random seeds for iseed in self . seeds : # generate data for MI measure X , Y = self . _generate_data ( inoise , ifunction , iseed , dataset = 'mi' ) # calculate MI mi_score , _ = run_rbig_models ( X , Y , measure = 'mi' , verbose = None , random_state = self . seed ) # ======================= # HSIC MEASURES # ======================= # initialize sigma init_sigma , sigma_params = self . _estimate_sigmas ( X , Y ) # convert to gamma init_gamma = sigma_to_gamma ( init_sigma ) gamma_params = sigma_to_gamma ( sigma_params ) # Loop through HSIC scoring methods for hsic_method in self . scorers : # Loop through gamma parameters for igamma in gamma_params : # generate data for MI measure X , Y = self . _generate_data ( inoise , ifunction , iseed , dataset = 'hsic' ) # Calculate HSIC hsic_score = self . _get_hsic ( X , Y , igamma , None , hsic_method ) # append results to results dataframe self . results_df = self . append_results ( self . results_df , ifunction , iseed , inoise , init_gamma , igamma , hsic_method , hsic_score , mi_score ) # save results to csv self . save_data ( self . results_df ) return self def _generate_data ( self , noise , function , seed , dataset = 'hsic' ): if dataset == 'hsic' : num_points = self . hsic_points elif dataset == 'mi' : num_points = self . mi_points else : raise ValueError ( f 'Unrecoginized dataset: { dataset } ' ) # get dataset X , Y = generate_dependence_data ( dataset = function , num_points = num_points , seed = seed , noise_x = noise , noise_y = noise ) return X , Y def _estimate_sigmas ( self , X , Y ): # estimate initialize sigma sigma_x = estimate_sigma ( X , method = self . sigma_est ) sigma_y = estimate_sigma ( Y , method = self . sigma_est ) # init overall sigma is mean between two init_sigma = np . mean ([ sigma_x , sigma_y ]) # get parameter grid sigmas = get_param_grid ( init_sigma , self . factor , self . n_gamma ) # convert to gammas return init_sigma , sigmas def _get_hsic ( self , X , Y , gamma , subsample , scorer ): # initialize hsic clf_hsic = HSIC ( gamma = gamma , scorer = scorer , subsample = subsample ) # calculate HSIC value clf_hsic . fit ( X , Y ) # return HSIC score return clf_hsic . score ( X ) def generate_results_df ( self ): return pd . DataFrame ( columns = [ 'trial' , 'function' , 'noise' , 'init_gamma' , 'gamma' , 'scorer' , 'value' , 'mi' , ]) def append_results ( self , results_df , function , trial , noise , init_gamma , gamma , hsic_method , hsic_score , mi_score ): # append data return results_df . append ({ 'function' : function , 'trial' : trial , 'noise' : noise , 'init_gamma' : init_gamma , 'gamma' : gamma , 'scorer' : hsic_method , 'value' : hsic_score , 'mi' : mi_score }, ignore_index = True ) def load_data ( self ): pass def save_data ( self , results_df ): results_df . to_csv ( f \" { self . save_path }{ self . save_name } .csv\" )","title":"Experiment Class"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#experiment-run","text":"# experimental params seed = 123 # reproducibility n_trials = 1 # number of trials hsic_points = 10_000 # number of points used for HSIC mi_points = 10_000 # number of points used for MI n_noise = 50 # number of points in noise param grid n_gamma = 50 # number of points in gamma param grid factor = 1 # log factor for gamma param grid bounds sigma_est = 'mean' # sigma initialization save_path = f ' { cwd } /../../results/hsic/' save_name = 'trial_v2_s10k' # initialize experiment class clf_exp = ExperimentKTA ( seed = seed , n_trials = n_trials , hsic_points = hsic_points , factor = factor , mi_points = mi_points , sigma_est = sigma_est , n_noise = n_noise , n_gamma = n_gamma , save_path = save_path , save_name = save_name , ) # run full experiment clf_exp . run_experiment () Function: line projects / 2019 _hsic_align / results / hsic","title":"Experiment Run"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#example","text":"","title":"Example"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#visualize-the-results","text":"","title":"Visualize the Results"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#figure-i-mutual-information-noise","text":"This first figure is to demonstrate how the mutual information compares with the amount of noise for each of the functions Linear , Sinusoidal , Circular , and Random . res_noise = results_df [ 'noise' ] . unique () . tolist () res_gammas = results_df [ 'gamma' ] . unique () . tolist () res_lines = results_df [ 'function' ] . unique () . tolist () fig , ax = plt . subplots () ax . scatter ( results_df [ results_df [ 'function' ] == 'line' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'line' ][ 'mi' ], label = 'Line' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'sine' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'sine' ][ 'mi' ], label = 'Sine' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'circ' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'circ' ][ 'mi' ], label = 'Circle' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'rand' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'rand' ][ 'mi' ], label = 'Random' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . set_xlabel ( 'Noise, $\\sigma_y$' ) ax . set_ylabel ( 'Mutual Information, MI$(X,Y)$' ) # ax.set_xscale('log') plt . legend () ax . set_title ( 'Experimental Parameter Space' ) plt . show () Line This has the most amount of MI with little noise but log-linearly decreases as we increase the noise. Sine This has the 2 nd most amount of MI with little noise. It also decreases as wee increase the noise. Curiously, we find that it has more MI than the linear function at some point around 10^{-2} 10^{-2} amount of noise. It could be due to the amount of structure still present within the sine function. Circle The circle has less MI overall than the linear and sine function and also decreases with added noise. Random There is no mutual information between them no matter how much more noise we inject.","title":"Figure I - Mutual Information &amp; Noise"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#plot-function","text":"def plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ): save_path = f ' { cwd } /../../results/hsic/figures/' # Set Title stuff if function == 'line' : title = 'Linear Function' elif function == 'sine' : title = 'Sine Function' elif function == 'circ' : title = 'Circle Function' elif function == 'rand' : title = 'Random Function' else : raise ValueError ( f 'Unrecognized function: { line } ' ) sub_results_df = results_df [ results_df [ 'function' ] == function ] free_params = [ # 'gamma', 'function' ] fixed_params = [ 'gamma' , 'value' , 'method' , 'mi' ] groups = sub_results_df . groupby ( free_params ) hue = 'gamma' fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 3 )) for iparams , idata in groups : # Plot I - HSIC pts = ax . scatter ( x = idata [ idata [ 'scorer' ] == hsic_method ][ 'value' ], y = idata [ idata [ 'scorer' ] == hsic_method ][ 'mi' ], c = idata [ idata [ 'scorer' ] == hsic_method ][ 'gamma' ], s = 20 , cmap = 'Spectral' , norm = matplotlib . colors . LogNorm () ) ax . set_xlabel ( hsic_method . upper () ) ax . set_ylabel ( 'Mutual Information' ) fig . colorbar ( pts , ax = ax , label = 'Gamma' ) # ax[0].get_legend().remove() # ax[1].get_legend().remove() # ax[2].get_legend().remove() ax . set_yscale ( 'log' ) ax . set_title ( title ) plt . tight_layout () plt . show () fig . savefig ( f \" { save_path } trialv1_ { function } _ { hsic_method } .png\" ) return None","title":"Plot Function"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#figure-ii-mi-vs-gamma-vs-hsic-linear-function","text":"plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'ctka' ) Observation I : The scaling The scales for HSIC method is different than the other two methods. Both KTA and cKTA are bounded at 1 whereas HSIC is only bounded at 0. Or at least from what we can see from the graphs given. It's a slightly different interpretation in the sense that c/KTA will model if they are the same whereas HSIC models if they are Observation II : The shape of the parameter space We can see in the figures above that each of the HSIC estimators have different overall shapes. The HSIC has a minimum of 0 always but the others have a minimum of 1. KTA has a maximum of 1 always but cKTA's maximum changes as more noise is inputed into the system. I would say that the shapes for the maximum values for HSIC and the minimum values of c/KTA are similar with respect to the amount of noise but HSIC is inverted than the others. Observation III : Reasonable values for minimum noise The c/KTA methods have values close to 1 for almost all gamma values until the MI goes to about 3. After that, the values spread out more. HSIC has a large range of values that can be found but it seems that only with noise do the range of values decrease.","title":"Figure II - MI vs Gamma vs HSIC (Linear Function)"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#case-ii-sine","text":"plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'ctka' ) This is a bit trickier. The HSIC seems to be similar. But the other two functions change. It appears that there is a maximum for the HSIC and the cKTA but not for the KTA. Yeet I think the max of the cKTA corresponds to the same values as the KTA.","title":"Case II - Sine"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#case-iii-circle","text":"plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'ctka' ) This is the trickiest case. The HSIC still has a maximum value. But again, the correspondence to meaning doesn't work with the HSIC value scaling. The CTKA and the KTA both don't seem to have a maximum for higher values of MI.","title":"Case III - Circle"},{"location":"notebooks/2_gamma_parameter/1_explore_exp/#case-iv-random","text":"plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'ctka' ) Completely random makes sense. However, the KTA is troubling because the range spans from 0.3 to 1.0 and there is no 0 included... Both the HSIC and the cKTA's range of gamma values seem reasonable.","title":"Case IV - Random"},{"location":"notebooks/2_gamma_parameter/2_visualize_1l/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Visualizing HSIC Measures \u00b6 import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 save_path = f ' { cwd } /../../results/hsic/' save_name = 'trial_v3' results_df = pd . read_csv ( f \" { save_path }{ save_name } .csv\" ) res_noise = results_df [ 'noise' ] . unique () . tolist () res_gammas = results_df [ 'gamma' ] . unique () . tolist () res_lines = results_df [ 'function' ] . unique () . tolist () Figure I - Mutual Information & Noise \u00b6 This first figure is to demonstrate how the mutual information compares with the amount of noise for each of the functions Linear , Sinusoidal , Circular , and Random . fig , ax = plt . subplots () ax . scatter ( results_df [ results_df [ 'function' ] == 'line' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'line' ][ 'mi' ], label = 'Line' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'sine' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'sine' ][ 'mi' ], label = 'Sine' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'circ' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'circ' ][ 'mi' ], label = 'Circle' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'rand' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'rand' ][ 'mi' ], label = 'Random' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . set_xlabel ( 'Noise, $\\sigma_y$' ) ax . set_ylabel ( 'Mutual Information, MI$(X,Y)$' ) # ax.set_xscale('log') plt . legend () ax . set_title ( 'Experimental Parameter Space' ) plt . show () save_path = f ' { cwd } /../../results/hsic/figures/' fig . savefig ( f \" { save_path } trialv1_parameters.png\" ) def plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'hsic' ): save_path = f ' { cwd } /../../results/hsic/figures/' # Set Title stuff if function == 'line' : title = 'Linear Function' elif function == 'sine' : title = 'Sine Function' elif function == 'circ' : title = 'Circle Function' elif function == 'rand' : title = 'Random Function' else : raise ValueError ( f 'Unrecognized function: { line } ' ) sub_results_df = results_df [ results_df [ 'function' ] == function ] free_params = [ # 'gamma', 'function' ] fixed_params = [ 'gamma' , 'value' , 'method' , 'mi' ] groups = sub_results_df . groupby ( free_params ) hue = 'gamma' fig = plt . figure () ax = fig . gca ( projection = '3d' ) for iparams , idata in groups : surf = ax . scatter ( np . log ( idata [ idata [ 'scorer' ] == hsic_method ][ 'mi' ] . values ), np . log ( idata [ idata [ 'scorer' ] == hsic_method ][ 'gamma' ] . values ), idata [ idata [ 'scorer' ] == hsic_method ][ 'value' ] . values , # s=20, c = np . log ( idata [ idata [ 'scorer' ] == hsic_method ][ 'gamma' ] . values ), cmap = 'Spectral' , # norm=matplotlib.colors.LogNorm() ) ax . set_xlabel ( 'Mutual Information' ) ax . set_ylabel ( 'Gamma' ) ax . set_zlabel ( hsic_method . upper () ) fig . colorbar ( surf , ax = ax , label = 'Gamma' ) # ax[0].get_legend().remove() # ax[1].get_legend().remove() # ax[2].get_legend().remove() # ax.set_scale('log') ax . view_init ( 30 , 35 ) ax . set_title ( title ) plt . tight_layout () plt . show () fig . savefig ( f \" { save_path } trialv1_ { function } _ { hsic_method } _3d.png\" ) return None plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'hsic' ) plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'tka' ) plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'ctka' ) def plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ): save_path = f ' { cwd } /../../results/hsic/figures/' # Set Title stuff if function == 'line' : title = 'Linear Function' elif function == 'sine' : title = 'Sine Function' elif function == 'circ' : title = 'Circle Function' elif function == 'rand' : title = 'Random Function' else : raise ValueError ( f 'Unrecognized function: { line } ' ) sub_results_df = results_df [ results_df [ 'function' ] == function ] free_params = [ # 'gamma', 'function' ] fixed_params = [ 'gamma' , 'value' , 'method' , 'mi' ] groups = sub_results_df . groupby ( free_params ) hue = 'gamma' fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 3 )) for iparams , idata in groups : # Plot I - HSIC pts = ax . scatter ( x = idata [ idata [ 'scorer' ] == hsic_method ][ 'value' ], y = idata [ idata [ 'scorer' ] == hsic_method ][ 'mi' ], c = idata [ idata [ 'scorer' ] == hsic_method ][ 'gamma' ], s = 20 , cmap = 'Spectral' , norm = matplotlib . colors . LogNorm () ) ax . set_xlabel ( hsic_method . upper () ) ax . set_ylabel ( 'Mutual Information' ) fig . colorbar ( pts , ax = ax , label = 'Gamma' ) # ax[0].get_legend().remove() # ax[1].get_legend().remove() # ax[2].get_legend().remove() ax . set_yscale ( 'log' ) ax . set_title ( title ) plt . tight_layout () plt . show () fig . savefig ( f \" { save_path } trialv1_ { function } _ { hsic_method } .png\" ) return None Figure II - MI vs Gamma vs HSIC (Linear Function) \u00b6 plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'ctka' ) plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'hsic' ) plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'tka' ) plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'ctka' ) Case II - Sine \u00b6 plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'ctka' ) plot_res_gamma_3D ( results_df , function = 'sine' , hsic_method = 'hsic' ) plot_res_gamma_3D ( results_df , function = 'sine' , hsic_method = 'tka' ) plot_res_gamma_3D ( results_df , function = 'sine' , hsic_method = 'ctka' ) Case III - Circle \u00b6 plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'ctka' ) plot_res_gamma_3D ( results_df , function = 'circ' , hsic_method = 'hsic' ) plot_res_gamma_3D ( results_df , function = 'circ' , hsic_method = 'tka' ) plot_res_gamma_3D ( results_df , function = 'circ' , hsic_method = 'ctka' ) Case IV - Random \u00b6 plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'ctka' ) plot_res_gamma_3D ( results_df , function = 'rand' , hsic_method = 'hsic' ) plot_res_gamma_3D ( results_df , function = 'rand' , hsic_method = 'tka' ) plot_res_gamma_3D ( results_df , function = 'rand' , hsic_method = 'ctka' )","title":"2 visualize 1l"},{"location":"notebooks/2_gamma_parameter/2_visualize_1l/#visualizing-hsic-measures","text":"import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 save_path = f ' { cwd } /../../results/hsic/' save_name = 'trial_v3' results_df = pd . read_csv ( f \" { save_path }{ save_name } .csv\" ) res_noise = results_df [ 'noise' ] . unique () . tolist () res_gammas = results_df [ 'gamma' ] . unique () . tolist () res_lines = results_df [ 'function' ] . unique () . tolist ()","title":"Visualizing HSIC Measures"},{"location":"notebooks/2_gamma_parameter/2_visualize_1l/#figure-i-mutual-information-noise","text":"This first figure is to demonstrate how the mutual information compares with the amount of noise for each of the functions Linear , Sinusoidal , Circular , and Random . fig , ax = plt . subplots () ax . scatter ( results_df [ results_df [ 'function' ] == 'line' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'line' ][ 'mi' ], label = 'Line' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'sine' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'sine' ][ 'mi' ], label = 'Sine' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'circ' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'circ' ][ 'mi' ], label = 'Circle' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'rand' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'rand' ][ 'mi' ], label = 'Random' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . set_xlabel ( 'Noise, $\\sigma_y$' ) ax . set_ylabel ( 'Mutual Information, MI$(X,Y)$' ) # ax.set_xscale('log') plt . legend () ax . set_title ( 'Experimental Parameter Space' ) plt . show () save_path = f ' { cwd } /../../results/hsic/figures/' fig . savefig ( f \" { save_path } trialv1_parameters.png\" ) def plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'hsic' ): save_path = f ' { cwd } /../../results/hsic/figures/' # Set Title stuff if function == 'line' : title = 'Linear Function' elif function == 'sine' : title = 'Sine Function' elif function == 'circ' : title = 'Circle Function' elif function == 'rand' : title = 'Random Function' else : raise ValueError ( f 'Unrecognized function: { line } ' ) sub_results_df = results_df [ results_df [ 'function' ] == function ] free_params = [ # 'gamma', 'function' ] fixed_params = [ 'gamma' , 'value' , 'method' , 'mi' ] groups = sub_results_df . groupby ( free_params ) hue = 'gamma' fig = plt . figure () ax = fig . gca ( projection = '3d' ) for iparams , idata in groups : surf = ax . scatter ( np . log ( idata [ idata [ 'scorer' ] == hsic_method ][ 'mi' ] . values ), np . log ( idata [ idata [ 'scorer' ] == hsic_method ][ 'gamma' ] . values ), idata [ idata [ 'scorer' ] == hsic_method ][ 'value' ] . values , # s=20, c = np . log ( idata [ idata [ 'scorer' ] == hsic_method ][ 'gamma' ] . values ), cmap = 'Spectral' , # norm=matplotlib.colors.LogNorm() ) ax . set_xlabel ( 'Mutual Information' ) ax . set_ylabel ( 'Gamma' ) ax . set_zlabel ( hsic_method . upper () ) fig . colorbar ( surf , ax = ax , label = 'Gamma' ) # ax[0].get_legend().remove() # ax[1].get_legend().remove() # ax[2].get_legend().remove() # ax.set_scale('log') ax . view_init ( 30 , 35 ) ax . set_title ( title ) plt . tight_layout () plt . show () fig . savefig ( f \" { save_path } trialv1_ { function } _ { hsic_method } _3d.png\" ) return None plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'hsic' ) plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'tka' ) plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'ctka' ) def plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ): save_path = f ' { cwd } /../../results/hsic/figures/' # Set Title stuff if function == 'line' : title = 'Linear Function' elif function == 'sine' : title = 'Sine Function' elif function == 'circ' : title = 'Circle Function' elif function == 'rand' : title = 'Random Function' else : raise ValueError ( f 'Unrecognized function: { line } ' ) sub_results_df = results_df [ results_df [ 'function' ] == function ] free_params = [ # 'gamma', 'function' ] fixed_params = [ 'gamma' , 'value' , 'method' , 'mi' ] groups = sub_results_df . groupby ( free_params ) hue = 'gamma' fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 3 )) for iparams , idata in groups : # Plot I - HSIC pts = ax . scatter ( x = idata [ idata [ 'scorer' ] == hsic_method ][ 'value' ], y = idata [ idata [ 'scorer' ] == hsic_method ][ 'mi' ], c = idata [ idata [ 'scorer' ] == hsic_method ][ 'gamma' ], s = 20 , cmap = 'Spectral' , norm = matplotlib . colors . LogNorm () ) ax . set_xlabel ( hsic_method . upper () ) ax . set_ylabel ( 'Mutual Information' ) fig . colorbar ( pts , ax = ax , label = 'Gamma' ) # ax[0].get_legend().remove() # ax[1].get_legend().remove() # ax[2].get_legend().remove() ax . set_yscale ( 'log' ) ax . set_title ( title ) plt . tight_layout () plt . show () fig . savefig ( f \" { save_path } trialv1_ { function } _ { hsic_method } .png\" ) return None","title":"Figure I - Mutual Information &amp; Noise"},{"location":"notebooks/2_gamma_parameter/2_visualize_1l/#figure-ii-mi-vs-gamma-vs-hsic-linear-function","text":"plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'ctka' ) plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'hsic' ) plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'tka' ) plot_res_gamma_3D ( results_df , function = 'line' , hsic_method = 'ctka' )","title":"Figure II - MI vs Gamma vs HSIC (Linear Function)"},{"location":"notebooks/2_gamma_parameter/2_visualize_1l/#case-ii-sine","text":"plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'ctka' ) plot_res_gamma_3D ( results_df , function = 'sine' , hsic_method = 'hsic' ) plot_res_gamma_3D ( results_df , function = 'sine' , hsic_method = 'tka' ) plot_res_gamma_3D ( results_df , function = 'sine' , hsic_method = 'ctka' )","title":"Case II - Sine"},{"location":"notebooks/2_gamma_parameter/2_visualize_1l/#case-iii-circle","text":"plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'ctka' ) plot_res_gamma_3D ( results_df , function = 'circ' , hsic_method = 'hsic' ) plot_res_gamma_3D ( results_df , function = 'circ' , hsic_method = 'tka' ) plot_res_gamma_3D ( results_df , function = 'circ' , hsic_method = 'ctka' )","title":"Case III - Circle"},{"location":"notebooks/2_gamma_parameter/2_visualize_1l/#case-iv-random","text":"plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'ctka' ) plot_res_gamma_3D ( results_df , function = 'rand' , hsic_method = 'hsic' ) plot_res_gamma_3D ( results_df , function = 'rand' , hsic_method = 'tka' ) plot_res_gamma_3D ( results_df , function = 'rand' , hsic_method = 'ctka' )","title":"Case IV - Random"},{"location":"notebooks/2_gamma_parameter/2_visualize_20k/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Visualizing HSIC Measures \u00b6 import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload ! ls / home / emmanuel / projects / 2019 _hsic_align / results / hsic / dist_v1_belkin.csv gamma_v1_median_f1.csv scale_v1.csv dist_v1_gamma.csv gamma_v1_median_f2.csv trial_large_v1.csv dist_v2_belkin.csv large_v2_silv.csv trial_v2_s20k.csv dist_v4_median.csv large_v3_silv.csv trial_v3.csv figures large_v4_mean.csv gamma_v1_median.csv large_v4_silv.csv save_path = f '/home/emmanuel/projects/2019_hsic_align/results/hsic/' save_name = 'gamma_v1_median_f2' results_df = pd . read_csv ( f \" { save_path }{ save_name } .csv\" ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 trial function noise init_gamma gamma scorer value mi 29995 29995 1 rand 0.501187 5.809637 0.123220 ctka 0.000252 0.009215 29996 29996 1 rand 0.501187 5.809637 0.102105 ctka 0.000253 0.009215 29997 29997 1 rand 0.501187 5.809637 0.084609 ctka 0.000253 0.009215 29998 29998 1 rand 0.501187 5.809637 0.070110 ctka 0.000254 0.009215 29999 29999 1 rand 0.501187 5.809637 0.058096 ctka 0.000254 0.009215 res_noise = results_df [ 'noise' ] . unique () . tolist () res_gammas = results_df [ 'gamma' ] . unique () . tolist () res_lines = results_df [ 'function' ] . unique () . tolist () Figure I - Mutual Information & Noise \u00b6 This first figure is to demonstrate how the mutual information compares with the amount of noise for each of the functions Linear , Sinusoidal , Circular , and Random . fig , ax = plt . subplots () ax . scatter ( results_df [ results_df [ 'function' ] == 'line' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'line' ][ 'mi' ], label = 'Line' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'sine' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'sine' ][ 'mi' ], label = 'Sine' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'circ' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'circ' ][ 'mi' ], label = 'Circle' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'rand' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'rand' ][ 'mi' ], label = 'Random' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . set_xlabel ( 'Noise, $\\sigma_y$' ) ax . set_ylabel ( 'Mutual Information, MI$(X,Y)$' ) # ax.set_xscale('log') plt . legend () ax . set_title ( 'Experimental Parameter Space' ) plt . show () def plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ): save_path = f ' { cwd } /../../results/figures/gamma_param/' # Set Title stuff if function == 'line' : title = 'Linear Function' elif function == 'sine' : title = 'Sine Function' elif function == 'circ' : title = 'Circle Function' elif function == 'rand' : title = 'Random Function' else : raise ValueError ( f 'Unrecognized function: { line } ' ) sub_results_df = results_df [ results_df [ 'function' ] == function ] free_params = [ # 'gamma', 'function' ] fixed_params = [ 'gamma' , 'value' , 'method' , 'mi' ] groups = sub_results_df . groupby ( free_params ) hue = 'gamma' fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 3 )) for iparams , idata in groups : # Plot I - HSIC pts = ax . scatter ( x = idata [ idata [ 'scorer' ] == hsic_method ][ 'value' ], y = idata [ idata [ 'scorer' ] == hsic_method ][ 'mi' ], c = idata [ idata [ 'scorer' ] == hsic_method ][ 'gamma' ], s = 20 , cmap = 'Spectral' , norm = matplotlib . colors . LogNorm () ) ax . set_xlabel ( hsic_method . upper () ) ax . set_ylabel ( 'Mutual Information' ) fig . colorbar ( pts , ax = ax , label = 'Gamma' ) # ax[0].get_legend().remove() # ax[1].get_legend().remove() # ax[2].get_legend().remove() ax . set_yscale ( 'log' ) ax . set_title ( title ) plt . tight_layout () plt . show () fig . savefig ( f \" { save_path } trialv1_ { function } _ { hsic_method } .png\" ) return None Figure II - MI vs Gamma vs HSIC (Linear Function) \u00b6 plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'ctka' ) Case II - Sine \u00b6 plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'ctka' ) Case III - Circle \u00b6 plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'ctka' ) Case IV - Random \u00b6 plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'ctka' )","title":"2 visualize 20k"},{"location":"notebooks/2_gamma_parameter/2_visualize_20k/#visualizing-hsic-measures","text":"import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload ! ls / home / emmanuel / projects / 2019 _hsic_align / results / hsic / dist_v1_belkin.csv gamma_v1_median_f1.csv scale_v1.csv dist_v1_gamma.csv gamma_v1_median_f2.csv trial_large_v1.csv dist_v2_belkin.csv large_v2_silv.csv trial_v2_s20k.csv dist_v4_median.csv large_v3_silv.csv trial_v3.csv figures large_v4_mean.csv gamma_v1_median.csv large_v4_silv.csv save_path = f '/home/emmanuel/projects/2019_hsic_align/results/hsic/' save_name = 'gamma_v1_median_f2' results_df = pd . read_csv ( f \" { save_path }{ save_name } .csv\" ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 trial function noise init_gamma gamma scorer value mi 29995 29995 1 rand 0.501187 5.809637 0.123220 ctka 0.000252 0.009215 29996 29996 1 rand 0.501187 5.809637 0.102105 ctka 0.000253 0.009215 29997 29997 1 rand 0.501187 5.809637 0.084609 ctka 0.000253 0.009215 29998 29998 1 rand 0.501187 5.809637 0.070110 ctka 0.000254 0.009215 29999 29999 1 rand 0.501187 5.809637 0.058096 ctka 0.000254 0.009215 res_noise = results_df [ 'noise' ] . unique () . tolist () res_gammas = results_df [ 'gamma' ] . unique () . tolist () res_lines = results_df [ 'function' ] . unique () . tolist ()","title":"Visualizing HSIC Measures"},{"location":"notebooks/2_gamma_parameter/2_visualize_20k/#figure-i-mutual-information-noise","text":"This first figure is to demonstrate how the mutual information compares with the amount of noise for each of the functions Linear , Sinusoidal , Circular , and Random . fig , ax = plt . subplots () ax . scatter ( results_df [ results_df [ 'function' ] == 'line' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'line' ][ 'mi' ], label = 'Line' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'sine' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'sine' ][ 'mi' ], label = 'Sine' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'circ' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'circ' ][ 'mi' ], label = 'Circle' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . scatter ( results_df [ results_df [ 'function' ] == 'rand' ][ 'noise' ], results_df [ results_df [ 'function' ] == 'rand' ][ 'mi' ], label = 'Random' ) plt . xscale ( 'log' ) plt . yscale ( 'log' ) ax . set_xlabel ( 'Noise, $\\sigma_y$' ) ax . set_ylabel ( 'Mutual Information, MI$(X,Y)$' ) # ax.set_xscale('log') plt . legend () ax . set_title ( 'Experimental Parameter Space' ) plt . show () def plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ): save_path = f ' { cwd } /../../results/figures/gamma_param/' # Set Title stuff if function == 'line' : title = 'Linear Function' elif function == 'sine' : title = 'Sine Function' elif function == 'circ' : title = 'Circle Function' elif function == 'rand' : title = 'Random Function' else : raise ValueError ( f 'Unrecognized function: { line } ' ) sub_results_df = results_df [ results_df [ 'function' ] == function ] free_params = [ # 'gamma', 'function' ] fixed_params = [ 'gamma' , 'value' , 'method' , 'mi' ] groups = sub_results_df . groupby ( free_params ) hue = 'gamma' fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 3 )) for iparams , idata in groups : # Plot I - HSIC pts = ax . scatter ( x = idata [ idata [ 'scorer' ] == hsic_method ][ 'value' ], y = idata [ idata [ 'scorer' ] == hsic_method ][ 'mi' ], c = idata [ idata [ 'scorer' ] == hsic_method ][ 'gamma' ], s = 20 , cmap = 'Spectral' , norm = matplotlib . colors . LogNorm () ) ax . set_xlabel ( hsic_method . upper () ) ax . set_ylabel ( 'Mutual Information' ) fig . colorbar ( pts , ax = ax , label = 'Gamma' ) # ax[0].get_legend().remove() # ax[1].get_legend().remove() # ax[2].get_legend().remove() ax . set_yscale ( 'log' ) ax . set_title ( title ) plt . tight_layout () plt . show () fig . savefig ( f \" { save_path } trialv1_ { function } _ { hsic_method } .png\" ) return None","title":"Figure I - Mutual Information &amp; Noise"},{"location":"notebooks/2_gamma_parameter/2_visualize_20k/#figure-ii-mi-vs-gamma-vs-hsic-linear-function","text":"plot_res_gamma ( results_df , function = 'line' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'line' , hsic_method = 'ctka' )","title":"Figure II - MI vs Gamma vs HSIC (Linear Function)"},{"location":"notebooks/2_gamma_parameter/2_visualize_20k/#case-ii-sine","text":"plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'sine' , hsic_method = 'ctka' )","title":"Case II - Sine"},{"location":"notebooks/2_gamma_parameter/2_visualize_20k/#case-iii-circle","text":"plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'circ' , hsic_method = 'ctka' )","title":"Case III - Circle"},{"location":"notebooks/2_gamma_parameter/2_visualize_20k/#case-iv-random","text":"plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'hsic' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'tka' ) plot_res_gamma ( results_df , function = 'rand' , hsic_method = 'ctka' )","title":"Case IV - Random"},{"location":"notebooks/2_gamma_parameter/gamma_trial_experiment/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import RBIGData # Experiments from experiments.param_space import ExperimentGamma # Kernel Dependency measure from models.dependence import HSIC , train_rbf_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import scipy.io as scio import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload SAVE_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/hsic/\" clf_exp = ExperimentGamma ( seed = 123 , n_trials = 1 , mi_points = 10_000 , n_noise = 50 , n_gamma = 50 , factor = 2 , sigma_est = 'median' , save_path = SAVE_PATH , save_name = 'gamma_v1_median' , ) # run full experiment clf_exp . run_experiment () Function: line --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) <ipython-input-6-92a6f1263002> in <module> 14 15 # run full experiment ---> 16 clf_exp . run_experiment ( ) ~/projects/2019_hsic_align/notebooks/2_gamma_parameter/../../src/experiments/param_space.py in run_experiment (self) 121 hsic_method , 122 hsic_score , --> 123 mi_score , 124 ) 125 ~/projects/2019_hsic_align/notebooks/2_gamma_parameter/../../src/experiments/param_space.py in append_results (self, results_df, function, trial, noise, init_gamma, gamma, hsic_method, hsic_score, mi_score) 234 \"mi\" : mi_score , 235 }, --> 236 ignore_index = True , 237 ) 238 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/frame.py in append (self, other, ignore_index, verify_integrity, sort) 7121 ignore_index = ignore_index , 7122 verify_integrity = verify_integrity , -> 7123 sort = sort , 7124 ) 7125 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/reshape/concat.py in concat (objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy) 256 ) 257 --> 258 return op . get_result ( ) 259 260 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/reshape/concat.py in get_result (self) 471 472 new_data = concatenate_block_managers( --> 473 mgrs_indexers , self . new_axes , concat_axis = self . axis , copy = self . copy 474 ) 475 if not self . copy : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/managers.py in concatenate_block_managers (mgrs_indexers, axes, concat_axis, copy) 2052 else : 2053 b = make_block( -> 2054 concatenate_join_units ( join_units , concat_axis , copy = copy ) , 2055 placement = placement , 2056 ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/concat.py in concatenate_join_units (join_units, concat_axis, copy) 251 to_concat = [ 252 ju . get_reindexed_values ( empty_dtype = empty_dtype , upcasted_na = upcasted_na ) --> 253 for ju in join_units 254 ] 255 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/concat.py in <listcomp> (.0) 251 to_concat = [ 252 ju . get_reindexed_values ( empty_dtype = empty_dtype , upcasted_na = upcasted_na ) --> 253 for ju in join_units 254 ] 255 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/concat.py in get_reindexed_values (self, empty_dtype, upcasted_na) 234 else : 235 for ax , indexer in self . indexers . items ( ) : --> 236 values = algos . take_nd ( values , indexer , axis = ax , fill_value = fill_value ) 237 238 return values ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd (arr, indexer, axis, out, fill_value, mask_info, allow_fill) 1717 1718 func = _get_take_nd_function( -> 1719 arr . ndim , arr . dtype , out . dtype , axis = axis , mask_info = mask_info 1720 ) 1721 func ( arr , indexer , out , fill_value ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/algorithms.py in _get_take_nd_function (ndim, arr_dtype, out_dtype, axis, mask_info) 1481 def _get_take_nd_function ( ndim , arr_dtype , out_dtype , axis = 0 , mask_info = None ) : 1482 if ndim <= 2 : -> 1483 tup = ( arr_dtype . name , out_dtype . name ) 1484 if ndim == 1 : 1485 func = _take_1d_dict . get ( tup , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/numpy/core/_dtype.py in _name_get (dtype) 325 326 # Builtin classes are documented as returning a \"bit name\" --> 327 name = dtype . type . __name__ 328 329 # handle bool_, str_, etc KeyboardInterrupt :","title":"Gamma trial experiment"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Checking the Isotropic scaling \u00b6 In this notebook, we will do a short demonstration for how the HSIC suffers from isotropic scaling factor. As outlined in this paper ,in a nutshell, we would prefer to have similarity measures that following the following properties: Invariance to Invertible Linear Transformations s(X,Y) = s(XA, YB) s(X,Y) = s(XA, YB) for any full rank A A and B B . Invariance to Orthogonal Transformation s(X,Y) = s(XU,YV) s(X,Y) = s(XU,YV) where U^\\top U=I U^\\top U=I and V^\\top V=I V^\\top V=I . Invariance to Isotropic Scaling s(X, Y)=s(\\alpha X, \\beta Y) s(X, Y)=s(\\alpha X, \\beta Y) where \\alpha,\\beta \\in \\mathbb{R}^+ \\alpha,\\beta \\in \\mathbb{R}^+ . Code \u00b6 import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC , train_rbf_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib.pyplot as plt import seaborn as sns plt . style . use ( 'ggplot' ) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 Example \u00b6 Data \u00b6 def get_data ( dataset = 'sine' , num_points = 1000 , seed = 123 , noise_x = 0.1 , noise_y = 0.1 ): # data params dataset = 'sine' num_points = 1000 seed = 123 noise_x = 0.1 noise_y = 0.1 alpha = 10 beta = 10 # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise_x , noise_y = noise_y ) return X , Y # data params dataset = 'sine' num_points = 1000 seed = 123 noise_x = 0.1 noise_y = 0.1 alpha = 10 beta = 10 # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise_x , noise_y = noise_y ) # plot fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 5 )) ax . scatter ( alpha * X , Y ) plt . legend ( fontsize = 20 ) plt . xticks ( fontsize = 20 ) plt . yticks ( fontsize = 20 ) plt . tight_layout () plt . show () save_path = f ' { cwd } /../../results/hsic/figures/demo/' fig . savefig ( f \" { save_path } demo_ { dataset } .png\" ) No handles with labels found to put in legend. Noise in the Data \u00b6 Linear Sinusoidal Circle Random Experiment \u00b6 We want a method that is invariant to an orthogonal transformation as well as isotropic scaling. The HSIC method is invariant to orthogonal transformations but not isotropic scaling. This can actually be rectified by simply normalizing the measure which is apparent in the centered kernel alignment measure (cKA). This notebook will be doing a short demonstration as to how the HSIC measure changes due to isotropic scaling whereas the cKA is not. Fixed Experimental Parameters Dataset - Sinesoidal Curve > This is sufficiently nonlinear with some dependencies within the data. Complex but simple to analyze. Kernel - RBF > A universal kernel that's quite simple and can potentially model any function. Gamma - silverman of data > We found in the previous notebook that the silverman works as a pretty decent estimator for the data. So we will reuse it in this experiment as well. n_samples, d_dimensions Free Experimental Parameters HSIC method (HSIC, KA, cKA) Scale applied to the data Helper Functions \u00b6 def get_hsic ( X , Y , scorer = 'hsic' , kernel = 'rbf' , gamma = 1.0 ): # hsic params subsample = None bias = True # initialize HSIC calculator clf_hsic = HSIC ( gamma = gamma , kernel = kernel , scorer = scorer , subsample = subsample , bias = bias ) # calculate HSIC return scorer clf_hsic . fit ( X , Y ); # hsic value and kernel alignment score return clf_hsic . hsic_value Experiment I - Linear Kernel \u00b6 # Fixed Params (Data) dataset = 'line' num_points = 1000 seed = 123 noise_x = 0.1 noise_y = 0.1 beta = 1.0 # Fixed Params (Algorithms) sigma_est = 'median' kernel = 'linear' # Free Params alphas = np . logspace ( - 2 , 2 , 10 ) scorers = [ 'hsic' , 'tka' , 'ctka' ] results_df = pd . DataFrame ( columns = [ 'scorer' , 'hsic' , 'scale' , 'gamma' ]) for iscorer in scorers : for ialpha in alphas : # generate data X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise_x , noise_y = noise_y , ) # Scale X,Y by factor alpha, beta X *= ialpha Y *= 1.0 # estimate sigma values init_sigma_X = estimate_sigma ( X , method = sigma_est ) init_sigma_Y = estimate_sigma ( Y , method = sigma_est ) init_sigma = np . mean ([ init_sigma_X , init_sigma_Y ]) init_gamma = sigma_to_gamma ( init_sigma ) # Calculate HSIC value hsic_val = get_hsic ( X , Y , scorer = iscorer , kernel = kernel , gamma = init_gamma ) # save results to dataframe results_df = results_df . append ({ 'scorer' : iscorer , 'hsic' : hsic_val , 'scale' : ialpha , 'gamma' : init_gamma , }, ignore_index = True ) results_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } scorer hsic scale gamma 0 hsic 6.436471e-07 0.010000 21.881260 1 hsic 4.983526e-06 0.027826 21.154142 2 hsic 3.858563e-05 0.077426 19.311447 3 hsic 2.987545e-04 0.215443 15.286885 4 hsic 2.313148e-03 0.599484 8.950672 Results \u00b6 def plot_results ( results_df , scorer ): # subset dataframe based on scorer results_df = results_df [ results_df [ 'scorer' ] == scorer ] # plot results fig , ax = plt . subplots ( ncols = 2 , figsize = ( 10 , 5 )) sns . lineplot ( x = \"scale\" , y = \"hsic\" , data = results_df , ax = ax [ 0 ]) sns . lineplot ( x = \"scale\" , y = \"gamma\" , data = results_df , ax = ax [ 1 ]) ax [ 0 ] . set_ylabel ( scorer . upper ()) ax [ 1 ] . set_yscale ( 'log' ) plt . show () plot_results ( results_df , 'hsic' ) plot_results ( results_df , 'tka' ) plot_results ( results_df , 'ctka' ) Experiment II - RBF Kernel \u00b6 # Fixed Params (Data) dataset = 'circ' num_points = 1000 seed = 123 noise_x = 0.1 noise_y = 0.1 beta = 1.0 # Fixed Params (Algorithms) sigma_est = 'belkin' kernel = 'rbf' # Free Params alphas = np . logspace ( - 2 , 2 , 10 ) scorers = [ 'hsic' , 'tka' , 'ctka' ] results_df = pd . DataFrame ( columns = [ 'scorer' , 'hsic' , 'scale' , 'gamma' ]) for iscorer in scorers : for ialpha in alphas : # generate data X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise_x , noise_y = noise_y , ) # print(X.min(), X.max()) # Scale X,Y by factor alpha, beta X *= ialpha Y *= ialpha # print(X.min(), X.max()) # estimate sigma values init_sigma_X = estimate_sigma ( X , method = sigma_est ) init_sigma_Y = estimate_sigma ( Y , method = sigma_est ) # print(init_sigma_X, init_sigma_Y) init_sigma = np . mean ([ init_sigma_X , init_sigma_Y ]) init_gamma = sigma_to_gamma ( init_sigma ) # Calculate HSIC value hsic_val = get_hsic ( X , Y , scorer = iscorer , kernel = kernel , gamma = init_gamma ) # save results to dataframe results_df = results_df . append ({ 'scorer' : iscorer , 'hsic' : hsic_val , 'scale' : ialpha , 'gamma' : init_gamma , }, ignore_index = True ) plot_results ( results_df , 'hsic' ) plot_results ( results_df , 'tka' ) plot_results ( results_df , 'ctka' ) Experiment III - Optimized RBF Gamma \u00b6 # Fixed Params (Data) dataset = 'circ' num_points = 1000 seed = 123 noise_x = 0.1 noise_y = 0.1 beta = 1.0 # Fixed Params (Algorithms) sigma_est = 'belkin' kernel = 'rbf' n_gamma = 50 factor = 2 n_jobs = - 1 cv = 2 # Free Params alphas = np . logspace ( - 2 , 2 , 10 ) scorers = [ 'hsic' , 'tka' , 'ctka' ] results_df = pd . DataFrame ( columns = [ 'scorer' , 'hsic' , 'scale' , 'gamma' ]) for iscorer in scorers : for ialpha in alphas : # generate data X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise_x , noise_y = noise_y , ) # Scale X,Y by factor alpha, beta # print(ialpha) X *= ialpha Y *= ialpha # estimate sigma values init_sigma_X = estimate_sigma ( X , method = sigma_est ) init_sigma_Y = estimate_sigma ( Y , method = sigma_est ) init_sigma = np . mean ([ init_sigma_X , init_sigma_Y ]) init_gamma = sigma_to_gamma ( init_sigma ) # Calculate HSIC value clf_hsic = train_rbf_hsic ( X , Y , scorer = iscorer , n_gamma = n_gamma , factor = factor , sigma_est = sigma_est , ) hsic_val = clf_hsic . score ( X ) # save results to dataframe results_df = results_df . append ({ 'scorer' : iscorer , 'hsic' : hsic_val , 'scale' : ialpha , 'gamma' : init_gamma , }, ignore_index = True ) Results \u00b6 plot_results ( results_df , 'hsic' ) plot_results ( results_df , 'tka' ) plot_results ( results_df , 'ctka' )","title":"0 preliminary exp Copy1"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#checking-the-isotropic-scaling","text":"In this notebook, we will do a short demonstration for how the HSIC suffers from isotropic scaling factor. As outlined in this paper ,in a nutshell, we would prefer to have similarity measures that following the following properties: Invariance to Invertible Linear Transformations s(X,Y) = s(XA, YB) s(X,Y) = s(XA, YB) for any full rank A A and B B . Invariance to Orthogonal Transformation s(X,Y) = s(XU,YV) s(X,Y) = s(XU,YV) where U^\\top U=I U^\\top U=I and V^\\top V=I V^\\top V=I . Invariance to Isotropic Scaling s(X, Y)=s(\\alpha X, \\beta Y) s(X, Y)=s(\\alpha X, \\beta Y) where \\alpha,\\beta \\in \\mathbb{R}^+ \\alpha,\\beta \\in \\mathbb{R}^+ .","title":"Checking the Isotropic scaling"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#code","text":"import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC , train_rbf_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib.pyplot as plt import seaborn as sns plt . style . use ( 'ggplot' ) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2","title":"Code"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#example","text":"","title":"Example"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#data","text":"def get_data ( dataset = 'sine' , num_points = 1000 , seed = 123 , noise_x = 0.1 , noise_y = 0.1 ): # data params dataset = 'sine' num_points = 1000 seed = 123 noise_x = 0.1 noise_y = 0.1 alpha = 10 beta = 10 # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise_x , noise_y = noise_y ) return X , Y # data params dataset = 'sine' num_points = 1000 seed = 123 noise_x = 0.1 noise_y = 0.1 alpha = 10 beta = 10 # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise_x , noise_y = noise_y ) # plot fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 5 )) ax . scatter ( alpha * X , Y ) plt . legend ( fontsize = 20 ) plt . xticks ( fontsize = 20 ) plt . yticks ( fontsize = 20 ) plt . tight_layout () plt . show () save_path = f ' { cwd } /../../results/hsic/figures/demo/' fig . savefig ( f \" { save_path } demo_ { dataset } .png\" ) No handles with labels found to put in legend.","title":"Data"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#noise-in-the-data","text":"Linear Sinusoidal Circle Random","title":"Noise in the Data"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#experiment","text":"We want a method that is invariant to an orthogonal transformation as well as isotropic scaling. The HSIC method is invariant to orthogonal transformations but not isotropic scaling. This can actually be rectified by simply normalizing the measure which is apparent in the centered kernel alignment measure (cKA). This notebook will be doing a short demonstration as to how the HSIC measure changes due to isotropic scaling whereas the cKA is not. Fixed Experimental Parameters Dataset - Sinesoidal Curve > This is sufficiently nonlinear with some dependencies within the data. Complex but simple to analyze. Kernel - RBF > A universal kernel that's quite simple and can potentially model any function. Gamma - silverman of data > We found in the previous notebook that the silverman works as a pretty decent estimator for the data. So we will reuse it in this experiment as well. n_samples, d_dimensions Free Experimental Parameters HSIC method (HSIC, KA, cKA) Scale applied to the data","title":"Experiment"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#helper-functions","text":"def get_hsic ( X , Y , scorer = 'hsic' , kernel = 'rbf' , gamma = 1.0 ): # hsic params subsample = None bias = True # initialize HSIC calculator clf_hsic = HSIC ( gamma = gamma , kernel = kernel , scorer = scorer , subsample = subsample , bias = bias ) # calculate HSIC return scorer clf_hsic . fit ( X , Y ); # hsic value and kernel alignment score return clf_hsic . hsic_value","title":"Helper Functions"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#experiment-i-linear-kernel","text":"# Fixed Params (Data) dataset = 'line' num_points = 1000 seed = 123 noise_x = 0.1 noise_y = 0.1 beta = 1.0 # Fixed Params (Algorithms) sigma_est = 'median' kernel = 'linear' # Free Params alphas = np . logspace ( - 2 , 2 , 10 ) scorers = [ 'hsic' , 'tka' , 'ctka' ] results_df = pd . DataFrame ( columns = [ 'scorer' , 'hsic' , 'scale' , 'gamma' ]) for iscorer in scorers : for ialpha in alphas : # generate data X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise_x , noise_y = noise_y , ) # Scale X,Y by factor alpha, beta X *= ialpha Y *= 1.0 # estimate sigma values init_sigma_X = estimate_sigma ( X , method = sigma_est ) init_sigma_Y = estimate_sigma ( Y , method = sigma_est ) init_sigma = np . mean ([ init_sigma_X , init_sigma_Y ]) init_gamma = sigma_to_gamma ( init_sigma ) # Calculate HSIC value hsic_val = get_hsic ( X , Y , scorer = iscorer , kernel = kernel , gamma = init_gamma ) # save results to dataframe results_df = results_df . append ({ 'scorer' : iscorer , 'hsic' : hsic_val , 'scale' : ialpha , 'gamma' : init_gamma , }, ignore_index = True ) results_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } scorer hsic scale gamma 0 hsic 6.436471e-07 0.010000 21.881260 1 hsic 4.983526e-06 0.027826 21.154142 2 hsic 3.858563e-05 0.077426 19.311447 3 hsic 2.987545e-04 0.215443 15.286885 4 hsic 2.313148e-03 0.599484 8.950672","title":"Experiment I - Linear Kernel"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#results","text":"def plot_results ( results_df , scorer ): # subset dataframe based on scorer results_df = results_df [ results_df [ 'scorer' ] == scorer ] # plot results fig , ax = plt . subplots ( ncols = 2 , figsize = ( 10 , 5 )) sns . lineplot ( x = \"scale\" , y = \"hsic\" , data = results_df , ax = ax [ 0 ]) sns . lineplot ( x = \"scale\" , y = \"gamma\" , data = results_df , ax = ax [ 1 ]) ax [ 0 ] . set_ylabel ( scorer . upper ()) ax [ 1 ] . set_yscale ( 'log' ) plt . show () plot_results ( results_df , 'hsic' ) plot_results ( results_df , 'tka' ) plot_results ( results_df , 'ctka' )","title":"Results"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#experiment-ii-rbf-kernel","text":"# Fixed Params (Data) dataset = 'circ' num_points = 1000 seed = 123 noise_x = 0.1 noise_y = 0.1 beta = 1.0 # Fixed Params (Algorithms) sigma_est = 'belkin' kernel = 'rbf' # Free Params alphas = np . logspace ( - 2 , 2 , 10 ) scorers = [ 'hsic' , 'tka' , 'ctka' ] results_df = pd . DataFrame ( columns = [ 'scorer' , 'hsic' , 'scale' , 'gamma' ]) for iscorer in scorers : for ialpha in alphas : # generate data X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise_x , noise_y = noise_y , ) # print(X.min(), X.max()) # Scale X,Y by factor alpha, beta X *= ialpha Y *= ialpha # print(X.min(), X.max()) # estimate sigma values init_sigma_X = estimate_sigma ( X , method = sigma_est ) init_sigma_Y = estimate_sigma ( Y , method = sigma_est ) # print(init_sigma_X, init_sigma_Y) init_sigma = np . mean ([ init_sigma_X , init_sigma_Y ]) init_gamma = sigma_to_gamma ( init_sigma ) # Calculate HSIC value hsic_val = get_hsic ( X , Y , scorer = iscorer , kernel = kernel , gamma = init_gamma ) # save results to dataframe results_df = results_df . append ({ 'scorer' : iscorer , 'hsic' : hsic_val , 'scale' : ialpha , 'gamma' : init_gamma , }, ignore_index = True ) plot_results ( results_df , 'hsic' ) plot_results ( results_df , 'tka' ) plot_results ( results_df , 'ctka' )","title":"Experiment II - RBF Kernel"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#experiment-iii-optimized-rbf-gamma","text":"# Fixed Params (Data) dataset = 'circ' num_points = 1000 seed = 123 noise_x = 0.1 noise_y = 0.1 beta = 1.0 # Fixed Params (Algorithms) sigma_est = 'belkin' kernel = 'rbf' n_gamma = 50 factor = 2 n_jobs = - 1 cv = 2 # Free Params alphas = np . logspace ( - 2 , 2 , 10 ) scorers = [ 'hsic' , 'tka' , 'ctka' ] results_df = pd . DataFrame ( columns = [ 'scorer' , 'hsic' , 'scale' , 'gamma' ]) for iscorer in scorers : for ialpha in alphas : # generate data X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise_x , noise_y = noise_y , ) # Scale X,Y by factor alpha, beta # print(ialpha) X *= ialpha Y *= ialpha # estimate sigma values init_sigma_X = estimate_sigma ( X , method = sigma_est ) init_sigma_Y = estimate_sigma ( Y , method = sigma_est ) init_sigma = np . mean ([ init_sigma_X , init_sigma_Y ]) init_gamma = sigma_to_gamma ( init_sigma ) # Calculate HSIC value clf_hsic = train_rbf_hsic ( X , Y , scorer = iscorer , n_gamma = n_gamma , factor = factor , sigma_est = sigma_est , ) hsic_val = clf_hsic . score ( X ) # save results to dataframe results_df = results_df . append ({ 'scorer' : iscorer , 'hsic' : hsic_val , 'scale' : ialpha , 'gamma' : init_gamma , }, ignore_index = True )","title":"Experiment III - Optimized RBF Gamma"},{"location":"notebooks/3_isotropic_scaling/0_preliminary_exp-Copy1/#results_1","text":"plot_results ( results_df , 'hsic' ) plot_results ( results_df , 'tka' ) plot_results ( results_df , 'ctka' )","title":"Results"},{"location":"notebooks/3_isotropic_scaling/2.0_scale_viz/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Isotropic Scaling Experiment \u00b6 Synopsis \u00b6 In this experiment, I will be looking at how the isotropic scaling effects the HSIC score for the HSIC and KA algorithms. In theory, because we are trying to find one parameter shared between the two kernel functions, there should be problems when the scale of one distribution is larger than another. It's a drawback of the method and it motivates the need to use two different parameters for the distributions. Code \u00b6 import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import warnings import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.toy import generate_dependence_data , generate_isotropic_data # Kernel Dependency measure from models.train_models import get_gamma_init from models.train_models import get_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid from models.ite_algorithms import run_rbig_models from sklearn.preprocessing import StandardScaler # Plotting from visualization.distribution import plot_scorer from visualization.scaling import plot_scorer_scale , plot_scorer_scale_norm # experiment helpers from tqdm import tqdm # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns # plt.style.use(['fivethirtyeight', 'seaborn-poster']) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline % load_ext autoreload % autoreload 2 Experimental Design \u00b6 The objective of this experiment is to measure how the Mutual information (MI) changes related to the HSIC score of different methods when we change the data and preprocessing conditions (normalization and scale). We change the nature of the data via the scale of the data received and whether or not we do a normalization procedure before we submit the datasets to our HSIC algorithms. Each HSIC method will give us a score and we can calculate the Mutual information Free Params Number of Trials ( seed ) 1:10 Scale or not scaled ( scale ) Normalized | Not Normalized ( normalize ) HSIC Algorithm ( method ) HSIC, KA, cKA Dataset ( dataset ) Linear, Sinusoidal, Circle, Random Amount of Noise ( noise List) log space Measurements Mutual Information ( mi ) HSIC score ( score ) Time for execution ( time ) Fixed Parameters Number of points ( num_points ) Noise for X points ( noise_x ) Noise for Y points ( noise_y ) from typing import Optional SAVE_PATH = '/home/emmanuel/figures/hsicalign/' plt . style . use ([ 'seaborn-talk' ]) def plot_results ( df : pd . DataFrame , scorer : str , hue : Optional [ str ] = None , style : Optional [ str ] = None , save_name : Optional [ str ] = None ) -> None : df = df [ df [ 'scorer' ] == scorer ] # plot data fig , ax = plt . subplots () pts = sns . scatterplot ( x = 'hsic_value' , y = 'mi' , hue = hue , style = style , data = df ) ax . set_ylabel ( 'Mutual Information' , fontsize = 20 ) ax . set_xlabel ( 'Score' , fontsize = 20 ) ax . legend ( fontsize = 20 ) if save_name is not None : fig . savefig ( SAVE_PATH + f \" { scorer } _ { save_name } .png\" ) plt . show () return Data \u00b6 cwd '/home/emmanuel/projects/2019_hsic_align/notebooks/3_isotropic_scaling' PROJECT_PATH = f \" { cwd } /../../\" RES_PATH = PROJECT_PATH + 'data/results/scaling/' RES_PATH '/home/emmanuel/projects/2019_hsic_align/notebooks/3_isotropic_scaling/../../data/results/scaling/' ! ls '/home/emmanuel/projects/2019_hsic_align/notebooks/3_isotropic_scaling/../../data/results/scaling/' exp_scale_c1.csv exp_scale_c2_v2.csv exp_scale_c4.csv exp_scale_c1_v1.csv exp_scale_c2_v3.csv exp_scale_c4_v1.csv exp_scale_c1_v2.csv exp_scale_c3.csv exp_scale_c4_v2.csv exp_scale_c1_v3.csv exp_scale_c3_v1.csv exp_scale_c4_v3.csv exp_scale_c2.csv exp_scale_c3_v2.csv exp_scale_test.csv exp_scale_c2_v1.csv exp_scale_c3_v3.csv scaling_v1.csv Case I - Unscaled, Unnormalized \u00b6 For this first walkthrough, we are assuming that the data is unscaled and that the data is unnormalized. Hypothesis : We all methods should showcase some relationship to the amount of Mutual information but it will not necessarily be a strict relationship. Thinking from the previous results, the KA method should perform the worst, the HSIC method should perform OK with some inconsistencies and the CKA should perform the best and showcase a trend. results_df = pd . read_csv ( RES_PATH + 'exp_scale_test.csv' , index_col = 0 ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset each gamma_method hsic_value mi noise normalized scale scorer trial 2395 sine 0.0 median_p0.5 0.194763 0.0 10.0 0.0 100.0 tka 1.0 2396 sine 0.0 median_p0.5 0.008053 0.0 10.0 0.0 100.0 ctka 1.0 2397 sine 1.0 median_p0.5 0.000585 0.0 10.0 0.0 100.0 hsic 1.0 2398 sine 1.0 median_p0.5 0.673256 0.0 10.0 0.0 100.0 tka 1.0 2399 sine 1.0 median_p0.5 0.006027 0.0 10.0 0.0 100.0 ctka 1.0 sub_df = results_df . copy () # sub_df = sub_df[sub_df['dataset'] == 'line'] sub_df = sub_df [ sub_df [ 'normalized' ] == 0.0 ] sub_df = sub_df [ sub_df [ 'each' ] == 1.0 ] sub_df = sub_df [ sub_df [ 'gamma_method' ] == 'median_p0.5' ] # sub_df = sub_df[sub_df['scorer'] == 'ctka'] # sub_df = sub_df[sub_df['trial'] == 1.0] # sub_df['mi'] = np.log2(sub_df['mi']) # plot data plot_results ( sub_df , 'hsic' , 'dataset' , save_name = \"case2_sep\" ) plot_results ( sub_df , 'tka' , 'dataset' ) plot_results ( sub_df , 'ctka' , 'dataset' ) results_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 dataset gamma_method hsic_value mi noise normalized scale scorer trial 0 0 line median_p0.2 0.112773 3.132759 0.01 0.0 1.0 hsic 1.0 1 1 line median_p0.2 0.995687 3.132759 0.01 0.0 1.0 tka 1.0 2 2 line median_p0.2 0.993657 3.132759 0.01 0.0 1.0 ctka 1.0 3 3 line median_p0.4 0.125462 3.132759 0.01 0.0 1.0 hsic 1.0 4 4 line median_p0.4 0.999011 3.132759 0.01 0.0 1.0 tka 1.0 Case II - UnScaled, Normalized \u00b6 results_df = pd . read_csv ( RES_PATH + 'exp_scale_c2.csv' ) sub_df = results_df . copy () # sub_df = sub_df[sub_df['dataset'] == 'line'] sub_df = sub_df [ sub_df [ 'normalized' ] == 1.0 ] sub_df = sub_df [ sub_df [ 'gamma_method' ] == 'median_p0.5' ] # sub_df = sub_df[sub_df['scorer'] == 'hsic'] # sub_df = sub_df[sub_df['trial'] == 1.0] # sub_df['mi'] = np.log2(sub_df['mi']) # plot data plot_results ( sub_df , 'hsic' , 'dataset' , save_name = \"case2_sep\" ) plot_results ( sub_df , 'tka' , 'dataset' ) plot_results ( sub_df , 'ctka' , 'dataset' , save_name = \"case2_same\" ) Case III - Scaled, Unnormalized \u00b6 results_df = pd . read_csv ( RES_PATH + 'exp_scale_c3_v2.csv' ) sub_df = results_df . copy () # sub_df = sub_df[sub_df['dataset'] == 'sine'] sub_df = sub_df [ sub_df [ 'normalized' ] == 0.0 ] sub_df = sub_df [ sub_df [ 'gamma_method' ] == 'median_p0.5' ] # sub_df = sub_df[sub_df['scorer'] == 'ctka'] # sub_df = sub_df[sub_df['trial'] == 1.0] # sub_df['mi'] = np.log2(sub_df['mi']) # plot data plot_results ( sub_df , 'hsic' , 'dataset' ) plot_results ( sub_df , 'tka' , 'dataset' ) plot_results ( sub_df , 'ctka' , 'dataset' ) Case IV - Scaled, Normalized \u00b6 results_df = pd . read_csv ( RES_PATH + 'exp_scale_c4_v2.csv' ) sub_df = results_df . copy () # sub_df = sub_df[sub_df['dataset'] == 'circ'] sub_df = sub_df [ sub_df [ 'normalized' ] == 1.0 ] # sub_df = sub_df[sub_df['gamma_method'] == 'median_p0.5'] # sub_df = sub_df[sub_df['scorer'] == 'ctka'] # sub_df = sub_df[sub_df['trial'] == 1.0] # sub_df['mi'] = np.log2(sub_df['mi']) # plot data plt . style . use ([ 'seaborn-poster' ]) plot_results ( sub_df , 'hsic' , 'dataset' , save_name = \"case4_same\" ) plot_results ( sub_df , 'tka' , 'dataset' ) plot_results ( sub_df , 'ctka' , 'dataset' , save_name = \"case4_same\" )","title":"2.0 scale viz"},{"location":"notebooks/3_isotropic_scaling/2.0_scale_viz/#isotropic-scaling-experiment","text":"","title":"Isotropic Scaling Experiment"},{"location":"notebooks/3_isotropic_scaling/2.0_scale_viz/#synopsis","text":"In this experiment, I will be looking at how the isotropic scaling effects the HSIC score for the HSIC and KA algorithms. In theory, because we are trying to find one parameter shared between the two kernel functions, there should be problems when the scale of one distribution is larger than another. It's a drawback of the method and it motivates the need to use two different parameters for the distributions.","title":"Synopsis"},{"location":"notebooks/3_isotropic_scaling/2.0_scale_viz/#code","text":"import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import warnings import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.toy import generate_dependence_data , generate_isotropic_data # Kernel Dependency measure from models.train_models import get_gamma_init from models.train_models import get_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid from models.ite_algorithms import run_rbig_models from sklearn.preprocessing import StandardScaler # Plotting from visualization.distribution import plot_scorer from visualization.scaling import plot_scorer_scale , plot_scorer_scale_norm # experiment helpers from tqdm import tqdm # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns # plt.style.use(['fivethirtyeight', 'seaborn-poster']) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline % load_ext autoreload % autoreload 2","title":"Code"},{"location":"notebooks/3_isotropic_scaling/2.0_scale_viz/#experimental-design","text":"The objective of this experiment is to measure how the Mutual information (MI) changes related to the HSIC score of different methods when we change the data and preprocessing conditions (normalization and scale). We change the nature of the data via the scale of the data received and whether or not we do a normalization procedure before we submit the datasets to our HSIC algorithms. Each HSIC method will give us a score and we can calculate the Mutual information Free Params Number of Trials ( seed ) 1:10 Scale or not scaled ( scale ) Normalized | Not Normalized ( normalize ) HSIC Algorithm ( method ) HSIC, KA, cKA Dataset ( dataset ) Linear, Sinusoidal, Circle, Random Amount of Noise ( noise List) log space Measurements Mutual Information ( mi ) HSIC score ( score ) Time for execution ( time ) Fixed Parameters Number of points ( num_points ) Noise for X points ( noise_x ) Noise for Y points ( noise_y ) from typing import Optional SAVE_PATH = '/home/emmanuel/figures/hsicalign/' plt . style . use ([ 'seaborn-talk' ]) def plot_results ( df : pd . DataFrame , scorer : str , hue : Optional [ str ] = None , style : Optional [ str ] = None , save_name : Optional [ str ] = None ) -> None : df = df [ df [ 'scorer' ] == scorer ] # plot data fig , ax = plt . subplots () pts = sns . scatterplot ( x = 'hsic_value' , y = 'mi' , hue = hue , style = style , data = df ) ax . set_ylabel ( 'Mutual Information' , fontsize = 20 ) ax . set_xlabel ( 'Score' , fontsize = 20 ) ax . legend ( fontsize = 20 ) if save_name is not None : fig . savefig ( SAVE_PATH + f \" { scorer } _ { save_name } .png\" ) plt . show () return","title":"Experimental Design"},{"location":"notebooks/3_isotropic_scaling/2.0_scale_viz/#data","text":"cwd '/home/emmanuel/projects/2019_hsic_align/notebooks/3_isotropic_scaling' PROJECT_PATH = f \" { cwd } /../../\" RES_PATH = PROJECT_PATH + 'data/results/scaling/' RES_PATH '/home/emmanuel/projects/2019_hsic_align/notebooks/3_isotropic_scaling/../../data/results/scaling/' ! ls '/home/emmanuel/projects/2019_hsic_align/notebooks/3_isotropic_scaling/../../data/results/scaling/' exp_scale_c1.csv exp_scale_c2_v2.csv exp_scale_c4.csv exp_scale_c1_v1.csv exp_scale_c2_v3.csv exp_scale_c4_v1.csv exp_scale_c1_v2.csv exp_scale_c3.csv exp_scale_c4_v2.csv exp_scale_c1_v3.csv exp_scale_c3_v1.csv exp_scale_c4_v3.csv exp_scale_c2.csv exp_scale_c3_v2.csv exp_scale_test.csv exp_scale_c2_v1.csv exp_scale_c3_v3.csv scaling_v1.csv","title":"Data"},{"location":"notebooks/3_isotropic_scaling/2.0_scale_viz/#case-i-unscaled-unnormalized","text":"For this first walkthrough, we are assuming that the data is unscaled and that the data is unnormalized. Hypothesis : We all methods should showcase some relationship to the amount of Mutual information but it will not necessarily be a strict relationship. Thinking from the previous results, the KA method should perform the worst, the HSIC method should perform OK with some inconsistencies and the CKA should perform the best and showcase a trend. results_df = pd . read_csv ( RES_PATH + 'exp_scale_test.csv' , index_col = 0 ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset each gamma_method hsic_value mi noise normalized scale scorer trial 2395 sine 0.0 median_p0.5 0.194763 0.0 10.0 0.0 100.0 tka 1.0 2396 sine 0.0 median_p0.5 0.008053 0.0 10.0 0.0 100.0 ctka 1.0 2397 sine 1.0 median_p0.5 0.000585 0.0 10.0 0.0 100.0 hsic 1.0 2398 sine 1.0 median_p0.5 0.673256 0.0 10.0 0.0 100.0 tka 1.0 2399 sine 1.0 median_p0.5 0.006027 0.0 10.0 0.0 100.0 ctka 1.0 sub_df = results_df . copy () # sub_df = sub_df[sub_df['dataset'] == 'line'] sub_df = sub_df [ sub_df [ 'normalized' ] == 0.0 ] sub_df = sub_df [ sub_df [ 'each' ] == 1.0 ] sub_df = sub_df [ sub_df [ 'gamma_method' ] == 'median_p0.5' ] # sub_df = sub_df[sub_df['scorer'] == 'ctka'] # sub_df = sub_df[sub_df['trial'] == 1.0] # sub_df['mi'] = np.log2(sub_df['mi']) # plot data plot_results ( sub_df , 'hsic' , 'dataset' , save_name = \"case2_sep\" ) plot_results ( sub_df , 'tka' , 'dataset' ) plot_results ( sub_df , 'ctka' , 'dataset' ) results_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 dataset gamma_method hsic_value mi noise normalized scale scorer trial 0 0 line median_p0.2 0.112773 3.132759 0.01 0.0 1.0 hsic 1.0 1 1 line median_p0.2 0.995687 3.132759 0.01 0.0 1.0 tka 1.0 2 2 line median_p0.2 0.993657 3.132759 0.01 0.0 1.0 ctka 1.0 3 3 line median_p0.4 0.125462 3.132759 0.01 0.0 1.0 hsic 1.0 4 4 line median_p0.4 0.999011 3.132759 0.01 0.0 1.0 tka 1.0","title":"Case I - Unscaled, Unnormalized"},{"location":"notebooks/3_isotropic_scaling/2.0_scale_viz/#case-ii-unscaled-normalized","text":"results_df = pd . read_csv ( RES_PATH + 'exp_scale_c2.csv' ) sub_df = results_df . copy () # sub_df = sub_df[sub_df['dataset'] == 'line'] sub_df = sub_df [ sub_df [ 'normalized' ] == 1.0 ] sub_df = sub_df [ sub_df [ 'gamma_method' ] == 'median_p0.5' ] # sub_df = sub_df[sub_df['scorer'] == 'hsic'] # sub_df = sub_df[sub_df['trial'] == 1.0] # sub_df['mi'] = np.log2(sub_df['mi']) # plot data plot_results ( sub_df , 'hsic' , 'dataset' , save_name = \"case2_sep\" ) plot_results ( sub_df , 'tka' , 'dataset' ) plot_results ( sub_df , 'ctka' , 'dataset' , save_name = \"case2_same\" )","title":"Case II - UnScaled, Normalized"},{"location":"notebooks/3_isotropic_scaling/2.0_scale_viz/#case-iii-scaled-unnormalized","text":"results_df = pd . read_csv ( RES_PATH + 'exp_scale_c3_v2.csv' ) sub_df = results_df . copy () # sub_df = sub_df[sub_df['dataset'] == 'sine'] sub_df = sub_df [ sub_df [ 'normalized' ] == 0.0 ] sub_df = sub_df [ sub_df [ 'gamma_method' ] == 'median_p0.5' ] # sub_df = sub_df[sub_df['scorer'] == 'ctka'] # sub_df = sub_df[sub_df['trial'] == 1.0] # sub_df['mi'] = np.log2(sub_df['mi']) # plot data plot_results ( sub_df , 'hsic' , 'dataset' ) plot_results ( sub_df , 'tka' , 'dataset' ) plot_results ( sub_df , 'ctka' , 'dataset' )","title":"Case III - Scaled, Unnormalized"},{"location":"notebooks/3_isotropic_scaling/2.0_scale_viz/#case-iv-scaled-normalized","text":"results_df = pd . read_csv ( RES_PATH + 'exp_scale_c4_v2.csv' ) sub_df = results_df . copy () # sub_df = sub_df[sub_df['dataset'] == 'circ'] sub_df = sub_df [ sub_df [ 'normalized' ] == 1.0 ] # sub_df = sub_df[sub_df['gamma_method'] == 'median_p0.5'] # sub_df = sub_df[sub_df['scorer'] == 'ctka'] # sub_df = sub_df[sub_df['trial'] == 1.0] # sub_df['mi'] = np.log2(sub_df['mi']) # plot data plt . style . use ([ 'seaborn-poster' ]) plot_results ( sub_df , 'hsic' , 'dataset' , save_name = \"case4_same\" ) plot_results ( sub_df , 'tka' , 'dataset' ) plot_results ( sub_df , 'ctka' , 'dataset' , save_name = \"case4_same\" )","title":"Case IV - Scaled, Normalized"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Isotropic Scaling Experiment \u00b6 Synopsis \u00b6 In this experiment, I will be looking at how the isotropic scaling effects the HSIC score for the HSIC and KA algorithms. In theory, because we are trying to find one parameter shared between the two kernel functions, there should be problems when the scale of one distribution is larger than another. It's a drawback of the method and it motivates the need to use two different parameters for the distributions. Code \u00b6 import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import warnings import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.toy import generate_dependence_data , generate_isotropic_data # Kernel Dependency measure from models.train_models import get_gamma_init from models.train_models import get_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid from models.ite_algorithms import run_rbig_models from sklearn.preprocessing import StandardScaler # Plotting from visualization.distribution import plot_scorer from visualization.scaling import plot_scorer_scale , plot_scorer_scale_norm # experiment helpers from tqdm import tqdm # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns # plt.style.use(['fivethirtyeight', 'seaborn-poster']) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline % load_ext autoreload % autoreload 2 plt . style . available ['seaborn-dark-palette', 'classic', 'ggplot', 'seaborn-dark', 'seaborn-pastel', 'seaborn-bright', 'seaborn-deep', 'tableau-colorblind10', 'seaborn-talk', 'fast', 'seaborn-ticks', 'seaborn-white', 'bmh', 'fivethirtyeight', 'seaborn-muted', '_classic_test', 'grayscale', 'seaborn-darkgrid', 'seaborn-poster', 'seaborn', 'seaborn-whitegrid', 'dark_background', 'seaborn-paper', 'seaborn-colorblind', 'seaborn-notebook', 'Solarize_Light2'] Experimental Design \u00b6 The objective of this experiment is to measure how the Mutual information (MI) changes related to the HSIC score of different methods when we change the data and preprocessing conditions (normalization and scale). We change the nature of the data via the scale of the data received and whether or not we do a normalization procedure before we submit the datasets to our HSIC algorithms. Each HSIC method will give us a score and we can calculate the Mutual information Free Params Number of Trials ( seed ) 1:10 Scale or not scaled ( scale ) Normalized | Not Normalized ( normalize ) HSIC Algorithm ( method ) HSIC, KA, cKA Dataset ( dataset ) Linear, Sinusoidal, Circle, Random Amount of Noise ( noise List) log space Measurements Mutual Information ( mi ) HSIC score ( score ) Time for execution ( time ) Fixed Parameters Number of points ( num_points ) Noise for X points ( noise_x ) Noise for Y points ( noise_y ) Demo \u00b6 class DataParams : num_points = 1_000 noise_y = 0.1 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ 'line' , 'sine' , 'circ' , 'rand' ] seed = np . linspace ( 1 , 10 , 10 ) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ True , False ] noise = np . logspace ( - 3 , 1 , 10 ) method = [ 'hsic' , 'tka' , 'ctka' ] each_length = [ False , True ] gamma_method = [ ( 'median' , 0.2 , None ), ( 'median' , 0.4 , None ), ( 'median' , 0.5 , None ), ( 'median' , 0.6 , None ), ( 'median' , 0.8 , None ), ] from scipy.special import digamma from sklearn.neighbors import NearestNeighbors from typing import Optional def compute_knn_mi ( x : np . ndarray , y : np . ndarray , n_neighbors : Optional [ int ] = 5 ) -> float : \"\"\"Compute mutual information between two continuous variables. Parameters ---------- x, y : ndarray, shape (n_samples,) Samples of two continuous random variables, must have an identical shape. n_neighbors : int Number of nearest neighbors to search for each point, see [1]_. Returns ------- mi : float Estimated mutual information. If it turned out to be negative it is replace by 0. Notes ----- True mutual information can't be negative. If its estimate by a numerical method is negative, it means (providing the method is adequate) that the mutual information is close to 0 and replacing it by 0 is a reasonable strategy. References ---------- .. [1] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual information\". Phys. Rev. E 69, 2004. \"\"\" n_samples = x . size x = x . reshape (( - 1 , 1 )) y = y . reshape (( - 1 , 1 )) xy = np . hstack (( x , y )) # Here we rely on NearestNeighbors to select the fastest algorithm. nn = NearestNeighbors ( metric = 'euclidean' , n_neighbors = n_neighbors ) nn . fit ( xy ) radius = nn . kneighbors ()[ 0 ] radius = np . nextafter ( radius [:, - 1 ], 0 ) # Algorithm is selected explicitly to allow passing an array as radius # later (not all algorithms support this). nn . set_params ( algorithm = 'kd_tree' ) nn . fit ( x ) ind = nn . radius_neighbors ( radius = radius , return_distance = False ) nx = np . array ([ i . size for i in ind ]) nn . fit ( y ) ind = nn . radius_neighbors ( radius = radius , return_distance = False ) ny = np . array ([ i . size for i in ind ]) mi = ( digamma ( n_samples ) + digamma ( n_neighbors ) - np . mean ( digamma ( nx + 1 )) - np . mean ( digamma ( ny + 1 ))) return max ( 0.0 , mi ) Helper Functions \u00b6 from typing import Tuple , Type , Optional def get_gamma_name ( gamma_method : Tuple [ str , str , str ]) -> str : if gamma_method [ 1 ] is None and gamma_method [ 2 ] is None : gamma_name = gamma_method [ 0 ] elif gamma_method [ 1 ] is not None and gamma_method [ 2 ] is None : gamma_name = f \" { gamma_method [ 0 ] } _p { gamma_method [ 1 ] } \" elif gamma_method [ 1 ] is None and gamma_method [ 2 ] is not None : gamma_name = f \" { gamma_method [ 0 ] } _s { gamma_method [ 2 ] } \" elif gamma_method [ 1 ] is not None and gamma_method [ 2 ] is not None : gamma_name = f \" { gamma_method [ 0 ] } _s { gamma_method [ 1 ] } _s { gamma_method [ 2 ] } \" else : raise ValueError ( 'Unrecognized Combination...' ) return gamma_name def plot_data ( X : np . ndarray , Y : np . ndarray ): fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 5 )) ax . scatter ( X , Y , color = 'red' ) # plt.legend(fontsize=20) plt . xticks ( fontsize = 20 ) plt . yticks ( fontsize = 20 ) plt . tight_layout () plt . show () PROJECT_PATH = \"/home/emmanuel/projects/2019_hsic_align/\" LOG_PATH = \"src/experiments/logs/\" SAVE_PATH = \"data/results/scaling/\" SAVE_NAME = 'exp_scale_test.csv' class ScaleExperiment : def __init__ ( self , data_params , exp_params ): self . data_params = data_params self . exp_params = exp_params def _get_data ( self , dataset : str , noise : float , seed : int ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Gathers the raw dependence data\"\"\" # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = 10_000 , #self.data_params.num_points, seed = seed , noise_x = noise , noise_y = noise , alpha = self . data_params . alpha , beta = self . data_params . beta ) return X , Y def _apply_noise ( self , X : np . ndarray , Y : np . ndarray , noise : float , seed : int ) -> Tuple [ np . ndarray , np . ndarray ]: rng = check_random_state ( seed ) X += rng . randn ( X . shape [ 0 ], X . shape [ 1 ]) # Y += rng.randn(Y.shape) return X , Y def _apply_scaling ( self , X : np . ndarray , scale : float ) -> np . ndarray : \"\"\"The scaling step in our experiment\"\"\" # apply scaling return scale * X def _apply_normalization ( self , X : np . ndarray , Y : np . ndarray , normalize : bool ) -> np . ndarray : \"\"\"The normalization step in our experiment.\"\"\" # apply normalization if normalize == True : X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) elif normalize == False : pass else : raise ValueError ( f 'Unrecognized boolean value for normalize { normalize } ' ) return X , Y def _apply_mi_estimate ( self , X : np . ndarray , Y : np . ndarray ) -> float : \"\"\"Apply Mutual Information estimator. We choose to use RBIG as our estimator.\"\"\" # estimate mutual information # mi = compute_knn_mi(X, Y, 15) mi , _ = run_rbig_models ( X , Y , measure = 'mi' , verbose = None ) return mi def _apply_hsic_estimate ( self , X : np . ndarray , Y : np . ndarray , method : str , gamma_init : Tuple [ str , Optional [ float ], Optional [ float ]], each_length : bool = False ) -> float : \"\"\"Apply HSIC estimator using one of the 3 algorithms: * HSIC * KA * cKA \"\"\" # initialize the gamma parameter if each_length == True : gamma_init_X , gamma_init_Y = get_gamma_init ( X , Y , method = gamma_init [ 0 ], percent = gamma_init [ 1 ], scale = gamma_init [ 2 ], each_length = True ) # get hsic_value hsic_value = get_hsic ( X = X , Y = Y , scorer = method , gamma_init_X = gamma_init_X , gamma_init_Y = gamma_init_Y , maximum = False ) elif each_length == False : gamma_init = get_gamma_init ( X , Y , method = gamma_init [ 0 ], percent = gamma_init [ 1 ], scale = gamma_init [ 2 ], each_length = False ) # get hsic_value hsic_value = get_hsic ( X , Y , method , gamma_init , maximum = False , subsample = self . data_params . num_points ) else : raise ValueError ( f 'Unrecognized selection for each_length: { each_length } ' ) return hsic_value def _experiment_step ( self , results_df : pd . DataFrame , dataset : str , noise : float , seed : int , scale : float , normalize : bool , method : str , gamma_init : Tuple [ str , Optional [ float ], Optional [ float ]], each_length : bool = False , ) -> pd . DataFrame : # Step I - Extract Data X , Y = self . _get_data ( dataset = dataset , noise = noise , seed = seed ) # # Step I.1 - Apply Noise # X, Y = self._apply_noise(X=X, Y=Y, noise=noise, seed=seed) # Step II - Apply Scaling X = self . _apply_scaling ( X = X , scale = scale ) # Step III - Apply Normalization X , Y = self . _apply_normalization ( X = X , Y = Y , normalize = normalize ) # Step IV - Estimate mutual information mi = self . _apply_mi_estimate ( X , Y ) # Step IV - Estimate HSIC value hsic_value = self . _apply_hsic_estimate ( X , Y , method = method , gamma_init = gamma_init , each_length = each_length ) # Step V - Save Results to dataframe results_df = results_df . append ({ 'normalized' : normalize , 'trial' : seed , 'dataset' : dataset , 'scale' : scale , 'scorer' : method , 'gamma_method' : get_gamma_name ( gamma_init ), 'hsic_value' : hsic_value , \"mi\" : mi , \"noise\" : noise , \"each\" : each_length , }, ignore_index = True ) return results_df def run_experiment ( self ): results_df = pd . DataFrame () # print(self.exp_params.seed) # Loop Through Free Parameters for iseed in self . exp_params . seed : # print(iseed) for idataset in self . exp_params . dataset : for inoise in self . exp_params . noise : for iscale in self . exp_params . scale : for inormalize in self . exp_params . normalized : for ilength in self . exp_params . each_length : for igamma in self . exp_params . gamma_method : for imethod in self . exp_params . method : results_df = self . _experiment_step ( results_df = results_df , dataset = idataset , noise = inoise , seed = iseed , scale = iscale , normalize = inormalize , method = imethod , gamma_init = igamma , each_length = ilength ) results_df . to_csv ( PROJECT_PATH + SAVE_PATH + f \" { SAVE_NAME } \" ) return results_df Test Run - Full Algorithm \u00b6 # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) # ======================================== # Step I - Extract data # ======================================== dataset = 'sine' noise = 0.01 seed = 123 X , Y = exp_class . _get_data ( dataset = dataset , noise = noise , seed = seed ) plot_data ( X , Y ) # ======================================== # Step IV - Estimate mutual information # ======================================== mi = exp_class . _apply_mi_estimate ( X , Y ) print ( f 'MI (RBIG): { mi : .4f } ' ) # ======================================== # Step II - Apply Scaling # ======================================== scale = 10. X = exp_class . _apply_scaling ( X = X , scale = scale ) plot_data ( X , Y ) # ======================================== # Step III - Apply Normalization # ======================================== normalize = True X , Y = exp_class . _apply_normalization ( X = X , Y = Y , normalize = normalize ) plot_data ( X , Y ) # ======================================== # Step V - Estimate HSIC value # ======================================== method = 'hsic' gamma_init = ( 'median' , 0.5 , None ) each_length = True hsic_value = exp_class . _apply_hsic_estimate ( X , Y , method = method , gamma_init = gamma_init , each_length = each_length ) print ( f 'HSIC score ( { method } ): { hsic_value : .4f } ' ) Test Run - Experimental Step \u00b6 class DataParams : num_points = 5_000 noise_y = 0.1 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ 'line' , 'sine' , # 'circ', # 'rand' ] seed = [ 1 ] #np.linspace(1,10,10) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ True , False ] noise = np . logspace ( - 3 , 1 , 10 ) method = [ 'hsic' , 'tka' , 'ctka' ] each_length = [ # False, True ] gamma_method = [ # ('median', 0.2, None), # ('median', 0.4, None), ( 'median' , 0.5 , None ), # ('median', 0.6, None), # ('median', 0.8, None), ] # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) results_df = pd . DataFrame () results_df = exp_class . _experiment_step ( results_df = results_df , dataset = dataset , noise = noise , seed = seed , scale = scale , normalize = normalize , method = method , gamma_init = gamma_init ) results_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset each gamma_method hsic_value mi noise normalized scale scorer trial 0 sine 0.0 median_p0.5 0.091784 3.355914 0.01 1.0 10.0 hsic 1.0 Test Run - Full Experiment Loop \u00b6 class DataParams : num_points = 1_000 noise_y = 0.1 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ 'line' , 'sine' , # 'circ', # 'rand' ] seed = [ 1 ] #np.linspace(1,10,10) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ True , False ] noise = np . logspace ( - 3 , 1 , 10 ) method = [ 'hsic' , 'tka' , 'ctka' ] each_length = [ False , True ] gamma_method = [ # ('median', 0.2, None), # ('median', 0.4, None), ( 'median' , 0.5 , None ), # ('median', 0.6, None), # ('median', 0.8, None), ] # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) results_df = exp_class . run_experiment () results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset each gamma_method hsic_value mi noise normalized scale scorer trial 2395 sine 0.0 median_p0.5 0.194763 0.0 10.0 0.0 100.0 tka 1.0 2396 sine 0.0 median_p0.5 0.008053 0.0 10.0 0.0 100.0 ctka 1.0 2397 sine 1.0 median_p0.5 0.000585 0.0 10.0 0.0 100.0 hsic 1.0 2398 sine 1.0 median_p0.5 0.673256 0.0 10.0 0.0 100.0 tka 1.0 2399 sine 1.0 median_p0.5 0.006027 0.0 10.0 0.0 100.0 ctka 1.0 Cases - Walkthrough \u00b6 def get_params ( case : int ): # Case I - Unscaled, Unnormalized if case == 1 : class DataParams : num_points = 2_000 noise_y = 0.0 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ \"line\" , \"sine\" , \"circ\" , # \"rand\" ] seed = np . linspace ( 1 , 10 , 10 , dtype = int ) scale = [ 1.0 ] normalized = [ False ] noise = np . logspace ( - 2 , 1 , 10 ) method = [ \"hsic\" , \"tka\" , \"ctka\" ] gamma_method = [ ( \"median\" , 0.2 , None ), ( \"median\" , 0.4 , None ), ( \"median\" , 0.5 , None ), ( \"median\" , 0.6 , None ), ( \"median\" , 0.8 , None ), ] # Case II - Unscaled, Normalized elif case == 2 : class DataParams : num_points = 2_000 noise_y = 0.0 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ \"line\" , \"sine\" , \"circ\" , # \"rand\" ] seed = np . linspace ( 1 , 10 , 10 , dtype = int ) scale = [ 1.0 ] normalized = [ True ] noise = np . logspace ( - 2 , 1 , 10 ) method = [ \"hsic\" , \"tka\" , \"ctka\" ] gamma_method = [ ( \"median\" , 0.2 , None ), ( \"median\" , 0.4 , None ), ( \"median\" , 0.5 , None ), ( \"median\" , 0.6 , None ), ( \"median\" , 0.8 , None ), ] # Case III - Scaled, Unnormalized elif case == 3 : class DataParams : num_points = 2_000 noise_y = 0.01 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ \"line\" , \"sine\" , \"circ\" , # \"rand\", ] seed = np . linspace ( 1 , 10 , 10 , dtype = int ) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ False ] noise = np . logspace ( - 2 , 1 , 10 ) method = [ \"hsic\" , \"tka\" , \"ctka\" ] gamma_method = [ ( \"median\" , 0.2 , None ), ( \"median\" , 0.4 , None ), ( \"median\" , 0.5 , None ), ( \"median\" , 0.6 , None ), ( \"median\" , 0.8 , None ), ] elif case == 4 : class DataParams : dataset = \"line\" num_points = 2_000 noise_y = 0.01 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ \"line\" , \"sine\" , \"circ\" , # \"rand\" ] seed = np . linspace ( 1 , 10 , 10 , dtype = int ) scale = np . logspace ( - 2 , 2 , 10 ) # [0.01, 1.0, 100.0] normalized = [ True ] noise = np . logspace ( - 3 , 1 , 10 ) method = [ \"hsic\" , \"tka\" , \"ctka\" ] gamma_method = [ ( \"median\" , 0.2 , None ), ( \"median\" , 0.4 , None ), ( \"median\" , 0.5 , None ), ( \"median\" , 0.6 , None ), ( \"median\" , 0.8 , None ), ] else : raise ValueError ( f \"Unrecognized case: ' { case } '\" ) return DataParams , ExpParams Case I - Unscaled, Unnormalized \u00b6 For this first walkthrough, we are assuming that the data is unscaled and that the data is unnormalized. Hypothesis : We all methods should showcase some relationship to the amount of Mutual information but it will not necessarily be a strict relationship. Thinking from the previous results, the KA method should perform the worst, the HSIC method should perform OK with some inconsistencies and the CKA should perform the best and showcase a trend. # case number case = 1 # get parameters DataParams , ExpParams = get_params ( case = case ) # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) results_df = exp_class . run_experiment () results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset gamma_method hsic_value mi noise normalized scale scorer trial 0 line median_p0.5 0.110588 3.094753 0.01 0.0 1.0 hsic 1.0 1 line median_p0.5 0.999366 3.094753 0.01 0.0 1.0 tka 1.0 2 line median_p0.5 0.998172 3.094753 0.01 0.0 1.0 ctka 1.0 3 line median_p0.5 0.105917 3.074389 0.01 0.0 1.0 hsic 2.0 4 line median_p0.5 0.999368 3.074389 0.01 0.0 1.0 tka 2.0 5 line median_p0.5 0.998062 3.074389 0.01 0.0 1.0 ctka 2.0 6 line median_p0.5 0.110391 3.111298 0.01 0.0 1.0 hsic 3.0 7 line median_p0.5 0.999400 3.111298 0.01 0.0 1.0 tka 3.0 8 line median_p0.5 0.998244 3.111298 0.01 0.0 1.0 ctka 3.0 Case II - Unscaled, Normalized \u00b6 In this case, we see that # case number case = 2 # get parameters DataParams , ExpParams = get_params ( case = case ) # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) # Run experiment results_df = exp_class . run_experiment () results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset gamma_method hsic_value mi noise normalized scale scorer trial 0 line median_p0.5 0.110589 3.094753 0.01 1.0 1.0 hsic 1.0 1 line median_p0.5 0.999366 3.094753 0.01 1.0 1.0 tka 1.0 2 line median_p0.5 0.998172 3.094753 0.01 1.0 1.0 ctka 1.0 3 line median_p0.5 0.089667 1.011999 0.10 1.0 1.0 hsic 1.0 4 line median_p0.5 0.946835 1.011999 0.10 1.0 1.0 tka 1.0 5 line median_p0.5 0.843181 1.011999 0.10 1.0 1.0 ctka 1.0 6 line median_p0.5 0.003926 0.043903 1.00 1.0 1.0 hsic 1.0 7 line median_p0.5 0.686470 0.043903 1.00 1.0 1.0 tka 1.0 8 line median_p0.5 0.040370 0.043903 1.00 1.0 1.0 ctka 1.0 Case III - Scaled, Unormalized \u00b6 # case number case = 3 # get parameters DataParams , ExpParams = get_params ( case = case ) # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) # Run Experiment results_df = exp_class . run_experiment () results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset gamma_method hsic_value mi noise normalized scale scorer trial 0 line median_p0.5 1.109297e-04 3.094753 0.01 0.0 0.01 hsic 1.0 1 line median_p0.5 6.316801e-01 3.094753 0.01 0.0 0.01 tka 1.0 2 line median_p0.5 6.369142e-01 3.094753 0.01 0.0 0.01 ctka 1.0 3 line median_p0.5 1.105885e-01 3.094753 0.01 0.0 1.00 hsic 1.0 4 line median_p0.5 9.993656e-01 3.094753 0.01 0.0 1.00 tka 1.0 5 line median_p0.5 9.981718e-01 3.094753 0.01 0.0 1.00 ctka 1.0 6 line median_p0.5 1.099729e-04 3.094753 0.01 0.0 100.00 hsic 1.0 7 line median_p0.5 6.323451e-01 3.094753 0.01 0.0 100.00 tka 1.0 8 line median_p0.5 6.371835e-01 3.094753 0.01 0.0 100.00 ctka 1.0 9 line median_p0.5 8.439792e-05 0.963049 0.10 0.0 0.01 hsic 1.0 10 line median_p0.5 6.369820e-01 0.963049 0.10 0.0 0.01 tka 1.0 11 line median_p0.5 5.583300e-01 0.963049 0.10 0.0 0.01 ctka 1.0 12 line median_p0.5 8.954440e-02 1.043494 0.10 0.0 1.00 hsic 1.0 13 line median_p0.5 9.467536e-01 1.043494 0.10 0.0 1.00 tka 1.0 14 line median_p0.5 8.424410e-01 1.043494 0.10 0.0 1.00 ctka 1.0 15 line median_p0.5 1.074575e-04 1.005067 0.10 0.0 100.00 hsic 1.0 16 line median_p0.5 6.325034e-01 1.005067 0.10 0.0 100.00 tka 1.0 17 line median_p0.5 5.704429e-01 1.005067 0.10 0.0 100.00 ctka 1.0 18 line median_p0.5 4.451921e-07 0.043903 1.00 0.0 0.01 hsic 1.0 19 line median_p0.5 6.299457e-01 0.043903 1.00 0.0 0.01 tka 1.0 20 line median_p0.5 3.129644e-02 0.043903 1.00 0.0 0.01 ctka 1.0 21 line median_p0.5 2.026650e-03 0.043903 1.00 0.0 1.00 hsic 1.0 22 line median_p0.5 6.870766e-01 0.043903 1.00 0.0 1.00 tka 1.0 23 line median_p0.5 3.598772e-02 0.043903 1.00 0.0 1.00 ctka 1.0 24 line median_p0.5 8.407697e-05 0.043903 1.00 0.0 100.00 hsic 1.0 25 line median_p0.5 6.384854e-01 0.043903 1.00 0.0 100.00 tka 1.0 26 line median_p0.5 4.028872e-02 0.043903 1.00 0.0 100.00 ctka 1.0 Case IV - Scaled, Normalized \u00b6 # case number case = 4 # get parameters DataParams , ExpParams = get_params ( case = case ) # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) # Run Experiment results_df = exp_class . run_experiment () results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset gamma_method hsic_value mi noise normalized scale scorer trial 0 line median_p0.5 0.110589 3.094753 0.01 1.0 0.01 hsic 1.0 1 line median_p0.5 0.999366 3.094753 0.01 1.0 0.01 tka 1.0 2 line median_p0.5 0.998172 3.094753 0.01 1.0 0.01 ctka 1.0 3 line median_p0.5 0.110589 3.094753 0.01 1.0 1.00 hsic 1.0 4 line median_p0.5 0.999366 3.094753 0.01 1.0 1.00 tka 1.0 5 line median_p0.5 0.998172 3.094753 0.01 1.0 1.00 ctka 1.0 6 line median_p0.5 0.110589 3.094753 0.01 1.0 100.00 hsic 1.0 7 line median_p0.5 0.999366 3.094753 0.01 1.0 100.00 tka 1.0 8 line median_p0.5 0.998172 3.094753 0.01 1.0 100.00 ctka 1.0 9 line median_p0.5 0.089667 1.036774 0.10 1.0 0.01 hsic 1.0 10 line median_p0.5 0.946835 1.036774 0.10 1.0 0.01 tka 1.0 11 line median_p0.5 0.843181 1.036774 0.10 1.0 0.01 ctka 1.0 12 line median_p0.5 0.089667 1.011999 0.10 1.0 1.00 hsic 1.0 13 line median_p0.5 0.946835 1.011999 0.10 1.0 1.00 tka 1.0 14 line median_p0.5 0.843181 1.011999 0.10 1.0 1.00 ctka 1.0 15 line median_p0.5 0.089667 1.036760 0.10 1.0 100.00 hsic 1.0 16 line median_p0.5 0.946835 1.036760 0.10 1.0 100.00 tka 1.0 17 line median_p0.5 0.843181 1.036760 0.10 1.0 100.00 ctka 1.0 18 line median_p0.5 0.003926 0.043903 1.00 1.0 0.01 hsic 1.0 19 line median_p0.5 0.686470 0.043903 1.00 1.0 0.01 tka 1.0 20 line median_p0.5 0.040370 0.043903 1.00 1.0 0.01 ctka 1.0 21 line median_p0.5 0.003926 0.043903 1.00 1.0 1.00 hsic 1.0 22 line median_p0.5 0.686470 0.043903 1.00 1.0 1.00 tka 1.0 23 line median_p0.5 0.040370 0.043903 1.00 1.0 1.00 ctka 1.0 24 line median_p0.5 0.003926 0.043903 1.00 1.0 100.00 hsic 1.0 25 line median_p0.5 0.686470 0.043903 1.00 1.0 100.00 tka 1.0 26 line median_p0.5 0.040370 0.043903 1.00 1.0 100.00 ctka 1.0","title":"3.0 scale walk"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#isotropic-scaling-experiment","text":"","title":"Isotropic Scaling Experiment"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#synopsis","text":"In this experiment, I will be looking at how the isotropic scaling effects the HSIC score for the HSIC and KA algorithms. In theory, because we are trying to find one parameter shared between the two kernel functions, there should be problems when the scale of one distribution is larger than another. It's a drawback of the method and it motivates the need to use two different parameters for the distributions.","title":"Synopsis"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#code","text":"import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import warnings import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.toy import generate_dependence_data , generate_isotropic_data # Kernel Dependency measure from models.train_models import get_gamma_init from models.train_models import get_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid from models.ite_algorithms import run_rbig_models from sklearn.preprocessing import StandardScaler # Plotting from visualization.distribution import plot_scorer from visualization.scaling import plot_scorer_scale , plot_scorer_scale_norm # experiment helpers from tqdm import tqdm # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns # plt.style.use(['fivethirtyeight', 'seaborn-poster']) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline % load_ext autoreload % autoreload 2 plt . style . available ['seaborn-dark-palette', 'classic', 'ggplot', 'seaborn-dark', 'seaborn-pastel', 'seaborn-bright', 'seaborn-deep', 'tableau-colorblind10', 'seaborn-talk', 'fast', 'seaborn-ticks', 'seaborn-white', 'bmh', 'fivethirtyeight', 'seaborn-muted', '_classic_test', 'grayscale', 'seaborn-darkgrid', 'seaborn-poster', 'seaborn', 'seaborn-whitegrid', 'dark_background', 'seaborn-paper', 'seaborn-colorblind', 'seaborn-notebook', 'Solarize_Light2']","title":"Code"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#experimental-design","text":"The objective of this experiment is to measure how the Mutual information (MI) changes related to the HSIC score of different methods when we change the data and preprocessing conditions (normalization and scale). We change the nature of the data via the scale of the data received and whether or not we do a normalization procedure before we submit the datasets to our HSIC algorithms. Each HSIC method will give us a score and we can calculate the Mutual information Free Params Number of Trials ( seed ) 1:10 Scale or not scaled ( scale ) Normalized | Not Normalized ( normalize ) HSIC Algorithm ( method ) HSIC, KA, cKA Dataset ( dataset ) Linear, Sinusoidal, Circle, Random Amount of Noise ( noise List) log space Measurements Mutual Information ( mi ) HSIC score ( score ) Time for execution ( time ) Fixed Parameters Number of points ( num_points ) Noise for X points ( noise_x ) Noise for Y points ( noise_y )","title":"Experimental Design"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#demo","text":"class DataParams : num_points = 1_000 noise_y = 0.1 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ 'line' , 'sine' , 'circ' , 'rand' ] seed = np . linspace ( 1 , 10 , 10 ) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ True , False ] noise = np . logspace ( - 3 , 1 , 10 ) method = [ 'hsic' , 'tka' , 'ctka' ] each_length = [ False , True ] gamma_method = [ ( 'median' , 0.2 , None ), ( 'median' , 0.4 , None ), ( 'median' , 0.5 , None ), ( 'median' , 0.6 , None ), ( 'median' , 0.8 , None ), ] from scipy.special import digamma from sklearn.neighbors import NearestNeighbors from typing import Optional def compute_knn_mi ( x : np . ndarray , y : np . ndarray , n_neighbors : Optional [ int ] = 5 ) -> float : \"\"\"Compute mutual information between two continuous variables. Parameters ---------- x, y : ndarray, shape (n_samples,) Samples of two continuous random variables, must have an identical shape. n_neighbors : int Number of nearest neighbors to search for each point, see [1]_. Returns ------- mi : float Estimated mutual information. If it turned out to be negative it is replace by 0. Notes ----- True mutual information can't be negative. If its estimate by a numerical method is negative, it means (providing the method is adequate) that the mutual information is close to 0 and replacing it by 0 is a reasonable strategy. References ---------- .. [1] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual information\". Phys. Rev. E 69, 2004. \"\"\" n_samples = x . size x = x . reshape (( - 1 , 1 )) y = y . reshape (( - 1 , 1 )) xy = np . hstack (( x , y )) # Here we rely on NearestNeighbors to select the fastest algorithm. nn = NearestNeighbors ( metric = 'euclidean' , n_neighbors = n_neighbors ) nn . fit ( xy ) radius = nn . kneighbors ()[ 0 ] radius = np . nextafter ( radius [:, - 1 ], 0 ) # Algorithm is selected explicitly to allow passing an array as radius # later (not all algorithms support this). nn . set_params ( algorithm = 'kd_tree' ) nn . fit ( x ) ind = nn . radius_neighbors ( radius = radius , return_distance = False ) nx = np . array ([ i . size for i in ind ]) nn . fit ( y ) ind = nn . radius_neighbors ( radius = radius , return_distance = False ) ny = np . array ([ i . size for i in ind ]) mi = ( digamma ( n_samples ) + digamma ( n_neighbors ) - np . mean ( digamma ( nx + 1 )) - np . mean ( digamma ( ny + 1 ))) return max ( 0.0 , mi )","title":"Demo"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#helper-functions","text":"from typing import Tuple , Type , Optional def get_gamma_name ( gamma_method : Tuple [ str , str , str ]) -> str : if gamma_method [ 1 ] is None and gamma_method [ 2 ] is None : gamma_name = gamma_method [ 0 ] elif gamma_method [ 1 ] is not None and gamma_method [ 2 ] is None : gamma_name = f \" { gamma_method [ 0 ] } _p { gamma_method [ 1 ] } \" elif gamma_method [ 1 ] is None and gamma_method [ 2 ] is not None : gamma_name = f \" { gamma_method [ 0 ] } _s { gamma_method [ 2 ] } \" elif gamma_method [ 1 ] is not None and gamma_method [ 2 ] is not None : gamma_name = f \" { gamma_method [ 0 ] } _s { gamma_method [ 1 ] } _s { gamma_method [ 2 ] } \" else : raise ValueError ( 'Unrecognized Combination...' ) return gamma_name def plot_data ( X : np . ndarray , Y : np . ndarray ): fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 5 )) ax . scatter ( X , Y , color = 'red' ) # plt.legend(fontsize=20) plt . xticks ( fontsize = 20 ) plt . yticks ( fontsize = 20 ) plt . tight_layout () plt . show () PROJECT_PATH = \"/home/emmanuel/projects/2019_hsic_align/\" LOG_PATH = \"src/experiments/logs/\" SAVE_PATH = \"data/results/scaling/\" SAVE_NAME = 'exp_scale_test.csv' class ScaleExperiment : def __init__ ( self , data_params , exp_params ): self . data_params = data_params self . exp_params = exp_params def _get_data ( self , dataset : str , noise : float , seed : int ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Gathers the raw dependence data\"\"\" # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = 10_000 , #self.data_params.num_points, seed = seed , noise_x = noise , noise_y = noise , alpha = self . data_params . alpha , beta = self . data_params . beta ) return X , Y def _apply_noise ( self , X : np . ndarray , Y : np . ndarray , noise : float , seed : int ) -> Tuple [ np . ndarray , np . ndarray ]: rng = check_random_state ( seed ) X += rng . randn ( X . shape [ 0 ], X . shape [ 1 ]) # Y += rng.randn(Y.shape) return X , Y def _apply_scaling ( self , X : np . ndarray , scale : float ) -> np . ndarray : \"\"\"The scaling step in our experiment\"\"\" # apply scaling return scale * X def _apply_normalization ( self , X : np . ndarray , Y : np . ndarray , normalize : bool ) -> np . ndarray : \"\"\"The normalization step in our experiment.\"\"\" # apply normalization if normalize == True : X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) elif normalize == False : pass else : raise ValueError ( f 'Unrecognized boolean value for normalize { normalize } ' ) return X , Y def _apply_mi_estimate ( self , X : np . ndarray , Y : np . ndarray ) -> float : \"\"\"Apply Mutual Information estimator. We choose to use RBIG as our estimator.\"\"\" # estimate mutual information # mi = compute_knn_mi(X, Y, 15) mi , _ = run_rbig_models ( X , Y , measure = 'mi' , verbose = None ) return mi def _apply_hsic_estimate ( self , X : np . ndarray , Y : np . ndarray , method : str , gamma_init : Tuple [ str , Optional [ float ], Optional [ float ]], each_length : bool = False ) -> float : \"\"\"Apply HSIC estimator using one of the 3 algorithms: * HSIC * KA * cKA \"\"\" # initialize the gamma parameter if each_length == True : gamma_init_X , gamma_init_Y = get_gamma_init ( X , Y , method = gamma_init [ 0 ], percent = gamma_init [ 1 ], scale = gamma_init [ 2 ], each_length = True ) # get hsic_value hsic_value = get_hsic ( X = X , Y = Y , scorer = method , gamma_init_X = gamma_init_X , gamma_init_Y = gamma_init_Y , maximum = False ) elif each_length == False : gamma_init = get_gamma_init ( X , Y , method = gamma_init [ 0 ], percent = gamma_init [ 1 ], scale = gamma_init [ 2 ], each_length = False ) # get hsic_value hsic_value = get_hsic ( X , Y , method , gamma_init , maximum = False , subsample = self . data_params . num_points ) else : raise ValueError ( f 'Unrecognized selection for each_length: { each_length } ' ) return hsic_value def _experiment_step ( self , results_df : pd . DataFrame , dataset : str , noise : float , seed : int , scale : float , normalize : bool , method : str , gamma_init : Tuple [ str , Optional [ float ], Optional [ float ]], each_length : bool = False , ) -> pd . DataFrame : # Step I - Extract Data X , Y = self . _get_data ( dataset = dataset , noise = noise , seed = seed ) # # Step I.1 - Apply Noise # X, Y = self._apply_noise(X=X, Y=Y, noise=noise, seed=seed) # Step II - Apply Scaling X = self . _apply_scaling ( X = X , scale = scale ) # Step III - Apply Normalization X , Y = self . _apply_normalization ( X = X , Y = Y , normalize = normalize ) # Step IV - Estimate mutual information mi = self . _apply_mi_estimate ( X , Y ) # Step IV - Estimate HSIC value hsic_value = self . _apply_hsic_estimate ( X , Y , method = method , gamma_init = gamma_init , each_length = each_length ) # Step V - Save Results to dataframe results_df = results_df . append ({ 'normalized' : normalize , 'trial' : seed , 'dataset' : dataset , 'scale' : scale , 'scorer' : method , 'gamma_method' : get_gamma_name ( gamma_init ), 'hsic_value' : hsic_value , \"mi\" : mi , \"noise\" : noise , \"each\" : each_length , }, ignore_index = True ) return results_df def run_experiment ( self ): results_df = pd . DataFrame () # print(self.exp_params.seed) # Loop Through Free Parameters for iseed in self . exp_params . seed : # print(iseed) for idataset in self . exp_params . dataset : for inoise in self . exp_params . noise : for iscale in self . exp_params . scale : for inormalize in self . exp_params . normalized : for ilength in self . exp_params . each_length : for igamma in self . exp_params . gamma_method : for imethod in self . exp_params . method : results_df = self . _experiment_step ( results_df = results_df , dataset = idataset , noise = inoise , seed = iseed , scale = iscale , normalize = inormalize , method = imethod , gamma_init = igamma , each_length = ilength ) results_df . to_csv ( PROJECT_PATH + SAVE_PATH + f \" { SAVE_NAME } \" ) return results_df","title":"Helper Functions"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#test-run-full-algorithm","text":"# Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) # ======================================== # Step I - Extract data # ======================================== dataset = 'sine' noise = 0.01 seed = 123 X , Y = exp_class . _get_data ( dataset = dataset , noise = noise , seed = seed ) plot_data ( X , Y ) # ======================================== # Step IV - Estimate mutual information # ======================================== mi = exp_class . _apply_mi_estimate ( X , Y ) print ( f 'MI (RBIG): { mi : .4f } ' ) # ======================================== # Step II - Apply Scaling # ======================================== scale = 10. X = exp_class . _apply_scaling ( X = X , scale = scale ) plot_data ( X , Y ) # ======================================== # Step III - Apply Normalization # ======================================== normalize = True X , Y = exp_class . _apply_normalization ( X = X , Y = Y , normalize = normalize ) plot_data ( X , Y ) # ======================================== # Step V - Estimate HSIC value # ======================================== method = 'hsic' gamma_init = ( 'median' , 0.5 , None ) each_length = True hsic_value = exp_class . _apply_hsic_estimate ( X , Y , method = method , gamma_init = gamma_init , each_length = each_length ) print ( f 'HSIC score ( { method } ): { hsic_value : .4f } ' )","title":"Test Run - Full Algorithm"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#test-run-experimental-step","text":"class DataParams : num_points = 5_000 noise_y = 0.1 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ 'line' , 'sine' , # 'circ', # 'rand' ] seed = [ 1 ] #np.linspace(1,10,10) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ True , False ] noise = np . logspace ( - 3 , 1 , 10 ) method = [ 'hsic' , 'tka' , 'ctka' ] each_length = [ # False, True ] gamma_method = [ # ('median', 0.2, None), # ('median', 0.4, None), ( 'median' , 0.5 , None ), # ('median', 0.6, None), # ('median', 0.8, None), ] # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) results_df = pd . DataFrame () results_df = exp_class . _experiment_step ( results_df = results_df , dataset = dataset , noise = noise , seed = seed , scale = scale , normalize = normalize , method = method , gamma_init = gamma_init ) results_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset each gamma_method hsic_value mi noise normalized scale scorer trial 0 sine 0.0 median_p0.5 0.091784 3.355914 0.01 1.0 10.0 hsic 1.0","title":"Test Run - Experimental Step"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#test-run-full-experiment-loop","text":"class DataParams : num_points = 1_000 noise_y = 0.1 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ 'line' , 'sine' , # 'circ', # 'rand' ] seed = [ 1 ] #np.linspace(1,10,10) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ True , False ] noise = np . logspace ( - 3 , 1 , 10 ) method = [ 'hsic' , 'tka' , 'ctka' ] each_length = [ False , True ] gamma_method = [ # ('median', 0.2, None), # ('median', 0.4, None), ( 'median' , 0.5 , None ), # ('median', 0.6, None), # ('median', 0.8, None), ] # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) results_df = exp_class . run_experiment () results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset each gamma_method hsic_value mi noise normalized scale scorer trial 2395 sine 0.0 median_p0.5 0.194763 0.0 10.0 0.0 100.0 tka 1.0 2396 sine 0.0 median_p0.5 0.008053 0.0 10.0 0.0 100.0 ctka 1.0 2397 sine 1.0 median_p0.5 0.000585 0.0 10.0 0.0 100.0 hsic 1.0 2398 sine 1.0 median_p0.5 0.673256 0.0 10.0 0.0 100.0 tka 1.0 2399 sine 1.0 median_p0.5 0.006027 0.0 10.0 0.0 100.0 ctka 1.0","title":"Test Run - Full Experiment Loop"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#cases-walkthrough","text":"def get_params ( case : int ): # Case I - Unscaled, Unnormalized if case == 1 : class DataParams : num_points = 2_000 noise_y = 0.0 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ \"line\" , \"sine\" , \"circ\" , # \"rand\" ] seed = np . linspace ( 1 , 10 , 10 , dtype = int ) scale = [ 1.0 ] normalized = [ False ] noise = np . logspace ( - 2 , 1 , 10 ) method = [ \"hsic\" , \"tka\" , \"ctka\" ] gamma_method = [ ( \"median\" , 0.2 , None ), ( \"median\" , 0.4 , None ), ( \"median\" , 0.5 , None ), ( \"median\" , 0.6 , None ), ( \"median\" , 0.8 , None ), ] # Case II - Unscaled, Normalized elif case == 2 : class DataParams : num_points = 2_000 noise_y = 0.0 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ \"line\" , \"sine\" , \"circ\" , # \"rand\" ] seed = np . linspace ( 1 , 10 , 10 , dtype = int ) scale = [ 1.0 ] normalized = [ True ] noise = np . logspace ( - 2 , 1 , 10 ) method = [ \"hsic\" , \"tka\" , \"ctka\" ] gamma_method = [ ( \"median\" , 0.2 , None ), ( \"median\" , 0.4 , None ), ( \"median\" , 0.5 , None ), ( \"median\" , 0.6 , None ), ( \"median\" , 0.8 , None ), ] # Case III - Scaled, Unnormalized elif case == 3 : class DataParams : num_points = 2_000 noise_y = 0.01 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ \"line\" , \"sine\" , \"circ\" , # \"rand\", ] seed = np . linspace ( 1 , 10 , 10 , dtype = int ) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ False ] noise = np . logspace ( - 2 , 1 , 10 ) method = [ \"hsic\" , \"tka\" , \"ctka\" ] gamma_method = [ ( \"median\" , 0.2 , None ), ( \"median\" , 0.4 , None ), ( \"median\" , 0.5 , None ), ( \"median\" , 0.6 , None ), ( \"median\" , 0.8 , None ), ] elif case == 4 : class DataParams : dataset = \"line\" num_points = 2_000 noise_y = 0.01 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ \"line\" , \"sine\" , \"circ\" , # \"rand\" ] seed = np . linspace ( 1 , 10 , 10 , dtype = int ) scale = np . logspace ( - 2 , 2 , 10 ) # [0.01, 1.0, 100.0] normalized = [ True ] noise = np . logspace ( - 3 , 1 , 10 ) method = [ \"hsic\" , \"tka\" , \"ctka\" ] gamma_method = [ ( \"median\" , 0.2 , None ), ( \"median\" , 0.4 , None ), ( \"median\" , 0.5 , None ), ( \"median\" , 0.6 , None ), ( \"median\" , 0.8 , None ), ] else : raise ValueError ( f \"Unrecognized case: ' { case } '\" ) return DataParams , ExpParams","title":"Cases - Walkthrough"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#case-i-unscaled-unnormalized","text":"For this first walkthrough, we are assuming that the data is unscaled and that the data is unnormalized. Hypothesis : We all methods should showcase some relationship to the amount of Mutual information but it will not necessarily be a strict relationship. Thinking from the previous results, the KA method should perform the worst, the HSIC method should perform OK with some inconsistencies and the CKA should perform the best and showcase a trend. # case number case = 1 # get parameters DataParams , ExpParams = get_params ( case = case ) # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) results_df = exp_class . run_experiment () results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset gamma_method hsic_value mi noise normalized scale scorer trial 0 line median_p0.5 0.110588 3.094753 0.01 0.0 1.0 hsic 1.0 1 line median_p0.5 0.999366 3.094753 0.01 0.0 1.0 tka 1.0 2 line median_p0.5 0.998172 3.094753 0.01 0.0 1.0 ctka 1.0 3 line median_p0.5 0.105917 3.074389 0.01 0.0 1.0 hsic 2.0 4 line median_p0.5 0.999368 3.074389 0.01 0.0 1.0 tka 2.0 5 line median_p0.5 0.998062 3.074389 0.01 0.0 1.0 ctka 2.0 6 line median_p0.5 0.110391 3.111298 0.01 0.0 1.0 hsic 3.0 7 line median_p0.5 0.999400 3.111298 0.01 0.0 1.0 tka 3.0 8 line median_p0.5 0.998244 3.111298 0.01 0.0 1.0 ctka 3.0","title":"Case I - Unscaled, Unnormalized"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#case-ii-unscaled-normalized","text":"In this case, we see that # case number case = 2 # get parameters DataParams , ExpParams = get_params ( case = case ) # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) # Run experiment results_df = exp_class . run_experiment () results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset gamma_method hsic_value mi noise normalized scale scorer trial 0 line median_p0.5 0.110589 3.094753 0.01 1.0 1.0 hsic 1.0 1 line median_p0.5 0.999366 3.094753 0.01 1.0 1.0 tka 1.0 2 line median_p0.5 0.998172 3.094753 0.01 1.0 1.0 ctka 1.0 3 line median_p0.5 0.089667 1.011999 0.10 1.0 1.0 hsic 1.0 4 line median_p0.5 0.946835 1.011999 0.10 1.0 1.0 tka 1.0 5 line median_p0.5 0.843181 1.011999 0.10 1.0 1.0 ctka 1.0 6 line median_p0.5 0.003926 0.043903 1.00 1.0 1.0 hsic 1.0 7 line median_p0.5 0.686470 0.043903 1.00 1.0 1.0 tka 1.0 8 line median_p0.5 0.040370 0.043903 1.00 1.0 1.0 ctka 1.0","title":"Case II - Unscaled, Normalized"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#case-iii-scaled-unormalized","text":"# case number case = 3 # get parameters DataParams , ExpParams = get_params ( case = case ) # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) # Run Experiment results_df = exp_class . run_experiment () results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset gamma_method hsic_value mi noise normalized scale scorer trial 0 line median_p0.5 1.109297e-04 3.094753 0.01 0.0 0.01 hsic 1.0 1 line median_p0.5 6.316801e-01 3.094753 0.01 0.0 0.01 tka 1.0 2 line median_p0.5 6.369142e-01 3.094753 0.01 0.0 0.01 ctka 1.0 3 line median_p0.5 1.105885e-01 3.094753 0.01 0.0 1.00 hsic 1.0 4 line median_p0.5 9.993656e-01 3.094753 0.01 0.0 1.00 tka 1.0 5 line median_p0.5 9.981718e-01 3.094753 0.01 0.0 1.00 ctka 1.0 6 line median_p0.5 1.099729e-04 3.094753 0.01 0.0 100.00 hsic 1.0 7 line median_p0.5 6.323451e-01 3.094753 0.01 0.0 100.00 tka 1.0 8 line median_p0.5 6.371835e-01 3.094753 0.01 0.0 100.00 ctka 1.0 9 line median_p0.5 8.439792e-05 0.963049 0.10 0.0 0.01 hsic 1.0 10 line median_p0.5 6.369820e-01 0.963049 0.10 0.0 0.01 tka 1.0 11 line median_p0.5 5.583300e-01 0.963049 0.10 0.0 0.01 ctka 1.0 12 line median_p0.5 8.954440e-02 1.043494 0.10 0.0 1.00 hsic 1.0 13 line median_p0.5 9.467536e-01 1.043494 0.10 0.0 1.00 tka 1.0 14 line median_p0.5 8.424410e-01 1.043494 0.10 0.0 1.00 ctka 1.0 15 line median_p0.5 1.074575e-04 1.005067 0.10 0.0 100.00 hsic 1.0 16 line median_p0.5 6.325034e-01 1.005067 0.10 0.0 100.00 tka 1.0 17 line median_p0.5 5.704429e-01 1.005067 0.10 0.0 100.00 ctka 1.0 18 line median_p0.5 4.451921e-07 0.043903 1.00 0.0 0.01 hsic 1.0 19 line median_p0.5 6.299457e-01 0.043903 1.00 0.0 0.01 tka 1.0 20 line median_p0.5 3.129644e-02 0.043903 1.00 0.0 0.01 ctka 1.0 21 line median_p0.5 2.026650e-03 0.043903 1.00 0.0 1.00 hsic 1.0 22 line median_p0.5 6.870766e-01 0.043903 1.00 0.0 1.00 tka 1.0 23 line median_p0.5 3.598772e-02 0.043903 1.00 0.0 1.00 ctka 1.0 24 line median_p0.5 8.407697e-05 0.043903 1.00 0.0 100.00 hsic 1.0 25 line median_p0.5 6.384854e-01 0.043903 1.00 0.0 100.00 tka 1.0 26 line median_p0.5 4.028872e-02 0.043903 1.00 0.0 100.00 ctka 1.0","title":"Case III - Scaled, Unormalized"},{"location":"notebooks/3_isotropic_scaling/3.0_scale_walk/#case-iv-scaled-normalized","text":"# case number case = 4 # get parameters DataParams , ExpParams = get_params ( case = case ) # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) # Run Experiment results_df = exp_class . run_experiment () results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset gamma_method hsic_value mi noise normalized scale scorer trial 0 line median_p0.5 0.110589 3.094753 0.01 1.0 0.01 hsic 1.0 1 line median_p0.5 0.999366 3.094753 0.01 1.0 0.01 tka 1.0 2 line median_p0.5 0.998172 3.094753 0.01 1.0 0.01 ctka 1.0 3 line median_p0.5 0.110589 3.094753 0.01 1.0 1.00 hsic 1.0 4 line median_p0.5 0.999366 3.094753 0.01 1.0 1.00 tka 1.0 5 line median_p0.5 0.998172 3.094753 0.01 1.0 1.00 ctka 1.0 6 line median_p0.5 0.110589 3.094753 0.01 1.0 100.00 hsic 1.0 7 line median_p0.5 0.999366 3.094753 0.01 1.0 100.00 tka 1.0 8 line median_p0.5 0.998172 3.094753 0.01 1.0 100.00 ctka 1.0 9 line median_p0.5 0.089667 1.036774 0.10 1.0 0.01 hsic 1.0 10 line median_p0.5 0.946835 1.036774 0.10 1.0 0.01 tka 1.0 11 line median_p0.5 0.843181 1.036774 0.10 1.0 0.01 ctka 1.0 12 line median_p0.5 0.089667 1.011999 0.10 1.0 1.00 hsic 1.0 13 line median_p0.5 0.946835 1.011999 0.10 1.0 1.00 tka 1.0 14 line median_p0.5 0.843181 1.011999 0.10 1.0 1.00 ctka 1.0 15 line median_p0.5 0.089667 1.036760 0.10 1.0 100.00 hsic 1.0 16 line median_p0.5 0.946835 1.036760 0.10 1.0 100.00 tka 1.0 17 line median_p0.5 0.843181 1.036760 0.10 1.0 100.00 ctka 1.0 18 line median_p0.5 0.003926 0.043903 1.00 1.0 0.01 hsic 1.0 19 line median_p0.5 0.686470 0.043903 1.00 1.0 0.01 tka 1.0 20 line median_p0.5 0.040370 0.043903 1.00 1.0 0.01 ctka 1.0 21 line median_p0.5 0.003926 0.043903 1.00 1.0 1.00 hsic 1.0 22 line median_p0.5 0.686470 0.043903 1.00 1.0 1.00 tka 1.0 23 line median_p0.5 0.040370 0.043903 1.00 1.0 1.00 ctka 1.0 24 line median_p0.5 0.003926 0.043903 1.00 1.0 100.00 hsic 1.0 25 line median_p0.5 0.686470 0.043903 1.00 1.0 100.00 tka 1.0 26 line median_p0.5 0.040370 0.043903 1.00 1.0 100.00 ctka 1.0","title":"Case IV - Scaled, Normalized"},{"location":"notebooks/3_isotropic_scaling/old/1.0_scale_walk/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Isotropic Scaling Experiment \u00b6 Synopsis \u00b6 In this experiment, I will be looking at how the isotropic scaling effects the HSIC score for the HSIC and KA algorithms. In theory, because we are trying to find one parameter shared between the two kernel functions, there should be problems when the scale of one distribution is larger than another. It's a drawback of the method and it motivates the need to use two different parameters for the distributions. Code \u00b6 import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import warnings import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.toy import generate_dependence_data , generate_isotropic_data # Kernel Dependency measure from models.train_models import get_gamma_init from models.train_models import get_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid from models.ite_algorithms import run_rbig_models from sklearn.preprocessing import StandardScaler # Plotting from visualization.distribution import plot_scorer from visualization.scaling import plot_scorer_scale , plot_scorer_scale_norm # experiment helpers from tqdm import tqdm # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns # plt.style.use(['fivethirtyeight', 'seaborn-poster']) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline % load_ext autoreload % autoreload 2 plt . style . available ['seaborn-dark-palette', 'classic', 'ggplot', 'seaborn-dark', 'seaborn-pastel', 'seaborn-bright', 'seaborn-deep', 'tableau-colorblind10', 'seaborn-talk', 'fast', 'seaborn-ticks', 'seaborn-white', 'bmh', 'fivethirtyeight', 'seaborn-muted', '_classic_test', 'grayscale', 'seaborn-darkgrid', 'seaborn-poster', 'seaborn', 'seaborn-whitegrid', 'dark_background', 'seaborn-paper', 'seaborn-colorblind', 'seaborn-notebook', 'Solarize_Light2'] Experimental Design \u00b6 The objective of this experiment is to measure how the Mutual information (MI) changes related to the HSIC score of different methods when we change the data and preprocessing conditions (normalization and scale). We change the nature of the data via the scale of the data received and whether or not we do a normalization procedure before we submit the datasets to our HSIC algorithms. Each HSIC method will give us a score and we can calculate the Mutual information Free Params Number of Trials ( seed ) 1:10 Scale or not scaled ( scale ) Normalized | Not Normalized ( normalize ) HSIC Algorithm ( method ) HSIC, KA, cKA Dataset ( dataset ) Linear, Sinusoidal, Circle, Random Amount of Noise ( noise List) log space Measurements Mutual Information ( mi ) HSIC score ( score ) Time for execution ( time ) Fixed Parameters Number of points ( num_points ) Noise for X points ( noise_x ) Noise for Y points ( noise_y ) Demo \u00b6 np . logspace ( - 2 , 0 , 10 ) array([0.01 , 0.01668101, 0.02782559, 0.04641589, 0.07742637, 0.12915497, 0.21544347, 0.35938137, 0.59948425, 1. ]) class DataParams : dataset = 'line' num_points = 500 noise_y = 0.1 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ 'line' , 'sine' , 'circ' , 'rand' ] seed = np . linspace ( 1 , 10 , 10 ) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ True , False ] noise = np . logspace ( - 3 , 1 , 10 ) method = [ 'hsic' , 'tka' , 'ctka' ] gamma_method = [ ( 'median' , 0.2 , None ), ( 'median' , 0.4 , None ), ( 'median' , 0.5 , None ), ( 'median' , 0.6 , None ), ( 'median' , 0.8 , None ), ] Helper Functions \u00b6 from typing import Tuple , Type , Optional def get_gamma_name ( gamma_method : Tuple [ str , str , str ]) -> str : if gamma_method [ 1 ] is None and gamma_method [ 2 ] is None : gamma_name = gamma_method [ 0 ] elif gamma_method [ 1 ] is not None and gamma_method [ 2 ] is None : gamma_name = f \" { gamma_method [ 0 ] } _p { gamma_method [ 1 ] } \" elif gamma_method [ 1 ] is None and gamma_method [ 2 ] is not None : gamma_name = f \" { gamma_method [ 0 ] } _s { gamma_method [ 2 ] } \" elif gamma_method [ 1 ] is not None and gamma_method [ 2 ] is not None : gamma_name = f \" { gamma_method [ 0 ] } _s { gamma_method [ 1 ] } _s { gamma_method [ 2 ] } \" else : raise ValueError ( 'Unrecognized Combination...' ) return gamma_name def plot_data ( X : np . ndarray , Y : np . ndarray ): fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 5 )) ax . scatter ( X , Y , color = 'red' ) # plt.legend(fontsize=20) plt . xticks ( fontsize = 20 ) plt . yticks ( fontsize = 20 ) plt . tight_layout () plt . show () class ScaleExperiment : def __init__ ( self , data_params , exp_params ): self . data_params = data_params self . exp_params = exp_params def _get_data ( self , dataset : str , noise : float , seed : int ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Gathers the raw dependence data\"\"\" # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = 10_000 , #self.data_params.num_points, seed = seed , noise_x = noise , noise_y = noise , alpha = self . data_params . alpha , beta = self . data_params . beta ) return X , Y def _apply_noise ( self , X : np . ndarray , Y : np . ndarray , noise : float , seed : int ) -> Tuple [ np . ndarray , np . ndarray ]: rng = check_random_state ( seed ) X += rng . randn ( X . shape [ 0 ], X . shape [ 1 ]) # Y += rng.randn(Y.shape) return X , Y def _apply_scaling ( self , X : np . ndarray , scale : float ) -> np . ndarray : \"\"\"The scaling step in our experiment\"\"\" # apply scaling return scale * X def _apply_normalization ( self , X : np . ndarray , Y : np . ndarray , normalize : bool ) -> np . ndarray : \"\"\"The normalization step in our experiment.\"\"\" # apply normalization if normalize == True : X = StandardScaler () . fit_transform ( X ) # Y = StandardScaler().fit_transform(Y) elif normalize == False : pass else : raise ValueError ( f 'Unrecognized boolean value for normalize { normalize } ' ) return X , Y def _apply_mi_estimate ( self , X : np . ndarray , Y : np . ndarray ) -> float : \"\"\"Apply Mutual Information estimator. We choose to use RBIG as our estimator.\"\"\" # estimate mutual information mi , _ = run_rbig_models ( X , Y , measure = 'mi' , verbose = None ) return mi def _apply_hsic_estimate ( self , X : np . ndarray , Y : np . ndarray , method : str , gamma_init : Tuple [ str , Optional [ float ], Optional [ float ]]) -> float : \"\"\"Apply HSIC estimator using one of the 3 algorithms: * HSIC * KA * cKA \"\"\" # initialize the gamma parameter gamma_init = get_gamma_init ( X , Y , gamma_init [ 0 ], gamma_init [ 1 ], gamma_init [ 2 ]) # get hsic_value hsic_value = get_hsic ( X , Y , method , gamma_init , maximum = False ) return hsic_value def _experiment_step ( self , results_df : pd . DataFrame , dataset : str , noise : float , seed : int , scale : float , normalize : bool , method : str , gamma_init : Tuple [ str , Optional [ float ], Optional [ float ]] ) -> pd . DataFrame : # Step I - Extract Data X , Y = self . _get_data ( dataset = dataset , noise = noise , seed = seed ) # # Step I.1 - Apply Noise # X, Y = self._apply_noise(X=X, Y=Y, noise=noise, seed=seed) # Step II - Apply Scaling X = self . _apply_scaling ( X = X , scale = scale ) # Step III - Apply Normalization X , Y = self . _apply_normalization ( X = X , Y = Y , normalize = normalize ) # Step IV - Estimate mutual information mi = self . _apply_mi_estimate ( X , Y ) # Step IV - Estimate HSIC value hsic_value = self . _apply_hsic_estimate ( X , Y , method , gamma_init ) # Step V - Save Results to dataframe results_df = results_df . append ({ 'normalized' : normalize , 'trial' : seed , 'dataset' : dataset , 'scale' : scale , 'scorer' : method , 'gamma_method' : get_gamma_name ( gamma_init ), 'hsic_value' : hsic_value , \"mi\" : mi , \"noise\" : noise , }, ignore_index = True ) return results_df def run_experiment ( self ): results_df = pd . DataFrame () # print(self.exp_params.seed) # Loop Through Free Parameters for iseed in self . exp_params . seed : # print(iseed) for idataset in self . exp_params . dataset : for inoise in self . exp_params . noise : for iscale in self . exp_params . scale : for inormalize in self . exp_params . normalized : for igamma in self . exp_params . gamma_method : for imethod in self . exp_params . method : results_df = self . _experiment_step ( results_df = results_df , dataset = idataset , noise = inoise , seed = iseed , scale = iscale , normalize = inormalize , method = imethod , gamma_init = igamma ) return results_df Test Run - Full Algorithm \u00b6 # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) # ======================================== # Step I - Extract data # ======================================== dataset = 'circ' noise = 0.000 seed = 1 X , Y = exp_class . _get_data ( dataset = dataset , noise = noise , seed = seed ) # plot_data(X,Y) # ======================================== # Step II - Apply Scaling # ======================================== scale = 1. X = exp_class . _apply_scaling ( X = X , scale = scale ) # plot_data(X,Y) # ======================================== # Step III - Apply Normalization # ======================================== normalize = False X , Y = exp_class . _apply_normalization ( X = X , Y = Y , normalize = normalize ) # plot_data(X,Y) # ======================================== # Step IV - Estimate mutual information # ======================================== mi = exp_class . _apply_mi_estimate ( X , Y ) print ( f 'MI (RBIG): { mi : .4f } ' ) # ======================================== # Step V - Estimate HSIC value # ======================================== method = 'ctka' gamma_init = ( 'median' , 0.5 , None ) hsic_value = exp_class . _apply_hsic_estimate ( X , Y , method , gamma_init ) print ( f 'HSIC score ( { method } ): { hsic_value : .4f } ' ) MI (RBIG): 1.8373 HSIC score (ctka): 0.0749 Test Run - Experimental Step \u00b6 # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) results_df = exp_class . _experiment_step ( dataset = dataset , noise = noise , seed = seed , scale = scale , normalize = normalize , method = method , gamma_init = gamma_init ) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-9-bada97fe429c> in <module> 8 normalize = normalize , 9 method = method , ---> 10 gamma_init = gamma_init 11 ) TypeError : _experiment_step() missing 1 required positional argument: 'results_df' results_df . head () Test Run - Full Experiment Loop \u00b6 class DataParams : dataset = 'line' num_points = 1_000 noise_y = 0.00 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ 'line' , 'sine' , 'circ' , 'rand' ] seed = np . linspace ( 1 , 10 , 10 , dtype = int ) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ True , False ] noise = [ 0.01 ] method = [ 'hsic' , 'tka' , 'ctka' ] gamma_method = [ ( 'median' , 0.5 , None ), ] # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) results_df = exp_class . run_experiment () results_df . tail ()","title":"1.0 scale walk"},{"location":"notebooks/3_isotropic_scaling/old/1.0_scale_walk/#isotropic-scaling-experiment","text":"","title":"Isotropic Scaling Experiment"},{"location":"notebooks/3_isotropic_scaling/old/1.0_scale_walk/#synopsis","text":"In this experiment, I will be looking at how the isotropic scaling effects the HSIC score for the HSIC and KA algorithms. In theory, because we are trying to find one parameter shared between the two kernel functions, there should be problems when the scale of one distribution is larger than another. It's a drawback of the method and it motivates the need to use two different parameters for the distributions.","title":"Synopsis"},{"location":"notebooks/3_isotropic_scaling/old/1.0_scale_walk/#code","text":"import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import warnings import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.toy import generate_dependence_data , generate_isotropic_data # Kernel Dependency measure from models.train_models import get_gamma_init from models.train_models import get_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid from models.ite_algorithms import run_rbig_models from sklearn.preprocessing import StandardScaler # Plotting from visualization.distribution import plot_scorer from visualization.scaling import plot_scorer_scale , plot_scorer_scale_norm # experiment helpers from tqdm import tqdm # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns # plt.style.use(['fivethirtyeight', 'seaborn-poster']) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline % load_ext autoreload % autoreload 2 plt . style . available ['seaborn-dark-palette', 'classic', 'ggplot', 'seaborn-dark', 'seaborn-pastel', 'seaborn-bright', 'seaborn-deep', 'tableau-colorblind10', 'seaborn-talk', 'fast', 'seaborn-ticks', 'seaborn-white', 'bmh', 'fivethirtyeight', 'seaborn-muted', '_classic_test', 'grayscale', 'seaborn-darkgrid', 'seaborn-poster', 'seaborn', 'seaborn-whitegrid', 'dark_background', 'seaborn-paper', 'seaborn-colorblind', 'seaborn-notebook', 'Solarize_Light2']","title":"Code"},{"location":"notebooks/3_isotropic_scaling/old/1.0_scale_walk/#experimental-design","text":"The objective of this experiment is to measure how the Mutual information (MI) changes related to the HSIC score of different methods when we change the data and preprocessing conditions (normalization and scale). We change the nature of the data via the scale of the data received and whether or not we do a normalization procedure before we submit the datasets to our HSIC algorithms. Each HSIC method will give us a score and we can calculate the Mutual information Free Params Number of Trials ( seed ) 1:10 Scale or not scaled ( scale ) Normalized | Not Normalized ( normalize ) HSIC Algorithm ( method ) HSIC, KA, cKA Dataset ( dataset ) Linear, Sinusoidal, Circle, Random Amount of Noise ( noise List) log space Measurements Mutual Information ( mi ) HSIC score ( score ) Time for execution ( time ) Fixed Parameters Number of points ( num_points ) Noise for X points ( noise_x ) Noise for Y points ( noise_y )","title":"Experimental Design"},{"location":"notebooks/3_isotropic_scaling/old/1.0_scale_walk/#demo","text":"np . logspace ( - 2 , 0 , 10 ) array([0.01 , 0.01668101, 0.02782559, 0.04641589, 0.07742637, 0.12915497, 0.21544347, 0.35938137, 0.59948425, 1. ]) class DataParams : dataset = 'line' num_points = 500 noise_y = 0.1 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ 'line' , 'sine' , 'circ' , 'rand' ] seed = np . linspace ( 1 , 10 , 10 ) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ True , False ] noise = np . logspace ( - 3 , 1 , 10 ) method = [ 'hsic' , 'tka' , 'ctka' ] gamma_method = [ ( 'median' , 0.2 , None ), ( 'median' , 0.4 , None ), ( 'median' , 0.5 , None ), ( 'median' , 0.6 , None ), ( 'median' , 0.8 , None ), ]","title":"Demo"},{"location":"notebooks/3_isotropic_scaling/old/1.0_scale_walk/#helper-functions","text":"from typing import Tuple , Type , Optional def get_gamma_name ( gamma_method : Tuple [ str , str , str ]) -> str : if gamma_method [ 1 ] is None and gamma_method [ 2 ] is None : gamma_name = gamma_method [ 0 ] elif gamma_method [ 1 ] is not None and gamma_method [ 2 ] is None : gamma_name = f \" { gamma_method [ 0 ] } _p { gamma_method [ 1 ] } \" elif gamma_method [ 1 ] is None and gamma_method [ 2 ] is not None : gamma_name = f \" { gamma_method [ 0 ] } _s { gamma_method [ 2 ] } \" elif gamma_method [ 1 ] is not None and gamma_method [ 2 ] is not None : gamma_name = f \" { gamma_method [ 0 ] } _s { gamma_method [ 1 ] } _s { gamma_method [ 2 ] } \" else : raise ValueError ( 'Unrecognized Combination...' ) return gamma_name def plot_data ( X : np . ndarray , Y : np . ndarray ): fig , ax = plt . subplots ( nrows = 1 , figsize = ( 7 , 5 )) ax . scatter ( X , Y , color = 'red' ) # plt.legend(fontsize=20) plt . xticks ( fontsize = 20 ) plt . yticks ( fontsize = 20 ) plt . tight_layout () plt . show () class ScaleExperiment : def __init__ ( self , data_params , exp_params ): self . data_params = data_params self . exp_params = exp_params def _get_data ( self , dataset : str , noise : float , seed : int ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"Gathers the raw dependence data\"\"\" # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = 10_000 , #self.data_params.num_points, seed = seed , noise_x = noise , noise_y = noise , alpha = self . data_params . alpha , beta = self . data_params . beta ) return X , Y def _apply_noise ( self , X : np . ndarray , Y : np . ndarray , noise : float , seed : int ) -> Tuple [ np . ndarray , np . ndarray ]: rng = check_random_state ( seed ) X += rng . randn ( X . shape [ 0 ], X . shape [ 1 ]) # Y += rng.randn(Y.shape) return X , Y def _apply_scaling ( self , X : np . ndarray , scale : float ) -> np . ndarray : \"\"\"The scaling step in our experiment\"\"\" # apply scaling return scale * X def _apply_normalization ( self , X : np . ndarray , Y : np . ndarray , normalize : bool ) -> np . ndarray : \"\"\"The normalization step in our experiment.\"\"\" # apply normalization if normalize == True : X = StandardScaler () . fit_transform ( X ) # Y = StandardScaler().fit_transform(Y) elif normalize == False : pass else : raise ValueError ( f 'Unrecognized boolean value for normalize { normalize } ' ) return X , Y def _apply_mi_estimate ( self , X : np . ndarray , Y : np . ndarray ) -> float : \"\"\"Apply Mutual Information estimator. We choose to use RBIG as our estimator.\"\"\" # estimate mutual information mi , _ = run_rbig_models ( X , Y , measure = 'mi' , verbose = None ) return mi def _apply_hsic_estimate ( self , X : np . ndarray , Y : np . ndarray , method : str , gamma_init : Tuple [ str , Optional [ float ], Optional [ float ]]) -> float : \"\"\"Apply HSIC estimator using one of the 3 algorithms: * HSIC * KA * cKA \"\"\" # initialize the gamma parameter gamma_init = get_gamma_init ( X , Y , gamma_init [ 0 ], gamma_init [ 1 ], gamma_init [ 2 ]) # get hsic_value hsic_value = get_hsic ( X , Y , method , gamma_init , maximum = False ) return hsic_value def _experiment_step ( self , results_df : pd . DataFrame , dataset : str , noise : float , seed : int , scale : float , normalize : bool , method : str , gamma_init : Tuple [ str , Optional [ float ], Optional [ float ]] ) -> pd . DataFrame : # Step I - Extract Data X , Y = self . _get_data ( dataset = dataset , noise = noise , seed = seed ) # # Step I.1 - Apply Noise # X, Y = self._apply_noise(X=X, Y=Y, noise=noise, seed=seed) # Step II - Apply Scaling X = self . _apply_scaling ( X = X , scale = scale ) # Step III - Apply Normalization X , Y = self . _apply_normalization ( X = X , Y = Y , normalize = normalize ) # Step IV - Estimate mutual information mi = self . _apply_mi_estimate ( X , Y ) # Step IV - Estimate HSIC value hsic_value = self . _apply_hsic_estimate ( X , Y , method , gamma_init ) # Step V - Save Results to dataframe results_df = results_df . append ({ 'normalized' : normalize , 'trial' : seed , 'dataset' : dataset , 'scale' : scale , 'scorer' : method , 'gamma_method' : get_gamma_name ( gamma_init ), 'hsic_value' : hsic_value , \"mi\" : mi , \"noise\" : noise , }, ignore_index = True ) return results_df def run_experiment ( self ): results_df = pd . DataFrame () # print(self.exp_params.seed) # Loop Through Free Parameters for iseed in self . exp_params . seed : # print(iseed) for idataset in self . exp_params . dataset : for inoise in self . exp_params . noise : for iscale in self . exp_params . scale : for inormalize in self . exp_params . normalized : for igamma in self . exp_params . gamma_method : for imethod in self . exp_params . method : results_df = self . _experiment_step ( results_df = results_df , dataset = idataset , noise = inoise , seed = iseed , scale = iscale , normalize = inormalize , method = imethod , gamma_init = igamma ) return results_df","title":"Helper Functions"},{"location":"notebooks/3_isotropic_scaling/old/1.0_scale_walk/#test-run-full-algorithm","text":"# Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) # ======================================== # Step I - Extract data # ======================================== dataset = 'circ' noise = 0.000 seed = 1 X , Y = exp_class . _get_data ( dataset = dataset , noise = noise , seed = seed ) # plot_data(X,Y) # ======================================== # Step II - Apply Scaling # ======================================== scale = 1. X = exp_class . _apply_scaling ( X = X , scale = scale ) # plot_data(X,Y) # ======================================== # Step III - Apply Normalization # ======================================== normalize = False X , Y = exp_class . _apply_normalization ( X = X , Y = Y , normalize = normalize ) # plot_data(X,Y) # ======================================== # Step IV - Estimate mutual information # ======================================== mi = exp_class . _apply_mi_estimate ( X , Y ) print ( f 'MI (RBIG): { mi : .4f } ' ) # ======================================== # Step V - Estimate HSIC value # ======================================== method = 'ctka' gamma_init = ( 'median' , 0.5 , None ) hsic_value = exp_class . _apply_hsic_estimate ( X , Y , method , gamma_init ) print ( f 'HSIC score ( { method } ): { hsic_value : .4f } ' ) MI (RBIG): 1.8373 HSIC score (ctka): 0.0749","title":"Test Run - Full Algorithm"},{"location":"notebooks/3_isotropic_scaling/old/1.0_scale_walk/#test-run-experimental-step","text":"# Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) results_df = exp_class . _experiment_step ( dataset = dataset , noise = noise , seed = seed , scale = scale , normalize = normalize , method = method , gamma_init = gamma_init ) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-9-bada97fe429c> in <module> 8 normalize = normalize , 9 method = method , ---> 10 gamma_init = gamma_init 11 ) TypeError : _experiment_step() missing 1 required positional argument: 'results_df' results_df . head ()","title":"Test Run - Experimental Step"},{"location":"notebooks/3_isotropic_scaling/old/1.0_scale_walk/#test-run-full-experiment-loop","text":"class DataParams : dataset = 'line' num_points = 1_000 noise_y = 0.00 alpha = 1.0 beta = 1.0 class ExpParams : dataset = [ 'line' , 'sine' , 'circ' , 'rand' ] seed = np . linspace ( 1 , 10 , 10 , dtype = int ) scale = np . logspace ( - 2 , 2 , 10 ) normalized = [ True , False ] noise = [ 0.01 ] method = [ 'hsic' , 'tka' , 'ctka' ] gamma_method = [ ( 'median' , 0.5 , None ), ] # Initialize Experiment class exp_class = ScaleExperiment ( DataParams , ExpParams , ) results_df = exp_class . run_experiment () results_df . tail ()","title":"Test Run - Full Experiment Loop"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Walkthrough - Gamma in the Distribution Sapce \u00b6 import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) import warnings from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.distribution import DataParams from features.utils import dict_product # Kernel Dependency measure from pysim.kernel.hsic import HSIC from pysim.kernel.utils import estimate_gamma , GammaParam , SigmaParam # RBIG IT measures # from models.ite_algorithms import run_rbig_models from models.dependence import HSICModel # Plotting from visualization.distribution import plot_scorer # experiment helpers from tqdm import tqdm # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-paper' ]) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/gamma_space/\" RES_PATH = \"/home/emmanuel/projects/2019_hsic_align/data/results/distributions/gamma_space/\" Datasets \u00b6 Samples - [500, 1K, 5K, 10K, 30K, 50K] Dimensions - [ 2, 3, 10, 50, 100] trials - 1:5 IT measures - Mutual Information Distributions - [Gaussian, T-Student] Functions \u00b6 # HSIC FUNCTION def get_hsic ( X , Y , scorer : str , sigma_X , sigma_Y ): # init hsic model class hsic_model = HSICModel () # hsic model params hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( inputs . X , inputs . Y , scorer ) return hsic_val Example Gaussian Distribution: 2D \u00b6 def plot_data ( X ): # plot data fig = plt . figure () g = sns . jointplot ( x = X [:, 0 ], y = X [:, 1 ], ) plt . show () Param I: Standardize or Non-Standardized Data \u00b6 \\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} \\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} <span><span class=\"MathJax_Preview\">\\bar{x} = \\frac{x - \\mu_x}{\\sigma_x}</span><script type=\"math/tex\">\\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} a) Not Standardized Data \u00b6 # initialize Data Params class example_params = DataParams ( standardize = False ) # generate data from params inputs_nstd = example_params . generate_data () plot_data ( inputs_nstd . X ) plt . gcf () plt . savefig ( f \" { FIG_PATH } 1_dataX_nstd.png\" ) plot_data ( inputs_nstd . Y ) plt . gcf () plt . savefig ( f \" { FIG_PATH } 1_dataY_nstd.png\" ) <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> b) Standardized Data \u00b6 # initialize Data Params class example_params = DataParams ( standardize = True ) # generate data from params inputs_std = example_params . generate_data () plot_data ( inputs_std . X ) plt . gcf () plt . savefig ( f \" { FIG_PATH } 1_dataX_std.png\" ) plot_data ( inputs_std . Y ) plt . gcf () plt . savefig ( f \" { FIG_PATH } 1_dataY_std.png\" ) <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> HSIC Algorithms \u00b6 Hilbert-Schmidt Independence Criterion (HSIC) Kernel Alignment (KA) Centered Kernel Alignment (CKA) HSIC \u00b6 algorithm path : src/models/dependence.py 2. Estimate HSIC \u00b6 2.1 - Same Length Scale \u00b6 # init gamma estimator sigma_estimator = SigmaParam ( method = 'median' , percent = 0.5 , per_dimension = False ) # estimate sigma sigma_X = sigma_estimator . estimate_sigma ( X = inputs . X , ) sigma_Y = sigma_estimator . estimate_sigma ( X = inputs . Y , ) print ( f 'Sigma_x: ' , sigma_X ) print ( f 'Sigma_y: ' , sigma_Y ) # init hsic model class hsic_model = HSICModel () # hsic model params hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( inputs . X , inputs . Y , 'hsic' ) print ( f \"HSIC: { hsic_val : .5f } \" ) Sigma_x: 1.6287986984984644 Sigma_y: 1.6423135950442704 HSIC: 0.00136 2.2 - Different Length Scale \u00b6 from sklearn.gaussian_process.kernels import RBF # init gamma estimator sigma_estimator = SigmaParam ( method = 'median' , percent = 0.5 , per_dimension = True ) # estimate sigma sigma_X = sigma_estimator . estimate_sigma ( X = inputs . X , ) sigma_Y = sigma_estimator . estimate_sigma ( X = inputs . Y , ) print ( f 'Sigma_x: ' , sigma_X ) print ( f 'Sigma_y: ' , sigma_Y ) # init hsic model class hsic_model = HSICModel ( kernel_X = RBF ( sigma_X ), kernel_Y = RBF ( sigma_Y )) # get hsic score hsic_val = hsic_model . get_score ( inputs . X , inputs . Y , 'hsic' ) print ( f \"HSIC: { hsic_val : .5f } \" ) Sigma_x: [0.90645763 0.79282285] Sigma_y: [0.8172308 0.89065151] HSIC: 0.00512 Experiment I - Different Scorers \u00b6 We are looking at different \"HSIC scorers\". They are: HSIC HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F Notice: we have the centered kernels, K_xH K_xH and no normalization. TKA TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} Notice: We have the uncentered kernels and a normalization factor. cTKA cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} Notice: We have the centered kernels and a normalization factor. # init gamma estimator sigma_estimator = SigmaParam ( method = 'median' , percent = 0.5 , per_dimension = True ) # estimate sigma sigma_X = sigma_estimator . estimate_sigma ( X = inputs . X , ) sigma_Y = sigma_estimator . estimate_sigma ( X = inputs . Y , ) print ( f 'Sigma_x: ' , sigma_X ) print ( f 'Sigma_y: ' , sigma_Y ) # experimental parameters hsic_model = HSICModel () # init hsic model class hsic_model = HSICModel () # hsic model params hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) scores = dict () # loop through scorers for iscorer in [ 'hsic' , 'ka' , 'cka' ]: # calculate hsic score iscore = hsic_model . get_score ( inputs_std . X , inputs_std . Y , iscorer ) # get HSIC value print ( f ' { iscorer . upper () } : { iscore : .4f } ' ) Sigma_x: [0.90645763 0.79282285] Sigma_y: [0.8172308 0.89065151] HSIC: 0.0051 KA: 0.4938 CKA: 0.0792 There is an obvious difference between each of them even though the distribution hasn't changed at all. It's clear that each of the methods have a slightly different form. So perhaps it's something to do with the parameters we've chosen. We need to investigate things further. Experiment II - Gamma Space \u00b6 Method 2 - Multiprocessing \u00b6 from experiments.utils import dict_product , run_parallel_step # Data Parameters example_data = DataParams () example_data . std = 10 inputs = example_data . generate_data () # experimental parameters n_grid_points = 20 gamma_grid = np . logspace ( - 3 , 3 , n_grid_points ) parameters = { \"scorer\" : [ 'hsic' , 'ka' , 'cka' ], \"gamma_X\" : np . copy ( gamma_grid ), \"gamma_Y\" : np . copy ( gamma_grid ), } # create a list of all param combinations parameters = list ( dict_product ( parameters )) n_params = len ( parameters ) print ( '# of Params:' , n_params ) # of Params: 1200 from typing import Dict # define step function def step ( params : Dict , inputs ): # init hsic model class hsic_model = HSICModel () # hsic model params hsic_model . gamma_X = params [ 'gamma_X' ] hsic_model . gamma_Y = params [ 'gamma_Y' ] # get hsic score score = hsic_model . get_score ( inputs . X , inputs . Y , params [ 'scorer' ]) results_df = pd . DataFrame ({ 'scorer' : [ params [ 'scorer' ]], 'gamma_X' : [ params [ 'gamma_X' ]], 'gamma_Y' : [ params [ 'gamma_Y' ]], 'score' : score , },) return results_df verbose = 1 n_jobs = 2 results = run_parallel_step ( exp_step = step , parameters = parameters , n_jobs = n_jobs , verbose = verbose , inputs = inputs ) [Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers. [Parallel(n_jobs=2)]: Done 956 tasks | elapsed: 2.0s [Parallel(n_jobs=2)]: Done 1200 out of 1200 | elapsed: 2.5s finished results_full_df = pd . concat ( results , ignore_index = True ) results_full_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } scorer gamma_X gamma_Y score 1195 cka 1000.0 54.555948 0.875085 1196 cka 1000.0 112.883789 0.930452 1197 cka 1000.0 233.572147 0.963310 1198 cka 1000.0 483.293024 0.981687 1199 cka 1000.0 1000.000000 0.991891 Viz - Heatmap of Values \u00b6 from typing import Optional def plot_gamma_grid ( grid_df : pd . DataFrame , scorer : str , ax : Optional = None ): if ax is None : fig , ax = plt . subplots ( figsize = ( 8 , 6.5 )) # =========================================== # Plot Gridded DataFrame # =========================================== # subset hsic method grid_df_ = grid_df [ grid_df [ 'scorer' ] == scorer ] . drop ( 'scorer' , axis = 1 ) # create a heatmap grid_df_ = pd . pivot_table ( grid_df_ , values = 'score' , index = [ 'gamma_Y' ], columns = 'gamma_X' ) # print(grid_df_) # min max if scorer == 'hsic' : vmax = 0.11 else : vmax = 1.0 # heatmap_data.columns = np.sqrt(1 / 2 * heatmap_data.columns.values) # heatmap_data.index = np.sqrt(1 / 2 * heatmap_data.index.values) pts = sns . heatmap ( data = grid_df_ , xticklabels = grid_df_ . columns . values . round ( decimals = 2 ), yticklabels = grid_df_ . index . values . round ( decimals = 2 ), vmin = 0 , vmax = vmax , ax = ax ) return plt . gcf (), ax # # ======================= # # HSIC # # ======================= # scorer = 'hsic' # fig, ax = plot_gamma_grid(param_df, scorer=scorer) # # ax.legend(ncol=1, fontsize=15) # ax.set_xlabel(r'$\\gamma_X$') # ax.set_ylabel(r'$\\gamma_Y$') # ax.set_title(f'{scorer.upper()} Score, MI: {inputs.mutual_info:.2f}') # plt.tight_layout() # plt.show() # # ======================= # # Kernel Alignment # # ======================= # scorer = 'ka' # fig, ax = plot_gamma_grid(param_df, scorer=scorer) # # ax.legend(ncol=1, fontsize=15) # ax.set_xlabel(r'$\\gamma_X$') # ax.set_ylabel(r'$\\gamma_Y$') # ax.set_title(f'{scorer.upper()} Score, MI: {inputs.mutual_info:.2f}') # plt.tight_layout() # plt.show() # ========================== # Centered Kernel Alignment # ========================== scorer = 'cka' fig , ax = plot_gamma_grid ( results_full_df , scorer = scorer ) # ax.legend(ncol=1, fontsize=15) ax . set_xlabel ( r '$\\gamma_X$' ) ax . set_ylabel ( r '$\\gamma_Y$' ) ax . set_title ( f ' { scorer . upper () } Score, MI: { inputs . mutual_info : .2f } ' ) plt . tight_layout () plt . show () Experiment III - Gamma Estimators \u00b6 # Data Parameters example_data = DataParams () example_data . std = 10 inputs = example_data . generate_data () # experimental parameters gamma_estimators = [ ( 'silverman' , None , None ), ( 'scott' , None , None ), * [( 'median' , x , None ) for x in np . arange ( 0.1 , 1.0 , 0.1 , dtype = np . float64 )] ] parameters = { \"scorer\" : [ 'hsic' , 'ka' , 'cka' ], \"gamma_est\" : gamma_estimators } # create a list of all param combinations parameters = list ( dict_product ( parameters )) n_params = len ( parameters ) print ( '# of Params:' , n_params ) # of Params: 33 from tqdm import tqdm # init hsic model class hsic_model = HSICModel () # results dataframe gamma_ests = list () # run experiment for iparams in tqdm ( parameters ): # estimate gamma gamma_X = estimate_gamma ( X = inputs . X , method = iparams [ 'gamma_est' ][ 0 ], percent = iparams [ 'gamma_est' ][ 1 ], scale = iparams [ 'gamma_est' ][ 2 ] ) gamma_Y = estimate_gamma ( X = inputs . Y , method = iparams [ 'gamma_est' ][ 0 ], percent = iparams [ 'gamma_est' ][ 1 ], scale = iparams [ 'gamma_est' ][ 2 ] ) # hsic model params hsic_model . gamma_X = gamma_X hsic_model . gamma_Y = gamma_Y # get hsic score score = hsic_model . get_score ( inputs . X , inputs . Y , iparams [ 'scorer' ]) # # init gamma estimator # gamma_est = GammaParam(*imethod) # # initialize gamma # gamma_init = get_gamma_init(X, Y, imethod[0], imethod[1]) # # get hsic_value # hsic_value = get_hsic(X, Y, iscorer, gamma_init, maximum=False) # append results to dataframe gamma_ests . append ( pd . DataFrame ({ 'scorer' : [ iparams [ 'scorer' ]], 'gamma_method' : [ iparams [ 'gamma_est' ][ 0 ]], 'gamma_scale' : [ iparams [ 'gamma_est' ][ 2 ]], 'gamma_percent' : [ iparams [ 'gamma_est' ][ 1 ]], 'gamma_X' : [ gamma_X ], 'gamma_Y' : [ gamma_Y ], 'score' : [ score ], })) # results_df.head() 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33/33 [00:00<00:00, 139.93it/s] gamma_ests_df = pd . concat ( gamma_ests , ignore_index = True ) gamma_ests_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } scorer gamma_method gamma_scale gamma_percent gamma_X gamma_Y score 28 cka median None 0.5 0.201849 0.240391 0.144038 29 cka median None 0.6 0.149283 0.183536 0.154599 30 cka median None 0.7 0.112474 0.142939 0.164639 31 cka median None 0.8 0.087687 0.116909 0.172534 32 cka median None 0.9 0.062305 0.082550 0.183174 from typing import List def plot_estimated_params ( ax , gamma_est_df : pd . DataFrame , gamma_estimators : List , scorer : str ): # subset hsic method df_ = gamma_est_df [ gamma_est_df [ 'scorer' ] == scorer ] # subset gamma estimators for iestimator in gamma_estimators : # subsets sub_df = df_ [ df_ [ 'gamma_method' ] == iestimator [ 0 ]] if iestimator [ 1 ] is not None : sub_df = sub_df [ sub_df [ 'gamma_percent' ] == iestimator [ 1 ]] if iestimator [ 2 ] is not None : sub_df = sub_df [ sub_df [ 'gamma_scale' ] == iestimator [ 2 ]] name = list ( filter ( None , iestimator )) name = '_' . join ( str ( i ) for i in name ) ax . scatter ( sub_df . gamma_X , sub_df . gamma_Y , s = 500 , label = f \" { name } \" , zorder = 3 , marker = '.' ) return ax # ========================== # Centered Kernel Alignment # ========================== scorer = 'cka' # Plot Grid fig , ax = plot_gamma_grid ( results_full_df , scorer = scorer ) # Plot points ax = plot_estimated_params ( ax , gamma_ests_df , gamma_estimators , scorer , ) ax . legend ( ncol = 1 , fontsize = 8 ) ax . set_xlabel ( r '$\\gamma_X$' ) ax . set_ylabel ( r '$\\gamma_Y$' ) ax . set_title ( f ' { scorer . upper () } Score, MI: { inputs . mutual_info : .2f } ' ) plt . tight_layout () plt . show () Viz - Combined Function \u00b6 def plot_dist_params ( param_df , gamma_ests_df , gamma_estimators , scorer : str ): # Plot Grid fig , ax = plot_gamma_grid ( param_df , scorer = scorer ) # Plot points ax = plot_estimated_params ( ax , gamma_ests_df , gamma_estimators , scorer , ) ax . legend ( ncol = 1 , fontsize = 8 ) ax . set_xlabel ( r '$\\gamma_X$' ) ax . set_ylabel ( r '$\\gamma_Y$' ) ax . set_title ( f ' { scorer . upper () } Score, MI: { inputs . mutual_info : .2f } ' ) plt . tight_layout () plt . show () plot_dist_params ( results_full_df , gamma_ests_df , gamma_estimators , 'hsic' ) plot_dist_params ( results_full_df , gamma_ests_df , gamma_estimators , 'ka' ) plot_dist_params ( results_full_df , gamma_ests_df , gamma_estimators , 'cka' )","title":"2.1 exp gamma space"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#walkthrough-gamma-in-the-distribution-sapce","text":"import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) import warnings from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.distribution import DataParams from features.utils import dict_product # Kernel Dependency measure from pysim.kernel.hsic import HSIC from pysim.kernel.utils import estimate_gamma , GammaParam , SigmaParam # RBIG IT measures # from models.ite_algorithms import run_rbig_models from models.dependence import HSICModel # Plotting from visualization.distribution import plot_scorer # experiment helpers from tqdm import tqdm # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-paper' ]) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/gamma_space/\" RES_PATH = \"/home/emmanuel/projects/2019_hsic_align/data/results/distributions/gamma_space/\"","title":"Walkthrough - Gamma in the Distribution Sapce"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#datasets","text":"Samples - [500, 1K, 5K, 10K, 30K, 50K] Dimensions - [ 2, 3, 10, 50, 100] trials - 1:5 IT measures - Mutual Information Distributions - [Gaussian, T-Student]","title":"Datasets"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#functions","text":"# HSIC FUNCTION def get_hsic ( X , Y , scorer : str , sigma_X , sigma_Y ): # init hsic model class hsic_model = HSICModel () # hsic model params hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( inputs . X , inputs . Y , scorer ) return hsic_val","title":"Functions"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#example-gaussian-distribution-2d","text":"def plot_data ( X ): # plot data fig = plt . figure () g = sns . jointplot ( x = X [:, 0 ], y = X [:, 1 ], ) plt . show ()","title":"Example Gaussian Distribution: 2D"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#param-i-standardize-or-non-standardized-data","text":"\\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} \\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} <span><span class=\"MathJax_Preview\">\\bar{x} = \\frac{x - \\mu_x}{\\sigma_x}</span><script type=\"math/tex\">\\bar{x} = \\frac{x - \\mu_x}{\\sigma_x}","title":"Param I: Standardize or Non-Standardized Data"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#a-not-standardized-data","text":"# initialize Data Params class example_params = DataParams ( standardize = False ) # generate data from params inputs_nstd = example_params . generate_data () plot_data ( inputs_nstd . X ) plt . gcf () plt . savefig ( f \" { FIG_PATH } 1_dataX_nstd.png\" ) plot_data ( inputs_nstd . Y ) plt . gcf () plt . savefig ( f \" { FIG_PATH } 1_dataY_nstd.png\" ) <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes>","title":"a) Not Standardized Data"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#b-standardized-data","text":"# initialize Data Params class example_params = DataParams ( standardize = True ) # generate data from params inputs_std = example_params . generate_data () plot_data ( inputs_std . X ) plt . gcf () plt . savefig ( f \" { FIG_PATH } 1_dataX_std.png\" ) plot_data ( inputs_std . Y ) plt . gcf () plt . savefig ( f \" { FIG_PATH } 1_dataY_std.png\" ) <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes>","title":"b) Standardized Data"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#hsic-algorithms","text":"Hilbert-Schmidt Independence Criterion (HSIC) Kernel Alignment (KA) Centered Kernel Alignment (CKA)","title":"HSIC Algorithms"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#hsic","text":"algorithm path : src/models/dependence.py","title":"HSIC"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#2-estimate-hsic","text":"","title":"2. Estimate HSIC"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#21-same-length-scale","text":"# init gamma estimator sigma_estimator = SigmaParam ( method = 'median' , percent = 0.5 , per_dimension = False ) # estimate sigma sigma_X = sigma_estimator . estimate_sigma ( X = inputs . X , ) sigma_Y = sigma_estimator . estimate_sigma ( X = inputs . Y , ) print ( f 'Sigma_x: ' , sigma_X ) print ( f 'Sigma_y: ' , sigma_Y ) # init hsic model class hsic_model = HSICModel () # hsic model params hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( inputs . X , inputs . Y , 'hsic' ) print ( f \"HSIC: { hsic_val : .5f } \" ) Sigma_x: 1.6287986984984644 Sigma_y: 1.6423135950442704 HSIC: 0.00136","title":"2.1 - Same Length Scale"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#22-different-length-scale","text":"from sklearn.gaussian_process.kernels import RBF # init gamma estimator sigma_estimator = SigmaParam ( method = 'median' , percent = 0.5 , per_dimension = True ) # estimate sigma sigma_X = sigma_estimator . estimate_sigma ( X = inputs . X , ) sigma_Y = sigma_estimator . estimate_sigma ( X = inputs . Y , ) print ( f 'Sigma_x: ' , sigma_X ) print ( f 'Sigma_y: ' , sigma_Y ) # init hsic model class hsic_model = HSICModel ( kernel_X = RBF ( sigma_X ), kernel_Y = RBF ( sigma_Y )) # get hsic score hsic_val = hsic_model . get_score ( inputs . X , inputs . Y , 'hsic' ) print ( f \"HSIC: { hsic_val : .5f } \" ) Sigma_x: [0.90645763 0.79282285] Sigma_y: [0.8172308 0.89065151] HSIC: 0.00512","title":"2.2 - Different Length Scale"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#experiment-i-different-scorers","text":"We are looking at different \"HSIC scorers\". They are: HSIC HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F Notice: we have the centered kernels, K_xH K_xH and no normalization. TKA TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} Notice: We have the uncentered kernels and a normalization factor. cTKA cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} Notice: We have the centered kernels and a normalization factor. # init gamma estimator sigma_estimator = SigmaParam ( method = 'median' , percent = 0.5 , per_dimension = True ) # estimate sigma sigma_X = sigma_estimator . estimate_sigma ( X = inputs . X , ) sigma_Y = sigma_estimator . estimate_sigma ( X = inputs . Y , ) print ( f 'Sigma_x: ' , sigma_X ) print ( f 'Sigma_y: ' , sigma_Y ) # experimental parameters hsic_model = HSICModel () # init hsic model class hsic_model = HSICModel () # hsic model params hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) scores = dict () # loop through scorers for iscorer in [ 'hsic' , 'ka' , 'cka' ]: # calculate hsic score iscore = hsic_model . get_score ( inputs_std . X , inputs_std . Y , iscorer ) # get HSIC value print ( f ' { iscorer . upper () } : { iscore : .4f } ' ) Sigma_x: [0.90645763 0.79282285] Sigma_y: [0.8172308 0.89065151] HSIC: 0.0051 KA: 0.4938 CKA: 0.0792 There is an obvious difference between each of them even though the distribution hasn't changed at all. It's clear that each of the methods have a slightly different form. So perhaps it's something to do with the parameters we've chosen. We need to investigate things further.","title":"Experiment I - Different Scorers"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#experiment-ii-gamma-space","text":"","title":"Experiment II - Gamma Space"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#method-2-multiprocessing","text":"from experiments.utils import dict_product , run_parallel_step # Data Parameters example_data = DataParams () example_data . std = 10 inputs = example_data . generate_data () # experimental parameters n_grid_points = 20 gamma_grid = np . logspace ( - 3 , 3 , n_grid_points ) parameters = { \"scorer\" : [ 'hsic' , 'ka' , 'cka' ], \"gamma_X\" : np . copy ( gamma_grid ), \"gamma_Y\" : np . copy ( gamma_grid ), } # create a list of all param combinations parameters = list ( dict_product ( parameters )) n_params = len ( parameters ) print ( '# of Params:' , n_params ) # of Params: 1200 from typing import Dict # define step function def step ( params : Dict , inputs ): # init hsic model class hsic_model = HSICModel () # hsic model params hsic_model . gamma_X = params [ 'gamma_X' ] hsic_model . gamma_Y = params [ 'gamma_Y' ] # get hsic score score = hsic_model . get_score ( inputs . X , inputs . Y , params [ 'scorer' ]) results_df = pd . DataFrame ({ 'scorer' : [ params [ 'scorer' ]], 'gamma_X' : [ params [ 'gamma_X' ]], 'gamma_Y' : [ params [ 'gamma_Y' ]], 'score' : score , },) return results_df verbose = 1 n_jobs = 2 results = run_parallel_step ( exp_step = step , parameters = parameters , n_jobs = n_jobs , verbose = verbose , inputs = inputs ) [Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers. [Parallel(n_jobs=2)]: Done 956 tasks | elapsed: 2.0s [Parallel(n_jobs=2)]: Done 1200 out of 1200 | elapsed: 2.5s finished results_full_df = pd . concat ( results , ignore_index = True ) results_full_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } scorer gamma_X gamma_Y score 1195 cka 1000.0 54.555948 0.875085 1196 cka 1000.0 112.883789 0.930452 1197 cka 1000.0 233.572147 0.963310 1198 cka 1000.0 483.293024 0.981687 1199 cka 1000.0 1000.000000 0.991891","title":"Method 2 - Multiprocessing"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#viz-heatmap-of-values","text":"from typing import Optional def plot_gamma_grid ( grid_df : pd . DataFrame , scorer : str , ax : Optional = None ): if ax is None : fig , ax = plt . subplots ( figsize = ( 8 , 6.5 )) # =========================================== # Plot Gridded DataFrame # =========================================== # subset hsic method grid_df_ = grid_df [ grid_df [ 'scorer' ] == scorer ] . drop ( 'scorer' , axis = 1 ) # create a heatmap grid_df_ = pd . pivot_table ( grid_df_ , values = 'score' , index = [ 'gamma_Y' ], columns = 'gamma_X' ) # print(grid_df_) # min max if scorer == 'hsic' : vmax = 0.11 else : vmax = 1.0 # heatmap_data.columns = np.sqrt(1 / 2 * heatmap_data.columns.values) # heatmap_data.index = np.sqrt(1 / 2 * heatmap_data.index.values) pts = sns . heatmap ( data = grid_df_ , xticklabels = grid_df_ . columns . values . round ( decimals = 2 ), yticklabels = grid_df_ . index . values . round ( decimals = 2 ), vmin = 0 , vmax = vmax , ax = ax ) return plt . gcf (), ax # # ======================= # # HSIC # # ======================= # scorer = 'hsic' # fig, ax = plot_gamma_grid(param_df, scorer=scorer) # # ax.legend(ncol=1, fontsize=15) # ax.set_xlabel(r'$\\gamma_X$') # ax.set_ylabel(r'$\\gamma_Y$') # ax.set_title(f'{scorer.upper()} Score, MI: {inputs.mutual_info:.2f}') # plt.tight_layout() # plt.show() # # ======================= # # Kernel Alignment # # ======================= # scorer = 'ka' # fig, ax = plot_gamma_grid(param_df, scorer=scorer) # # ax.legend(ncol=1, fontsize=15) # ax.set_xlabel(r'$\\gamma_X$') # ax.set_ylabel(r'$\\gamma_Y$') # ax.set_title(f'{scorer.upper()} Score, MI: {inputs.mutual_info:.2f}') # plt.tight_layout() # plt.show() # ========================== # Centered Kernel Alignment # ========================== scorer = 'cka' fig , ax = plot_gamma_grid ( results_full_df , scorer = scorer ) # ax.legend(ncol=1, fontsize=15) ax . set_xlabel ( r '$\\gamma_X$' ) ax . set_ylabel ( r '$\\gamma_Y$' ) ax . set_title ( f ' { scorer . upper () } Score, MI: { inputs . mutual_info : .2f } ' ) plt . tight_layout () plt . show ()","title":"Viz - Heatmap of Values"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#experiment-iii-gamma-estimators","text":"# Data Parameters example_data = DataParams () example_data . std = 10 inputs = example_data . generate_data () # experimental parameters gamma_estimators = [ ( 'silverman' , None , None ), ( 'scott' , None , None ), * [( 'median' , x , None ) for x in np . arange ( 0.1 , 1.0 , 0.1 , dtype = np . float64 )] ] parameters = { \"scorer\" : [ 'hsic' , 'ka' , 'cka' ], \"gamma_est\" : gamma_estimators } # create a list of all param combinations parameters = list ( dict_product ( parameters )) n_params = len ( parameters ) print ( '# of Params:' , n_params ) # of Params: 33 from tqdm import tqdm # init hsic model class hsic_model = HSICModel () # results dataframe gamma_ests = list () # run experiment for iparams in tqdm ( parameters ): # estimate gamma gamma_X = estimate_gamma ( X = inputs . X , method = iparams [ 'gamma_est' ][ 0 ], percent = iparams [ 'gamma_est' ][ 1 ], scale = iparams [ 'gamma_est' ][ 2 ] ) gamma_Y = estimate_gamma ( X = inputs . Y , method = iparams [ 'gamma_est' ][ 0 ], percent = iparams [ 'gamma_est' ][ 1 ], scale = iparams [ 'gamma_est' ][ 2 ] ) # hsic model params hsic_model . gamma_X = gamma_X hsic_model . gamma_Y = gamma_Y # get hsic score score = hsic_model . get_score ( inputs . X , inputs . Y , iparams [ 'scorer' ]) # # init gamma estimator # gamma_est = GammaParam(*imethod) # # initialize gamma # gamma_init = get_gamma_init(X, Y, imethod[0], imethod[1]) # # get hsic_value # hsic_value = get_hsic(X, Y, iscorer, gamma_init, maximum=False) # append results to dataframe gamma_ests . append ( pd . DataFrame ({ 'scorer' : [ iparams [ 'scorer' ]], 'gamma_method' : [ iparams [ 'gamma_est' ][ 0 ]], 'gamma_scale' : [ iparams [ 'gamma_est' ][ 2 ]], 'gamma_percent' : [ iparams [ 'gamma_est' ][ 1 ]], 'gamma_X' : [ gamma_X ], 'gamma_Y' : [ gamma_Y ], 'score' : [ score ], })) # results_df.head() 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33/33 [00:00<00:00, 139.93it/s] gamma_ests_df = pd . concat ( gamma_ests , ignore_index = True ) gamma_ests_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } scorer gamma_method gamma_scale gamma_percent gamma_X gamma_Y score 28 cka median None 0.5 0.201849 0.240391 0.144038 29 cka median None 0.6 0.149283 0.183536 0.154599 30 cka median None 0.7 0.112474 0.142939 0.164639 31 cka median None 0.8 0.087687 0.116909 0.172534 32 cka median None 0.9 0.062305 0.082550 0.183174 from typing import List def plot_estimated_params ( ax , gamma_est_df : pd . DataFrame , gamma_estimators : List , scorer : str ): # subset hsic method df_ = gamma_est_df [ gamma_est_df [ 'scorer' ] == scorer ] # subset gamma estimators for iestimator in gamma_estimators : # subsets sub_df = df_ [ df_ [ 'gamma_method' ] == iestimator [ 0 ]] if iestimator [ 1 ] is not None : sub_df = sub_df [ sub_df [ 'gamma_percent' ] == iestimator [ 1 ]] if iestimator [ 2 ] is not None : sub_df = sub_df [ sub_df [ 'gamma_scale' ] == iestimator [ 2 ]] name = list ( filter ( None , iestimator )) name = '_' . join ( str ( i ) for i in name ) ax . scatter ( sub_df . gamma_X , sub_df . gamma_Y , s = 500 , label = f \" { name } \" , zorder = 3 , marker = '.' ) return ax # ========================== # Centered Kernel Alignment # ========================== scorer = 'cka' # Plot Grid fig , ax = plot_gamma_grid ( results_full_df , scorer = scorer ) # Plot points ax = plot_estimated_params ( ax , gamma_ests_df , gamma_estimators , scorer , ) ax . legend ( ncol = 1 , fontsize = 8 ) ax . set_xlabel ( r '$\\gamma_X$' ) ax . set_ylabel ( r '$\\gamma_Y$' ) ax . set_title ( f ' { scorer . upper () } Score, MI: { inputs . mutual_info : .2f } ' ) plt . tight_layout () plt . show ()","title":"Experiment III - Gamma Estimators"},{"location":"notebooks/4_distributions/2.1_exp_gamma_space/#viz-combined-function","text":"def plot_dist_params ( param_df , gamma_ests_df , gamma_estimators , scorer : str ): # Plot Grid fig , ax = plot_gamma_grid ( param_df , scorer = scorer ) # Plot points ax = plot_estimated_params ( ax , gamma_ests_df , gamma_estimators , scorer , ) ax . legend ( ncol = 1 , fontsize = 8 ) ax . set_xlabel ( r '$\\gamma_X$' ) ax . set_ylabel ( r '$\\gamma_Y$' ) ax . set_title ( f ' { scorer . upper () } Score, MI: { inputs . mutual_info : .2f } ' ) plt . tight_layout () plt . show () plot_dist_params ( results_full_df , gamma_ests_df , gamma_estimators , 'hsic' ) plot_dist_params ( results_full_df , gamma_ests_df , gamma_estimators , 'ka' ) plot_dist_params ( results_full_df , gamma_ests_df , gamma_estimators , 'cka' )","title":"Viz - Combined Function"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Code Review III - Multivariate Distributions \u00b6 Now, the moment we've all be waiting for: How do these methods perform on multivariate distributions. So for this code review, I'll be walking through how these methods compare and I will try to have some telling plots where we outline exactly how each method performs when estimating multivariate distributions such as the Gaussian and T-Student. Recap \u00b6 So far we've seen how we can estimate sigma as well as how we can estimate the HSIC value. We've seen that this HSIC value depends on the sigma estimator method as well as how we configure the sigma parameter (per dataset, per dimension). So we have a set of methods, now we just need to see how these methods perform when we change the number of dimensions as well as the amount of samples. import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) import warnings from typing import Optional , Tuple from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.distribution import DataParams , Inputs # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from models.dependence import HSICModel # RBIG IT measures # from models.ite_algorithms import run_rbig_models # Plotting from visualization.distribution import plot_scorer # experiment helpers from experiments.utils import dict_product , run_parallel_step from tqdm import tqdm # Plotting Procedures import matplotlib sns . reset_defaults () # sns.set_style('whitegrid') #sns.set_context('talk') sns . set_context ( context = 'poster' , font_scale = 0.7 , rc = { 'font.family' : 'sans-serif' }) # sns.set(font='sans-serif') % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload ! pwd /home/emmanuel/projects/2019_hsic_align/notebooks/4_distributions FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/mutual_info/\" RES_PATH = \"/home/emmanuel/projects/2019_hsic_align/data/results/distributions/mutual_info/\" Experimental Parameters \u00b6 # initialize the holder for the parameters parameters = {} Case I - HSIC Estimator \u00b6 In this first part, we have 3 cases of HSIC as a combination of a centered kernel and whether or not we normalize the covariance term. The 3 \"scorers\" are as follows: HSIC HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F In this case, the kernels are centered , but the score is not normalized . Kernel Alignment (KA) TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} In this case, the kernels are not centered but the score is normalized . cTKA cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} In this case, the kernels are centered and the score is normalized . # def get_hsic( # X: np.ndarray, # Y: np.ndarray, # scorer: str, # sigma_X: Optional[float]=None, # sigma_Y: Optional[float]=None # ) -> float: # \"\"\"Estimates the HSIC value given some data, sigma and # the score.\"\"\" # # init hsic model class # hsic_model = HSICModel() # # hsic model params # if sigma_X is not None: # hsic_model.kernel_X = RBF(sigma_X) # hsic_model.kernel_Y = RBF(sigma_Y) # # get hsic score # hsic_val = hsic_model.get_score(X, Y, scorer) # return hsic_val # parameters parameters [ 'scorer' ] = [ 'hsic' , 'ka' , 'cka' ] Case II - Sigma Estimator \u00b6 For this parameter, we are interested in estimating a few things: We want to know which estimator to choose from. Kernel methods are great if the parameters of the kernel are correct. In supervised scenarios, we can simply learn the appropriate kernel parameters that best fit our data given some criteria. In unsupervised settings, we generally do not know which parameters to choose from. But there are many different ways to choose the parameters as every lab/researcher has their own method that \"they swear by\". I will choose some of the most common ones: Silverman Scott Mean Distance Median Distance Median Distance with the k^{th} k^{th} sample (or percent) of that distance matrix. Case III - Sigma Application \u00b6 We want to know the how we are applying the length scale. We have three cases to consider: One length scale for both datasets One length scale per dataset One length scale per dataset per dimension This is important as it could turn a good estimator into a bad estimator. Scott and Silverman work very well for univariate distributions but not very well for multivariate distributions. So if we have one scott/silverman estimate per feature, then this estimator might be a lot better and yield much better results. For the case of the RBF kernel, having one length scale per dimension corresponds to the ARD Kernel which assigns a length scale (or relevance values) per feature. We don't typically use the ARD kernel for kernel methods that we cannot optimize using some gradient function due to how expensive it is. But in this case, it isn't so expensive because we are choosing not to optimizing anything. from typing import Optional from scipy.spatial.distance import pdist , squareform from models.dependence import HSICModel def scotts_factor ( X : np . ndarray ) -> float : \"\"\"Scotts Method to estimate the length scale of the rbf kernel. factor = n**(-1./(d+4)) Parameters ---------- X : np.ndarry Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape return np . power ( n_samples , - 1 / ( n_features + 4. )) def silvermans_factor ( X : np . ndarray ) -> float : \"\"\"Silvermans method used to estimate the length scale of the rbf kernel. factor = (n * (d + 2) / 4.)**(-1. / (d + 4)). Parameters ---------- X : np.ndarray, Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape base = ( n_samples * ( n_features + 2. ) ) / 4. return np . power ( base , - 1 / ( n_features + 4. )) def kth_distance ( dists : np . ndarray , percent : float ) -> np . ndarray : # kth distance calculation (50%) kth_sample = int ( percent * dists . shape [ 0 ]) # take the Kth neighbours of that distance k_dist = dists [:, kth_sample ] return k_dist def sigma_estimate ( X : np . ndarray , method : str = 'median' , percent : Optional [ int ] = None , heuristic : bool = False ) -> float : # get the squared euclidean distances if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) elif percent is not None : kth_sample = int (( percent / 100 ) * X . shape [ 0 ]) dists = np . sort ( squareform ( pdist ( X , 'sqeuclidean' )))[:, kth_sample ] # print(dists.shape, dists.min(), dists.max()) else : dists = np . sort ( pdist ( X , 'sqeuclidean' )) # print(dists.shape, dists.min(), dists.max()) if method == 'median' : sigma = np . median ( dists ) elif method == 'mean' : sigma = np . mean ( dists ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" ) if heuristic : sigma = np . sqrt ( sigma / 2 ) return sigma # Parameters for the estimators parameters [ 'sigma_estimator' ] = [ ( 'median' , 15 ), ( 'median' , 20 ), ( 'median' , 50 ), ( 'median' , 80 ), ( 'scott' , None ), ( 'silverman' , None ), ( 'median' , None ), ] parameters [ 'separate_scales' ] = [ True ] parameters [ 'per_dimension' ] = [ True , False ] Case IV - Standardize or not Standardize \u00b6 This is a simple case but it can have drastic changes in the results of estimating the length scale. In ML, we tend to standardize our datasets because the algorithms do better with predictions with the ranges are contained. Datasets with massive values for certain features could have adverse affects on the representation and the predictions. The formula is given by: \\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} \\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} Note : this is scaling per feature and not per sample. # from typing import Tuple, Optional def standardize_data ( X : np . ndarray , Y : np . ndarray , standardize : bool = False ) -> Tuple [ np . ndarray , np . ndarray ]: X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) return X , Y # experimental parameters parameters [ 'standardize' ] = [ True , False ] Case V - Multivariate Datasets \u00b6 For this experiment, we have generated samples for two sets of multivariate distributions: the Gaussian and the T-Student. We have varied the parameters so that we get a variety of samples, dimensions and the amount of similarity (that we can analytically calculate) between them. For example, we can take a Gaussian distribution with a covariance and generate a similar Gaussian distribution with the same number of samples and variance with a covariance. We know the cross-covariance between them and the self-covariances, so we can analytically calculate the mutual information between the two. MI is absolute which is the dependence or similarity between the two datasets. Now, we will see how the HSIC scores will do versus this variation of dataset size and shape. We have the following parameters: Parameter Entry Samples 50, 100, 500, 1K, 5K Dimensions 2, 3, 10, 50, 100 Trials 1 \\rightarrow \\rightarrow 5 Distributions Gaussian, T-Student std (Gauss dist) 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 nu (T-Stu dist) 1, 2, 3, 4, 5, 6, 7, 8, 9 # example parameters for the dataset parameters [ 'dataset' ] = [ 'gauss' ] parameters [ 'std' ] = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 ] parameters [ 'nu' ] = [ 1 ] parameters [ 'trial' ] = [ 1 , 2 , 3 , 4 , 5 ] parameters [ 'dimensions' ] = [ 2 , 3 , 10 , 50 , 100 ] # Loop Params loop_params = {} loop_params [ \"samples\" ] = [ 50 , 100 , 500 , 1_000 , 5_000 ] # example parameters function example_params = DataParams () # generates a named tuple containing the inputs and the MI inputs = example_params . generate_data () Main Loop ( Update ) \u00b6 So it turns out just doing a blind parallel scheme ended up taking too much time. So I decided to break the problem up a bit. Do 1 Main Loop (Samples) I decided not to combine all of the combinations; I did all except for the number of samples. Everytime I was watching the progress bar, it would slow down every once in a while. That was because the bottleneck for kernel methods is the number of samples. We have cases of 1_000 which isn't too bad, but 5_000 samples is where the methods really start to slow down. In addition, there will be a lot of memory consumption. So I decided to do a main loop through the number of samples (starting from the smallest and ending with the largest). That way, we can get the easier datasets out of the way and then work on the larger datasets later. Controlling the number of jobs. As I mentioned before, the bottleneck is the number of samples. With 5_000, this starts to eat up a lot of memory when doing this in parallel. So to prevent this I set it up such that I control the number of cores doing the processing. Like so: # Samples Cores 50 28 100 28 500 28 1_000 16 5_000 8 Appending Data Because there was a lot of data being shifted around ( \\sim 297000 \\sim 297000 parameters), the resulting dataframe which stores the experimental results is going to be huge. So I decided that for every call to the main loop, I will run append those results to a csv file and then del that dataframe to free up memory. Experiment \u00b6 We have a lot of parameters. So we are going to run everything in parallel so that we can save time. We will do this by giving the cartesian product of our nD list of parameters. This will give us a list of tuples where each entry is a set of parameters to evaluate. The length of this list will be the total number of parameters. # create a list of all param combinations # shuffle parameters params = list ( dict_product ( parameters )) loop_params = list ( dict_product ( loop_params )) # parameters_list = list(dict_product(parameters)) n_params , n_loop_params = len ( params ), len ( loop_params ) print ( '# of Params:' , n_params , n_loop_params ) # of Params: 23100 5 from typing import Dict def step ( params : Dict , loop_param : Dict , ): # ================ # DATA # ================ dist_data = DataParams ( dataset = params [ \"dataset\" ], trial = params [ \"trial\" ], std = params [ \"std\" ], nu = params [ \"nu\" ], samples = loop_param [ \"samples\" ], dimensions = params [ \"dimensions\" ], ) # generate data inputs = dist_data . generate_data () # ======================== # Estimate Sigma # ======================== f_x = lambda x : sigma_estimate ( x , method = params [ 'sigma_estimator' ][ 0 ], percent = params [ 'sigma_estimator' ][ 1 ], heuristic = False ) # ======================== # Per Dimension # ======================== if params [ 'per_dimension' ]: sigma_X = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . X . T ] sigma_Y = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . Y . T ] else : sigma_X = f_x ( inputs . X ) sigma_Y = f_x ( inputs . Y ) # ========================= # Estimate HSIC # ========================= hsic_clf = HSICModel ( kernel_X = RBF ( sigma_X ), kernel_Y = RBF ( sigma_Y ), ) score = hsic_clf . get_score ( inputs . X , inputs . Y , params [ 'scorer' ]) # ==================== # Results # ==================== # append results to dataframe results_df = pd . DataFrame ( { # Data Params \"dataset\" : [ params [ \"dataset\" ]], \"trial\" : [ params [ \"trial\" ]], \"std\" : [ params [ \"std\" ]], \"nu\" : [ params [ \"nu\" ]], \"samples\" : [ loop_param [ \"samples\" ]], \"dimensions\" : [ params [ \"dimensions\" ]], # STANDARDIZE PARSM \"standardize\" : [ params [ \"standardize\" ]], # SIGMA FORMAT PARAMS \"per_dimension\" : [ params [ \"per_dimension\" ]], # SIGMA METHOD PARAMS \"sigma_method\" : [ params [ \"sigma_estimator\" ][ 0 ]], \"sigma_percent\" : [ params [ \"sigma_estimator\" ][ 1 ]], \"sigma_X\" : [ sigma_X ], \"sigma_Y\" : [ sigma_Y ], # HSIC Params \"scorer\" : [ params [ \"scorer\" ]], \"score\" : [ score ], \"mutual_info\" : [ inputs . mutual_info ], } ) return results_df Test - Single Step \u00b6 results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = loop_params [ 0 ], ) [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 3.8s [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 5.6s [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 7.7s [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 10.5s [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 13.8s [Parallel(n_jobs=-1)]: Done 3144 tasks | elapsed: 17.8s [Parallel(n_jobs=-1)]: Done 3994 tasks | elapsed: 22.3s [Parallel(n_jobs=-1)]: Done 4944 tasks | elapsed: 26.9s [Parallel(n_jobs=-1)]: Done 6640 tasks | elapsed: 32.8s [Parallel(n_jobs=-1)]: Done 8940 tasks | elapsed: 40.0s [Parallel(n_jobs=-1)]: Done 11440 tasks | elapsed: 47.6s --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) <ipython-input-35-3df2e8759391> in <module> ----> 1 results_df = run_parallel_step( 2 exp_step = step , 3 parameters = params , 4 n_jobs = - 1 , 5 verbose = 1 , ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/utils.py in run_parallel_step (exp_step, parameters, n_jobs, verbose, **kwargs) 96 97 # loop through parameters ---> 98 results = Parallel(n_jobs=n_jobs, verbose=verbose)( 99 delayed ( exp_step ) ( iparam , ** kwargs ) for iparam in parameters 100 ) ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py in __call__ (self, iterable) 1015 1016 with self . _backend . retrieval_context ( ) : -> 1017 self . retrieve ( ) 1018 # Make sure that we get a last message telling us we are done 1019 elapsed_time = time . time ( ) - self . _start_time ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py in retrieve (self) 907 try : 908 if getattr ( self . _backend , 'supports_timeout' , False ) : --> 909 self . _output . extend ( job . get ( timeout = self . timeout ) ) 910 else : 911 self . _output . extend ( job . get ( ) ) ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/_parallel_backends.py in wrap_future_result (future, timeout) 560 AsyncResults.get from multiprocessing.\"\"\" 561 try : --> 562 return future . result ( timeout = timeout ) 563 except LokyTimeoutError : 564 raise TimeoutError ( ) ~/.conda/envs/hsic_align/lib/python3.8/concurrent/futures/_base.py in result (self, timeout) 432 return self . __get_result ( ) 433 --> 434 self . _condition . wait ( timeout ) 435 436 if self . _state in [ CANCELLED , CANCELLED_AND_NOTIFIED ] : ~/.conda/envs/hsic_align/lib/python3.8/threading.py in wait (self, timeout) 300 try : # restore state no matter what (e.g., KeyboardInterrupt) 301 if timeout is None : --> 302 waiter . acquire ( ) 303 gotit = True 304 else : KeyboardInterrupt : results_df . tail () --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-36-5747df3a89d5> in <module> ----> 1 results_df . tail ( ) NameError : name 'results_df' is not defined # save results save_name = \"test\" dataset = 'gaussian' header = True mode = \"w\" with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) # get params # params, loop_params = get_parameters(args.dataset, njobs=args.njobs) save_name = \"test\" dataset = 'gaussian' # initialize datast header = True mode = \"w\" with tqdm ( loop_params ) as pbar : for iparam in pbar : pbar . set_description ( f \"# Samples: { iparam [ 'samples' ] } , Tasks: { len ( params ) } \" ) results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = iparam , ) # concat current results results_df = pd . concat ( results_df , ignore_index = True ) # save results with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) header = False mode = \"a\" del results_df break # Samples: 50, Tasks: 23100: 0%| | 0/5 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.0s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 4.8s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.5s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 10.7s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 14.7s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.4s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 24.9s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 30.6s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 37.5s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 43.8s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 51.4s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 50, Tasks: 23100: 0%| | 0/5 [01:27<?, ?it/s] step_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 0 gauss 1 1 1 50 2 True True True median 0.1 [0.1686566316684468, 0.14612229488391992] [0.1589719949193001, 0.1680410083908699] hsic 0.019091 0.0 Test - Full Loop \u00b6 # get params # params, loop_params = get_parameters(args.dataset, njobs=args.njobs) save_name = \"test_full\" dataset = 'gaussian' # initialize dataset header = True mode = \"w\" with tqdm ( loop_params ) as pbar : for iparam in pbar : pbar . set_description ( f \"# Samples: { iparam [ 'samples' ] } , Tasks: { len ( params ) } \" ) results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = iparam , ) # concat current results results_df = pd . concat ( results_df , ignore_index = True ) # save results with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) header = False mode = \"a\" # Samples: 50, Tasks: 23100: 0%| | 0/5 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.0s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 4.7s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.4s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 10.7s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 14.9s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.5s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 24.8s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 30.7s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 37.1s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 44.5s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 52.6s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 100, Tasks: 23100: 20%|\u2588\u2588 | 1/5 [01:27<05:51, 87.81s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.2s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.7s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 5.0s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.8s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 11.4s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 15.3s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.8s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 25.6s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 31.7s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 38.3s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 45.4s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 53.3s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 500, Tasks: 23100: 40%|\u2588\u2588\u2588\u2588 | 2/5 [02:57<04:24, 88.32s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 195 tasks | elapsed: 10.0s [Parallel(n_jobs=-1)]: Done 450 tasks | elapsed: 22.8s [Parallel(n_jobs=-1)]: Done 800 tasks | elapsed: 29.2s [Parallel(n_jobs=-1)]: Done 1250 tasks | elapsed: 38.5s [Parallel(n_jobs=-1)]: Done 1800 tasks | elapsed: 59.6s [Parallel(n_jobs=-1)]: Done 2450 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 3200 tasks | elapsed: 1.5min [Parallel(n_jobs=-1)]: Done 4050 tasks | elapsed: 2.0min [Parallel(n_jobs=-1)]: Done 5000 tasks | elapsed: 2.1min [Parallel(n_jobs=-1)]: Done 6050 tasks | elapsed: 2.2min [Parallel(n_jobs=-1)]: Done 7200 tasks | elapsed: 2.6min [Parallel(n_jobs=-1)]: Done 8450 tasks | elapsed: 3.2min [Parallel(n_jobs=-1)]: Done 9800 tasks | elapsed: 3.7min [Parallel(n_jobs=-1)]: Done 11250 tasks | elapsed: 4.4min [Parallel(n_jobs=-1)]: Done 12800 tasks | elapsed: 4.8min [Parallel(n_jobs=-1)]: Done 14450 tasks | elapsed: 5.0min [Parallel(n_jobs=-1)]: Done 16200 tasks | elapsed: 5.8min [Parallel(n_jobs=-1)]: Done 18050 tasks | elapsed: 6.7min [Parallel(n_jobs=-1)]: Done 20000 tasks | elapsed: 7.4min [Parallel(n_jobs=-1)]: Done 22050 tasks | elapsed: 7.6min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 8.0min finished # Samples: 1000, Tasks: 23100: 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 3/5 [11:14<07:01, 210.85s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 27.9s [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 1.3min [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 1.9min [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 2.3min [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 3.8min [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 4.6min [Parallel(n_jobs=-1)]: Done 3144 tasks | elapsed: 5.9min [Parallel(n_jobs=-1)]: Done 3994 tasks | elapsed: 7.8min [Parallel(n_jobs=-1)]: Done 4944 tasks | elapsed: 8.0min [Parallel(n_jobs=-1)]: Done 5994 tasks | elapsed: 8.2min [Parallel(n_jobs=-1)]: Done 7144 tasks | elapsed: 9.8min [Parallel(n_jobs=-1)]: Done 8394 tasks | elapsed: 11.8min [Parallel(n_jobs=-1)]: Done 9744 tasks | elapsed: 13.8min [Parallel(n_jobs=-1)]: Done 11194 tasks | elapsed: 16.5min [Parallel(n_jobs=-1)]: Done 12744 tasks | elapsed: 17.9min [Parallel(n_jobs=-1)]: Done 14394 tasks | elapsed: 18.3min [Parallel(n_jobs=-1)]: Done 16144 tasks | elapsed: 21.6min [Parallel(n_jobs=-1)]: Done 17994 tasks | elapsed: 25.0min [Parallel(n_jobs=-1)]: Done 19944 tasks | elapsed: 27.7min [Parallel(n_jobs=-1)]: Done 21994 tasks | elapsed: 28.0min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 29.7min finished # Samples: 5000, Tasks: 23100: 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 4/5 [41:13<11:27, 687.29s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 13.4min [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 37.4min [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 53.4min [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 65.1min [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 108.6min [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 130.8min results_df = pd . read_csv ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" ) results_df = results_df . loc [:, ~ results_df . columns . str . match ( 'Unnamed' )] results_df = results_df . astype ( object ) . replace ( np . nan , 'None' ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 115495 gauss 5 11 1 5000 2 False False median None 2.596209486629066 2.533566551925972 cka 0.408078 0.390005 115496 gauss 5 11 1 5000 3 False False median None 4.114994392992097 4.495821703399767 cka 0.453781 0.377389 115497 gauss 5 11 1 5000 10 False False median None 14.882197509532734 15.57776152697343 cka 0.752609 0.929178 115498 gauss 5 11 1 5000 50 False False median None 67.1011981827926 65.92873890142732 cka 0.969342 4.052644 115499 gauss 5 11 1 5000 100 False False median None 129.70371717695562 129.7259155663332 cka 0.985882 7.938746 results_df . sigma_percent . unique () . tolist () [15.0, 20.0, 50.0, 80.0, 'None'] Visualization \u00b6 Indiscrimenant Points - Dimensions, Samples Method - colors Standardize - type Correlation (MI, Score) Method I - Scott, Silverman \u00b6 # segment scott sub_df = results_df [ results_df [ \"sigma_method\" ] == 'silverman' ] # sub_df = sub_df[sub_df[\"sigma_percent\"] == 'None'] # dropcolumns with dimensions and samples sub_df = sub_df . drop ([ 'dimensions' , 'samples' , 'std' , 'nu' , 'trial' , 'dataset' , 'sigma_X' , 'sigma_Y' ], axis = 1 ) sub_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } standardize per_dimension sigma_method sigma_percent scorer score mutual_info 114395 False False silverman None cka 0.044627 0.390005 114396 False False silverman None cka 0.065012 0.377389 114397 False False silverman None cka 0.966685 0.929178 114398 False False silverman None cka 1.000000 4.052644 114399 False False silverman None cka 1.000000 7.938746 Convenience Functions \u00b6 I - Subsetting the DataFrame \u00b6 We want to be able to query the dataframe with multiple queries at a time. So I'll create a namedtuple which will hold the name of the column and the elements I want to access. Then I'll have a function that will take a list of these datastructures from typing import List , Optional , Union df_query = namedtuple ( 'df_query' , [ 'name' , 'elements' ]) def subset_dataframe ( df : pd . DataFrame , queries : List [ df_query ], ) -> pd . DataFrame : # copy dataframe to prevent overwriting sub_df = df . copy () # for iquery in queries : sub_df = sub_df [ sub_df [ iquery . name ] . isin ( iquery . elements )] return sub_df # subset dataframe scorer = 'hsic' hsic_data_df = subset_dataframe ( results_df , [ df_query ( 'scorer' , [ scorer ])]) hsic_data_df . head ( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 0 gauss 1 1 1 50 2 True True median 15 [0.05289913460722866, 0.046005156305852286] [0.0603301351143148, 0.06549625956610451] hsic 0.019532 0.0 1 gauss 1 1 1 50 3 True True median 15 [0.05289913460722866, 0.046005156305852286, 0.... [0.06549625956610451, 0.05939212909166344, 0.0... hsic 0.019590 0.0 # check for iscorer in [ 'hsic' , 'ka' , 'cka' ]: # subset dataframe sub_df = subset_dataframe ( results_df , [ df_query ( 'scorer' , [ iscorer ])]) # check that the only element is the one we query-ed assert sub_df . scorer . unique () . tolist () == [ iscorer ] II - Correlations \u00b6 I want to see the correlations between the mutual information and the score. So I'll make a dedicated function to handle that. I'll use a namedtuple to ensure that the results are a callable datastructure and immutable (cannot be overwritten). from scipy import stats from collections import namedtuple corr_stats = namedtuple ( 'corr_stats' , [ 'pearson' , 'spearman' ]) def get_correlations ( df : pd . DataFrame ): \"\"\"Inputs a dataframe and outputs the correlation between the mutual information and the score. Requires the 'mutual_info' and 'score' columns.\"\"\" # check that columns are in dataframe msg = \"No 'mutual_info' and/or 'score' column(s) found in dataframe\" assert { 'mutual_info' , \"score\" } . issubset ( df . columns ), msg # get pearson correlation corr_pear = stats . pearsonr ( df . score , df . mutual_info )[ 0 ] # get spearman correlation corr_spear = stats . spearmanr ( df . score , df . mutual_info )[ 0 ] return corr_stats ( corr_pear , corr_spear ) scorer = 'hsic' sub_df = subset_dataframe ( results_df , 'scorer' , [ scorer ]) test_corrs = get_correlations ( sub_df ) # check if output is named tuple assert isinstance ( test_corrs , corr_stats ) III - Plotting (score vs MI) \u00b6 I want to plot the score versus the mutual information. This will be the plot given the data we have. There are two competing factors that we need to address: per dimension and standardization . The plots were be per method and will either address whether per dimension makes sense or per standardize. def plot_score_vs_mi ( df : pd . DataFrame , scorer : Optional [ str ] = None , # methods: List[str]=['silverman'], # percent: Optional[List[str]]=None, compare : str = 'standard' ): # copy dataframe to prevent overwriting sub_df = df . copy () # segment method if scorer is not None : sub_df = subset_dataframe ( sub_df , [ df_query ( 'scorer' , [ scorer ])]) # # get percentage (if necessary) # if percent is not None: # sub_df = df[df[\"sigma_method\"].isin(percent)] # dropcolumns with dimensions and samples sub_df = sub_df . drop ([ 'dimensions' , 'samples' , 'std' , 'nu' , 'trial' , 'dataset' , 'sigma_X' , 'sigma_Y' ], axis = 1 ) if compare == 'standard' : true_df = sub_df [ sub_df [ 'standardize' ] == True ] true_corrs = get_correlations ( true_df ) true_label = f \"Standardized, (p: { true_corrs . pearson : .2f } , sp: { true_corrs . spearman : .2f } )\" false_df = sub_df [ sub_df [ 'standardize' ] == False ] false_corrs = get_correlations ( false_df ) false_label = f \"Non-Standardized, (p: { false_corrs . pearson : .2f } , sp: { false_corrs . spearman : .2f } )\" elif compare == 'dimension' : true_df = sub_df [ sub_df [ 'per_dimension' ] == True ] true_corrs = get_correlations ( true_df ) true_label = f \"Per Dimension, (p: { true_corrs . pearson : .2f } , sp: { true_corrs . spearman : .2f } )\" false_df = sub_df [ sub_df [ 'per_dimension' ] == False ] false_corrs = get_correlations ( false_df ) false_label = f \"Same, (p: { false_corrs . pearson : .2f } , sp: { false_corrs . spearman : .2f } )\" # plot fig , ax = plt . subplots () ax . scatter ( true_df . score , true_df . mutual_info , marker = 'o' , s = 30 , label = true_label ) ax . scatter ( false_df . score , false_df . mutual_info , marker = 'x' , s = 30 , label = false_label ) ax . legend () ax . set_yscale ( 'symlog' ) ax . set_xlabel ( 'Score' ) ax . set_ylabel ( 'Mutual Information' ) # ax.set_title(f\"{scorer.upper()}\") # ax.text(0.18, 0.18, r, {'color': 'C0', 'fontsize': 16}) return fig , ax Case I - Standardize or Not? \u00b6 # initialize list of queries queries = [] # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) # query dataframe for scott and silverman methods sigma_methods = [ 'scott' , 'silverman' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); Case II - Median (no percent) \u00b6 # initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 'None' ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); Case III - Median + Percent (50, 20, 60) \u00b6 # initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); Case IV - Median + Standardization \u00b6 # initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for hsic standardize = [ True ,] queries . append ( df_query ( 'standardize' , standardize )) sub_df = subset_dataframe ( results_df , queries ) print ( sub_df . shape ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); (24750, 15) Case IV - Median w/o Standardization \u00b6 # initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for hsic standardize = [ False ,] queries . append ( df_query ( 'standardize' , standardize )) sub_df = subset_dataframe ( results_df , queries ) print ( sub_df . shape ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); (24750, 15) import time t0 = time . time () df_ = pd . concat ( results_df , ignore_index = True ) t1 = time . time () - t0 print ( f \"Time Taken: { t1 : .2f } secs\" ) df_ . tail () Time Taken: 37.71 secs .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 59395 gauss 5 11 1 50 2 False False False median 0.9 2.88898 2.88898 cka 0.480297 0.390005 59396 gauss 5 11 1 50 3 False False False median 0.9 3.35418 3.35418 cka 0.530064 0.377389 59397 gauss 5 11 1 50 10 False False False median 0.9 5.687 5.687 cka 0.714579 0.929178 59398 gauss 5 11 1 50 50 False False False median 0.9 13.6425 13.6425 cka 0.975977 4.052644 59399 gauss 5 11 1 50 100 False False False median 0.9 19.2544 19.2544 cka 0.987792 7.938746 Note : This is another bottleneck. Appending to File \u00b6 We can use this simple pseudocode to append to a file. mode = 'a' header = False with open ( f \" { RES_PATH }{ save_name } .csv\" , mode ) as f : df . to_csv ( f , header = header ) header = True","title":"2.2 exp mutual info"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#code-review-iii-multivariate-distributions","text":"Now, the moment we've all be waiting for: How do these methods perform on multivariate distributions. So for this code review, I'll be walking through how these methods compare and I will try to have some telling plots where we outline exactly how each method performs when estimating multivariate distributions such as the Gaussian and T-Student.","title":"Code Review III - Multivariate Distributions"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#recap","text":"So far we've seen how we can estimate sigma as well as how we can estimate the HSIC value. We've seen that this HSIC value depends on the sigma estimator method as well as how we configure the sigma parameter (per dataset, per dimension). So we have a set of methods, now we just need to see how these methods perform when we change the number of dimensions as well as the amount of samples. import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) import warnings from typing import Optional , Tuple from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.distribution import DataParams , Inputs # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from models.dependence import HSICModel # RBIG IT measures # from models.ite_algorithms import run_rbig_models # Plotting from visualization.distribution import plot_scorer # experiment helpers from experiments.utils import dict_product , run_parallel_step from tqdm import tqdm # Plotting Procedures import matplotlib sns . reset_defaults () # sns.set_style('whitegrid') #sns.set_context('talk') sns . set_context ( context = 'poster' , font_scale = 0.7 , rc = { 'font.family' : 'sans-serif' }) # sns.set(font='sans-serif') % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload ! pwd /home/emmanuel/projects/2019_hsic_align/notebooks/4_distributions FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/mutual_info/\" RES_PATH = \"/home/emmanuel/projects/2019_hsic_align/data/results/distributions/mutual_info/\"","title":"Recap"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#experimental-parameters","text":"# initialize the holder for the parameters parameters = {}","title":"Experimental Parameters"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#case-i-hsic-estimator","text":"In this first part, we have 3 cases of HSIC as a combination of a centered kernel and whether or not we normalize the covariance term. The 3 \"scorers\" are as follows: HSIC HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F In this case, the kernels are centered , but the score is not normalized . Kernel Alignment (KA) TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} In this case, the kernels are not centered but the score is normalized . cTKA cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} In this case, the kernels are centered and the score is normalized . # def get_hsic( # X: np.ndarray, # Y: np.ndarray, # scorer: str, # sigma_X: Optional[float]=None, # sigma_Y: Optional[float]=None # ) -> float: # \"\"\"Estimates the HSIC value given some data, sigma and # the score.\"\"\" # # init hsic model class # hsic_model = HSICModel() # # hsic model params # if sigma_X is not None: # hsic_model.kernel_X = RBF(sigma_X) # hsic_model.kernel_Y = RBF(sigma_Y) # # get hsic score # hsic_val = hsic_model.get_score(X, Y, scorer) # return hsic_val # parameters parameters [ 'scorer' ] = [ 'hsic' , 'ka' , 'cka' ]","title":"Case I - HSIC Estimator"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#case-ii-sigma-estimator","text":"For this parameter, we are interested in estimating a few things: We want to know which estimator to choose from. Kernel methods are great if the parameters of the kernel are correct. In supervised scenarios, we can simply learn the appropriate kernel parameters that best fit our data given some criteria. In unsupervised settings, we generally do not know which parameters to choose from. But there are many different ways to choose the parameters as every lab/researcher has their own method that \"they swear by\". I will choose some of the most common ones: Silverman Scott Mean Distance Median Distance Median Distance with the k^{th} k^{th} sample (or percent) of that distance matrix.","title":"Case II - Sigma Estimator"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#case-iii-sigma-application","text":"We want to know the how we are applying the length scale. We have three cases to consider: One length scale for both datasets One length scale per dataset One length scale per dataset per dimension This is important as it could turn a good estimator into a bad estimator. Scott and Silverman work very well for univariate distributions but not very well for multivariate distributions. So if we have one scott/silverman estimate per feature, then this estimator might be a lot better and yield much better results. For the case of the RBF kernel, having one length scale per dimension corresponds to the ARD Kernel which assigns a length scale (or relevance values) per feature. We don't typically use the ARD kernel for kernel methods that we cannot optimize using some gradient function due to how expensive it is. But in this case, it isn't so expensive because we are choosing not to optimizing anything. from typing import Optional from scipy.spatial.distance import pdist , squareform from models.dependence import HSICModel def scotts_factor ( X : np . ndarray ) -> float : \"\"\"Scotts Method to estimate the length scale of the rbf kernel. factor = n**(-1./(d+4)) Parameters ---------- X : np.ndarry Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape return np . power ( n_samples , - 1 / ( n_features + 4. )) def silvermans_factor ( X : np . ndarray ) -> float : \"\"\"Silvermans method used to estimate the length scale of the rbf kernel. factor = (n * (d + 2) / 4.)**(-1. / (d + 4)). Parameters ---------- X : np.ndarray, Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape base = ( n_samples * ( n_features + 2. ) ) / 4. return np . power ( base , - 1 / ( n_features + 4. )) def kth_distance ( dists : np . ndarray , percent : float ) -> np . ndarray : # kth distance calculation (50%) kth_sample = int ( percent * dists . shape [ 0 ]) # take the Kth neighbours of that distance k_dist = dists [:, kth_sample ] return k_dist def sigma_estimate ( X : np . ndarray , method : str = 'median' , percent : Optional [ int ] = None , heuristic : bool = False ) -> float : # get the squared euclidean distances if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) elif percent is not None : kth_sample = int (( percent / 100 ) * X . shape [ 0 ]) dists = np . sort ( squareform ( pdist ( X , 'sqeuclidean' )))[:, kth_sample ] # print(dists.shape, dists.min(), dists.max()) else : dists = np . sort ( pdist ( X , 'sqeuclidean' )) # print(dists.shape, dists.min(), dists.max()) if method == 'median' : sigma = np . median ( dists ) elif method == 'mean' : sigma = np . mean ( dists ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" ) if heuristic : sigma = np . sqrt ( sigma / 2 ) return sigma # Parameters for the estimators parameters [ 'sigma_estimator' ] = [ ( 'median' , 15 ), ( 'median' , 20 ), ( 'median' , 50 ), ( 'median' , 80 ), ( 'scott' , None ), ( 'silverman' , None ), ( 'median' , None ), ] parameters [ 'separate_scales' ] = [ True ] parameters [ 'per_dimension' ] = [ True , False ]","title":"Case III - Sigma Application"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#case-iv-standardize-or-not-standardize","text":"This is a simple case but it can have drastic changes in the results of estimating the length scale. In ML, we tend to standardize our datasets because the algorithms do better with predictions with the ranges are contained. Datasets with massive values for certain features could have adverse affects on the representation and the predictions. The formula is given by: \\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} \\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} Note : this is scaling per feature and not per sample. # from typing import Tuple, Optional def standardize_data ( X : np . ndarray , Y : np . ndarray , standardize : bool = False ) -> Tuple [ np . ndarray , np . ndarray ]: X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) return X , Y # experimental parameters parameters [ 'standardize' ] = [ True , False ]","title":"Case IV - Standardize or not Standardize"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#case-v-multivariate-datasets","text":"For this experiment, we have generated samples for two sets of multivariate distributions: the Gaussian and the T-Student. We have varied the parameters so that we get a variety of samples, dimensions and the amount of similarity (that we can analytically calculate) between them. For example, we can take a Gaussian distribution with a covariance and generate a similar Gaussian distribution with the same number of samples and variance with a covariance. We know the cross-covariance between them and the self-covariances, so we can analytically calculate the mutual information between the two. MI is absolute which is the dependence or similarity between the two datasets. Now, we will see how the HSIC scores will do versus this variation of dataset size and shape. We have the following parameters: Parameter Entry Samples 50, 100, 500, 1K, 5K Dimensions 2, 3, 10, 50, 100 Trials 1 \\rightarrow \\rightarrow 5 Distributions Gaussian, T-Student std (Gauss dist) 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 nu (T-Stu dist) 1, 2, 3, 4, 5, 6, 7, 8, 9 # example parameters for the dataset parameters [ 'dataset' ] = [ 'gauss' ] parameters [ 'std' ] = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 ] parameters [ 'nu' ] = [ 1 ] parameters [ 'trial' ] = [ 1 , 2 , 3 , 4 , 5 ] parameters [ 'dimensions' ] = [ 2 , 3 , 10 , 50 , 100 ] # Loop Params loop_params = {} loop_params [ \"samples\" ] = [ 50 , 100 , 500 , 1_000 , 5_000 ] # example parameters function example_params = DataParams () # generates a named tuple containing the inputs and the MI inputs = example_params . generate_data ()","title":"Case V - Multivariate Datasets"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#main-loop-update","text":"So it turns out just doing a blind parallel scheme ended up taking too much time. So I decided to break the problem up a bit. Do 1 Main Loop (Samples) I decided not to combine all of the combinations; I did all except for the number of samples. Everytime I was watching the progress bar, it would slow down every once in a while. That was because the bottleneck for kernel methods is the number of samples. We have cases of 1_000 which isn't too bad, but 5_000 samples is where the methods really start to slow down. In addition, there will be a lot of memory consumption. So I decided to do a main loop through the number of samples (starting from the smallest and ending with the largest). That way, we can get the easier datasets out of the way and then work on the larger datasets later. Controlling the number of jobs. As I mentioned before, the bottleneck is the number of samples. With 5_000, this starts to eat up a lot of memory when doing this in parallel. So to prevent this I set it up such that I control the number of cores doing the processing. Like so: # Samples Cores 50 28 100 28 500 28 1_000 16 5_000 8 Appending Data Because there was a lot of data being shifted around ( \\sim 297000 \\sim 297000 parameters), the resulting dataframe which stores the experimental results is going to be huge. So I decided that for every call to the main loop, I will run append those results to a csv file and then del that dataframe to free up memory.","title":"Main Loop (Update)"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#experiment","text":"We have a lot of parameters. So we are going to run everything in parallel so that we can save time. We will do this by giving the cartesian product of our nD list of parameters. This will give us a list of tuples where each entry is a set of parameters to evaluate. The length of this list will be the total number of parameters. # create a list of all param combinations # shuffle parameters params = list ( dict_product ( parameters )) loop_params = list ( dict_product ( loop_params )) # parameters_list = list(dict_product(parameters)) n_params , n_loop_params = len ( params ), len ( loop_params ) print ( '# of Params:' , n_params , n_loop_params ) # of Params: 23100 5 from typing import Dict def step ( params : Dict , loop_param : Dict , ): # ================ # DATA # ================ dist_data = DataParams ( dataset = params [ \"dataset\" ], trial = params [ \"trial\" ], std = params [ \"std\" ], nu = params [ \"nu\" ], samples = loop_param [ \"samples\" ], dimensions = params [ \"dimensions\" ], ) # generate data inputs = dist_data . generate_data () # ======================== # Estimate Sigma # ======================== f_x = lambda x : sigma_estimate ( x , method = params [ 'sigma_estimator' ][ 0 ], percent = params [ 'sigma_estimator' ][ 1 ], heuristic = False ) # ======================== # Per Dimension # ======================== if params [ 'per_dimension' ]: sigma_X = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . X . T ] sigma_Y = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . Y . T ] else : sigma_X = f_x ( inputs . X ) sigma_Y = f_x ( inputs . Y ) # ========================= # Estimate HSIC # ========================= hsic_clf = HSICModel ( kernel_X = RBF ( sigma_X ), kernel_Y = RBF ( sigma_Y ), ) score = hsic_clf . get_score ( inputs . X , inputs . Y , params [ 'scorer' ]) # ==================== # Results # ==================== # append results to dataframe results_df = pd . DataFrame ( { # Data Params \"dataset\" : [ params [ \"dataset\" ]], \"trial\" : [ params [ \"trial\" ]], \"std\" : [ params [ \"std\" ]], \"nu\" : [ params [ \"nu\" ]], \"samples\" : [ loop_param [ \"samples\" ]], \"dimensions\" : [ params [ \"dimensions\" ]], # STANDARDIZE PARSM \"standardize\" : [ params [ \"standardize\" ]], # SIGMA FORMAT PARAMS \"per_dimension\" : [ params [ \"per_dimension\" ]], # SIGMA METHOD PARAMS \"sigma_method\" : [ params [ \"sigma_estimator\" ][ 0 ]], \"sigma_percent\" : [ params [ \"sigma_estimator\" ][ 1 ]], \"sigma_X\" : [ sigma_X ], \"sigma_Y\" : [ sigma_Y ], # HSIC Params \"scorer\" : [ params [ \"scorer\" ]], \"score\" : [ score ], \"mutual_info\" : [ inputs . mutual_info ], } ) return results_df","title":"Experiment"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#test-single-step","text":"results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = loop_params [ 0 ], ) [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 3.8s [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 5.6s [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 7.7s [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 10.5s [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 13.8s [Parallel(n_jobs=-1)]: Done 3144 tasks | elapsed: 17.8s [Parallel(n_jobs=-1)]: Done 3994 tasks | elapsed: 22.3s [Parallel(n_jobs=-1)]: Done 4944 tasks | elapsed: 26.9s [Parallel(n_jobs=-1)]: Done 6640 tasks | elapsed: 32.8s [Parallel(n_jobs=-1)]: Done 8940 tasks | elapsed: 40.0s [Parallel(n_jobs=-1)]: Done 11440 tasks | elapsed: 47.6s --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) <ipython-input-35-3df2e8759391> in <module> ----> 1 results_df = run_parallel_step( 2 exp_step = step , 3 parameters = params , 4 n_jobs = - 1 , 5 verbose = 1 , ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/utils.py in run_parallel_step (exp_step, parameters, n_jobs, verbose, **kwargs) 96 97 # loop through parameters ---> 98 results = Parallel(n_jobs=n_jobs, verbose=verbose)( 99 delayed ( exp_step ) ( iparam , ** kwargs ) for iparam in parameters 100 ) ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py in __call__ (self, iterable) 1015 1016 with self . _backend . retrieval_context ( ) : -> 1017 self . retrieve ( ) 1018 # Make sure that we get a last message telling us we are done 1019 elapsed_time = time . time ( ) - self . _start_time ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py in retrieve (self) 907 try : 908 if getattr ( self . _backend , 'supports_timeout' , False ) : --> 909 self . _output . extend ( job . get ( timeout = self . timeout ) ) 910 else : 911 self . _output . extend ( job . get ( ) ) ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/_parallel_backends.py in wrap_future_result (future, timeout) 560 AsyncResults.get from multiprocessing.\"\"\" 561 try : --> 562 return future . result ( timeout = timeout ) 563 except LokyTimeoutError : 564 raise TimeoutError ( ) ~/.conda/envs/hsic_align/lib/python3.8/concurrent/futures/_base.py in result (self, timeout) 432 return self . __get_result ( ) 433 --> 434 self . _condition . wait ( timeout ) 435 436 if self . _state in [ CANCELLED , CANCELLED_AND_NOTIFIED ] : ~/.conda/envs/hsic_align/lib/python3.8/threading.py in wait (self, timeout) 300 try : # restore state no matter what (e.g., KeyboardInterrupt) 301 if timeout is None : --> 302 waiter . acquire ( ) 303 gotit = True 304 else : KeyboardInterrupt : results_df . tail () --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-36-5747df3a89d5> in <module> ----> 1 results_df . tail ( ) NameError : name 'results_df' is not defined # save results save_name = \"test\" dataset = 'gaussian' header = True mode = \"w\" with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) # get params # params, loop_params = get_parameters(args.dataset, njobs=args.njobs) save_name = \"test\" dataset = 'gaussian' # initialize datast header = True mode = \"w\" with tqdm ( loop_params ) as pbar : for iparam in pbar : pbar . set_description ( f \"# Samples: { iparam [ 'samples' ] } , Tasks: { len ( params ) } \" ) results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = iparam , ) # concat current results results_df = pd . concat ( results_df , ignore_index = True ) # save results with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) header = False mode = \"a\" del results_df break # Samples: 50, Tasks: 23100: 0%| | 0/5 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.0s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 4.8s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.5s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 10.7s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 14.7s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.4s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 24.9s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 30.6s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 37.5s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 43.8s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 51.4s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 50, Tasks: 23100: 0%| | 0/5 [01:27<?, ?it/s] step_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 0 gauss 1 1 1 50 2 True True True median 0.1 [0.1686566316684468, 0.14612229488391992] [0.1589719949193001, 0.1680410083908699] hsic 0.019091 0.0","title":"Test - Single Step"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#test-full-loop","text":"# get params # params, loop_params = get_parameters(args.dataset, njobs=args.njobs) save_name = \"test_full\" dataset = 'gaussian' # initialize dataset header = True mode = \"w\" with tqdm ( loop_params ) as pbar : for iparam in pbar : pbar . set_description ( f \"# Samples: { iparam [ 'samples' ] } , Tasks: { len ( params ) } \" ) results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = iparam , ) # concat current results results_df = pd . concat ( results_df , ignore_index = True ) # save results with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) header = False mode = \"a\" # Samples: 50, Tasks: 23100: 0%| | 0/5 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.0s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 4.7s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.4s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 10.7s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 14.9s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.5s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 24.8s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 30.7s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 37.1s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 44.5s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 52.6s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 100, Tasks: 23100: 20%|\u2588\u2588 | 1/5 [01:27<05:51, 87.81s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.2s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.7s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 5.0s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.8s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 11.4s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 15.3s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.8s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 25.6s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 31.7s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 38.3s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 45.4s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 53.3s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 500, Tasks: 23100: 40%|\u2588\u2588\u2588\u2588 | 2/5 [02:57<04:24, 88.32s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 195 tasks | elapsed: 10.0s [Parallel(n_jobs=-1)]: Done 450 tasks | elapsed: 22.8s [Parallel(n_jobs=-1)]: Done 800 tasks | elapsed: 29.2s [Parallel(n_jobs=-1)]: Done 1250 tasks | elapsed: 38.5s [Parallel(n_jobs=-1)]: Done 1800 tasks | elapsed: 59.6s [Parallel(n_jobs=-1)]: Done 2450 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 3200 tasks | elapsed: 1.5min [Parallel(n_jobs=-1)]: Done 4050 tasks | elapsed: 2.0min [Parallel(n_jobs=-1)]: Done 5000 tasks | elapsed: 2.1min [Parallel(n_jobs=-1)]: Done 6050 tasks | elapsed: 2.2min [Parallel(n_jobs=-1)]: Done 7200 tasks | elapsed: 2.6min [Parallel(n_jobs=-1)]: Done 8450 tasks | elapsed: 3.2min [Parallel(n_jobs=-1)]: Done 9800 tasks | elapsed: 3.7min [Parallel(n_jobs=-1)]: Done 11250 tasks | elapsed: 4.4min [Parallel(n_jobs=-1)]: Done 12800 tasks | elapsed: 4.8min [Parallel(n_jobs=-1)]: Done 14450 tasks | elapsed: 5.0min [Parallel(n_jobs=-1)]: Done 16200 tasks | elapsed: 5.8min [Parallel(n_jobs=-1)]: Done 18050 tasks | elapsed: 6.7min [Parallel(n_jobs=-1)]: Done 20000 tasks | elapsed: 7.4min [Parallel(n_jobs=-1)]: Done 22050 tasks | elapsed: 7.6min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 8.0min finished # Samples: 1000, Tasks: 23100: 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 3/5 [11:14<07:01, 210.85s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 27.9s [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 1.3min [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 1.9min [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 2.3min [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 3.8min [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 4.6min [Parallel(n_jobs=-1)]: Done 3144 tasks | elapsed: 5.9min [Parallel(n_jobs=-1)]: Done 3994 tasks | elapsed: 7.8min [Parallel(n_jobs=-1)]: Done 4944 tasks | elapsed: 8.0min [Parallel(n_jobs=-1)]: Done 5994 tasks | elapsed: 8.2min [Parallel(n_jobs=-1)]: Done 7144 tasks | elapsed: 9.8min [Parallel(n_jobs=-1)]: Done 8394 tasks | elapsed: 11.8min [Parallel(n_jobs=-1)]: Done 9744 tasks | elapsed: 13.8min [Parallel(n_jobs=-1)]: Done 11194 tasks | elapsed: 16.5min [Parallel(n_jobs=-1)]: Done 12744 tasks | elapsed: 17.9min [Parallel(n_jobs=-1)]: Done 14394 tasks | elapsed: 18.3min [Parallel(n_jobs=-1)]: Done 16144 tasks | elapsed: 21.6min [Parallel(n_jobs=-1)]: Done 17994 tasks | elapsed: 25.0min [Parallel(n_jobs=-1)]: Done 19944 tasks | elapsed: 27.7min [Parallel(n_jobs=-1)]: Done 21994 tasks | elapsed: 28.0min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 29.7min finished # Samples: 5000, Tasks: 23100: 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 4/5 [41:13<11:27, 687.29s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 13.4min [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 37.4min [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 53.4min [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 65.1min [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 108.6min [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 130.8min results_df = pd . read_csv ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" ) results_df = results_df . loc [:, ~ results_df . columns . str . match ( 'Unnamed' )] results_df = results_df . astype ( object ) . replace ( np . nan , 'None' ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 115495 gauss 5 11 1 5000 2 False False median None 2.596209486629066 2.533566551925972 cka 0.408078 0.390005 115496 gauss 5 11 1 5000 3 False False median None 4.114994392992097 4.495821703399767 cka 0.453781 0.377389 115497 gauss 5 11 1 5000 10 False False median None 14.882197509532734 15.57776152697343 cka 0.752609 0.929178 115498 gauss 5 11 1 5000 50 False False median None 67.1011981827926 65.92873890142732 cka 0.969342 4.052644 115499 gauss 5 11 1 5000 100 False False median None 129.70371717695562 129.7259155663332 cka 0.985882 7.938746 results_df . sigma_percent . unique () . tolist () [15.0, 20.0, 50.0, 80.0, 'None']","title":"Test - Full Loop"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#visualization","text":"Indiscrimenant Points - Dimensions, Samples Method - colors Standardize - type Correlation (MI, Score)","title":"Visualization"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#method-i-scott-silverman","text":"# segment scott sub_df = results_df [ results_df [ \"sigma_method\" ] == 'silverman' ] # sub_df = sub_df[sub_df[\"sigma_percent\"] == 'None'] # dropcolumns with dimensions and samples sub_df = sub_df . drop ([ 'dimensions' , 'samples' , 'std' , 'nu' , 'trial' , 'dataset' , 'sigma_X' , 'sigma_Y' ], axis = 1 ) sub_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } standardize per_dimension sigma_method sigma_percent scorer score mutual_info 114395 False False silverman None cka 0.044627 0.390005 114396 False False silverman None cka 0.065012 0.377389 114397 False False silverman None cka 0.966685 0.929178 114398 False False silverman None cka 1.000000 4.052644 114399 False False silverman None cka 1.000000 7.938746","title":"Method I - Scott, Silverman"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#convenience-functions","text":"","title":"Convenience Functions"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#i-subsetting-the-dataframe","text":"We want to be able to query the dataframe with multiple queries at a time. So I'll create a namedtuple which will hold the name of the column and the elements I want to access. Then I'll have a function that will take a list of these datastructures from typing import List , Optional , Union df_query = namedtuple ( 'df_query' , [ 'name' , 'elements' ]) def subset_dataframe ( df : pd . DataFrame , queries : List [ df_query ], ) -> pd . DataFrame : # copy dataframe to prevent overwriting sub_df = df . copy () # for iquery in queries : sub_df = sub_df [ sub_df [ iquery . name ] . isin ( iquery . elements )] return sub_df # subset dataframe scorer = 'hsic' hsic_data_df = subset_dataframe ( results_df , [ df_query ( 'scorer' , [ scorer ])]) hsic_data_df . head ( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 0 gauss 1 1 1 50 2 True True median 15 [0.05289913460722866, 0.046005156305852286] [0.0603301351143148, 0.06549625956610451] hsic 0.019532 0.0 1 gauss 1 1 1 50 3 True True median 15 [0.05289913460722866, 0.046005156305852286, 0.... [0.06549625956610451, 0.05939212909166344, 0.0... hsic 0.019590 0.0 # check for iscorer in [ 'hsic' , 'ka' , 'cka' ]: # subset dataframe sub_df = subset_dataframe ( results_df , [ df_query ( 'scorer' , [ iscorer ])]) # check that the only element is the one we query-ed assert sub_df . scorer . unique () . tolist () == [ iscorer ]","title":"I - Subsetting the DataFrame"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#ii-correlations","text":"I want to see the correlations between the mutual information and the score. So I'll make a dedicated function to handle that. I'll use a namedtuple to ensure that the results are a callable datastructure and immutable (cannot be overwritten). from scipy import stats from collections import namedtuple corr_stats = namedtuple ( 'corr_stats' , [ 'pearson' , 'spearman' ]) def get_correlations ( df : pd . DataFrame ): \"\"\"Inputs a dataframe and outputs the correlation between the mutual information and the score. Requires the 'mutual_info' and 'score' columns.\"\"\" # check that columns are in dataframe msg = \"No 'mutual_info' and/or 'score' column(s) found in dataframe\" assert { 'mutual_info' , \"score\" } . issubset ( df . columns ), msg # get pearson correlation corr_pear = stats . pearsonr ( df . score , df . mutual_info )[ 0 ] # get spearman correlation corr_spear = stats . spearmanr ( df . score , df . mutual_info )[ 0 ] return corr_stats ( corr_pear , corr_spear ) scorer = 'hsic' sub_df = subset_dataframe ( results_df , 'scorer' , [ scorer ]) test_corrs = get_correlations ( sub_df ) # check if output is named tuple assert isinstance ( test_corrs , corr_stats )","title":"II - Correlations"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#iii-plotting-score-vs-mi","text":"I want to plot the score versus the mutual information. This will be the plot given the data we have. There are two competing factors that we need to address: per dimension and standardization . The plots were be per method and will either address whether per dimension makes sense or per standardize. def plot_score_vs_mi ( df : pd . DataFrame , scorer : Optional [ str ] = None , # methods: List[str]=['silverman'], # percent: Optional[List[str]]=None, compare : str = 'standard' ): # copy dataframe to prevent overwriting sub_df = df . copy () # segment method if scorer is not None : sub_df = subset_dataframe ( sub_df , [ df_query ( 'scorer' , [ scorer ])]) # # get percentage (if necessary) # if percent is not None: # sub_df = df[df[\"sigma_method\"].isin(percent)] # dropcolumns with dimensions and samples sub_df = sub_df . drop ([ 'dimensions' , 'samples' , 'std' , 'nu' , 'trial' , 'dataset' , 'sigma_X' , 'sigma_Y' ], axis = 1 ) if compare == 'standard' : true_df = sub_df [ sub_df [ 'standardize' ] == True ] true_corrs = get_correlations ( true_df ) true_label = f \"Standardized, (p: { true_corrs . pearson : .2f } , sp: { true_corrs . spearman : .2f } )\" false_df = sub_df [ sub_df [ 'standardize' ] == False ] false_corrs = get_correlations ( false_df ) false_label = f \"Non-Standardized, (p: { false_corrs . pearson : .2f } , sp: { false_corrs . spearman : .2f } )\" elif compare == 'dimension' : true_df = sub_df [ sub_df [ 'per_dimension' ] == True ] true_corrs = get_correlations ( true_df ) true_label = f \"Per Dimension, (p: { true_corrs . pearson : .2f } , sp: { true_corrs . spearman : .2f } )\" false_df = sub_df [ sub_df [ 'per_dimension' ] == False ] false_corrs = get_correlations ( false_df ) false_label = f \"Same, (p: { false_corrs . pearson : .2f } , sp: { false_corrs . spearman : .2f } )\" # plot fig , ax = plt . subplots () ax . scatter ( true_df . score , true_df . mutual_info , marker = 'o' , s = 30 , label = true_label ) ax . scatter ( false_df . score , false_df . mutual_info , marker = 'x' , s = 30 , label = false_label ) ax . legend () ax . set_yscale ( 'symlog' ) ax . set_xlabel ( 'Score' ) ax . set_ylabel ( 'Mutual Information' ) # ax.set_title(f\"{scorer.upper()}\") # ax.text(0.18, 0.18, r, {'color': 'C0', 'fontsize': 16}) return fig , ax","title":"III - Plotting (score vs MI)"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#case-i-standardize-or-not","text":"# initialize list of queries queries = [] # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) # query dataframe for scott and silverman methods sigma_methods = [ 'scott' , 'silverman' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' );","title":"Case I - Standardize or Not?"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#case-ii-median-no-percent","text":"# initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 'None' ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' );","title":"Case II - Median (no percent)"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#case-iii-median-percent-50-20-60","text":"# initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' );","title":"Case III - Median + Percent (50, 20, 60)"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#case-iv-median-standardization","text":"# initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for hsic standardize = [ True ,] queries . append ( df_query ( 'standardize' , standardize )) sub_df = subset_dataframe ( results_df , queries ) print ( sub_df . shape ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); (24750, 15)","title":"Case IV - Median + Standardization"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#case-iv-median-wo-standardization","text":"# initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for hsic standardize = [ False ,] queries . append ( df_query ( 'standardize' , standardize )) sub_df = subset_dataframe ( results_df , queries ) print ( sub_df . shape ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); (24750, 15) import time t0 = time . time () df_ = pd . concat ( results_df , ignore_index = True ) t1 = time . time () - t0 print ( f \"Time Taken: { t1 : .2f } secs\" ) df_ . tail () Time Taken: 37.71 secs .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 59395 gauss 5 11 1 50 2 False False False median 0.9 2.88898 2.88898 cka 0.480297 0.390005 59396 gauss 5 11 1 50 3 False False False median 0.9 3.35418 3.35418 cka 0.530064 0.377389 59397 gauss 5 11 1 50 10 False False False median 0.9 5.687 5.687 cka 0.714579 0.929178 59398 gauss 5 11 1 50 50 False False False median 0.9 13.6425 13.6425 cka 0.975977 4.052644 59399 gauss 5 11 1 50 100 False False False median 0.9 19.2544 19.2544 cka 0.987792 7.938746 Note : This is another bottleneck.","title":"Case IV - Median w/o Standardization"},{"location":"notebooks/4_distributions/2.2_exp_mutual_info/#appending-to-file","text":"We can use this simple pseudocode to append to a file. mode = 'a' header = False with open ( f \" { RES_PATH }{ save_name } .csv\" , mode ) as f : df . to_csv ( f , header = header ) header = True","title":"Appending to File"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Walkthrough - Mutual Info vs. Score for Multivariate Distributions \u00b6 This notebook will go through some of the results of the experiment. We will be looking at the 4 factors (standardization, sigma estimator, sigma format and HSIC estimator) and try to discern how the relationship between the score and the mutual information content. It will be a bit tedious to go through things step by step, but hopefully at the end we will recover some sort of relationship. import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) import pathlib import warnings from typing import Optional , Tuple from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.distribution import DataParams , Inputs # Kernel Dependency measure from models.dependence import HSICModel from pysim.kernel.utils import GammaParam , SigmaParam from sklearn.gaussian_process.kernels import RBF # RBIG IT measures # from models.ite_algorithms import run_rbig_models # Plotting from visualization.distribution import plot_scorer # experiment helpers from tqdm import tqdm # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-talk' ]) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 Data \u00b6 FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/mutual_info/\" RES_PATH = \"/home/emmanuel/projects/2019_hsic_align/data/results/distributions/mutual_info/\" ! ls $ RES_PATH old v2_gauss.csv v2_tstudent.csv v3_gauss.csv v3_tstudent.csv Datasets \u00b6 Samples - [500, 1K, 5K, 10K, 30K, 50K] Dimensions - [ 2, 3, 10, 50, 100] trials - 1:5 IT measures - Mutual Information Distributions - [Gaussian, T-Student] T-student Dataset \u00b6 header = [ \"dataset\" , \"trial\" , \"std\" , \"nu\" , \"samples\" , \"dimensions\" , \"standardize\" , \"per_dimension\" , \"separate_scales\" , # SIGMA METHOD PARAMS \"sigma_method\" , \"sigma_percent\" , \"sigma_X\" , \"sigma_Y\" , # HSIC Params \"scorer\" , \"score\" , \"mutual_info\" , ] dataset = 'gauss' # other option tstudent # results_df = pd.read_csv(f\"{RES_PATH}old/{dataset}_mi.csv\") results_df = pd . concat ([ pd . read_csv ( f \" { RES_PATH } /v3_ { dataset } .csv\" , index_col = 0 ), # pd.read_csv(f\"{RES_PATH}/tstudent_mi.csv\", index_col=0) ], ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 72595 gauss 3 10 1 1000 100 False False True median 0.6 12.155468486773366 12.162266644633538 cka 0.966180 4.499836 72596 gauss 4 9 1 1000 3 True True True median 0.7 [1.231808543687941, 1.2683032892452757, 1.3248... [1.2830421106381964, 1.2864799758681433, 1.345... ka 0.690803 0.227706 72597 gauss 3 5 1 1000 3 True False True median 0.7 2.5454157789422895 2.511007319936148 ka 0.918447 0.063609 72598 gauss 2 9 1 1000 10 True False True median 0.7 4.475119613359233 4.572660190532879 hsic 0.009036 0.642396 72599 gauss 1 3 1 1000 2 False True False median 0.3 0.4820529963785358 0.4820529963785358 hsic 0.000832 0.007718 Cleaning \u00b6 So we need to clean this up a little bit. We don't need the sigma values (for now) We should take the average of the trials to get some estimates res_df_ = results_df . copy () # drop sigma, dataset name columns res_df_ = res_df_ . drop ([ # 'sigma_X', 'sigma_Y', 'dataset' ], axis = 1 ) # ================= # average trials # ================= # get dependent variables dependent_vars = [ # Daataset params \"std\" , \"nu\" , \"samples\" , \"dimensions\" , # STANDARDIZE PARAMS \"standardize\" , # SIGMA FORMAT PARAMS \"per_dimension\" , \"separate_scales\" , # SIGMA METHOD PARAMS \"sigma_method\" , \"sigma_percent\" , # HSIC Params \"scorer\" , \"score\" , \"mutual_info\" , # \"trial\" ] res_df_ = res_df_ [ res_df_ [ 'trial' ] == 1 ] . drop ( 'trial' , axis = 1 ) # res_df_.set_index(dependent_vars).groupby(['trial']).mean() res_df_ . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 3 6 1 50 10 False False True median 0.6 4.587135794016568 4.532509381053911 cka 0.429800 0.345177 4 2 1 50 3 True False False median 0.5 2.121602678238625 2.121602678238625 cka 0.073628 0.006926 6 7 1 50 100 True True True median 0.6 [1.0758027372612888, 0.917571157405785, 0.9510... [1.1113174977338918, 1.0792566072679066, 1.146... ka 1.000000 1.852470 12 6 1 50 10 True True False median 0.9 2.09805241194907 2.09805241194907 hsic 0.015722 0.345177 15 5 1 50 10 False True True median 0.4 [0.6540492606563242, 0.5471914802282377, 0.654... [0.7206302062452035, 0.6874572716393927, 0.630... cka 0.999924 0.270526 Case I - Different HSIC Scorer \u00b6 def plot_scores ( df : pd . DataFrame ) -> None : # choose the 3 cases (i.e. the scorers) fig , ax = plt . subplots ( ncols = 3 , figsize = ( 20 , 5 )) # Case I HSIC scorer = 'hsic' case_ = df [ df [ 'scorer' ] == scorer ] ax [ 0 ] . scatter ( case_ . score . values , case_ . mutual_info . values , s = 10 ,) ax [ 0 ] . set_title ( f ' { scorer . upper () } ' ) ax [ 0 ] . set_xlabel ( f 'Score' ) ax [ 0 ] . set_ylabel ( 'Mutual Info' ) # Case II - CKA scorer = 'cka' case_ = df [ df [ 'scorer' ] == scorer ] ax [ 1 ] . scatter ( case_ . score . values , case_ . mutual_info . values , s = 10 ,) ax [ 1 ] . set_title ( f ' { scorer . upper () } ' ) ax [ 1 ] . set_xlabel ( f 'Score' ) ax [ 1 ] . set_ylabel ( 'Mutual Info' ) # ax[1].set_yscale('log') # Case III - KA scorer = 'ka' case_ = df [ df [ 'scorer' ] == scorer ] ax [ 2 ] . scatter ( case_ . score . values , case_ . mutual_info . values , s = 10 ,) ax [ 2 ] . set_title ( f ' { scorer . upper () } ' ) ax [ 2 ] . set_xlabel ( f 'Score' ) ax [ 2 ] . set_ylabel ( 'Mutual Info' ) plt . show () return None plot_scores ( res_df_ ) As we can see, this is nearly impossible to discern. The patterns are all over the place. So let's break down this further. Case II - Sigma Estimator \u00b6 We have a few different methods for estimating sigma. Scott, Silverman Median Values Silverman, Scott \u00b6 constant_methods = [ 'scott' , 'silverman' ] # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] plot_scores ( sub_df_ ) Medians \u00b6 percent_methods = res_df_ [ 'sigma_percent' ] . unique () . tolist () # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] plot_scores ( sub_df_ ) Medians - Reasonable \u00b6 percent_methods = [ 0.30000000000000004 , 0.4 , 0.5 ] # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] plot_scores ( sub_df_ ) Case III - Sigma Configuration \u00b6 Same Length Scale Separate Length Scales Length Scale per Dimension constant_methods = [ 'scott' , 'silverman' ] # seperate_length_scale = # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] plot_scores ( sub_df_ ) Estimator - Medians \u00b6 percent_methods = res_df_ [ 'sigma_percent' ] . unique () . tolist () # seperate_length_scale = # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset print ( \"Per Dimension, Same Data\" ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] plot_scores ( sub_df_ ) Per Dimension, Same Data Sigma Estimator - Medians, Reasonable \u00b6 percent_methods = [ 0.30000000000000004 , 0.4 , 0.5 ] # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] plot_scores ( sub_df_ ) Case IV - Standardize or Not \u00b6 Estimator: Scott/Silverman | NOT Standardized \u00b6 constant_methods = [ 'scott' , 'silverman' ] # seperate_length_scale = # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) Scott / Silverman | Standardized \u00b6 constant_methods = [ 'scott' , 'silverman' ] # seperate_length_scale = # subset dataset print ( 'Same Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Per Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) Same Scale, Same Dim Per Scale, Same Dim Per Scale, Per Dim Medians | Not Standardized \u00b6 percent_methods = res_df_ [ 'sigma_percent' ] . unique () . tolist () # seperate_length_scale = # subset dataset print ( 'Same Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Per Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) Same Scale, Same Dim Per Scale, Same Dim Per Scale, Per Dim Medians | STANDARDIZED \u00b6 percent_methods = res_df_ [ 'sigma_percent' ] . unique () . tolist () # seperate_length_scale = # subset dataset print ( 'Same Scale, Same Dim, Standardized' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Same Dim, Standardized' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Per Dim, Standardized' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) Same Scale, Same Dim, Standardized Per Scale, Same Dim, Standardized Per Scale, Per Dim, Standardized Medians (Reasonable) | NOT STANDARDIZED \u00b6 percent_methods = [ 0.30000000000000004 , 0.4 , 0.5 ] # seperate_length_scale = # subset dataset print ( 'Same Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Per Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) Same Scale, Same Dim Per Scale, Same Dim Per Scale, Per Dim Medians (Reasonable) | STANDARDIZED \u00b6 * Mix - Dimensions, Samples * Colors * Sigma Config - separate length, per dimension, same all, standardize or not * Show 1 estimator! Objective : We want 1 method to rule them all!! percent_methods = [ 0.30000000000000004 ] # seperate_length_scale = # subset dataset print ( 'Same Scale, Same Dim, STANDARDIZED' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] # sub_df_ = sub_df_[sub_df_['dimensions'] == 50] # sub_df_ = sub_df_[sub_df_['samples'] == 50] sub_df_ . head () plot_scores ( sub_df_ ) # # subset dataset # print('Per Scale, Same Dim, STANDARDIZED') # sub_df_ = res_df_[res_df_['sigma_percent'].isin(percent_methods)] # sub_df_ = sub_df_[sub_df_['separate_scales'] == True] # sub_df_ = sub_df_[sub_df_['per_dimension'] == False] # sub_df_ = sub_df_[sub_df_['standardize'] == True] # plot_scores(sub_df_) # # subset dataset # print('Per Scale, Per Dim, STANDARDIZED') # sub_df_ = res_df_[res_df_['sigma_percent'].isin(percent_methods)] # sub_df_ = sub_df_[sub_df_['separate_scales'] == True] # sub_df_ = sub_df_[sub_df_['per_dimension'] == True] # sub_df_ = sub_df_[sub_df_['standardize'] == True] # plot_scores(sub_df_) Same Scale, Same Dim, STANDARDIZED Viz I - Difference in Method \u00b6 For the first visualization, we're just going to get a general overview of how each method performs from typing import List , Callable def plot_individual_scores ( scores_df : pd . DataFrame , gamma_estimators : List , scorer : str , dataset : str = 'gauss' , mi_scale : Optional [ Callable [[ np . ndarray ], np . ndarray ]] = None ): # intialize plot fig , ax = plt . subplots () # subset dataset df_ = scores_df [ scores_df [ 'dataset' ] == dataset ] # subset hsic method df_ = df_ [ df_ [ 'scorer' ] == scorer ] if mi_scale is not None : df_ [ 'mutual_info' ] = mi_scale ( df_ [ 'mutual_info' ]) # subset gamma estimators for iestimator in gamma_estimators : # subsets sub_df = df_ [ df_ [ 'gamma_method' ] == iestimator [ 0 ]] if iestimator [ 1 ] is not None : sub_df = sub_df [ sub_df [ 'gamma_percent' ] == iestimator [ 1 ]] if iestimator [ 2 ] is not None : sub_df = sub_df [ sub_df [ 'gamma_scale' ] == iestimator [ 2 ]] name = list ( filter ( None , iestimator )) name = '_' . join ( str ( i ) for i in name ) ax . scatter ( sub_df . score , sub_df . mutual_info , s = 50 , label = f \" { name } \" , zorder = 3 , marker = '.' ) return fig , ax Viz - Scott, Silverman \u00b6 This should be the worst one for each of them because this method isn't taking into account the dimensions or the samples in a very smart way. It's fine for 1D examples, but we know that this isn't very good for data with a large number of samples or large number of dimensions. demo_params = [ ( 'silverman' , None , None ), ( 'scott' , None , None ), # *[('median', x, None) for x in np.arange(0.1, 1.0, 0.1, dtype=np.float64)] ] scorer = 'cka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" ) scorer = 'hsic' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" ) scorer = 'cka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" ) scorer = 'cka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" ) scorer = 'ka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" ) scorer = 'ka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" ) Viz - Median Distances (All) \u00b6 So for this, I will be looking at a few median distance values. This is the standard method so it will be good to compare. [( 'median' , x , None ) for x in np . arange ( 0.1 , 1.0 , 0.1 , dtype = np . float64 )] [('median', 0.1, None), ('median', 0.2, None), ('median', 0.30000000000000004, None), ('median', 0.4, None), ('median', 0.5, None), ('median', 0.6, None), ('median', 0.7000000000000001, None), ('median', 0.8, None), ('median', 0.9, None)] demo_params = [ ( 'median' , 0.30000000000000004 , None ), ( 'median' , 0.5 , None ), ( 'median' , 0.7000000000000001 , None ), ] demo_params = [( 'median' , x , None ) for x in np . arange ( 0.1 , 1.0 , 0.1 , dtype = np . float64 )] projects / 2019 _hsic_align / results / figures / distribution_experiment / mutual_info scorer = 'hsic' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'hsic' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'cka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'cka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'ka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'ka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) #### Reasonable demo_params = [ ( 'median' , 0.30000000000000004 , None ), ( 'median' , 0.5 , None ), ( 'median' , 0.7000000000000001 , None ), ] scorer = 'hsic' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'hsic' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'cka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'cka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'ka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'ka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" )","title":"2.3 viz mutual info"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#walkthrough-mutual-info-vs-score-for-multivariate-distributions","text":"This notebook will go through some of the results of the experiment. We will be looking at the 4 factors (standardization, sigma estimator, sigma format and HSIC estimator) and try to discern how the relationship between the score and the mutual information content. It will be a bit tedious to go through things step by step, but hopefully at the end we will recover some sort of relationship. import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) import pathlib import warnings from typing import Optional , Tuple from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.distribution import DataParams , Inputs # Kernel Dependency measure from models.dependence import HSICModel from pysim.kernel.utils import GammaParam , SigmaParam from sklearn.gaussian_process.kernels import RBF # RBIG IT measures # from models.ite_algorithms import run_rbig_models # Plotting from visualization.distribution import plot_scorer # experiment helpers from tqdm import tqdm # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-talk' ]) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2","title":"Walkthrough - Mutual Info vs. Score for Multivariate Distributions"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#data","text":"FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/mutual_info/\" RES_PATH = \"/home/emmanuel/projects/2019_hsic_align/data/results/distributions/mutual_info/\" ! ls $ RES_PATH old v2_gauss.csv v2_tstudent.csv v3_gauss.csv v3_tstudent.csv","title":"Data"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#datasets","text":"Samples - [500, 1K, 5K, 10K, 30K, 50K] Dimensions - [ 2, 3, 10, 50, 100] trials - 1:5 IT measures - Mutual Information Distributions - [Gaussian, T-Student]","title":"Datasets"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#t-student-dataset","text":"header = [ \"dataset\" , \"trial\" , \"std\" , \"nu\" , \"samples\" , \"dimensions\" , \"standardize\" , \"per_dimension\" , \"separate_scales\" , # SIGMA METHOD PARAMS \"sigma_method\" , \"sigma_percent\" , \"sigma_X\" , \"sigma_Y\" , # HSIC Params \"scorer\" , \"score\" , \"mutual_info\" , ] dataset = 'gauss' # other option tstudent # results_df = pd.read_csv(f\"{RES_PATH}old/{dataset}_mi.csv\") results_df = pd . concat ([ pd . read_csv ( f \" { RES_PATH } /v3_ { dataset } .csv\" , index_col = 0 ), # pd.read_csv(f\"{RES_PATH}/tstudent_mi.csv\", index_col=0) ], ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 72595 gauss 3 10 1 1000 100 False False True median 0.6 12.155468486773366 12.162266644633538 cka 0.966180 4.499836 72596 gauss 4 9 1 1000 3 True True True median 0.7 [1.231808543687941, 1.2683032892452757, 1.3248... [1.2830421106381964, 1.2864799758681433, 1.345... ka 0.690803 0.227706 72597 gauss 3 5 1 1000 3 True False True median 0.7 2.5454157789422895 2.511007319936148 ka 0.918447 0.063609 72598 gauss 2 9 1 1000 10 True False True median 0.7 4.475119613359233 4.572660190532879 hsic 0.009036 0.642396 72599 gauss 1 3 1 1000 2 False True False median 0.3 0.4820529963785358 0.4820529963785358 hsic 0.000832 0.007718","title":"T-student Dataset"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#cleaning","text":"So we need to clean this up a little bit. We don't need the sigma values (for now) We should take the average of the trials to get some estimates res_df_ = results_df . copy () # drop sigma, dataset name columns res_df_ = res_df_ . drop ([ # 'sigma_X', 'sigma_Y', 'dataset' ], axis = 1 ) # ================= # average trials # ================= # get dependent variables dependent_vars = [ # Daataset params \"std\" , \"nu\" , \"samples\" , \"dimensions\" , # STANDARDIZE PARAMS \"standardize\" , # SIGMA FORMAT PARAMS \"per_dimension\" , \"separate_scales\" , # SIGMA METHOD PARAMS \"sigma_method\" , \"sigma_percent\" , # HSIC Params \"scorer\" , \"score\" , \"mutual_info\" , # \"trial\" ] res_df_ = res_df_ [ res_df_ [ 'trial' ] == 1 ] . drop ( 'trial' , axis = 1 ) # res_df_.set_index(dependent_vars).groupby(['trial']).mean() res_df_ . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 3 6 1 50 10 False False True median 0.6 4.587135794016568 4.532509381053911 cka 0.429800 0.345177 4 2 1 50 3 True False False median 0.5 2.121602678238625 2.121602678238625 cka 0.073628 0.006926 6 7 1 50 100 True True True median 0.6 [1.0758027372612888, 0.917571157405785, 0.9510... [1.1113174977338918, 1.0792566072679066, 1.146... ka 1.000000 1.852470 12 6 1 50 10 True True False median 0.9 2.09805241194907 2.09805241194907 hsic 0.015722 0.345177 15 5 1 50 10 False True True median 0.4 [0.6540492606563242, 0.5471914802282377, 0.654... [0.7206302062452035, 0.6874572716393927, 0.630... cka 0.999924 0.270526","title":"Cleaning"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#case-i-different-hsic-scorer","text":"def plot_scores ( df : pd . DataFrame ) -> None : # choose the 3 cases (i.e. the scorers) fig , ax = plt . subplots ( ncols = 3 , figsize = ( 20 , 5 )) # Case I HSIC scorer = 'hsic' case_ = df [ df [ 'scorer' ] == scorer ] ax [ 0 ] . scatter ( case_ . score . values , case_ . mutual_info . values , s = 10 ,) ax [ 0 ] . set_title ( f ' { scorer . upper () } ' ) ax [ 0 ] . set_xlabel ( f 'Score' ) ax [ 0 ] . set_ylabel ( 'Mutual Info' ) # Case II - CKA scorer = 'cka' case_ = df [ df [ 'scorer' ] == scorer ] ax [ 1 ] . scatter ( case_ . score . values , case_ . mutual_info . values , s = 10 ,) ax [ 1 ] . set_title ( f ' { scorer . upper () } ' ) ax [ 1 ] . set_xlabel ( f 'Score' ) ax [ 1 ] . set_ylabel ( 'Mutual Info' ) # ax[1].set_yscale('log') # Case III - KA scorer = 'ka' case_ = df [ df [ 'scorer' ] == scorer ] ax [ 2 ] . scatter ( case_ . score . values , case_ . mutual_info . values , s = 10 ,) ax [ 2 ] . set_title ( f ' { scorer . upper () } ' ) ax [ 2 ] . set_xlabel ( f 'Score' ) ax [ 2 ] . set_ylabel ( 'Mutual Info' ) plt . show () return None plot_scores ( res_df_ ) As we can see, this is nearly impossible to discern. The patterns are all over the place. So let's break down this further.","title":"Case I - Different HSIC Scorer"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#case-ii-sigma-estimator","text":"We have a few different methods for estimating sigma. Scott, Silverman Median Values","title":"Case II - Sigma Estimator"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#silverman-scott","text":"constant_methods = [ 'scott' , 'silverman' ] # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] plot_scores ( sub_df_ )","title":"Silverman, Scott"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#medians","text":"percent_methods = res_df_ [ 'sigma_percent' ] . unique () . tolist () # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] plot_scores ( sub_df_ )","title":"Medians"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#medians-reasonable","text":"percent_methods = [ 0.30000000000000004 , 0.4 , 0.5 ] # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] plot_scores ( sub_df_ )","title":"Medians - Reasonable"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#case-iii-sigma-configuration","text":"Same Length Scale Separate Length Scales Length Scale per Dimension constant_methods = [ 'scott' , 'silverman' ] # seperate_length_scale = # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] plot_scores ( sub_df_ )","title":"Case III - Sigma Configuration"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#estimator-medians","text":"percent_methods = res_df_ [ 'sigma_percent' ] . unique () . tolist () # seperate_length_scale = # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset print ( \"Per Dimension, Same Data\" ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] plot_scores ( sub_df_ ) Per Dimension, Same Data","title":"Estimator - Medians"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#sigma-estimator-medians-reasonable","text":"percent_methods = [ 0.30000000000000004 , 0.4 , 0.5 ] # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] plot_scores ( sub_df_ )","title":"Sigma Estimator - Medians, Reasonable"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#case-iv-standardize-or-not","text":"","title":"Case IV - Standardize or Not"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#estimator-scottsilverman-not-standardized","text":"constant_methods = [ 'scott' , 'silverman' ] # seperate_length_scale = # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ )","title":"Estimator: Scott/Silverman | NOT Standardized"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#scott-silverman-standardized","text":"constant_methods = [ 'scott' , 'silverman' ] # seperate_length_scale = # subset dataset print ( 'Same Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Per Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_method' ] . isin ( constant_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) Same Scale, Same Dim Per Scale, Same Dim Per Scale, Per Dim","title":"Scott / Silverman | Standardized"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#medians-not-standardized","text":"percent_methods = res_df_ [ 'sigma_percent' ] . unique () . tolist () # seperate_length_scale = # subset dataset print ( 'Same Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Per Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) Same Scale, Same Dim Per Scale, Same Dim Per Scale, Per Dim","title":"Medians | Not Standardized"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#medians-standardized","text":"percent_methods = res_df_ [ 'sigma_percent' ] . unique () . tolist () # seperate_length_scale = # subset dataset print ( 'Same Scale, Same Dim, Standardized' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Same Dim, Standardized' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Per Dim, Standardized' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] plot_scores ( sub_df_ ) Same Scale, Same Dim, Standardized Per Scale, Same Dim, Standardized Per Scale, Per Dim, Standardized","title":"Medians | STANDARDIZED"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#medians-reasonable-not-standardized","text":"percent_methods = [ 0.30000000000000004 , 0.4 , 0.5 ] # seperate_length_scale = # subset dataset print ( 'Same Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Same Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) # subset dataset print ( 'Per Scale, Per Dim' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == True ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == False ] plot_scores ( sub_df_ ) Same Scale, Same Dim Per Scale, Same Dim Per Scale, Per Dim","title":"Medians (Reasonable) | NOT STANDARDIZED"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#medians-reasonable-standardized","text":"* Mix - Dimensions, Samples * Colors * Sigma Config - separate length, per dimension, same all, standardize or not * Show 1 estimator! Objective : We want 1 method to rule them all!! percent_methods = [ 0.30000000000000004 ] # seperate_length_scale = # subset dataset print ( 'Same Scale, Same Dim, STANDARDIZED' ) sub_df_ = res_df_ [ res_df_ [ 'sigma_percent' ] . isin ( percent_methods )] sub_df_ = sub_df_ [ sub_df_ [ 'separate_scales' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'per_dimension' ] == False ] sub_df_ = sub_df_ [ sub_df_ [ 'standardize' ] == True ] # sub_df_ = sub_df_[sub_df_['dimensions'] == 50] # sub_df_ = sub_df_[sub_df_['samples'] == 50] sub_df_ . head () plot_scores ( sub_df_ ) # # subset dataset # print('Per Scale, Same Dim, STANDARDIZED') # sub_df_ = res_df_[res_df_['sigma_percent'].isin(percent_methods)] # sub_df_ = sub_df_[sub_df_['separate_scales'] == True] # sub_df_ = sub_df_[sub_df_['per_dimension'] == False] # sub_df_ = sub_df_[sub_df_['standardize'] == True] # plot_scores(sub_df_) # # subset dataset # print('Per Scale, Per Dim, STANDARDIZED') # sub_df_ = res_df_[res_df_['sigma_percent'].isin(percent_methods)] # sub_df_ = sub_df_[sub_df_['separate_scales'] == True] # sub_df_ = sub_df_[sub_df_['per_dimension'] == True] # sub_df_ = sub_df_[sub_df_['standardize'] == True] # plot_scores(sub_df_) Same Scale, Same Dim, STANDARDIZED","title":"Medians (Reasonable) | STANDARDIZED"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#viz-i-difference-in-method","text":"For the first visualization, we're just going to get a general overview of how each method performs from typing import List , Callable def plot_individual_scores ( scores_df : pd . DataFrame , gamma_estimators : List , scorer : str , dataset : str = 'gauss' , mi_scale : Optional [ Callable [[ np . ndarray ], np . ndarray ]] = None ): # intialize plot fig , ax = plt . subplots () # subset dataset df_ = scores_df [ scores_df [ 'dataset' ] == dataset ] # subset hsic method df_ = df_ [ df_ [ 'scorer' ] == scorer ] if mi_scale is not None : df_ [ 'mutual_info' ] = mi_scale ( df_ [ 'mutual_info' ]) # subset gamma estimators for iestimator in gamma_estimators : # subsets sub_df = df_ [ df_ [ 'gamma_method' ] == iestimator [ 0 ]] if iestimator [ 1 ] is not None : sub_df = sub_df [ sub_df [ 'gamma_percent' ] == iestimator [ 1 ]] if iestimator [ 2 ] is not None : sub_df = sub_df [ sub_df [ 'gamma_scale' ] == iestimator [ 2 ]] name = list ( filter ( None , iestimator )) name = '_' . join ( str ( i ) for i in name ) ax . scatter ( sub_df . score , sub_df . mutual_info , s = 50 , label = f \" { name } \" , zorder = 3 , marker = '.' ) return fig , ax","title":"Viz I - Difference in Method"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#viz-scott-silverman","text":"This should be the worst one for each of them because this method isn't taking into account the dimensions or the samples in a very smart way. It's fine for 1D examples, but we know that this isn't very good for data with a large number of samples or large number of dimensions. demo_params = [ ( 'silverman' , None , None ), ( 'scott' , None , None ), # *[('median', x, None) for x in np.arange(0.1, 1.0, 0.1, dtype=np.float64)] ] scorer = 'cka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" ) scorer = 'hsic' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" ) scorer = 'cka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" ) scorer = 'cka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" ) scorer = 'ka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" ) scorer = 'ka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) ax . legend () plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _standard.png\" )","title":"Viz - Scott, Silverman"},{"location":"notebooks/4_distributions/2.3_viz_mutual_info/#viz-median-distances-all","text":"So for this, I will be looking at a few median distance values. This is the standard method so it will be good to compare. [( 'median' , x , None ) for x in np . arange ( 0.1 , 1.0 , 0.1 , dtype = np . float64 )] [('median', 0.1, None), ('median', 0.2, None), ('median', 0.30000000000000004, None), ('median', 0.4, None), ('median', 0.5, None), ('median', 0.6, None), ('median', 0.7000000000000001, None), ('median', 0.8, None), ('median', 0.9, None)] demo_params = [ ( 'median' , 0.30000000000000004 , None ), ( 'median' , 0.5 , None ), ( 'median' , 0.7000000000000001 , None ), ] demo_params = [( 'median' , x , None ) for x in np . arange ( 0.1 , 1.0 , 0.1 , dtype = np . float64 )] projects / 2019 _hsic_align / results / figures / distribution_experiment / mutual_info scorer = 'hsic' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'hsic' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'cka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'cka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'ka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'ka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) #### Reasonable demo_params = [ ( 'median' , 0.30000000000000004 , None ), ( 'median' , 0.5 , None ), ( 'median' , 0.7000000000000001 , None ), ] scorer = 'hsic' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'hsic' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'cka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'cka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'ka' dataset = 'gauss' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" ) scorer = 'ka' dataset = 'tstudent' fig , ax = plot_individual_scores ( results_df , demo_params , scorer , dataset , mi_scale = np . log2 ) ax . set_xlabel ( f \"Score\" ) ax . set_ylabel ( f \"Mutual Information\" ) ax . set_title ( f \"Method: { scorer } , Dataset: { dataset } \" ) # ax.legend() plt . tight_layout () fig . savefig ( f \" { FIG_PATH }{ scorer } _ { dataset } _median_all.png\" )","title":"Viz - Median Distances (All)"},{"location":"notebooks/4_distributions/untitled/","text":"Names \"dataset\" \"trial\" \"std\" \"nu \"samples\" \"dimensions\" # STANDARDIZE PARSM \"standardize\": [params[\"standardize\"]], SIGMA FORMAT PARAMS \"per_dimension\": [params[\"per_dimension\"]], \"separate_scales\": [params[\"separate_scales\"]], # SIGMA METHOD PARAMS \"sigma_method\": [params[\"sigma_estimator\"][0]], \"sigma_percent\": [params[\"sigma_estimator\"][1]], \"sigma_X\": [sigma_X], sigma_Y\": [sigma_Y], # HSIC Params \"scorer\": [params[\"scorer\"]], \"score\": [score], \"mutual_info\": [inputs.mutual_info],","title":"Untitled"},{"location":"notebooks/4_distributions/old/0_demo/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Distribution Experiment \u00b6 import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import RBIGData # Experiments from experiments.distributions import DistributionExp # Kernel Dependency measure from models.dependence import HSIC , train_rbf_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import scipy.io as scio import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 path '/home/emmanuel/projects/2019_hsic_align/notebooks/4_distributions/../../src' Datasets \u00b6 Samples - [500, 1K, 5K, 10K, 30K, 50K] Dimensions - [ 2, 3, 10, 50, 100] trials - [1,5] IT measures - [TC, H, MI, KLD] Distributions - [Linear, Gaussian, T-Student] Example - Gaussian Distribution \u00b6 data_path = \"/media/disk/erc/papers/2018_RBIG_IT_measures/2018_RBIG_IT_measures/reproducible_results/DATA/\" gauss_data = f \" { data_path } MI_gaus/\" sample_data = \"DATA_MI_gaus_nd_3_Ns_500_tryal_1.mat\" dat = scio . loadmat ( f \" { gauss_data }{ sample_data } \" ) X , Y , mi_val = dat [ 'X' ], dat [ 'Y' ], dat [ 'MI_ori_nats' ] Using the Helper function \u00b6 from typing import Optional class MIData : \"\"\"MI Data Dataset ------- trials = 1:5 samples = 50, 100, 500, 1_000, 5_000 dimensions = 2, 3, 10, 50, 100 std = 1:11 nu = 1:9 \"\"\" def __init__ ( self , distribution : Optional [ 'gauss' ]) -> None : self . distribution = distribution self . data_path = \"/media/disk/erc/papers/2019_HSIC_ALIGN/data/mi_distributions/\" if self . distribution == 'gauss' : self . dist_path = f \" { self . data_path } MI_gaus/\" elif self . distribution == 'tstudent' : self . dist_path = f \" { self . data_path } MI_tstu/\" else : raise ValueError ( f \"Unrecognized Dataset: { distribution } \" ) def get_data ( self , samples = 50 , dimensions = 2 , std = 1 , trial = 1 , nu = 1 ): if self . distribution == 'gauss' : dat = scio . loadmat ( f \" { self . dist_path } DATA_MI_gaus_nd_ { dimensions } _\" f \"Ns_ { samples } _std_ { std } _tryal_ { trial } .mat\" ) return dat [ 'X' ], dat [ 'Y' ], float ( dat [ 'MI_ori_nats' ][ 0 ][ 0 ]) elif self . distribution == 'tstudent' : dat = scio . loadmat ( f \" { self . dist_path } DATA_MI_tstu_nd_ { dimensions } _\" f \"Ns_ { samples } _tryal_ { trial } _nu_ { nu } .mat\" ) return dat [ 'X' ], dat [ 'Y' ], float ( dat [ 'MI_ori_nats' ][ 0 ][ 0 ]) else : raise ValueError ( f \"Unrecognized distribution ' { self . distribution } '\" ) itera = { '1' : 'a' , '2' : 'b' } for iitera in itera . items (): print ( iitera [ 0 ], iitera [ 1 ]) 1 a 2 b dataset = 'tstudent' mi_loader = MIData ( 'tstudent' ) x , y , mi = mi_loader . get_data () SAVE_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/hsic/\" clf_exp = DistributionExp ( seed = 123 , factor = 1 , sigma_est = 'median' , n_gamma = 10 , save_path = SAVE_PATH , save_name = 'dist_v2_belkin' , ) # run full experiment clf_exp . run_experiment () Function: gauss --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) <ipython-input-6-6466ca7e5a66> in <module> 11 12 # run full experiment ---> 13 clf_exp . run_experiment ( ) ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/distributions.py in run_experiment (self) 223 hsic_method = hsic_method , 224 hsic_score = hsic_score , --> 225 mi_score = mi_score , 226 ) 227 ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/distributions.py in append_results (self, results_df, dataset, trial, n_samples, d_dimensions, std, nu, gamma, gamma_median, gamma_silv, gamma_scott, gamma_belkin, hsic_method, hsic_score, mi_score) 332 \"mi_score\" : mi_score , 333 }, --> 334 ignore_index = True , 335 ) 336 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/frame.py in append (self, other, ignore_index, verify_integrity, sort) 7103 columns = combined_columns , 7104 ) -> 7105 other = other . _convert ( datetime = True , timedelta = True ) 7106 if not self . columns . equals ( combined_columns ) : 7107 self = self . reindex ( columns = combined_columns ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/generic.py in _convert (self, datetime, numeric, timedelta, coerce, copy) 6044 timedelta = timedelta , 6045 coerce = coerce , -> 6046 copy = copy , 6047 ) 6048 ).__finalize__(self) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/managers.py in convert (self, **kwargs) 582 583 def convert ( self , ** kwargs ) : --> 584 return self . apply ( \"convert\" , ** kwargs ) 585 586 def replace ( self , value , ** kwargs ) : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/managers.py in apply (self, f, axes, filter, do_integrity_check, consolidate, **kwargs) 436 kwargs [ k ] = obj . reindex ( b_items , axis = axis , copy = align_copy ) 437 --> 438 applied = getattr ( b , f ) ( ** kwargs ) 439 result_blocks = _extend_blocks ( applied , result_blocks ) 440 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/blocks.py in convert (self, *args, **kwargs) 2821 2822 if by_item and not self . _is_single_block : -> 2823 blocks = self . split_and_operate ( None , f , False ) 2824 else : 2825 values = f ( None , self . values . ravel ( ) , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/blocks.py in split_and_operate (self, mask, f, inplace) 491 # need a new block 492 if m . any ( ) : --> 493 nv = f ( m , v , i ) 494 else : 495 nv = v if inplace else v . copy ( ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/blocks.py in f (m, v, i) 2812 def f ( m , v , i ) : 2813 shape = v . shape -> 2814 values = fn ( v . ravel ( ) , ** fn_kwargs ) 2815 if isinstance ( values , np . ndarray ) : 2816 # TODO: allow EA once reshape is supported ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/dtypes/cast.py in soft_convert_objects (values, datetime, numeric, timedelta, coerce, copy) 844 # bound of nanosecond-resolution 64-bit integers. 845 try : --> 846 values = lib . maybe_convert_objects ( values , convert_datetime = datetime ) 847 except OutOfBoundsDatetime : 848 pass KeyboardInterrupt :","title":"0 demo"},{"location":"notebooks/4_distributions/old/0_demo/#distribution-experiment","text":"import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import RBIGData # Experiments from experiments.distributions import DistributionExp # Kernel Dependency measure from models.dependence import HSIC , train_rbf_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import scipy.io as scio import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 path '/home/emmanuel/projects/2019_hsic_align/notebooks/4_distributions/../../src'","title":"Distribution Experiment"},{"location":"notebooks/4_distributions/old/0_demo/#datasets","text":"Samples - [500, 1K, 5K, 10K, 30K, 50K] Dimensions - [ 2, 3, 10, 50, 100] trials - [1,5] IT measures - [TC, H, MI, KLD] Distributions - [Linear, Gaussian, T-Student]","title":"Datasets"},{"location":"notebooks/4_distributions/old/0_demo/#example-gaussian-distribution","text":"data_path = \"/media/disk/erc/papers/2018_RBIG_IT_measures/2018_RBIG_IT_measures/reproducible_results/DATA/\" gauss_data = f \" { data_path } MI_gaus/\" sample_data = \"DATA_MI_gaus_nd_3_Ns_500_tryal_1.mat\" dat = scio . loadmat ( f \" { gauss_data }{ sample_data } \" ) X , Y , mi_val = dat [ 'X' ], dat [ 'Y' ], dat [ 'MI_ori_nats' ]","title":"Example - Gaussian Distribution"},{"location":"notebooks/4_distributions/old/0_demo/#using-the-helper-function","text":"from typing import Optional class MIData : \"\"\"MI Data Dataset ------- trials = 1:5 samples = 50, 100, 500, 1_000, 5_000 dimensions = 2, 3, 10, 50, 100 std = 1:11 nu = 1:9 \"\"\" def __init__ ( self , distribution : Optional [ 'gauss' ]) -> None : self . distribution = distribution self . data_path = \"/media/disk/erc/papers/2019_HSIC_ALIGN/data/mi_distributions/\" if self . distribution == 'gauss' : self . dist_path = f \" { self . data_path } MI_gaus/\" elif self . distribution == 'tstudent' : self . dist_path = f \" { self . data_path } MI_tstu/\" else : raise ValueError ( f \"Unrecognized Dataset: { distribution } \" ) def get_data ( self , samples = 50 , dimensions = 2 , std = 1 , trial = 1 , nu = 1 ): if self . distribution == 'gauss' : dat = scio . loadmat ( f \" { self . dist_path } DATA_MI_gaus_nd_ { dimensions } _\" f \"Ns_ { samples } _std_ { std } _tryal_ { trial } .mat\" ) return dat [ 'X' ], dat [ 'Y' ], float ( dat [ 'MI_ori_nats' ][ 0 ][ 0 ]) elif self . distribution == 'tstudent' : dat = scio . loadmat ( f \" { self . dist_path } DATA_MI_tstu_nd_ { dimensions } _\" f \"Ns_ { samples } _tryal_ { trial } _nu_ { nu } .mat\" ) return dat [ 'X' ], dat [ 'Y' ], float ( dat [ 'MI_ori_nats' ][ 0 ][ 0 ]) else : raise ValueError ( f \"Unrecognized distribution ' { self . distribution } '\" ) itera = { '1' : 'a' , '2' : 'b' } for iitera in itera . items (): print ( iitera [ 0 ], iitera [ 1 ]) 1 a 2 b dataset = 'tstudent' mi_loader = MIData ( 'tstudent' ) x , y , mi = mi_loader . get_data () SAVE_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/hsic/\" clf_exp = DistributionExp ( seed = 123 , factor = 1 , sigma_est = 'median' , n_gamma = 10 , save_path = SAVE_PATH , save_name = 'dist_v2_belkin' , ) # run full experiment clf_exp . run_experiment () Function: gauss --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) <ipython-input-6-6466ca7e5a66> in <module> 11 12 # run full experiment ---> 13 clf_exp . run_experiment ( ) ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/distributions.py in run_experiment (self) 223 hsic_method = hsic_method , 224 hsic_score = hsic_score , --> 225 mi_score = mi_score , 226 ) 227 ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/distributions.py in append_results (self, results_df, dataset, trial, n_samples, d_dimensions, std, nu, gamma, gamma_median, gamma_silv, gamma_scott, gamma_belkin, hsic_method, hsic_score, mi_score) 332 \"mi_score\" : mi_score , 333 }, --> 334 ignore_index = True , 335 ) 336 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/frame.py in append (self, other, ignore_index, verify_integrity, sort) 7103 columns = combined_columns , 7104 ) -> 7105 other = other . _convert ( datetime = True , timedelta = True ) 7106 if not self . columns . equals ( combined_columns ) : 7107 self = self . reindex ( columns = combined_columns ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/generic.py in _convert (self, datetime, numeric, timedelta, coerce, copy) 6044 timedelta = timedelta , 6045 coerce = coerce , -> 6046 copy = copy , 6047 ) 6048 ).__finalize__(self) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/managers.py in convert (self, **kwargs) 582 583 def convert ( self , ** kwargs ) : --> 584 return self . apply ( \"convert\" , ** kwargs ) 585 586 def replace ( self , value , ** kwargs ) : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/managers.py in apply (self, f, axes, filter, do_integrity_check, consolidate, **kwargs) 436 kwargs [ k ] = obj . reindex ( b_items , axis = axis , copy = align_copy ) 437 --> 438 applied = getattr ( b , f ) ( ** kwargs ) 439 result_blocks = _extend_blocks ( applied , result_blocks ) 440 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/blocks.py in convert (self, *args, **kwargs) 2821 2822 if by_item and not self . _is_single_block : -> 2823 blocks = self . split_and_operate ( None , f , False ) 2824 else : 2825 values = f ( None , self . values . ravel ( ) , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/blocks.py in split_and_operate (self, mask, f, inplace) 491 # need a new block 492 if m . any ( ) : --> 493 nv = f ( m , v , i ) 494 else : 495 nv = v if inplace else v . copy ( ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/blocks.py in f (m, v, i) 2812 def f ( m , v , i ) : 2813 shape = v . shape -> 2814 values = fn ( v . ravel ( ) , ** fn_kwargs ) 2815 if isinstance ( values , np . ndarray ) : 2816 # TODO: allow EA once reshape is supported ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/dtypes/cast.py in soft_convert_objects (values, datetime, numeric, timedelta, coerce, copy) 844 # bound of nanosecond-resolution 64-bit integers. 845 try : --> 846 values = lib . maybe_convert_objects ( values , convert_datetime = datetime ) 847 except OutOfBoundsDatetime : 848 pass KeyboardInterrupt :","title":"Using the Helper function"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Distribution Experiment - Walkthrough \u00b6 import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import warnings import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.it_data import MIData # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models # experiment helpers from tqdm import tqdm import prefect # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ( 'ggplot' ) sns . set_style ( \"dark\" ) sns . set_context ( \"poster\" ) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 Datasets \u00b6 Samples - [500, 1K, 5K, 10K, 30K, 50K] Dimensions - [ 2, 3, 10, 50, 100] trials - 1:5 IT measures - Mutual Information Distributions - [Gaussian, T-Student] Example Gaussian Distribution: 2D \u00b6 # dataloader params dataset = 'gauss' # initialize dataloader dataloader = MIData ( dataset ) # dataset params samples = 100 dimensions = 2 std = 1 trial = 1 # extract dataset X , Y , mi_val = dataloader . get_data ( samples = samples , dimensions = dimensions , std = std , trial = trial ) from prefect import task , Flow , Parameter @task def get_data ( dataset : str , samples : int , dimensions : int , dof : int , trial : int ): dataloader = MIData ( dataset ) # extract dataset X , Y , mi_val = dataloader . get_data ( samples = samples , dimensions = dimensions , std = dof , trial = trial ) data = { 'X' : X , \"Y\" : Y , \"mi_val\" : mi_val } return data class GetData ( Task ): def __init__ ( self , dataset : str = 'gauss' , samples : int = 100 , dimensions : int = 2 , std : int = 1 , trial : int = 1 , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . dataset = dataset self . samples = samples self . dimensions = dimensions self . std = std self . trial = trial def run ( self , ) with Flow ( \"Run experiment\" ) as flow : # Data Params dataset = Parameter ( \"dataset\" , default = 'gauss' ) samples = Parameter ( \"samples\" , default = 100 ) dimensions = Parameter ( \"dimensions\" , default = 2 ) std = Parameter ( \"std\" , default = 1 ) trial = Parameter ( \"trial\" , default = 1 ) # Load Data data = get_data ( dataset , samples , dimensions , std , trial ) flow . run () [2019-10-22 14:16:39,783] INFO - prefect.FlowRunner | Beginning Flow run for 'Run experiment' [2019-10-22 14:16:39,787] INFO - prefect.FlowRunner | Starting flow run. [2019-10-22 14:16:39,800] INFO - prefect.TaskRunner | Task 'dimensions': Starting task run... [2019-10-22 14:16:39,806] INFO - prefect.TaskRunner | Task 'dimensions': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,816] INFO - prefect.TaskRunner | Task 'trial': Starting task run... [2019-10-22 14:16:39,821] INFO - prefect.TaskRunner | Task 'trial': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,831] INFO - prefect.TaskRunner | Task 'dataset': Starting task run... [2019-10-22 14:16:39,836] INFO - prefect.TaskRunner | Task 'dataset': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,847] INFO - prefect.TaskRunner | Task 'samples': Starting task run... [2019-10-22 14:16:39,852] INFO - prefect.TaskRunner | Task 'samples': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,862] INFO - prefect.TaskRunner | Task 'std': Starting task run... [2019-10-22 14:16:39,867] INFO - prefect.TaskRunner | Task 'std': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,876] INFO - prefect.TaskRunner | Task 'get_data': Starting task run... [2019-10-22 14:16:39,885] INFO - prefect.TaskRunner | Task 'get_data': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,888] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded <Success: \"All reference tasks succeeded.\"> flow . tasks {<Parameter: dataset>, <Parameter: dimensions>, <Parameter: samples>, <Parameter: std>, <Parameter: trial>, <Task: get_data>} class ExpParams : # dataset params samples = 100 dimensions = 2 std = 1 trial = 1 # plot data fig = plt . figure ( figsize = ( 10 , 10 )) g = sns . jointplot ( x = X [:, 0 ], y = X [:, 1 ], ) plt . title ( 'X' ) plt . show () # plot data fig = plt . figure ( figsize = ( 10 , 10 )) g = sns . jointplot ( x = Y [:, 0 ], y = Y [:, 1 ], ) plt . title ( 'Y' ) plt . show () <Figure size 720x720 with 0 Axes> <Figure size 720x720 with 0 Axes> HSIC Algorithms \u00b6 HSIC \u00b6 algorithm path : src/models/dependence.py 1. Initialize Gamma \u00b6 # sigma initialization params percent = . 2 method = 'belkin' # initialize sigma sigma_init_X = estimate_sigma ( X , method = method , percent = percent ) sigma_init_Y = estimate_sigma ( Y , method = method , percent = percent ) print ( f 'Sigma_x: ' , sigma_init_X ) print ( f 'Sigma_y: ' , sigma_init_Y ) Sigma_x: 0.9583709525127224 Sigma_y: 0.8719893561231888 1.1 Mean of Initial sigmas \u00b6 sigma_init = np . mean ([ sigma_init_X , sigma_init_Y ]) print ( f 'Sigma_init (Belkin): ' , sigma_init ) Sigma_init (Belkin): 0.9151801543179556 1.3 Convert Gamma to Sigma \u00b6 The standard kernel function is: K(x,y)= \\exp(-\\frac{||x-y||^2}{2\\sigma^2}) K(x,y)= \\exp(-\\frac{||x-y||^2}{2\\sigma^2}) Sklearn uses the following RBF kernel function: K(x,y)= \\exp(-\\gamma||x-y||^2) K(x,y)= \\exp(-\\gamma||x-y||^2) So the following relationship is: \\gamma = \\frac{1}{2\\sigma^2} \\gamma = \\frac{1}{2\\sigma^2} <span><span class=\"MathJax_Preview\">\\gamma = \\frac{1}{2\\sigma^2}</span><script type=\"math/tex\">\\gamma = \\frac{1}{2\\sigma^2} # convert sigma to gamma gamma_init = sigma_to_gamma ( sigma_init ) # check if true assert ( gamma_init == 1 / ( 2 * sigma_init ** 2 )) print ( 'Gamma_init (Belkin):' , gamma_init ) Gamma_init (Belkin): 0.5969759242357159 1.4 Create Function \u00b6 from typing import Optional @task def get_gamma_init ( data , method : str , percent : Optional [ float ] = None ) -> float : \"\"\"Get Gamma initializer Parameters ---------- method : str, the initialization method percent : float if using the Belkin method, this uses a percentage of the kth nearest neighbour Returns ------- gamma_init : float the initial gamma value \"\"\" # initialize sigma sigma_init_X = estimate_sigma ( data [ \"X\" ], method = method , percent = percent ) sigma_init_Y = estimate_sigma ( data [ \"Y\" ], method = method , percent = percent ) # mean of the two sigma_init = np . mean ([ sigma_init_X , sigma_init_Y ]) # convert sigma to gamma gamma_init = sigma_to_gamma ( sigma_init ) # return initial gamma value return { \"gamma_init\" : gamma_init } data <Task: get_data> with Flow ( \"Run experiment\" ) as flow : # Data Params dataset = Parameter ( \"dataset\" , default = 'gauss' ) samples = Parameter ( \"samples\" , default = 100 ) dimensions = Parameter ( \"dimensions\" , default = 2 ) std = Parameter ( \"std\" , default = 1 ) trial = Parameter ( \"trial\" , default = 1 ) # Load Data data = get_data ( dataset , samples , dimensions , std , trial ) # Gamma Parameters method = Parameter ( \"method\" , default = 'median' ) percent = Parameter ( \"percent\" , default = 0.2 ) # get gamma gamma_init = get_gamma_init ( data , method , percent ) flow . run () [2019-10-22 14:17:31,762] INFO - prefect.FlowRunner | Beginning Flow run for 'Run experiment' [2019-10-22 14:17:31,766] INFO - prefect.FlowRunner | Starting flow run. [2019-10-22 14:17:31,780] INFO - prefect.TaskRunner | Task 'dimensions': Starting task run... [2019-10-22 14:17:31,786] INFO - prefect.TaskRunner | Task 'dimensions': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,797] INFO - prefect.TaskRunner | Task 'dataset': Starting task run... [2019-10-22 14:17:31,803] INFO - prefect.TaskRunner | Task 'dataset': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,813] INFO - prefect.TaskRunner | Task 'std': Starting task run... [2019-10-22 14:17:31,818] INFO - prefect.TaskRunner | Task 'std': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,828] INFO - prefect.TaskRunner | Task 'trial': Starting task run... [2019-10-22 14:17:31,833] INFO - prefect.TaskRunner | Task 'trial': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,843] INFO - prefect.TaskRunner | Task 'method': Starting task run... [2019-10-22 14:17:31,848] INFO - prefect.TaskRunner | Task 'method': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,857] INFO - prefect.TaskRunner | Task 'percent': Starting task run... [2019-10-22 14:17:31,862] INFO - prefect.TaskRunner | Task 'percent': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,872] INFO - prefect.TaskRunner | Task 'samples': Starting task run... [2019-10-22 14:17:31,877] INFO - prefect.TaskRunner | Task 'samples': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,887] INFO - prefect.TaskRunner | Task 'get_data': Starting task run... [2019-10-22 14:17:31,895] INFO - prefect.TaskRunner | Task 'get_data': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,910] INFO - prefect.TaskRunner | Task 'get_gamma_init': Starting task run... [2019-10-22 14:17:31,918] INFO - prefect.TaskRunner | Task 'get_gamma_init': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,921] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded <Task: get_gamma_init> <Success: \"All reference tasks succeeded.\"> 4. Calculate HSIC \u00b6 # hsic parameters kernel = 'rbf' scorer = 'hsic' subsample = None bias = True # initialize HSIC model clf_hsic = HSIC ( gamma = gamma_init , kernel = kernel , scorer = scorer , subsample = subsample , bias = bias ) # fit model to data clf_hsic . fit ( X , Y ) # get hsic value hsic_value = clf_hsic . score ( X ) print ( 'HSIC: ' , hsic_value ) HSIC: 0.004420621559606378 @task def get_hsic ( data , scorer : str , gamma_init ) -> float : \"\"\"Gets the HSIC parameters Parameters ---------- X : np.ndarray, (n_samples, d_dimensions) 1st input array Y : np.ndarray, (n_samples, d_dimensions) 2nd input array scorer : str, the scorer to calculate the hsic * hsic - HSIC method * tka - kernel tangent alignment * ctka - centered kernel tangent alignment gamma_init : float the initial gamma parameter Returns ------- hsic_value : float the hsic value calculated from the scorer \"\"\" # hsic parameters kernel = 'rbf' subsample = None bias = True # initialize HSIC model clf_hsic = HSIC ( gamma = gamma_init [ 'gamma_init' ], kernel = kernel , scorer = scorer , subsample = subsample , bias = bias ) # fit model to data clf_hsic . fit ( data [ 'X' ], data [ 'Y' ]) # get hsic value hsic_value = clf_hsic . score ( data [ 'X' ]) return { \"hsic_value\" : hsic_value } with Flow ( \"Run experiment\" ) as flow : # Data Params dataset = Parameter ( \"dataset\" , default = 'gauss' ) samples = Parameter ( \"samples\" , default = 100 ) dimensions = Parameter ( \"dimensions\" , default = 2 ) std = Parameter ( \"std\" , default = 1 ) trial = Parameter ( \"trial\" , default = 1 ) # Load Data data = get_data ( dataset , samples , dimensions , std , trial ) # Gamma Parameters method = Parameter ( \"method\" , default = 'median' ) percent = Parameter ( \"percent\" , default = 0.2 ) # get gamma gamma_init = get_gamma_init ( data , method , percent ) # HSIC Params scorer = Parameter ( \"scorer\" , default = 'hsic' ) # Get HSIC value hsic_value = get_hsic ( data , scorer , gamma_init ) # Save data for isamples in [ 50 , 100 ]: flow . run ( parameters = { 'samples' : isamples }) [2019-10-22 14:24:44,522] INFO - prefect.FlowRunner | Beginning Flow run for 'Run experiment' [2019-10-22 14:24:44,526] INFO - prefect.FlowRunner | Starting flow run. [2019-10-22 14:24:44,541] INFO - prefect.TaskRunner | Task 'samples': Starting task run... [2019-10-22 14:24:44,547] INFO - prefect.TaskRunner | Task 'samples': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,558] INFO - prefect.TaskRunner | Task 'std': Starting task run... [2019-10-22 14:24:44,564] INFO - prefect.TaskRunner | Task 'std': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,574] INFO - prefect.TaskRunner | Task 'trial': Starting task run... [2019-10-22 14:24:44,579] INFO - prefect.TaskRunner | Task 'trial': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,586] INFO - prefect.TaskRunner | Task 'scorer': Starting task run... [2019-10-22 14:24:44,590] INFO - prefect.TaskRunner | Task 'scorer': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,597] INFO - prefect.TaskRunner | Task 'method': Starting task run... [2019-10-22 14:24:44,601] INFO - prefect.TaskRunner | Task 'method': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,607] INFO - prefect.TaskRunner | Task 'dataset': Starting task run... [2019-10-22 14:24:44,612] INFO - prefect.TaskRunner | Task 'dataset': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,618] INFO - prefect.TaskRunner | Task 'percent': Starting task run... [2019-10-22 14:24:44,622] INFO - prefect.TaskRunner | Task 'percent': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,629] INFO - prefect.TaskRunner | Task 'dimensions': Starting task run... [2019-10-22 14:24:44,633] INFO - prefect.TaskRunner | Task 'dimensions': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,639] INFO - prefect.TaskRunner | Task 'get_data': Starting task run... [2019-10-22 14:24:44,648] INFO - prefect.TaskRunner | Task 'get_data': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,663] INFO - prefect.TaskRunner | Task 'get_gamma_init': Starting task run... [2019-10-22 14:24:44,670] INFO - prefect.TaskRunner | Task 'get_gamma_init': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,683] INFO - prefect.TaskRunner | Task 'get_hsic': Starting task run... [2019-10-22 14:24:44,691] INFO - prefect.TaskRunner | Task 'get_hsic': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,693] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded [2019-10-22 14:24:44,696] INFO - prefect.FlowRunner | Beginning Flow run for 'Run experiment' [2019-10-22 14:24:44,699] INFO - prefect.FlowRunner | Starting flow run. [2019-10-22 14:24:44,710] INFO - prefect.TaskRunner | Task 'samples': Starting task run... [2019-10-22 14:24:44,715] INFO - prefect.TaskRunner | Task 'samples': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,725] INFO - prefect.TaskRunner | Task 'std': Starting task run... [2019-10-22 14:24:44,730] INFO - prefect.TaskRunner | Task 'std': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,740] INFO - prefect.TaskRunner | Task 'trial': Starting task run... [2019-10-22 14:24:44,745] INFO - prefect.TaskRunner | Task 'trial': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,755] INFO - prefect.TaskRunner | Task 'scorer': Starting task run... [2019-10-22 14:24:44,760] INFO - prefect.TaskRunner | Task 'scorer': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,769] INFO - prefect.TaskRunner | Task 'method': Starting task run... [2019-10-22 14:24:44,775] INFO - prefect.TaskRunner | Task 'method': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,784] INFO - prefect.TaskRunner | Task 'dataset': Starting task run... [2019-10-22 14:24:44,789] INFO - prefect.TaskRunner | Task 'dataset': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,799] INFO - prefect.TaskRunner | Task 'percent': Starting task run... [2019-10-22 14:24:44,804] INFO - prefect.TaskRunner | Task 'percent': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,813] INFO - prefect.TaskRunner | Task 'dimensions': Starting task run... [2019-10-22 14:24:44,818] INFO - prefect.TaskRunner | Task 'dimensions': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,828] INFO - prefect.TaskRunner | Task 'get_data': Starting task run... [2019-10-22 14:24:44,836] INFO - prefect.TaskRunner | Task 'get_data': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,851] INFO - prefect.TaskRunner | Task 'get_gamma_init': Starting task run... [2019-10-22 14:24:44,859] INFO - prefect.TaskRunner | Task 'get_gamma_init': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,873] INFO - prefect.TaskRunner | Task 'get_hsic': Starting task run... [2019-10-22 14:24:44,886] INFO - prefect.TaskRunner | Task 'get_hsic': finished task run for task with final state: 'Success' 0.002959198175196714 0.0011819445258014604 [2019-10-22 14:24:44,889] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded Experiment I - Different Scorers \u00b6 We are looking at different \"HSIC scorers\". They are: HSIC HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F Notice: we have the centered kernels, K_xH K_xH and no normalization. TKA TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} Notice: We have the uncentered kernels and a normalization factor. cTKA cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} Notice: We have the centered kernels and a normalization factor. # experimental parameters method = 'belkin' percent = 0.2 hsic_values = dict () for iscorer in [ 'hsic' , 'tka' , 'ctka' ]: # get initial gamma gamma_init = get_gamma_init ( X , Y , method , percent ) # get HSIC value hsic_values [ iscorer ] = get_hsic ( X , Y , iscorer , gamma_init ) print ( hsic_values ) {'hsic': 0.004420621559606378, 'tka': 0.543442521262865, 'ctka': 0.06751049509744558} Experiment II - Different Scorers, Initializers \u00b6 # dataset params dataset = 'gauss' samples = 100 dimensions = 2 std = 1 trial = 1 # extract dataset X , Y , mi_val = MIData ( dataset ) . get_data ( samples = samples , dimensions = dimensions , std = std , trial = trial ) # experimental parameters scorers = [ 'hsic' , 'tka' , 'ctka' ] gamma_methods = [ ( 'silverman' , None ), ( 'scott' , None ), ( 'median' , None ), ( 'belkin' , 0.1 ), ( 'belkin' , 0.2 ), ( 'belkin' , 0.4 ), ( 'belkin' , 0.8 ), ] # results dataframe results_df = pd . DataFrame () # run experiment for iscorer in scorers : for imethod in gamma_methods : # initialize gamma gamma_init = get_gamma_init ( X , Y , imethod [ 0 ], imethod [ 1 ]) # get hsic_value hsic_value = get_hsic ( X , Y , iscorer , gamma_init ) # append results to dataframe results_df = results_df . append ({ 'scorer' : iscorer , 'gamma_method' : f \" { imethod [ 0 ] } _ { imethod [ 1 ] } \" if imethod [ 1 ] is not None else f \" { imethod [ 0 ] } \" , 'gamma_init' : gamma_init , 'hsic_value' : hsic_value }, ignore_index = True ) results_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gamma_init gamma_method hsic_value scorer 0 2.320794 silverman 0.008088 hsic 1 2.320794 scott 0.008088 hsic 2 0.185138 median 0.001182 hsic 3 1.239664 belkin_0.1 0.006772 hsic 4 0.596976 belkin_0.2 0.004421 hsic # plot the results def plot_scorer ( scorer : str ) -> None : fig , ax = plt . subplots ( nrows = 1 , ncols = 1 , figsize = ( 5 , 5 )) sns . scatterplot ( x = 'gamma_init' , y = 'hsic_value' , hue = 'gamma_method' , data = results_df [ results_df [ 'scorer' ] == scorer ], ax = ax ) ax . set_ylabel ( 'Score' ) ax . set_xlabel ( 'Gamma Initialization' ) ax . legend ( prop = { 'size' : 9 }) ax . set_title ( scorer . upper ()) plt . show () plot_scorer ( 'hsic' ) plot_scorer ( 'tka' ) plot_scorer ( 'ctka' ) Experiment II - Different Scorers, Initializations and Degree of Freedom \u00b6 In this experiment, we'll be looking at how do the HSIC values change depending upon the gamma initialization as well as the degree of freedom we choose. In the Gaussian distribution, this is the standard deviation, \\sigma \\sigma and the T-Student distribution this is the \\nu \\nu parameter. from tqdm import trange , tqdm # dataset params dataset = 'gauss' samples = 100 dimensions = 2 std = 1 trial = 1 # experimental parameters scorers = [ 'hsic' , 'tka' , 'ctka' ] gamma_methods = [ ( 'silverman' , None ), ( 'scott' , None ), ( 'median' , None ), ( 'belkin' , 0.1 ), ( 'belkin' , 0.2 ), ( 'belkin' , 0.4 ), ( 'belkin' , 0.8 ), ( 'max' , None ) ] dof_params = np . linspace ( 1 , 11 , 11 , endpoint = True ) # results dataframe results_df = pd . DataFrame () # run experiment with tqdm ( gamma_methods ) as gamma_bar : for imethod in gamma_bar : for iscorer in scorers : for idof in dof_params : # extract dataset X , Y , mi_val = MIData ( dataset ) . get_data ( samples = samples , dimensions = dimensions , std = int ( idof ), trial = trial ) # initialize gamma if imethod [ 0 ] == 'max' : clf_hsic = train_rbf_hsic ( X , Y , iscorer , 50 , 1 , 'median' ) hsic_value = clf_hsic . score ( X ) else : gamma_init = get_gamma_init ( X , Y , imethod [ 0 ], imethod [ 1 ]) hsic_value = get_hsic ( X , Y , iscorer , gamma_init ) # append results to dataframe results_df = results_df . append ({ 'scorer' : iscorer , 'gamma_method' : f \" { imethod [ 0 ] } _ { imethod [ 1 ] } \" if imethod [ 1 ] is not None else f \" { imethod [ 0 ] } \" , 'gamma_init' : gamma_init , 'hsic_value' : hsic_value , 'std' : idof , 'mi_value' : mi_val , }, ignore_index = True ) results_df . head () 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:11<00:00, 1.44s/it] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gamma_init gamma_method hsic_value mi_value scorer std 0 2.320794 silverman 0.008088 0.000000 hsic 1.0 1 2.320794 silverman 0.008068 0.002053 hsic 2.0 2 2.320794 silverman 0.008096 0.007718 hsic 3.0 3 2.320794 silverman 0.008163 0.016467 hsic 4.0 4 2.320794 silverman 0.008259 0.027999 hsic 5.0 # plot the results def plot_scorer_mi ( df : pd . DataFrame , scorer : str ) -> None : fig , ax = plt . subplots ( nrows = 1 , ncols = 1 , figsize = ( 5 , 5 )) sns . scatterplot ( x = 'hsic_value' , y = 'mi_value' , hue = 'gamma_method' , data = df [ df [ 'scorer' ] == scorer ], ax = ax ) ax . set_ylabel ( 'Mutual Information' ) ax . set_xlabel ( 'Score' ) ax . legend ( prop = { 'size' : 9 }) ax . set_title ( scorer . upper ()) plt . show () plot_scorer_mi ( results_df , 'hsic' ) plot_scorer_mi ( results_df , 'tka' ) plot_scorer_mi ( results_df , 'ctka' ) Same Experiment, but with a higher number of samples and dimensions \u00b6 # dataset params dataset = 'gauss' samples = [ 1_000 ] dimensions = [ 50 ] trials = [ 1 ] # experimental parameters scorers = [ 'hsic' , 'tka' , 'ctka' ] gamma_methods = [ ( 'silverman' , None ), ( 'scott' , None ), ( 'median' , None ), ( 'belkin' , 0.1 ), ( 'belkin' , 0.2 ), ( 'belkin' , 0.4 ), ( 'belkin' , 0.8 ), ( 'max' , None ) ] dof_params = np . linspace ( 1 , 11 , 11 , endpoint = True ) # results dataframe results_df = pd . DataFrame () # run experiment with tqdm ( gamma_methods ) as gamma_bar : for imethod in gamma_bar : for isample in samples : for idim in dimensions : for itrial in trials : for iscorer in scorers : for idof in dof_params : # extract dataset X , Y , mi_val = MIData ( dataset ) . get_data ( samples = isample , dimensions = idim , std = int ( idof ), trial = itrial ) # initialize gamma print ( imethod [ 0 ], imethod [ 1 ]) if imethod [ 0 ] == 'max' : clf_hsic = train_rbf_hsic ( X , Y , iscorer , 50 , 1 , 'median' ) hsic_value = clf_hsic . score ( X ) else : gamma_init = get_gamma_init ( X , Y , imethod [ 0 ], imethod [ 1 ]) hsic_value = get_hsic ( X , Y , iscorer , gamma_init ) # get hsic_value # append results to dataframe results_df = results_df . append ({ 'samples' : isample , 'dimensions' : idim , 'trial' : itrial , 'scorer' : iscorer , 'gamma_method' : f \" { imethod [ 0 ] } _ { imethod [ 1 ] } \" if imethod [ 1 ] is not None else f \" { imethod [ 0 ] } \" , 'gamma_init' : gamma_init , 'hsic_value' : hsic_value , 'std' : idof , 'mi_value' : mi_val , }, ignore_index = True ) results_df . head () 0%| | 0/8 [00:00<?, ?it/s] silverman None --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-87-b149632f687f> in <module> 44 else : 45 ---> 46 gamma_init = get_gamma_init ( X , Y , imethod [ 0 ] , imethod [ 1 ] ) 47 hsic_value = get_hsic ( X , Y , iscorer , gamma_init ) 48 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/prefect/core/task.py in __call__ (self, mapped, task_args, upstream_tasks, flow, *args, **kwargs) 362 new = self . copy ( ** ( task_args or { } ) ) 363 new.bind( --> 364 * args , mapped = mapped , upstream_tasks = upstream_tasks , flow = flow , ** kwargs 365 ) 366 return new ~/.conda/envs/it4dnn/lib/python3.6/site-packages/prefect/core/task.py in bind (self, mapped, upstream_tasks, flow, *args, **kwargs) 402 # this will raise an error if callargs weren't all provided 403 signature = inspect . signature ( self . run ) --> 404 callargs = dict ( signature . bind ( * args , ** kwargs ) . arguments ) # type: Dict 405 406 # bind() compresses all variable keyword arguments under the ** argument name, ~/.conda/envs/it4dnn/lib/python3.6/inspect.py in bind (*args, **kwargs) 2995 if the passed arguments can not be bound . 2996 \"\"\" -> 2997 return args [ 0 ] . _bind ( args [ 1 : ] , kwargs ) 2998 2999 def bind_partial ( * args , ** kwargs ) : ~/.conda/envs/it4dnn/lib/python3.6/inspect.py in _bind (self, args, kwargs, partial) 2916 param = next ( parameters ) 2917 except StopIteration : -> 2918 raise TypeError ( 'too many positional arguments' ) from None 2919 else : 2920 if param . kind in ( _VAR_KEYWORD , _KEYWORD_ONLY ) : TypeError : too many positional arguments res_high_df = results_df . copy () plot_scorer_mi ( res_high_df , 'hsic' ) plot_scorer_mi ( res_high_df , 'tka' ) plot_scorer_mi ( res_high_df , 'ctka' )","title":"2.1 exp walkthrough"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#distribution-experiment-walkthrough","text":"import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import warnings import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.it_data import MIData # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models # experiment helpers from tqdm import tqdm import prefect # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ( 'ggplot' ) sns . set_style ( \"dark\" ) sns . set_context ( \"poster\" ) warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2","title":"Distribution Experiment - Walkthrough"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#datasets","text":"Samples - [500, 1K, 5K, 10K, 30K, 50K] Dimensions - [ 2, 3, 10, 50, 100] trials - 1:5 IT measures - Mutual Information Distributions - [Gaussian, T-Student]","title":"Datasets"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#example-gaussian-distribution-2d","text":"# dataloader params dataset = 'gauss' # initialize dataloader dataloader = MIData ( dataset ) # dataset params samples = 100 dimensions = 2 std = 1 trial = 1 # extract dataset X , Y , mi_val = dataloader . get_data ( samples = samples , dimensions = dimensions , std = std , trial = trial ) from prefect import task , Flow , Parameter @task def get_data ( dataset : str , samples : int , dimensions : int , dof : int , trial : int ): dataloader = MIData ( dataset ) # extract dataset X , Y , mi_val = dataloader . get_data ( samples = samples , dimensions = dimensions , std = dof , trial = trial ) data = { 'X' : X , \"Y\" : Y , \"mi_val\" : mi_val } return data class GetData ( Task ): def __init__ ( self , dataset : str = 'gauss' , samples : int = 100 , dimensions : int = 2 , std : int = 1 , trial : int = 1 , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . dataset = dataset self . samples = samples self . dimensions = dimensions self . std = std self . trial = trial def run ( self , ) with Flow ( \"Run experiment\" ) as flow : # Data Params dataset = Parameter ( \"dataset\" , default = 'gauss' ) samples = Parameter ( \"samples\" , default = 100 ) dimensions = Parameter ( \"dimensions\" , default = 2 ) std = Parameter ( \"std\" , default = 1 ) trial = Parameter ( \"trial\" , default = 1 ) # Load Data data = get_data ( dataset , samples , dimensions , std , trial ) flow . run () [2019-10-22 14:16:39,783] INFO - prefect.FlowRunner | Beginning Flow run for 'Run experiment' [2019-10-22 14:16:39,787] INFO - prefect.FlowRunner | Starting flow run. [2019-10-22 14:16:39,800] INFO - prefect.TaskRunner | Task 'dimensions': Starting task run... [2019-10-22 14:16:39,806] INFO - prefect.TaskRunner | Task 'dimensions': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,816] INFO - prefect.TaskRunner | Task 'trial': Starting task run... [2019-10-22 14:16:39,821] INFO - prefect.TaskRunner | Task 'trial': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,831] INFO - prefect.TaskRunner | Task 'dataset': Starting task run... [2019-10-22 14:16:39,836] INFO - prefect.TaskRunner | Task 'dataset': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,847] INFO - prefect.TaskRunner | Task 'samples': Starting task run... [2019-10-22 14:16:39,852] INFO - prefect.TaskRunner | Task 'samples': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,862] INFO - prefect.TaskRunner | Task 'std': Starting task run... [2019-10-22 14:16:39,867] INFO - prefect.TaskRunner | Task 'std': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,876] INFO - prefect.TaskRunner | Task 'get_data': Starting task run... [2019-10-22 14:16:39,885] INFO - prefect.TaskRunner | Task 'get_data': finished task run for task with final state: 'Success' [2019-10-22 14:16:39,888] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded <Success: \"All reference tasks succeeded.\"> flow . tasks {<Parameter: dataset>, <Parameter: dimensions>, <Parameter: samples>, <Parameter: std>, <Parameter: trial>, <Task: get_data>} class ExpParams : # dataset params samples = 100 dimensions = 2 std = 1 trial = 1 # plot data fig = plt . figure ( figsize = ( 10 , 10 )) g = sns . jointplot ( x = X [:, 0 ], y = X [:, 1 ], ) plt . title ( 'X' ) plt . show () # plot data fig = plt . figure ( figsize = ( 10 , 10 )) g = sns . jointplot ( x = Y [:, 0 ], y = Y [:, 1 ], ) plt . title ( 'Y' ) plt . show () <Figure size 720x720 with 0 Axes> <Figure size 720x720 with 0 Axes>","title":"Example Gaussian Distribution: 2D"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#hsic-algorithms","text":"","title":"HSIC Algorithms"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#hsic","text":"algorithm path : src/models/dependence.py","title":"HSIC"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#1-initialize-gamma","text":"# sigma initialization params percent = . 2 method = 'belkin' # initialize sigma sigma_init_X = estimate_sigma ( X , method = method , percent = percent ) sigma_init_Y = estimate_sigma ( Y , method = method , percent = percent ) print ( f 'Sigma_x: ' , sigma_init_X ) print ( f 'Sigma_y: ' , sigma_init_Y ) Sigma_x: 0.9583709525127224 Sigma_y: 0.8719893561231888","title":"1. Initialize Gamma"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#11-mean-of-initial-sigmas","text":"sigma_init = np . mean ([ sigma_init_X , sigma_init_Y ]) print ( f 'Sigma_init (Belkin): ' , sigma_init ) Sigma_init (Belkin): 0.9151801543179556","title":"1.1 Mean of Initial sigmas"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#13-convert-gamma-to-sigma","text":"The standard kernel function is: K(x,y)= \\exp(-\\frac{||x-y||^2}{2\\sigma^2}) K(x,y)= \\exp(-\\frac{||x-y||^2}{2\\sigma^2}) Sklearn uses the following RBF kernel function: K(x,y)= \\exp(-\\gamma||x-y||^2) K(x,y)= \\exp(-\\gamma||x-y||^2) So the following relationship is: \\gamma = \\frac{1}{2\\sigma^2} \\gamma = \\frac{1}{2\\sigma^2} <span><span class=\"MathJax_Preview\">\\gamma = \\frac{1}{2\\sigma^2}</span><script type=\"math/tex\">\\gamma = \\frac{1}{2\\sigma^2} # convert sigma to gamma gamma_init = sigma_to_gamma ( sigma_init ) # check if true assert ( gamma_init == 1 / ( 2 * sigma_init ** 2 )) print ( 'Gamma_init (Belkin):' , gamma_init ) Gamma_init (Belkin): 0.5969759242357159","title":"1.3 Convert Gamma to Sigma"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#14-create-function","text":"from typing import Optional @task def get_gamma_init ( data , method : str , percent : Optional [ float ] = None ) -> float : \"\"\"Get Gamma initializer Parameters ---------- method : str, the initialization method percent : float if using the Belkin method, this uses a percentage of the kth nearest neighbour Returns ------- gamma_init : float the initial gamma value \"\"\" # initialize sigma sigma_init_X = estimate_sigma ( data [ \"X\" ], method = method , percent = percent ) sigma_init_Y = estimate_sigma ( data [ \"Y\" ], method = method , percent = percent ) # mean of the two sigma_init = np . mean ([ sigma_init_X , sigma_init_Y ]) # convert sigma to gamma gamma_init = sigma_to_gamma ( sigma_init ) # return initial gamma value return { \"gamma_init\" : gamma_init } data <Task: get_data> with Flow ( \"Run experiment\" ) as flow : # Data Params dataset = Parameter ( \"dataset\" , default = 'gauss' ) samples = Parameter ( \"samples\" , default = 100 ) dimensions = Parameter ( \"dimensions\" , default = 2 ) std = Parameter ( \"std\" , default = 1 ) trial = Parameter ( \"trial\" , default = 1 ) # Load Data data = get_data ( dataset , samples , dimensions , std , trial ) # Gamma Parameters method = Parameter ( \"method\" , default = 'median' ) percent = Parameter ( \"percent\" , default = 0.2 ) # get gamma gamma_init = get_gamma_init ( data , method , percent ) flow . run () [2019-10-22 14:17:31,762] INFO - prefect.FlowRunner | Beginning Flow run for 'Run experiment' [2019-10-22 14:17:31,766] INFO - prefect.FlowRunner | Starting flow run. [2019-10-22 14:17:31,780] INFO - prefect.TaskRunner | Task 'dimensions': Starting task run... [2019-10-22 14:17:31,786] INFO - prefect.TaskRunner | Task 'dimensions': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,797] INFO - prefect.TaskRunner | Task 'dataset': Starting task run... [2019-10-22 14:17:31,803] INFO - prefect.TaskRunner | Task 'dataset': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,813] INFO - prefect.TaskRunner | Task 'std': Starting task run... [2019-10-22 14:17:31,818] INFO - prefect.TaskRunner | Task 'std': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,828] INFO - prefect.TaskRunner | Task 'trial': Starting task run... [2019-10-22 14:17:31,833] INFO - prefect.TaskRunner | Task 'trial': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,843] INFO - prefect.TaskRunner | Task 'method': Starting task run... [2019-10-22 14:17:31,848] INFO - prefect.TaskRunner | Task 'method': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,857] INFO - prefect.TaskRunner | Task 'percent': Starting task run... [2019-10-22 14:17:31,862] INFO - prefect.TaskRunner | Task 'percent': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,872] INFO - prefect.TaskRunner | Task 'samples': Starting task run... [2019-10-22 14:17:31,877] INFO - prefect.TaskRunner | Task 'samples': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,887] INFO - prefect.TaskRunner | Task 'get_data': Starting task run... [2019-10-22 14:17:31,895] INFO - prefect.TaskRunner | Task 'get_data': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,910] INFO - prefect.TaskRunner | Task 'get_gamma_init': Starting task run... [2019-10-22 14:17:31,918] INFO - prefect.TaskRunner | Task 'get_gamma_init': finished task run for task with final state: 'Success' [2019-10-22 14:17:31,921] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded <Task: get_gamma_init> <Success: \"All reference tasks succeeded.\">","title":"1.4 Create Function"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#4-calculate-hsic","text":"# hsic parameters kernel = 'rbf' scorer = 'hsic' subsample = None bias = True # initialize HSIC model clf_hsic = HSIC ( gamma = gamma_init , kernel = kernel , scorer = scorer , subsample = subsample , bias = bias ) # fit model to data clf_hsic . fit ( X , Y ) # get hsic value hsic_value = clf_hsic . score ( X ) print ( 'HSIC: ' , hsic_value ) HSIC: 0.004420621559606378 @task def get_hsic ( data , scorer : str , gamma_init ) -> float : \"\"\"Gets the HSIC parameters Parameters ---------- X : np.ndarray, (n_samples, d_dimensions) 1st input array Y : np.ndarray, (n_samples, d_dimensions) 2nd input array scorer : str, the scorer to calculate the hsic * hsic - HSIC method * tka - kernel tangent alignment * ctka - centered kernel tangent alignment gamma_init : float the initial gamma parameter Returns ------- hsic_value : float the hsic value calculated from the scorer \"\"\" # hsic parameters kernel = 'rbf' subsample = None bias = True # initialize HSIC model clf_hsic = HSIC ( gamma = gamma_init [ 'gamma_init' ], kernel = kernel , scorer = scorer , subsample = subsample , bias = bias ) # fit model to data clf_hsic . fit ( data [ 'X' ], data [ 'Y' ]) # get hsic value hsic_value = clf_hsic . score ( data [ 'X' ]) return { \"hsic_value\" : hsic_value } with Flow ( \"Run experiment\" ) as flow : # Data Params dataset = Parameter ( \"dataset\" , default = 'gauss' ) samples = Parameter ( \"samples\" , default = 100 ) dimensions = Parameter ( \"dimensions\" , default = 2 ) std = Parameter ( \"std\" , default = 1 ) trial = Parameter ( \"trial\" , default = 1 ) # Load Data data = get_data ( dataset , samples , dimensions , std , trial ) # Gamma Parameters method = Parameter ( \"method\" , default = 'median' ) percent = Parameter ( \"percent\" , default = 0.2 ) # get gamma gamma_init = get_gamma_init ( data , method , percent ) # HSIC Params scorer = Parameter ( \"scorer\" , default = 'hsic' ) # Get HSIC value hsic_value = get_hsic ( data , scorer , gamma_init ) # Save data for isamples in [ 50 , 100 ]: flow . run ( parameters = { 'samples' : isamples }) [2019-10-22 14:24:44,522] INFO - prefect.FlowRunner | Beginning Flow run for 'Run experiment' [2019-10-22 14:24:44,526] INFO - prefect.FlowRunner | Starting flow run. [2019-10-22 14:24:44,541] INFO - prefect.TaskRunner | Task 'samples': Starting task run... [2019-10-22 14:24:44,547] INFO - prefect.TaskRunner | Task 'samples': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,558] INFO - prefect.TaskRunner | Task 'std': Starting task run... [2019-10-22 14:24:44,564] INFO - prefect.TaskRunner | Task 'std': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,574] INFO - prefect.TaskRunner | Task 'trial': Starting task run... [2019-10-22 14:24:44,579] INFO - prefect.TaskRunner | Task 'trial': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,586] INFO - prefect.TaskRunner | Task 'scorer': Starting task run... [2019-10-22 14:24:44,590] INFO - prefect.TaskRunner | Task 'scorer': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,597] INFO - prefect.TaskRunner | Task 'method': Starting task run... [2019-10-22 14:24:44,601] INFO - prefect.TaskRunner | Task 'method': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,607] INFO - prefect.TaskRunner | Task 'dataset': Starting task run... [2019-10-22 14:24:44,612] INFO - prefect.TaskRunner | Task 'dataset': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,618] INFO - prefect.TaskRunner | Task 'percent': Starting task run... [2019-10-22 14:24:44,622] INFO - prefect.TaskRunner | Task 'percent': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,629] INFO - prefect.TaskRunner | Task 'dimensions': Starting task run... [2019-10-22 14:24:44,633] INFO - prefect.TaskRunner | Task 'dimensions': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,639] INFO - prefect.TaskRunner | Task 'get_data': Starting task run... [2019-10-22 14:24:44,648] INFO - prefect.TaskRunner | Task 'get_data': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,663] INFO - prefect.TaskRunner | Task 'get_gamma_init': Starting task run... [2019-10-22 14:24:44,670] INFO - prefect.TaskRunner | Task 'get_gamma_init': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,683] INFO - prefect.TaskRunner | Task 'get_hsic': Starting task run... [2019-10-22 14:24:44,691] INFO - prefect.TaskRunner | Task 'get_hsic': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,693] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded [2019-10-22 14:24:44,696] INFO - prefect.FlowRunner | Beginning Flow run for 'Run experiment' [2019-10-22 14:24:44,699] INFO - prefect.FlowRunner | Starting flow run. [2019-10-22 14:24:44,710] INFO - prefect.TaskRunner | Task 'samples': Starting task run... [2019-10-22 14:24:44,715] INFO - prefect.TaskRunner | Task 'samples': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,725] INFO - prefect.TaskRunner | Task 'std': Starting task run... [2019-10-22 14:24:44,730] INFO - prefect.TaskRunner | Task 'std': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,740] INFO - prefect.TaskRunner | Task 'trial': Starting task run... [2019-10-22 14:24:44,745] INFO - prefect.TaskRunner | Task 'trial': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,755] INFO - prefect.TaskRunner | Task 'scorer': Starting task run... [2019-10-22 14:24:44,760] INFO - prefect.TaskRunner | Task 'scorer': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,769] INFO - prefect.TaskRunner | Task 'method': Starting task run... [2019-10-22 14:24:44,775] INFO - prefect.TaskRunner | Task 'method': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,784] INFO - prefect.TaskRunner | Task 'dataset': Starting task run... [2019-10-22 14:24:44,789] INFO - prefect.TaskRunner | Task 'dataset': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,799] INFO - prefect.TaskRunner | Task 'percent': Starting task run... [2019-10-22 14:24:44,804] INFO - prefect.TaskRunner | Task 'percent': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,813] INFO - prefect.TaskRunner | Task 'dimensions': Starting task run... [2019-10-22 14:24:44,818] INFO - prefect.TaskRunner | Task 'dimensions': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,828] INFO - prefect.TaskRunner | Task 'get_data': Starting task run... [2019-10-22 14:24:44,836] INFO - prefect.TaskRunner | Task 'get_data': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,851] INFO - prefect.TaskRunner | Task 'get_gamma_init': Starting task run... [2019-10-22 14:24:44,859] INFO - prefect.TaskRunner | Task 'get_gamma_init': finished task run for task with final state: 'Success' [2019-10-22 14:24:44,873] INFO - prefect.TaskRunner | Task 'get_hsic': Starting task run... [2019-10-22 14:24:44,886] INFO - prefect.TaskRunner | Task 'get_hsic': finished task run for task with final state: 'Success' 0.002959198175196714 0.0011819445258014604 [2019-10-22 14:24:44,889] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded","title":"4. Calculate HSIC"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#experiment-i-different-scorers","text":"We are looking at different \"HSIC scorers\". They are: HSIC HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F Notice: we have the centered kernels, K_xH K_xH and no normalization. TKA TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} Notice: We have the uncentered kernels and a normalization factor. cTKA cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} Notice: We have the centered kernels and a normalization factor. # experimental parameters method = 'belkin' percent = 0.2 hsic_values = dict () for iscorer in [ 'hsic' , 'tka' , 'ctka' ]: # get initial gamma gamma_init = get_gamma_init ( X , Y , method , percent ) # get HSIC value hsic_values [ iscorer ] = get_hsic ( X , Y , iscorer , gamma_init ) print ( hsic_values ) {'hsic': 0.004420621559606378, 'tka': 0.543442521262865, 'ctka': 0.06751049509744558}","title":"Experiment I - Different Scorers"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#experiment-ii-different-scorers-initializers","text":"# dataset params dataset = 'gauss' samples = 100 dimensions = 2 std = 1 trial = 1 # extract dataset X , Y , mi_val = MIData ( dataset ) . get_data ( samples = samples , dimensions = dimensions , std = std , trial = trial ) # experimental parameters scorers = [ 'hsic' , 'tka' , 'ctka' ] gamma_methods = [ ( 'silverman' , None ), ( 'scott' , None ), ( 'median' , None ), ( 'belkin' , 0.1 ), ( 'belkin' , 0.2 ), ( 'belkin' , 0.4 ), ( 'belkin' , 0.8 ), ] # results dataframe results_df = pd . DataFrame () # run experiment for iscorer in scorers : for imethod in gamma_methods : # initialize gamma gamma_init = get_gamma_init ( X , Y , imethod [ 0 ], imethod [ 1 ]) # get hsic_value hsic_value = get_hsic ( X , Y , iscorer , gamma_init ) # append results to dataframe results_df = results_df . append ({ 'scorer' : iscorer , 'gamma_method' : f \" { imethod [ 0 ] } _ { imethod [ 1 ] } \" if imethod [ 1 ] is not None else f \" { imethod [ 0 ] } \" , 'gamma_init' : gamma_init , 'hsic_value' : hsic_value }, ignore_index = True ) results_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gamma_init gamma_method hsic_value scorer 0 2.320794 silverman 0.008088 hsic 1 2.320794 scott 0.008088 hsic 2 0.185138 median 0.001182 hsic 3 1.239664 belkin_0.1 0.006772 hsic 4 0.596976 belkin_0.2 0.004421 hsic # plot the results def plot_scorer ( scorer : str ) -> None : fig , ax = plt . subplots ( nrows = 1 , ncols = 1 , figsize = ( 5 , 5 )) sns . scatterplot ( x = 'gamma_init' , y = 'hsic_value' , hue = 'gamma_method' , data = results_df [ results_df [ 'scorer' ] == scorer ], ax = ax ) ax . set_ylabel ( 'Score' ) ax . set_xlabel ( 'Gamma Initialization' ) ax . legend ( prop = { 'size' : 9 }) ax . set_title ( scorer . upper ()) plt . show () plot_scorer ( 'hsic' ) plot_scorer ( 'tka' ) plot_scorer ( 'ctka' )","title":"Experiment II - Different Scorers, Initializers"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#experiment-ii-different-scorers-initializations-and-degree-of-freedom","text":"In this experiment, we'll be looking at how do the HSIC values change depending upon the gamma initialization as well as the degree of freedom we choose. In the Gaussian distribution, this is the standard deviation, \\sigma \\sigma and the T-Student distribution this is the \\nu \\nu parameter. from tqdm import trange , tqdm # dataset params dataset = 'gauss' samples = 100 dimensions = 2 std = 1 trial = 1 # experimental parameters scorers = [ 'hsic' , 'tka' , 'ctka' ] gamma_methods = [ ( 'silverman' , None ), ( 'scott' , None ), ( 'median' , None ), ( 'belkin' , 0.1 ), ( 'belkin' , 0.2 ), ( 'belkin' , 0.4 ), ( 'belkin' , 0.8 ), ( 'max' , None ) ] dof_params = np . linspace ( 1 , 11 , 11 , endpoint = True ) # results dataframe results_df = pd . DataFrame () # run experiment with tqdm ( gamma_methods ) as gamma_bar : for imethod in gamma_bar : for iscorer in scorers : for idof in dof_params : # extract dataset X , Y , mi_val = MIData ( dataset ) . get_data ( samples = samples , dimensions = dimensions , std = int ( idof ), trial = trial ) # initialize gamma if imethod [ 0 ] == 'max' : clf_hsic = train_rbf_hsic ( X , Y , iscorer , 50 , 1 , 'median' ) hsic_value = clf_hsic . score ( X ) else : gamma_init = get_gamma_init ( X , Y , imethod [ 0 ], imethod [ 1 ]) hsic_value = get_hsic ( X , Y , iscorer , gamma_init ) # append results to dataframe results_df = results_df . append ({ 'scorer' : iscorer , 'gamma_method' : f \" { imethod [ 0 ] } _ { imethod [ 1 ] } \" if imethod [ 1 ] is not None else f \" { imethod [ 0 ] } \" , 'gamma_init' : gamma_init , 'hsic_value' : hsic_value , 'std' : idof , 'mi_value' : mi_val , }, ignore_index = True ) results_df . head () 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:11<00:00, 1.44s/it] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gamma_init gamma_method hsic_value mi_value scorer std 0 2.320794 silverman 0.008088 0.000000 hsic 1.0 1 2.320794 silverman 0.008068 0.002053 hsic 2.0 2 2.320794 silverman 0.008096 0.007718 hsic 3.0 3 2.320794 silverman 0.008163 0.016467 hsic 4.0 4 2.320794 silverman 0.008259 0.027999 hsic 5.0 # plot the results def plot_scorer_mi ( df : pd . DataFrame , scorer : str ) -> None : fig , ax = plt . subplots ( nrows = 1 , ncols = 1 , figsize = ( 5 , 5 )) sns . scatterplot ( x = 'hsic_value' , y = 'mi_value' , hue = 'gamma_method' , data = df [ df [ 'scorer' ] == scorer ], ax = ax ) ax . set_ylabel ( 'Mutual Information' ) ax . set_xlabel ( 'Score' ) ax . legend ( prop = { 'size' : 9 }) ax . set_title ( scorer . upper ()) plt . show () plot_scorer_mi ( results_df , 'hsic' ) plot_scorer_mi ( results_df , 'tka' ) plot_scorer_mi ( results_df , 'ctka' )","title":"Experiment II - Different Scorers, Initializations and Degree of Freedom"},{"location":"notebooks/4_distributions/old/2.1_exp_walkthrough/#same-experiment-but-with-a-higher-number-of-samples-and-dimensions","text":"# dataset params dataset = 'gauss' samples = [ 1_000 ] dimensions = [ 50 ] trials = [ 1 ] # experimental parameters scorers = [ 'hsic' , 'tka' , 'ctka' ] gamma_methods = [ ( 'silverman' , None ), ( 'scott' , None ), ( 'median' , None ), ( 'belkin' , 0.1 ), ( 'belkin' , 0.2 ), ( 'belkin' , 0.4 ), ( 'belkin' , 0.8 ), ( 'max' , None ) ] dof_params = np . linspace ( 1 , 11 , 11 , endpoint = True ) # results dataframe results_df = pd . DataFrame () # run experiment with tqdm ( gamma_methods ) as gamma_bar : for imethod in gamma_bar : for isample in samples : for idim in dimensions : for itrial in trials : for iscorer in scorers : for idof in dof_params : # extract dataset X , Y , mi_val = MIData ( dataset ) . get_data ( samples = isample , dimensions = idim , std = int ( idof ), trial = itrial ) # initialize gamma print ( imethod [ 0 ], imethod [ 1 ]) if imethod [ 0 ] == 'max' : clf_hsic = train_rbf_hsic ( X , Y , iscorer , 50 , 1 , 'median' ) hsic_value = clf_hsic . score ( X ) else : gamma_init = get_gamma_init ( X , Y , imethod [ 0 ], imethod [ 1 ]) hsic_value = get_hsic ( X , Y , iscorer , gamma_init ) # get hsic_value # append results to dataframe results_df = results_df . append ({ 'samples' : isample , 'dimensions' : idim , 'trial' : itrial , 'scorer' : iscorer , 'gamma_method' : f \" { imethod [ 0 ] } _ { imethod [ 1 ] } \" if imethod [ 1 ] is not None else f \" { imethod [ 0 ] } \" , 'gamma_init' : gamma_init , 'hsic_value' : hsic_value , 'std' : idof , 'mi_value' : mi_val , }, ignore_index = True ) results_df . head () 0%| | 0/8 [00:00<?, ?it/s] silverman None --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-87-b149632f687f> in <module> 44 else : 45 ---> 46 gamma_init = get_gamma_init ( X , Y , imethod [ 0 ] , imethod [ 1 ] ) 47 hsic_value = get_hsic ( X , Y , iscorer , gamma_init ) 48 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/prefect/core/task.py in __call__ (self, mapped, task_args, upstream_tasks, flow, *args, **kwargs) 362 new = self . copy ( ** ( task_args or { } ) ) 363 new.bind( --> 364 * args , mapped = mapped , upstream_tasks = upstream_tasks , flow = flow , ** kwargs 365 ) 366 return new ~/.conda/envs/it4dnn/lib/python3.6/site-packages/prefect/core/task.py in bind (self, mapped, upstream_tasks, flow, *args, **kwargs) 402 # this will raise an error if callargs weren't all provided 403 signature = inspect . signature ( self . run ) --> 404 callargs = dict ( signature . bind ( * args , ** kwargs ) . arguments ) # type: Dict 405 406 # bind() compresses all variable keyword arguments under the ** argument name, ~/.conda/envs/it4dnn/lib/python3.6/inspect.py in bind (*args, **kwargs) 2995 if the passed arguments can not be bound . 2996 \"\"\" -> 2997 return args [ 0 ] . _bind ( args [ 1 : ] , kwargs ) 2998 2999 def bind_partial ( * args , ** kwargs ) : ~/.conda/envs/it4dnn/lib/python3.6/inspect.py in _bind (self, args, kwargs, partial) 2916 param = next ( parameters ) 2917 except StopIteration : -> 2918 raise TypeError ( 'too many positional arguments' ) from None 2919 else : 2920 if param . kind in ( _VAR_KEYWORD , _KEYWORD_ONLY ) : TypeError : too many positional arguments res_high_df = results_df . copy () plot_scorer_mi ( res_high_df , 'hsic' ) plot_scorer_mi ( res_high_df , 'tka' ) plot_scorer_mi ( res_high_df , 'ctka' )","title":"Same Experiment, but with a higher number of samples and dimensions"},{"location":"notebooks/4_distributions/old/3.1_trial_experiment/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import RBIGData # Experiments from experiments.distributions import DistributionExp # Kernel Dependency measure from models.dependence import HSIC , train_rbf_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import scipy.io as scio import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload float ( '0.1' ) 0.1 Trial Experiment \u00b6 I am basically just testing the script that I use on the SLURM server before I send it off to the batch processing. SAVE_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/hsic/\" clf_exp = DistributionExp ( seed = 123 , factor = 1 , sigma_est = 'median' , n_gamma = 10 , save_path = SAVE_PATH , save_name = 'dist_v1_gamma' , ) # run full experiment clf_exp . run_experiment () Function: gauss --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) <ipython-input-23-937e854bdd0b> in <module> 11 12 # run full experiment ---> 13 clf_exp . run_experiment ( ) ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/distributions.py in run_experiment (self) 214 hsic_method = hsic_method , 215 hsic_score = hsic_score , --> 216 mi_score = mi_score , 217 ) 218 ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/distributions.py in append_results (self, results_df, dataset, trial, n_samples, d_dimensions, std, nu, gamma, gamma_init, hsic_method, hsic_score, mi_score) 337 \"mi_score\" : mi_score , 338 }, --> 339 ignore_index = True , 340 ) 341 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/frame.py in append (self, other, ignore_index, verify_integrity, sort) 7121 ignore_index = ignore_index , 7122 verify_integrity = verify_integrity , -> 7123 sort = sort , 7124 ) 7125 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/reshape/concat.py in concat (objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy) 253 verify_integrity = verify_integrity , 254 copy = copy , --> 255 sort = sort , 256 ) 257 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/reshape/concat.py in __init__ (self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort) 333 334 # consolidate --> 335 obj . _consolidate ( inplace = True ) 336 ndims . add ( obj . ndim ) 337 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/generic.py in _consolidate (self, inplace) 5268 inplace = validate_bool_kwarg ( inplace , \"inplace\" ) 5269 if inplace : -> 5270 self . _consolidate_inplace ( ) 5271 else : 5272 f = lambda : self . _data . consolidate ( ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/generic.py in _consolidate_inplace (self) 5250 self . _data = self . _data . consolidate ( ) 5251 -> 5252 self . _protect_consolidate ( f ) 5253 5254 def _consolidate ( self , inplace = False ) : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/generic.py in _protect_consolidate (self, f) 5239 \"\"\" 5240 blocks_before = len ( self . _data . blocks ) -> 5241 result = f ( ) 5242 if len ( self . _data . blocks ) != blocks_before : 5243 self . _clear_item_cache ( ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/generic.py in f () 5248 5249 def f ( ) : -> 5250 self . _data = self . _data . consolidate ( ) 5251 5252 self . _protect_consolidate ( f ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/managers.py in consolidate (self) 930 bm = self . __class__ ( self . blocks , self . axes ) 931 bm . _is_consolidated = False --> 932 bm . _consolidate_inplace ( ) 933 return bm 934 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/managers.py in _consolidate_inplace (self) 935 def _consolidate_inplace ( self ) : 936 if not self . is_consolidated ( ) : --> 937 self . blocks = tuple ( _consolidate ( self . blocks ) ) 938 self . _is_consolidated = True 939 self . _known_consolidated = True ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/managers.py in _consolidate (blocks) 1911 for ( _can_consolidate , dtype ) , group_blocks in grouper : 1912 merged_blocks = _merge_blocks( -> 1913 list ( group_blocks ) , dtype = dtype , _can_consolidate = _can_consolidate 1914 ) 1915 new_blocks = _extend_blocks ( merged_blocks , new_blocks ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/blocks.py in _merge_blocks (blocks, dtype, _can_consolidate) 3321 3322 argsort = np . argsort ( new_mgr_locs ) -> 3323 new_values = new_values [ argsort ] 3324 new_mgr_locs = new_mgr_locs [ argsort ] 3325 KeyboardInterrupt :","title":"3.1 trial experiment"},{"location":"notebooks/4_distributions/old/3.1_trial_experiment/#trial-experiment","text":"I am basically just testing the script that I use on the SLURM server before I send it off to the batch processing. SAVE_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/hsic/\" clf_exp = DistributionExp ( seed = 123 , factor = 1 , sigma_est = 'median' , n_gamma = 10 , save_path = SAVE_PATH , save_name = 'dist_v1_gamma' , ) # run full experiment clf_exp . run_experiment () Function: gauss --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) <ipython-input-23-937e854bdd0b> in <module> 11 12 # run full experiment ---> 13 clf_exp . run_experiment ( ) ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/distributions.py in run_experiment (self) 214 hsic_method = hsic_method , 215 hsic_score = hsic_score , --> 216 mi_score = mi_score , 217 ) 218 ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/distributions.py in append_results (self, results_df, dataset, trial, n_samples, d_dimensions, std, nu, gamma, gamma_init, hsic_method, hsic_score, mi_score) 337 \"mi_score\" : mi_score , 338 }, --> 339 ignore_index = True , 340 ) 341 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/frame.py in append (self, other, ignore_index, verify_integrity, sort) 7121 ignore_index = ignore_index , 7122 verify_integrity = verify_integrity , -> 7123 sort = sort , 7124 ) 7125 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/reshape/concat.py in concat (objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy) 253 verify_integrity = verify_integrity , 254 copy = copy , --> 255 sort = sort , 256 ) 257 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/reshape/concat.py in __init__ (self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort) 333 334 # consolidate --> 335 obj . _consolidate ( inplace = True ) 336 ndims . add ( obj . ndim ) 337 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/generic.py in _consolidate (self, inplace) 5268 inplace = validate_bool_kwarg ( inplace , \"inplace\" ) 5269 if inplace : -> 5270 self . _consolidate_inplace ( ) 5271 else : 5272 f = lambda : self . _data . consolidate ( ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/generic.py in _consolidate_inplace (self) 5250 self . _data = self . _data . consolidate ( ) 5251 -> 5252 self . _protect_consolidate ( f ) 5253 5254 def _consolidate ( self , inplace = False ) : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/generic.py in _protect_consolidate (self, f) 5239 \"\"\" 5240 blocks_before = len ( self . _data . blocks ) -> 5241 result = f ( ) 5242 if len ( self . _data . blocks ) != blocks_before : 5243 self . _clear_item_cache ( ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/generic.py in f () 5248 5249 def f ( ) : -> 5250 self . _data = self . _data . consolidate ( ) 5251 5252 self . _protect_consolidate ( f ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/managers.py in consolidate (self) 930 bm = self . __class__ ( self . blocks , self . axes ) 931 bm . _is_consolidated = False --> 932 bm . _consolidate_inplace ( ) 933 return bm 934 ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/managers.py in _consolidate_inplace (self) 935 def _consolidate_inplace ( self ) : 936 if not self . is_consolidated ( ) : --> 937 self . blocks = tuple ( _consolidate ( self . blocks ) ) 938 self . _is_consolidated = True 939 self . _known_consolidated = True ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/managers.py in _consolidate (blocks) 1911 for ( _can_consolidate , dtype ) , group_blocks in grouper : 1912 merged_blocks = _merge_blocks( -> 1913 list ( group_blocks ) , dtype = dtype , _can_consolidate = _can_consolidate 1914 ) 1915 new_blocks = _extend_blocks ( merged_blocks , new_blocks ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/internals/blocks.py in _merge_blocks (blocks, dtype, _can_consolidate) 3321 3322 argsort = np . argsort ( new_mgr_locs ) -> 3323 new_values = new_values [ argsort ] 3324 new_mgr_locs = new_mgr_locs [ argsort ] 3325 KeyboardInterrupt :","title":"Trial Experiment"},{"location":"notebooks/4_distributions/old/3_exp_dimensions/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Experiment III - Samples vs Dimensions \u00b6 import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import RBIGData # Kernel Dependency measure from models.dependence import HSIC , train_rbf_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 clf_rbigdata = RBIGData ( dataset = dataset , info_meas = info_meas ) Datasets \u00b6 * Samples - [500, 1K, 5K, 10K, 30K, 50K] * Dimensions - [ 2, 3, 10, 50, 100] * trials - [1,5] * IT measures - [TC, H, MI, KLD] * Distributions - [Linear, Gaussian, T-Student] # dataset params dataset = 'gauss' info_meas = 'mi' # initialize dataset Gen clf_rbigdata = RBIGData ( dataset = dataset , info_meas = info_meas ) # extract data and results d_dimensions = 2 n_samples = 500 t_trials = 2 nu = None mu = None data = clf_rbigdata . get_data ( d_dimensions = d_dimensions , n_samples = n_samples , t_trials = t_trials , nu = nu , mu = mu ) X , Y = data [ 'X' ], data [ 'Y' ] # extract data and results d_dimensions = 2 n_samples = 500 t_trials = 2 nu = 1 mu = 4 results = clf_rbigdata . get_results ( d_dimensions = d_dimensions , n_samples = n_samples , t_trials = t_trials , nu = nu , mu = mu ) DATA_MI_tstu_nd_2_Ns_500_tryal_2_nu_1.mat HSIC Measures \u00b6 # hsic params kernel = 'rbf' scorers = [ 'hsic' , 'tka' , 'ctka' ] subsample = None bias = True # HSIC train parameters n_gamma = 1000 sigma_est = 'mean' factor = 1 verbose = 1 n_jobs = - 1 cv = 2 for iscorer in scorers : print ( f 'Scorer: { iscorer } ' ) # initialize HSIC calculator clf_hsic = HSIC ( kernel = kernel , scorer = iscorer , subsample = subsample , bias = bias ) # calculate HSIC return scorer clf_hsic = train_rbf_hsic ( X , Y , clf_hsic , n_gamma = n_gamma , factor = factor , sigma_est = sigma_est , verbose = verbose , n_jobs = n_jobs , cv = cv ) # # hsic value and kernel alignment score # hsic_val = clf_hsic.hsic_value Scorer: hsic Fitting 2 folds for each of 1000 candidates, totalling 2000 fits [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 151 tasks | elapsed: 1.9s [Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 2.9s finished [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. Best HSIC score: 0.00515 gamma: 0.384 Scorer: tka Fitting 2 folds for each of 1000 candidates, totalling 2000 fits [Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 1.4s finished [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. Best TKA score: 0.99683 gamma: 0.005 Scorer: ctka Fitting 2 folds for each of 1000 candidates, totalling 2000 fits [Parallel(n_jobs=-1)]: Done 280 tasks | elapsed: 0.4s Best CTKA score: 0.70761 gamma: 50.000 [Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 1.3s finished Experiment Class \u00b6 class LargeScaleKTA : def __init__ ( self , seed = 123 , n_gamma = 100 , factor = 1 , sigma_est = 'silverman' , save_path = None , save_name = 'scale_test' ): # fixed experimental params self . seed = seed self . n_gamma = n_gamma self . factor = factor self . sigma_est = sigma_est self . save_path = save_path self . save_name = save_name self . datasets = [ 'gauss' , 'tstudent' , ] self . nus = [ 1 , 2 , 3 ] self . trials = [ 1 , 2 , 3 , 4 , 5 ] self . n_samples = [ 500 , 1_000 , 5_000 , 10_000 , # 30_000, # 50_000 ] self . d_dimensions = [ 2 , 3 , 10 , 50 , 100 ] # free experimental params self . scorers = [ 'hsic' , 'tka' , 'ctka' , ] # saved dataframe pass def run_experiment ( self ): # initialize results dataframe self . results_df = self . generate_results_df () # Loop through datasets for idataset in self . datasets : print ( f \"Function: { idataset } \" ) # Loop through samples for isample in self . n_samples : for idimension in self . d_dimensions : # Loop through random seeds for itrial in self . trials : if idataset == 'tstudent' : for inu in self . nus : X , Y = self . _get_data ( idataset , 'mi' , idimension , isample , itrial , inu ) # Loop through HSIC scoring methods for hsic_method in self . scorers : # ======================= # HSIC MEASURES # ======================= # Calculate HSIC hsic_score , gamma = self . _get_hsic ( X , Y , hsic_method ) # append results to results dataframe self . results_df = self . append_results ( self . results_df , idataset , itrial , isample , idimensions , inu , gamma , hsic_method , hsic_score , ) # save results to csv self . save_data ( self . results_df ) elif idataset == 'gauss' : X , Y = self . _get_data ( idataset , 'mi' , idimension , isample , itrial , None ) # ======================= # HSIC MEASURES # ======================= # Loop through HSIC scoring methods for hsic_method in self . scorers : # ======================= # HSIC MEASURES # ======================= # Calculate HSIC hsic_score , gamma = self . _get_hsic ( X , Y , hsic_method ) # append results to results dataframe self . results_df = self . append_results ( self . results_df , idataset , itrial , isample , idimension , np . nan , gamma , hsic_method , hsic_score , ) # save results to csv self . save_data ( self . results_df ) else : raise ValueError ( f \"Unrecognized dataset: { idataset } \" ) return self def _get_data ( self , dataset , info_meas , dimensions , samples , trials , nu ): # initialize dataset Generator clf_rbigdata = RBIGData ( dataset = dataset , info_meas = info_meas ) data = clf_rbigdata . get_data ( d_dimensions = dimensions , n_samples = samples , t_trials = trials , nu = nu , ) return data [ 'X' ], data [ 'Y' ] def _get_hsic ( self , X , Y , scorer ): # hsic params kernel = 'rbf' subsample = None bias = True # initialize HSIC calculator clf_hsic = HSIC ( kernel = kernel , scorer = scorer , subsample = subsample , bias = bias ) # calculate HSIC return scorer clf_hsic = train_rbf_hsic ( X , Y , clf_hsic , n_gamma = self . n_gamma , factor = self . factor , sigma_est = self . sigma_est , verbose = 0 , n_jobs =- 1 , cv = 3 ) # hsic value and kernel alignment score return clf_hsic . hsic_value , clf_hsic . gamma def generate_results_df ( self ): return pd . DataFrame ( columns = [ 'dataset' , 'trial' , 'n_samples' , 'd_dimensions' , 'nu' , 'gamma' , 'scorer' , 'value' , ]) def append_results ( self , results_df , dataset , trial , n_samples , d_dimensions , nu , gamma , hsic_method , hsic_score , ): # append data return results_df . append ({ 'dataset' : dataset , 'trial' : trial , 'n_samples' : n_samples , 'd_dimensions' : d_dimensions , 'nu' : nu , 'gamma' : gamma , 'scorer' : hsic_method , 'value' : hsic_score , }, ignore_index = True ) def load_data ( self ): pass def save_data ( self , results_df ): results_df . to_csv ( f \" { self . save_path }{ self . save_name } .csv\" ) # experimental params seed = 123 # reproducibility n_gamma = 100 # number of points in gamma param grid factor = 1 # log factor for gamma param grid bounds sigma_est = 'mean' # sigma initialization save_path = f ' { cwd } /../../results/hsic/' save_name = 'trial_large_v1' # initialize experiment class clf_exp = LargeScaleKTA ( seed = seed , factor = factor , sigma_est = sigma_est , n_gamma = n_gamma , save_path = save_path , save_name = save_name , ) # run full experiment clf_exp . run_experiment () Function: gauss","title":"3 exp dimensions"},{"location":"notebooks/4_distributions/old/3_exp_dimensions/#experiment-iii-samples-vs-dimensions","text":"import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import RBIGData # Kernel Dependency measure from models.dependence import HSIC , train_rbf_hsic from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 clf_rbigdata = RBIGData ( dataset = dataset , info_meas = info_meas )","title":"Experiment III - Samples vs Dimensions"},{"location":"notebooks/4_distributions/old/3_exp_dimensions/#datasets","text":"* Samples - [500, 1K, 5K, 10K, 30K, 50K] * Dimensions - [ 2, 3, 10, 50, 100] * trials - [1,5] * IT measures - [TC, H, MI, KLD] * Distributions - [Linear, Gaussian, T-Student] # dataset params dataset = 'gauss' info_meas = 'mi' # initialize dataset Gen clf_rbigdata = RBIGData ( dataset = dataset , info_meas = info_meas ) # extract data and results d_dimensions = 2 n_samples = 500 t_trials = 2 nu = None mu = None data = clf_rbigdata . get_data ( d_dimensions = d_dimensions , n_samples = n_samples , t_trials = t_trials , nu = nu , mu = mu ) X , Y = data [ 'X' ], data [ 'Y' ] # extract data and results d_dimensions = 2 n_samples = 500 t_trials = 2 nu = 1 mu = 4 results = clf_rbigdata . get_results ( d_dimensions = d_dimensions , n_samples = n_samples , t_trials = t_trials , nu = nu , mu = mu ) DATA_MI_tstu_nd_2_Ns_500_tryal_2_nu_1.mat","title":"Datasets"},{"location":"notebooks/4_distributions/old/3_exp_dimensions/#hsic-measures","text":"# hsic params kernel = 'rbf' scorers = [ 'hsic' , 'tka' , 'ctka' ] subsample = None bias = True # HSIC train parameters n_gamma = 1000 sigma_est = 'mean' factor = 1 verbose = 1 n_jobs = - 1 cv = 2 for iscorer in scorers : print ( f 'Scorer: { iscorer } ' ) # initialize HSIC calculator clf_hsic = HSIC ( kernel = kernel , scorer = iscorer , subsample = subsample , bias = bias ) # calculate HSIC return scorer clf_hsic = train_rbf_hsic ( X , Y , clf_hsic , n_gamma = n_gamma , factor = factor , sigma_est = sigma_est , verbose = verbose , n_jobs = n_jobs , cv = cv ) # # hsic value and kernel alignment score # hsic_val = clf_hsic.hsic_value Scorer: hsic Fitting 2 folds for each of 1000 candidates, totalling 2000 fits [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 151 tasks | elapsed: 1.9s [Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 2.9s finished [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. Best HSIC score: 0.00515 gamma: 0.384 Scorer: tka Fitting 2 folds for each of 1000 candidates, totalling 2000 fits [Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 1.4s finished [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. Best TKA score: 0.99683 gamma: 0.005 Scorer: ctka Fitting 2 folds for each of 1000 candidates, totalling 2000 fits [Parallel(n_jobs=-1)]: Done 280 tasks | elapsed: 0.4s Best CTKA score: 0.70761 gamma: 50.000 [Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 1.3s finished","title":"HSIC Measures"},{"location":"notebooks/4_distributions/old/3_exp_dimensions/#experiment-class","text":"class LargeScaleKTA : def __init__ ( self , seed = 123 , n_gamma = 100 , factor = 1 , sigma_est = 'silverman' , save_path = None , save_name = 'scale_test' ): # fixed experimental params self . seed = seed self . n_gamma = n_gamma self . factor = factor self . sigma_est = sigma_est self . save_path = save_path self . save_name = save_name self . datasets = [ 'gauss' , 'tstudent' , ] self . nus = [ 1 , 2 , 3 ] self . trials = [ 1 , 2 , 3 , 4 , 5 ] self . n_samples = [ 500 , 1_000 , 5_000 , 10_000 , # 30_000, # 50_000 ] self . d_dimensions = [ 2 , 3 , 10 , 50 , 100 ] # free experimental params self . scorers = [ 'hsic' , 'tka' , 'ctka' , ] # saved dataframe pass def run_experiment ( self ): # initialize results dataframe self . results_df = self . generate_results_df () # Loop through datasets for idataset in self . datasets : print ( f \"Function: { idataset } \" ) # Loop through samples for isample in self . n_samples : for idimension in self . d_dimensions : # Loop through random seeds for itrial in self . trials : if idataset == 'tstudent' : for inu in self . nus : X , Y = self . _get_data ( idataset , 'mi' , idimension , isample , itrial , inu ) # Loop through HSIC scoring methods for hsic_method in self . scorers : # ======================= # HSIC MEASURES # ======================= # Calculate HSIC hsic_score , gamma = self . _get_hsic ( X , Y , hsic_method ) # append results to results dataframe self . results_df = self . append_results ( self . results_df , idataset , itrial , isample , idimensions , inu , gamma , hsic_method , hsic_score , ) # save results to csv self . save_data ( self . results_df ) elif idataset == 'gauss' : X , Y = self . _get_data ( idataset , 'mi' , idimension , isample , itrial , None ) # ======================= # HSIC MEASURES # ======================= # Loop through HSIC scoring methods for hsic_method in self . scorers : # ======================= # HSIC MEASURES # ======================= # Calculate HSIC hsic_score , gamma = self . _get_hsic ( X , Y , hsic_method ) # append results to results dataframe self . results_df = self . append_results ( self . results_df , idataset , itrial , isample , idimension , np . nan , gamma , hsic_method , hsic_score , ) # save results to csv self . save_data ( self . results_df ) else : raise ValueError ( f \"Unrecognized dataset: { idataset } \" ) return self def _get_data ( self , dataset , info_meas , dimensions , samples , trials , nu ): # initialize dataset Generator clf_rbigdata = RBIGData ( dataset = dataset , info_meas = info_meas ) data = clf_rbigdata . get_data ( d_dimensions = dimensions , n_samples = samples , t_trials = trials , nu = nu , ) return data [ 'X' ], data [ 'Y' ] def _get_hsic ( self , X , Y , scorer ): # hsic params kernel = 'rbf' subsample = None bias = True # initialize HSIC calculator clf_hsic = HSIC ( kernel = kernel , scorer = scorer , subsample = subsample , bias = bias ) # calculate HSIC return scorer clf_hsic = train_rbf_hsic ( X , Y , clf_hsic , n_gamma = self . n_gamma , factor = self . factor , sigma_est = self . sigma_est , verbose = 0 , n_jobs =- 1 , cv = 3 ) # hsic value and kernel alignment score return clf_hsic . hsic_value , clf_hsic . gamma def generate_results_df ( self ): return pd . DataFrame ( columns = [ 'dataset' , 'trial' , 'n_samples' , 'd_dimensions' , 'nu' , 'gamma' , 'scorer' , 'value' , ]) def append_results ( self , results_df , dataset , trial , n_samples , d_dimensions , nu , gamma , hsic_method , hsic_score , ): # append data return results_df . append ({ 'dataset' : dataset , 'trial' : trial , 'n_samples' : n_samples , 'd_dimensions' : d_dimensions , 'nu' : nu , 'gamma' : gamma , 'scorer' : hsic_method , 'value' : hsic_score , }, ignore_index = True ) def load_data ( self ): pass def save_data ( self , results_df ): results_df . to_csv ( f \" { self . save_path }{ self . save_name } .csv\" ) # experimental params seed = 123 # reproducibility n_gamma = 100 # number of points in gamma param grid factor = 1 # log factor for gamma param grid bounds sigma_est = 'mean' # sigma initialization save_path = f ' { cwd } /../../results/hsic/' save_name = 'trial_large_v1' # initialize experiment class clf_exp = LargeScaleKTA ( seed = seed , factor = factor , sigma_est = sigma_est , n_gamma = n_gamma , save_path = save_path , save_name = save_name , ) # run full experiment clf_exp . run_experiment () Function: gauss","title":"Experiment Class"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Visualizing HSIC Measures \u00b6 import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures # Plotting from visualization.distribution import plot_scorer_mi from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ( 'ggplot' ) sns . set_style ( \"dark\" ) sns . set_context ( \"poster\" ) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 fig_path = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/\" save_path = f ' { cwd } /../../results/distribution/' save_name = 'dist_v3_medians' cols = [ 'dataset' , 'trial' , 'samples' , 'dimensions' , 'dof' , 'gamma_method' , 'gamma_init' , 'scorer' , 'hsic_value' , 'mi_value' ] results_df = pd . read_csv ( f \" { save_path }{ save_name } .csv\" ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 dataset dimensions dof gamma_init gamma_method hsic_value mi_value samples scorer trial 82495 82495 gauss 100.0 7.0 3.129779e-07 median_s100 0.946841 1.904172 5000.0 ctka 5.0 82496 82496 gauss 100.0 8.0 3.302133e-07 median_s100 0.962541 2.463445 5000.0 ctka 5.0 82497 82497 gauss 100.0 9.0 3.489629e-07 median_s100 0.973092 3.332690 5000.0 ctka 5.0 82498 82498 gauss 100.0 10.0 3.692956e-07 median_s100 0.980514 4.828360 5000.0 ctka 5.0 82499 82499 gauss 100.0 11.0 3.915986e-07 median_s100 0.985921 7.938746 5000.0 ctka 5.0 results_df = results_df [ cols ] results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial samples dimensions dof gamma_method gamma_init scorer hsic_value mi_value 82495 gauss 5.0 5000.0 100.0 7.0 median_s100 3.129779e-07 ctka 0.946841 1.904172 82496 gauss 5.0 5000.0 100.0 8.0 median_s100 3.302133e-07 ctka 0.962541 2.463445 82497 gauss 5.0 5000.0 100.0 9.0 median_s100 3.489629e-07 ctka 0.973092 3.332690 82498 gauss 5.0 5000.0 100.0 10.0 median_s100 3.692956e-07 ctka 0.980514 4.828360 82499 gauss 5.0 5000.0 100.0 11.0 median_s100 3.915986e-07 ctka 0.985921 7.938746 res_samples = results_df [ 'samples' ] . unique () . tolist () res_dists = results_df [ 'dataset' ] . unique () . tolist () res_dimensions = results_df [ 'dimensions' ] . unique () . tolist () res_scorer = results_df [ 'scorer' ] . unique () . tolist () res_gamma = results_df [ 'gamma_method' ] . unique () . tolist () Figure I - Gaussian Distribution \u00b6 results_gaussian = results_df [ results_df [ 'dataset' ] == 'gauss' ] results_gaussian . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial samples dimensions dof gamma_method gamma_init scorer hsic_value mi_value 82495 gauss 5.0 5000.0 100.0 7.0 median_s100 3.129779e-07 ctka 0.946841 1.904172 82496 gauss 5.0 5000.0 100.0 8.0 median_s100 3.302133e-07 ctka 0.962541 2.463445 82497 gauss 5.0 5000.0 100.0 9.0 median_s100 3.489629e-07 ctka 0.973092 3.332690 82498 gauss 5.0 5000.0 100.0 10.0 median_s100 3.692956e-07 ctka 0.980514 4.828360 82499 gauss 5.0 5000.0 100.0 11.0 median_s100 3.915986e-07 ctka 0.985921 7.938746 1. Take the Mean wrt to the experimental params \u00b6 def average_trials ( res_df ): # Take the average of the trials cols = res_df . columns . tolist () # cols.remove('trial') # cols.remove('value') # cols.remove('gamma') return res_df . groupby ( cols ) . mean () . drop ( 'trial' , axis = 1 ) . reset_index () def variance_trials ( res_df ): # Take the average of the trials cols = res_df . columns . tolist () cols . remove ( 'trial' ) return res_df . groupby ( cols ) . std () . reset_index () . drop ( 'trial' , axis = 1 ) II - Extract the fixed variables with labels \u00b6 def plot_prepare ( res_df , dataset = 'gauss' ): # grab dataset attributes (fixed variables) d_dimensions = res_df [ 'dimensions' ] . unique () n_samples = res_df [ 'samples' ] . unique () dataset = res_df [ 'dataset' ] . unique () gamma_method = res_df [ 'gamma_method' ] . unique () scorers = res_df [ 'scorer' ] . unique () . tolist () fixed_vars = { 'dimensions' : int ( d_dimensions ), 'samples' : int ( n_samples ), 'gamma_method' : gamma_method , 'dataset' : dataset , 'scorer' : scorers , } return res_df , fixed_vars Step III - Plot \u00b6 def plot_gammas ( res_df , fixed_vars , save = True ): for iscore in res_df . groupby ( 'scorer' ): # print(iscore[1].head()) mean_results = iscore [ 1 ] . groupby ([ 'dataset' , 'dimensions' , 'scorer' , 'dof' , 'gamma_method' ]) . median () std_results = iscore [ 1 ] . groupby ([ 'dataset' , 'dimensions' , 'scorer' , 'dof' , 'gamma_method' ]) . std () mean_results [ 'hsic_std' ] = std_results [ 'hsic_value' ] . values mean_results [ 'mi_std' ] = std_results [ 'mi_value' ] . values mean_results = mean_results . reset_index () . drop ( columns = [ 'scorer' , 'trial' , 'samples' ]) gamma_legend = mean_results [ 'gamma_init' ] . unique () # print(mean_results.head(3)) # break # print(mean_results.head()) fig , ax = plt . subplots () pts = sns . scatterplot ( x = 'hsic_value' , y = 'mi_value' , hue = 'gamma_method' , data = mean_results , # size='hsic_std', # sizes=(50,200), legend = 'brief' , ax = ax , # hue='gamma', # hue_norm=matplotlib.colors.LogNorm(), # label=iscore[0].upper(), palette = 'Spectral' ) # ax.legend(gamma_legend) ax . legend ( prop = { 'size' : 9 }) ax . set_xlabel ( 'Score' ) ax . set_ylabel ( r 'Mutual Information' ) ax . set_title ( f \"D: { int ( fixed_vars [ 'dimensions' ]) } ,\" f \" N: { fixed_vars [ 'samples' ] } ,\" f \" { fixed_vars [ 'dataset' ][ 0 ] } , \" f \" { iscore [ 0 ] . upper () } \" ) # set xlimits for KTA and CKTA if iscore [ 0 ] in [ 'ctka' , 'tka' ] and fixed_vars [ 'dataset' ][ 0 ] == 'gauss' : ax . set_xlim ([ - 0.1 , 1.1 ]) elif iscore [ 0 ] in [ 'hsic' ] and fixed_vars [ 'dataset' ][ 0 ] == 'gauss' : ax . set_xlim ([ - 0.05 , 0.5 ]) # COLORBAR # norm = matplotlib.colors.LogNorm(mean_results.gamma.min(), mean_results.gamma.max()) # sm = plt.cm.ScalarMappable(cmap=\"Spectral\", norm=norm) # sm.set_array([]) # pts.figure.colorbar(sm, label=r'RBF Bandwidth, $\\gamma$') plt . show () if save : save_name = \\ f \" { fixed_vars [ 'dataset' ][ 0 ] } _\" + \\ f \" { int ( fixed_vars [ 'samples' ]) } _\" + \\ f \" { int ( fixed_vars [ 'dimensions' ]) } _\" + \\ f \" { iscore [ 0 ] . upper () } \" + \\ \".png\" fig . savefig ( fig_path + save_name ) return None plot_groups = [ 'dataset' , 'samples' , 'dimensions' , ] subres = results_gaussian . groupby ( plot_groups ) for igroup in subres : igroup , fixed_vars = plot_prepare ( igroup [ 1 ]) print ( fixed_vars [ 'gamma_method' ]) t = igroup # print(t.head()) plot_gammas ( igroup , fixed_vars , save = True ) # break ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] Figure I - T-Student Distribution \u00b6 This first figure is to demonstrate how the mutual information compares with the amount of noise for each of the functions Linear , Sinusoidal , Circular , and Random . results_gaussian = results_df [ results_df [ 'dataset' ] == 'gauss' ] results_tstudent = results_df [ results_df [ 'dataset' ] == 'tstudent' ] results_tstudent . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial samples dimensions dof gamma_method gamma_init scorer hsic_value mi_value 0 tstudent 1.0 50.0 2.0 1.0 silverman 1.842016 hsic 0.019911 0.302042 1 tstudent 1.0 50.0 2.0 2.0 silverman 1.842016 hsic 0.018461 0.136519 2 tstudent 1.0 50.0 2.0 3.0 silverman 1.842016 hsic 0.017661 0.079458 3 tstudent 1.0 50.0 2.0 4.0 silverman 1.842016 hsic 0.017227 0.052638 4 tstudent 1.0 50.0 2.0 5.0 silverman 1.842016 hsic 0.016863 0.037823 plot_groups = [ 'dataset' , 'samples' , 'dimensions' , ] subres = results_tstudent . groupby ( plot_groups ) for igroup in subres : igroup , fixed_vars = plot_prepare ( igroup [ 1 ]) t = igroup plot_gammas ( igroup , fixed_vars , save = True ) def plot_prepare_all ( res_df , dataset = 'gauss' ): # grab dataset attributes (fixed variables) dataset = res_df [ 'dataset' ] . unique () gamma_init = res_df [ 'gamma_method' ] . unique () scorers = res_df [ 'scorer' ] . unique () . tolist () fixed_vars = { 'gamma_method' : gamma_init , 'dataset' : dataset , 'scorer' : scorers , } return res_df , fixed_vars def plot_all ( res_df , fixed_vars , save = True , drop = None , subset = None ): for iscore in res_df . groupby ( 'scorer' ): # print(iscore[1].head()) # Drop unnecessary columns mean_results = iscore [ 1 ] . groupby ([ 'mi_value' , 'gamma_method' ]) . median () std_results = iscore [ 1 ] . groupby ([ 'mi_value' , 'gamma_method' ]) . std () # print(mean_results.head(3)) mean_results = mean_results . reset_index () . drop ( columns = [ 'trial' , 'samples' , 'dimensions' , 'dof' ]) gamma_legend = mean_results [ 'gamma_method' ] . unique () # Transform the mi_scores mean_results [ 'mi_value' ] += 1 #np.log2(mean_results['mi_score']+1) if subset is not None : mean_results = mean_results [ mean_results [ 'gamma_method' ] . isin ( subset )] if drop is not None : mean_results = mean_results [ ~ mean_results [ 'gamma_method' ] . isin ( drop )] # print(mean_results.head(3)) # print(mean_results.head(3)) # break # print(mean_results.head()) fig , ax = plt . subplots () pts = sns . scatterplot ( x = 'hsic_value' , y = 'mi_value' , hue = 'gamma_method' , data = mean_results , # size='hsic_std', # sizes=(50,200), legend = 'brief' , ax = ax , # hue='gamma', # hue_norm=matplotlib.colors.LogNorm(), # label=iscore[0].upper(), palette = 'Spectral' ) ax . legend ( prop = { 'size' : 9 }) ax . set_yscale ( 'log' ) ax . set_xlabel ( 'Score' ) ax . set_ylabel ( r 'Mutual Information' ) ax . set_title ( f \" { fixed_vars [ 'dataset' ][ 0 ] } , \" f \" { iscore [ 0 ] . upper () } \" ) # COLORBAR # norm = matplotlib.colors.LogNorm(mean_results.gamma.min(), mean_results.gamma.max()) # sm = plt.cm.ScalarMappable(cmap=\"Spectral\", norm=norm) # sm.set_array([]) # pts.figure.colorbar(sm, label=r'RBF Bandwidth, $\\gamma$') plt . show () if save : save_name = \\ f \" { fixed_vars [ 'dataset' ][ 0 ] } _\" + \\ f \" { iscore [ 0 ] . upper () } \" + \\ \".png\" fig . savefig ( fig_path + save_name ) return None t . tail () --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-6-e0babcf6284a> in <module> ----> 1 t . tail ( ) NameError : name 't' is not defined plt . style . available Plot Everything Together - Colors: Gamma Method \u00b6 Standard Methods: Median, Silverman, Scott, Max \u00b6 plot_scorer_mi ( results_df , 'hsic' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , # 'max', 'median_s0.01' , 'median_s0.11' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'tka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , # 'max', 'median_s0.01' , 'median_s0.11' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'ctka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , # 'max', 'median_s0.01' , 'median_s0.11' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) Median Percent Methods \u00b6 plot_scorer_mi ( results_df , 'hsic' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , # 'median_p0.2', # 'median_p0.4', # 'median_p0.6', # 'median_p0.8', 'max' , 'median_s0.01' , 'median_s0.1' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'tka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , # 'median_p0.2', # 'median_p0.4', # 'median_p0.6', # 'median_p0.8', 'max' , 'median_s0.01' , 'median_s0.1' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'ctka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , # 'median_p0.2', # 'median_p0.4', # 'median_p0.6', # 'median_p0.8', 'max' , 'median_s0.01' , 'median_s0.1' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) Median Scale \u00b6 plot_scorer_mi ( results_df , 'hsic' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , 'max' , # 'median_s0.01', # 'median_s0.11', # 'median_s10', # 'median_s100', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'tka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , 'max' , # 'median_s0.01', # 'median_s0.11', # 'median_s10', # 'median_s100', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'ctka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , 'max' , # 'median_s0.01', # 'median_s0.11', # 'median_s10', # 'median_s100', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) Plot Everything Together - Colors: Distribution \u00b6 plot_scorer_mi ( results_df , scorer = 'hsic' , hue = 'dataset' , dataset = None , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', # 'belkin_0.1', # 'max', # 'belkin_0.2', # 'belkin_0.5', # 'belkin_0.4', # 'belkin_0.6', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' ) plot_scorer_mi ( results_df , scorer = 'tka' , hue = 'dataset' , dataset = None , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', # 'belkin_0.1', # 'max', # 'belkin_0.2', # 'belkin_0.5', # 'belkin_0.4', # 'belkin_0.6', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' ) plot_scorer_mi ( results_df , scorer = 'ctka' , hue = 'dataset' , dataset = None , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', # 'belkin_0.1', # 'max', # 'belkin_0.2', # 'belkin_0.5', # 'belkin_0.4', # 'belkin_0.6', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' ) Plot Individual \u00b6 plot_scorer_mi ( results_df , 'hsic' , None , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'median' , 'silverman' , 'scott' , 'belkin_0.1' , 'max' , 'belkin_0.2' , 'belkin_0.5' , 'belkin_0.4' , 'belkin_0.6' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' ) plot_scorer_mi ( results_df , 'tka' , None , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'median' , 'silverman' , 'scott' , 'belkin_0.1' , 'max' , 'belkin_0.2' , 'belkin_0.5' , 'belkin_0.4' , 'belkin_0.6' ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , ) plot_scorer_mi ( results_df , 'ctka' , None , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'median' , 'silverman' , 'scott' , 'belkin_0.1' , 'max' , 'belkin_0.2' , 'belkin_0.5' , 'belkin_0.4' , 'belkin_0.6' ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' ) plot_scorer_mi ( results_df , 'hsic' , 'tstudent' , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'silverman' , 'scott' , 'belkin_0.1' , 'belkin_0.5' ]), style = [ 'seaborn' , 'seaborn-talk' ], log_mi = True , log_score = False , save = True , title = '' ) plot_scorer_mi ( results_df , 'tka' , 'tstudent' , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'max' , 'silverman' , 'scott' , 'belkin_0.1' , 'belkin_0.5' ]), style = [ 'seaborn' , 'seaborn-talk' ], log_mi = True , log_score = False , save = True , title = '' , ) plot_scorer_mi ( results_df , 'ctka' , 'tstudent' , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'max' , 'silverman' , 'scott' , 'belkin_0.1' , 'belkin_0.5' ]), style = [ 'seaborn' , 'seaborn-talk' ], log_mi = True , log_score = False , save = True , title = '' ) plot_groups = [ 'dataset' , ] subres = results_df . groupby ( plot_groups ) for igroup in subres : igroup , fixed_vars = plot_prepare_all ( igroup [ 1 ]) t = igroup plot_all ( igroup , fixed_vars , save = False , drop = None , subset = None ) # break","title":"4 visualize dimensions"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#visualizing-hsic-measures","text":"import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures # Plotting from visualization.distribution import plot_scorer_mi from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ( 'ggplot' ) sns . set_style ( \"dark\" ) sns . set_context ( \"poster\" ) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 fig_path = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/\" save_path = f ' { cwd } /../../results/distribution/' save_name = 'dist_v3_medians' cols = [ 'dataset' , 'trial' , 'samples' , 'dimensions' , 'dof' , 'gamma_method' , 'gamma_init' , 'scorer' , 'hsic_value' , 'mi_value' ] results_df = pd . read_csv ( f \" { save_path }{ save_name } .csv\" ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 dataset dimensions dof gamma_init gamma_method hsic_value mi_value samples scorer trial 82495 82495 gauss 100.0 7.0 3.129779e-07 median_s100 0.946841 1.904172 5000.0 ctka 5.0 82496 82496 gauss 100.0 8.0 3.302133e-07 median_s100 0.962541 2.463445 5000.0 ctka 5.0 82497 82497 gauss 100.0 9.0 3.489629e-07 median_s100 0.973092 3.332690 5000.0 ctka 5.0 82498 82498 gauss 100.0 10.0 3.692956e-07 median_s100 0.980514 4.828360 5000.0 ctka 5.0 82499 82499 gauss 100.0 11.0 3.915986e-07 median_s100 0.985921 7.938746 5000.0 ctka 5.0 results_df = results_df [ cols ] results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial samples dimensions dof gamma_method gamma_init scorer hsic_value mi_value 82495 gauss 5.0 5000.0 100.0 7.0 median_s100 3.129779e-07 ctka 0.946841 1.904172 82496 gauss 5.0 5000.0 100.0 8.0 median_s100 3.302133e-07 ctka 0.962541 2.463445 82497 gauss 5.0 5000.0 100.0 9.0 median_s100 3.489629e-07 ctka 0.973092 3.332690 82498 gauss 5.0 5000.0 100.0 10.0 median_s100 3.692956e-07 ctka 0.980514 4.828360 82499 gauss 5.0 5000.0 100.0 11.0 median_s100 3.915986e-07 ctka 0.985921 7.938746 res_samples = results_df [ 'samples' ] . unique () . tolist () res_dists = results_df [ 'dataset' ] . unique () . tolist () res_dimensions = results_df [ 'dimensions' ] . unique () . tolist () res_scorer = results_df [ 'scorer' ] . unique () . tolist () res_gamma = results_df [ 'gamma_method' ] . unique () . tolist ()","title":"Visualizing HSIC Measures"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#figure-i-gaussian-distribution","text":"results_gaussian = results_df [ results_df [ 'dataset' ] == 'gauss' ] results_gaussian . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial samples dimensions dof gamma_method gamma_init scorer hsic_value mi_value 82495 gauss 5.0 5000.0 100.0 7.0 median_s100 3.129779e-07 ctka 0.946841 1.904172 82496 gauss 5.0 5000.0 100.0 8.0 median_s100 3.302133e-07 ctka 0.962541 2.463445 82497 gauss 5.0 5000.0 100.0 9.0 median_s100 3.489629e-07 ctka 0.973092 3.332690 82498 gauss 5.0 5000.0 100.0 10.0 median_s100 3.692956e-07 ctka 0.980514 4.828360 82499 gauss 5.0 5000.0 100.0 11.0 median_s100 3.915986e-07 ctka 0.985921 7.938746","title":"Figure I - Gaussian Distribution"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#1-take-the-mean-wrt-to-the-experimental-params","text":"def average_trials ( res_df ): # Take the average of the trials cols = res_df . columns . tolist () # cols.remove('trial') # cols.remove('value') # cols.remove('gamma') return res_df . groupby ( cols ) . mean () . drop ( 'trial' , axis = 1 ) . reset_index () def variance_trials ( res_df ): # Take the average of the trials cols = res_df . columns . tolist () cols . remove ( 'trial' ) return res_df . groupby ( cols ) . std () . reset_index () . drop ( 'trial' , axis = 1 )","title":"1. Take the Mean wrt to the experimental params"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#ii-extract-the-fixed-variables-with-labels","text":"def plot_prepare ( res_df , dataset = 'gauss' ): # grab dataset attributes (fixed variables) d_dimensions = res_df [ 'dimensions' ] . unique () n_samples = res_df [ 'samples' ] . unique () dataset = res_df [ 'dataset' ] . unique () gamma_method = res_df [ 'gamma_method' ] . unique () scorers = res_df [ 'scorer' ] . unique () . tolist () fixed_vars = { 'dimensions' : int ( d_dimensions ), 'samples' : int ( n_samples ), 'gamma_method' : gamma_method , 'dataset' : dataset , 'scorer' : scorers , } return res_df , fixed_vars","title":"II - Extract the fixed variables with labels"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#step-iii-plot","text":"def plot_gammas ( res_df , fixed_vars , save = True ): for iscore in res_df . groupby ( 'scorer' ): # print(iscore[1].head()) mean_results = iscore [ 1 ] . groupby ([ 'dataset' , 'dimensions' , 'scorer' , 'dof' , 'gamma_method' ]) . median () std_results = iscore [ 1 ] . groupby ([ 'dataset' , 'dimensions' , 'scorer' , 'dof' , 'gamma_method' ]) . std () mean_results [ 'hsic_std' ] = std_results [ 'hsic_value' ] . values mean_results [ 'mi_std' ] = std_results [ 'mi_value' ] . values mean_results = mean_results . reset_index () . drop ( columns = [ 'scorer' , 'trial' , 'samples' ]) gamma_legend = mean_results [ 'gamma_init' ] . unique () # print(mean_results.head(3)) # break # print(mean_results.head()) fig , ax = plt . subplots () pts = sns . scatterplot ( x = 'hsic_value' , y = 'mi_value' , hue = 'gamma_method' , data = mean_results , # size='hsic_std', # sizes=(50,200), legend = 'brief' , ax = ax , # hue='gamma', # hue_norm=matplotlib.colors.LogNorm(), # label=iscore[0].upper(), palette = 'Spectral' ) # ax.legend(gamma_legend) ax . legend ( prop = { 'size' : 9 }) ax . set_xlabel ( 'Score' ) ax . set_ylabel ( r 'Mutual Information' ) ax . set_title ( f \"D: { int ( fixed_vars [ 'dimensions' ]) } ,\" f \" N: { fixed_vars [ 'samples' ] } ,\" f \" { fixed_vars [ 'dataset' ][ 0 ] } , \" f \" { iscore [ 0 ] . upper () } \" ) # set xlimits for KTA and CKTA if iscore [ 0 ] in [ 'ctka' , 'tka' ] and fixed_vars [ 'dataset' ][ 0 ] == 'gauss' : ax . set_xlim ([ - 0.1 , 1.1 ]) elif iscore [ 0 ] in [ 'hsic' ] and fixed_vars [ 'dataset' ][ 0 ] == 'gauss' : ax . set_xlim ([ - 0.05 , 0.5 ]) # COLORBAR # norm = matplotlib.colors.LogNorm(mean_results.gamma.min(), mean_results.gamma.max()) # sm = plt.cm.ScalarMappable(cmap=\"Spectral\", norm=norm) # sm.set_array([]) # pts.figure.colorbar(sm, label=r'RBF Bandwidth, $\\gamma$') plt . show () if save : save_name = \\ f \" { fixed_vars [ 'dataset' ][ 0 ] } _\" + \\ f \" { int ( fixed_vars [ 'samples' ]) } _\" + \\ f \" { int ( fixed_vars [ 'dimensions' ]) } _\" + \\ f \" { iscore [ 0 ] . upper () } \" + \\ \".png\" fig . savefig ( fig_path + save_name ) return None plot_groups = [ 'dataset' , 'samples' , 'dimensions' , ] subres = results_gaussian . groupby ( plot_groups ) for igroup in subres : igroup , fixed_vars = plot_prepare ( igroup [ 1 ]) print ( fixed_vars [ 'gamma_method' ]) t = igroup # print(t.head()) plot_gammas ( igroup , fixed_vars , save = True ) # break ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max'] ['silverman' 'scott' 'median' 'belkin_0.1' 'belkin_0.2' 'belkin_0.4' 'belkin_0.5' 'belkin_0.6' 'belkin_0.8' 'max']","title":"Step III - Plot"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#figure-i-t-student-distribution","text":"This first figure is to demonstrate how the mutual information compares with the amount of noise for each of the functions Linear , Sinusoidal , Circular , and Random . results_gaussian = results_df [ results_df [ 'dataset' ] == 'gauss' ] results_tstudent = results_df [ results_df [ 'dataset' ] == 'tstudent' ] results_tstudent . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial samples dimensions dof gamma_method gamma_init scorer hsic_value mi_value 0 tstudent 1.0 50.0 2.0 1.0 silverman 1.842016 hsic 0.019911 0.302042 1 tstudent 1.0 50.0 2.0 2.0 silverman 1.842016 hsic 0.018461 0.136519 2 tstudent 1.0 50.0 2.0 3.0 silverman 1.842016 hsic 0.017661 0.079458 3 tstudent 1.0 50.0 2.0 4.0 silverman 1.842016 hsic 0.017227 0.052638 4 tstudent 1.0 50.0 2.0 5.0 silverman 1.842016 hsic 0.016863 0.037823 plot_groups = [ 'dataset' , 'samples' , 'dimensions' , ] subres = results_tstudent . groupby ( plot_groups ) for igroup in subres : igroup , fixed_vars = plot_prepare ( igroup [ 1 ]) t = igroup plot_gammas ( igroup , fixed_vars , save = True ) def plot_prepare_all ( res_df , dataset = 'gauss' ): # grab dataset attributes (fixed variables) dataset = res_df [ 'dataset' ] . unique () gamma_init = res_df [ 'gamma_method' ] . unique () scorers = res_df [ 'scorer' ] . unique () . tolist () fixed_vars = { 'gamma_method' : gamma_init , 'dataset' : dataset , 'scorer' : scorers , } return res_df , fixed_vars def plot_all ( res_df , fixed_vars , save = True , drop = None , subset = None ): for iscore in res_df . groupby ( 'scorer' ): # print(iscore[1].head()) # Drop unnecessary columns mean_results = iscore [ 1 ] . groupby ([ 'mi_value' , 'gamma_method' ]) . median () std_results = iscore [ 1 ] . groupby ([ 'mi_value' , 'gamma_method' ]) . std () # print(mean_results.head(3)) mean_results = mean_results . reset_index () . drop ( columns = [ 'trial' , 'samples' , 'dimensions' , 'dof' ]) gamma_legend = mean_results [ 'gamma_method' ] . unique () # Transform the mi_scores mean_results [ 'mi_value' ] += 1 #np.log2(mean_results['mi_score']+1) if subset is not None : mean_results = mean_results [ mean_results [ 'gamma_method' ] . isin ( subset )] if drop is not None : mean_results = mean_results [ ~ mean_results [ 'gamma_method' ] . isin ( drop )] # print(mean_results.head(3)) # print(mean_results.head(3)) # break # print(mean_results.head()) fig , ax = plt . subplots () pts = sns . scatterplot ( x = 'hsic_value' , y = 'mi_value' , hue = 'gamma_method' , data = mean_results , # size='hsic_std', # sizes=(50,200), legend = 'brief' , ax = ax , # hue='gamma', # hue_norm=matplotlib.colors.LogNorm(), # label=iscore[0].upper(), palette = 'Spectral' ) ax . legend ( prop = { 'size' : 9 }) ax . set_yscale ( 'log' ) ax . set_xlabel ( 'Score' ) ax . set_ylabel ( r 'Mutual Information' ) ax . set_title ( f \" { fixed_vars [ 'dataset' ][ 0 ] } , \" f \" { iscore [ 0 ] . upper () } \" ) # COLORBAR # norm = matplotlib.colors.LogNorm(mean_results.gamma.min(), mean_results.gamma.max()) # sm = plt.cm.ScalarMappable(cmap=\"Spectral\", norm=norm) # sm.set_array([]) # pts.figure.colorbar(sm, label=r'RBF Bandwidth, $\\gamma$') plt . show () if save : save_name = \\ f \" { fixed_vars [ 'dataset' ][ 0 ] } _\" + \\ f \" { iscore [ 0 ] . upper () } \" + \\ \".png\" fig . savefig ( fig_path + save_name ) return None t . tail () --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-6-e0babcf6284a> in <module> ----> 1 t . tail ( ) NameError : name 't' is not defined plt . style . available","title":"Figure I - T-Student Distribution"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#plot-everything-together-colors-gamma-method","text":"","title":"Plot Everything Together - Colors: Gamma Method"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#standard-methods-median-silverman-scott-max","text":"plot_scorer_mi ( results_df , 'hsic' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , # 'max', 'median_s0.01' , 'median_s0.11' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'tka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , # 'max', 'median_s0.01' , 'median_s0.11' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'ctka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , # 'max', 'median_s0.01' , 'median_s0.11' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True )","title":"Standard Methods: Median, Silverman, Scott, Max"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#median-percent-methods","text":"plot_scorer_mi ( results_df , 'hsic' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , # 'median_p0.2', # 'median_p0.4', # 'median_p0.6', # 'median_p0.8', 'max' , 'median_s0.01' , 'median_s0.1' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'tka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , # 'median_p0.2', # 'median_p0.4', # 'median_p0.6', # 'median_p0.8', 'max' , 'median_s0.01' , 'median_s0.1' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'ctka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , # 'median_p0.2', # 'median_p0.4', # 'median_p0.6', # 'median_p0.8', 'max' , 'median_s0.01' , 'median_s0.1' , 'median_s10' , 'median_s100' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True )","title":"Median Percent Methods"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#median-scale","text":"plot_scorer_mi ( results_df , 'hsic' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , 'max' , # 'median_s0.01', # 'median_s0.11', # 'median_s10', # 'median_s100', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'tka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , 'max' , # 'median_s0.01', # 'median_s0.11', # 'median_s10', # 'median_s100', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True ) plot_scorer_mi ( results_df , 'ctka' , None , hue = 'gamma_method' , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', 'silverman' , 'scott' , 'median_p0.2' , 'median_p0.4' , 'median_p0.6' , 'median_p0.8' , 'max' , # 'median_s0.01', # 'median_s0.11', # 'median_s10', # 'median_s100', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , plot_legend = True )","title":"Median Scale"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#plot-everything-together-colors-distribution","text":"plot_scorer_mi ( results_df , scorer = 'hsic' , hue = 'dataset' , dataset = None , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', # 'belkin_0.1', # 'max', # 'belkin_0.2', # 'belkin_0.5', # 'belkin_0.4', # 'belkin_0.6', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' ) plot_scorer_mi ( results_df , scorer = 'tka' , hue = 'dataset' , dataset = None , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', # 'belkin_0.1', # 'max', # 'belkin_0.2', # 'belkin_0.5', # 'belkin_0.4', # 'belkin_0.6', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' ) plot_scorer_mi ( results_df , scorer = 'ctka' , hue = 'dataset' , dataset = None , omit_samples = ( 'samples' , [ '50' , '100' , '500' , '1000' ]), omit_methods = ( 'gamma_method' , [ # 'median', # 'silverman', # 'scott', # 'belkin_0.1', # 'max', # 'belkin_0.2', # 'belkin_0.5', # 'belkin_0.4', # 'belkin_0.6', ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' )","title":"Plot Everything Together - Colors: Distribution"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions/#plot-individual","text":"plot_scorer_mi ( results_df , 'hsic' , None , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'median' , 'silverman' , 'scott' , 'belkin_0.1' , 'max' , 'belkin_0.2' , 'belkin_0.5' , 'belkin_0.4' , 'belkin_0.6' , ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' ) plot_scorer_mi ( results_df , 'tka' , None , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'median' , 'silverman' , 'scott' , 'belkin_0.1' , 'max' , 'belkin_0.2' , 'belkin_0.5' , 'belkin_0.4' , 'belkin_0.6' ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' , ) plot_scorer_mi ( results_df , 'ctka' , None , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'median' , 'silverman' , 'scott' , 'belkin_0.1' , 'max' , 'belkin_0.2' , 'belkin_0.5' , 'belkin_0.4' , 'belkin_0.6' ]), style = [ 'seaborn' , 'seaborn-paper' ], log_mi = True , log_score = False , save = True , title = '' ) plot_scorer_mi ( results_df , 'hsic' , 'tstudent' , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'silverman' , 'scott' , 'belkin_0.1' , 'belkin_0.5' ]), style = [ 'seaborn' , 'seaborn-talk' ], log_mi = True , log_score = False , save = True , title = '' ) plot_scorer_mi ( results_df , 'tka' , 'tstudent' , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'max' , 'silverman' , 'scott' , 'belkin_0.1' , 'belkin_0.5' ]), style = [ 'seaborn' , 'seaborn-talk' ], log_mi = True , log_score = False , save = True , title = '' , ) plot_scorer_mi ( results_df , 'ctka' , 'tstudent' , ( 'samples' , [ '50' , '100' , '500' , '1000' ]), ( 'gamma_method' , [ 'max' , 'silverman' , 'scott' , 'belkin_0.1' , 'belkin_0.5' ]), style = [ 'seaborn' , 'seaborn-talk' ], log_mi = True , log_score = False , save = True , title = '' ) plot_groups = [ 'dataset' , ] subres = results_df . groupby ( plot_groups ) for igroup in subres : igroup , fixed_vars = plot_prepare_all ( igroup [ 1 ]) t = igroup plot_all ( igroup , fixed_vars , save = False , drop = None , subset = None ) # break","title":"Plot Individual"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions_original/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Visualizing HSIC Measures \u00b6 import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 fig_path = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/\" save_path = f ' { cwd } /../../results/hsic/' save_name = 'dist_v2_belkin' cols = [ 'dataset' , 'trial' , 'n_samples' , 'd_dimensions' , 'nu' , 'std' , 'gamma' , 'gamma_median' , 'gamma_silv' , 'gamma_scott' , 'gamma_belkin' , 'scorer' , 'value' , 'mi_score' ] results_df = pd . read_csv ( f \" { save_path }{ save_name } .csv\" )[ cols ] results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial n_samples d_dimensions nu std gamma gamma_median gamma_silv gamma_scott gamma_belkin scorer value mi_score 7495 tstudent 5 5000 100 20.0 NaN 0.275053 11.709883 0.893117 0.921368 8.754526 tka 1.000000 8.098041 7496 tstudent 5 5000 100 20.0 NaN 0.275053 11.709883 0.893117 0.921368 8.754526 ctka 1.000000 8.098041 7497 tstudent 5 5000 100 30.0 NaN 0.005442 11.549000 0.893117 0.921368 8.718251 hsic 0.025679 7.993998 7498 tstudent 5 5000 100 30.0 NaN 0.281852 11.549000 0.893117 0.921368 8.718251 tka 1.000000 7.993998 7499 tstudent 5 5000 100 30.0 NaN 0.281852 11.549000 0.893117 0.921368 8.718251 ctka 1.000000 7.993998 res_samples = results_df [ 'n_samples' ] . unique () . tolist () res_dists = results_df [ 'dataset' ] . unique () . tolist () res_dimensions = results_df [ 'd_dimensions' ] . unique () . tolist () res_scorer = results_df [ 'scorer' ] . unique () . tolist () Figure I - Gaussian Distribution \u00b6 results_gaussian = results_df [ results_df [ 'dataset' ] == 'gauss' ] results_gaussian . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial n_samples d_dimensions nu std gamma gamma_median gamma_silv gamma_scott gamma_belkin scorer value mi_score 4120 gauss 5 5000 100 NaN 0.9 0.285036 11.635845 0.893117 0.921368 9.328636 tka 1.000000 4.828360 4121 gauss 5 5000 100 NaN 0.9 0.285036 11.635845 0.893117 0.921368 9.328636 ctka 1.000000 4.828360 4122 gauss 5 5000 100 NaN 1.0 0.005679 11.299636 0.893117 0.921368 8.659846 hsic 0.026563 7.938746 4123 gauss 5 5000 100 NaN 1.0 0.294129 11.299636 0.893117 0.921368 8.659846 tka 1.000000 7.938746 4124 gauss 5 5000 100 NaN 1.0 0.294129 11.299636 0.893117 0.921368 8.659846 ctka 1.000000 7.938746 Figure I - T-Student Distribution \u00b6 This first figure is to demonstrate how the mutual information compares with the amount of noise for each of the functions Linear , Sinusoidal , Circular , and Random . results_gaussian = results_df [ results_df [ 'dataset' ] == 'gauss' ] results_tstudent = results_df [ results_df [ 'dataset' ] == 'tstudent' ] results_tstudent . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial n_samples d_dimensions nu std gamma gamma_median gamma_silv gamma_scott gamma_belkin scorer value mi_score 4125 tstudent 1 50 2 1.0 NaN 0.244634 4.263675 0.521001 0.521001 1.915118 hsic 0.026925 0.302042 4126 tstudent 1 50 2 1.0 NaN 0.000193 4.263675 0.521001 0.521001 1.915118 tka 0.999865 0.302042 4127 tstudent 1 50 2 1.0 NaN 1.934087 4.263675 0.521001 0.521001 1.915118 ctka 0.630722 0.302042 4128 tstudent 1 50 2 2.0 NaN 4.484111 2.444370 0.521001 0.521001 1.049202 hsic 0.018855 0.136519 4129 tstudent 1 50 2 2.0 NaN 0.000448 2.444370 0.521001 0.521001 1.049202 tka 0.999888 0.136519 Step I - Take the mean wrt the experimental parameters \u00b6 def average_trials ( res_df ): # Take the average of the trials cols = res_df . columns . tolist () # cols.remove('trial') # cols.remove('value') # cols.remove('gamma') return res_df . groupby ( cols ) . mean () . drop ( 'trial' , axis = 1 ) . reset_index () def variance_trials ( res_df ): # Take the average of the trials cols = res_df . columns . tolist () cols . remove ( 'trial' ) return res_df . groupby ( cols ) . std () . reset_index () . drop ( 'trial' , axis = 1 ) exp_vars = [ 'dataset' , 'trial' , 'n_samples' , 'd_dimensions' , 'nu' , 'std' , 'gamma' , 'gamma_median' , 'gamma_silv' , 'gamma_scott' , 'gamma_belkin' , 'scorer' , 'value' ] cols = results_tstudent . columns . tolist () # cols.remove('trial') # cols.remove('value') # cols.remove('gamma') res = average_trials ( results_tstudent ) res . head () --------------------------------------------------------------------------- DataError Traceback (most recent call last) <ipython-input-10-30ea35f40b59> in <module> 18 # cols.remove('value') 19 # cols.remove('gamma') ---> 20 res = average_trials ( results_tstudent ) 21 22 res . head ( ) <ipython-input-9-b503816a108f> in average_trials (res_df) 5 # cols.remove('value') 6 # cols.remove('gamma') ----> 7 return res_df . groupby ( cols ) . mean ( ) . drop ( 'trial' , axis = 1 ) . reset_index ( ) 8 9 def variance_trials ( res_df ) : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/groupby/groupby.py in mean (self, *args, **kwargs) 1203 try : 1204 return self._cython_agg_general( -> 1205 \"mean\" , alt = lambda x , axis : Series ( x ) . mean ( ** kwargs ) , ** kwargs 1206 ) 1207 except GroupByError : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/groupby/generic.py in _cython_agg_general (self, how, alt, numeric_only, min_count) 126 def _cython_agg_general ( self , how , alt = None , numeric_only = True , min_count = - 1 ) : 127 new_items, new_blocks = self._cython_agg_blocks( --> 128 how , alt = alt , numeric_only = numeric_only , min_count = min_count 129 ) 130 return self . _wrap_agged_blocks ( new_items , new_blocks ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/groupby/generic.py in _cython_agg_blocks (self, how, alt, numeric_only, min_count) 186 187 if len ( new_blocks ) == 0 : --> 188 raise DataError ( \"No numeric types to aggregate\" ) 189 190 # reset the locs in the blocks to correspond to our DataError : No numeric types to aggregate def plot_prepare ( res_df , dataset = 'gauss' ): # grab dataset attributes (fixed variables) d_dimensions = res_df [ 'd_dimensions' ] . unique () n_samples = res_df [ 'n_samples' ] . unique () dataset = res_df [ 'dataset' ] . unique () gamma_scott = res_df [ 'gamma_scott' ] . unique () gamma_silv = res_df [ 'gamma_silv' ] . unique () gamma_median = res_df [ 'gamma_median' ] . unique () gamma_belkin = res_df [ 'gamma_belkin' ] . unique () scorers = res_df [ 'scorer' ] . unique () . tolist () # print(gamma_median) # get fixed variables if dataset == 'gauss' : fixed_vars = { 'd_dimensions' : int ( d_dimensions ), 'n_samples' : int ( n_samples ), 'dataset' : dataset , 'scorer' : scorers , } elif dataset == 'tstudent' : fixed_vars = { 'd_dimensions' : int ( d_dimensions ), 'n_samples' : int ( n_samples ), 'dataset' : dataset , 'scorer' : scorers , } else : raise ValueError ( f 'Unrecognized distribution { dataset } ' ) return res_df , fixed_vars def plot_gauss ( res_df , fixed_vars , save = True ): for iscore in res_df . groupby ( 'scorer' ): # print(iscore[1].head()) mean_results = iscore [ 1 ] . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'std' ]) . median () std_results = iscore [ 1 ] . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'std' ]) . std () mean_results [ 'hsic_std' ] = std_results [ 'value' ] . values mean_results [ 'mi_std' ] = std_results [ 'mi_score' ] . values mean_results = mean_results . reset_index () # break # print(mean_results.head()) fig , ax = plt . subplots () pts = sns . scatterplot ( x = 'value' , y = 'mi_score' , data = mean_results , size = 'hsic_std' , sizes = ( 50 , 200 ), ax = ax , hue = 'gamma' , # hue_norm=matplotlib.colors.LogNorm(), label = iscore [ 0 ] . upper (), palette = 'Spectral' ) ax . legend ([ str ( iscore [ 0 ])]) ax . set_xlabel ( 'HSIC Value' ) ax . set_ylabel ( r 'Mutual Information' ) ax . set_title ( f \"D: { int ( fixed_vars [ 'd_dimensions' ]) } ,\" f \" N: { fixed_vars [ 'n_samples' ] } ,\" f \" { fixed_vars [ 'dataset' ][ 0 ] } \" ) # COLORBAR norm = matplotlib . colors . LogNorm ( mean_results . gamma . min (), mean_results . gamma . max ()) sm = plt . cm . ScalarMappable ( cmap = \"Spectral\" , norm = norm ) sm . set_array ([]) pts . figure . colorbar ( sm , label = r 'RBF Bandwidth, $\\gamma$' ) if not save : plt . show () else : save_name = \\ f \" { fixed_vars [ 'dataset' ][ 0 ] } _\" + \\ f \" { int ( fixed_vars [ 'n_samples' ]) } _\" + \\ f \" { int ( fixed_vars [ 'd_dimensions' ]) } _\" + \\ f \" { int ( fixed_vars [ 'std' ]) } _\" + \\ f \" { iscore [ 0 ] . upper () } \" + \\ \".png\" fig . savefig ( fig_path + save_name ) return None def plot_tstudent ( res_df , fixed_vars , save = True ): for iscore in res_df . groupby ( 'scorer' ): # print(iscore[1].head()) mean_results = iscore [ 1 ] . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'nu' ]) . median () std_results = iscore [ 1 ] . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'nu' ]) . std () mean_results [ 'hsic_std' ] = std_results [ 'value' ] . values mean_results [ 'mi_std' ] = std_results [ 'mi_score' ] . values mean_results = mean_results . reset_index () # break # print(mean_results.head()) fig , ax = plt . subplots () pts = sns . scatterplot ( x = 'value' , y = 'mi_score' , data = mean_results , size = 'hsic_std' , sizes = ( 50 , 200 ), ax = ax , hue = 'gamma' , # hue_norm=matplotlib.colors.LogNorm(), label = iscore [ 0 ] . upper (), palette = 'Spectral' ) ax . legend ([ str ( iscore [ 0 ])]) ax . set_xlabel ( 'HSIC Value' ) ax . set_ylabel ( r 'MI (nats)' ) ax . set_title ( f \"D: { int ( fixed_vars [ 'd_dimensions' ]) } ,\" f \" N: { fixed_vars [ 'n_samples' ] } ,\" f \" { fixed_vars [ 'dataset' ][ 0 ] } \" ) # COLORBAR norm = matplotlib . colors . LogNorm ( mean_results . gamma . min (), mean_results . gamma . max ()) sm = plt . cm . ScalarMappable ( cmap = \"Spectral\" , norm = norm ) sm . set_array ([]) pts . figure . colorbar ( sm , label = r 'RBF Bandwidth, $\\gamma$' ) if not save : plt . show () else : save_name = \\ f \" { fixed_vars [ 'dataset' ][ 0 ] } _\" + \\ f \" { int ( fixed_vars [ 'n_samples' ]) } _\" + \\ f \" { int ( fixed_vars [ 'd_dimensions' ]) } _\" + \\ f \" { int ( fixed_vars [ 'nu' ]) } _\" + \\ f \" { iscore [ 0 ] . upper () } \" + \\ \".png\" fig . savefig ( fig_path + save_name ) return None plot_groups = [ 'dataset' , 'n_samples' , 'd_dimensions' , 'dataset' , ] subres = results_tstudent . groupby ( plot_groups ) for igroup in subres : igroup , fixed_vars = plot_prepare ( igroup [ 1 ]) t = igroup plot_tstudent ( igroup , fixed_vars , save = False ) break plot_groups = [ 'dataset' , 'n_samples' , 'd_dimensions' , 'dataset' , ] subres = results_gaussian . groupby ( plot_groups ) for igroup in subres : igroup , fixed_vars = plot_prepare ( igroup [ 1 ]) t = igroup plot_gauss ( igroup , fixed_vars , save = False ) break for igroup in subres : igroup , fixed_vars = plot_prepare ( igroup [ 1 ]) t = igroup plot_tstudent ( igroup , fixed_vars , save = False ) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> plot_groups = [ 'dataset' , 'n_samples' , 'd_dimensions' , 'dataset' , ] subres = results_tstudent . groupby ( plot_groups ) np . linspace ( 1 , 100 , 5 ) array([ 1. , 25.75, 50.5 , 75.25, 100. ]) fixed_vars . keys () dict_keys(['d_dimensions', 'n_samples', 'dataset', 'scorer']) t . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'nu' ]) . mean () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } trial n_samples std gamma gamma_median gamma_silv gamma_scott gamma_belkin value dataset d_dimensions scorer nu tstudent 2 ctka 1.0 3 50 NaN 0.696469 3.637672 0.521001 0.521001 1.414238 0.783332 2.0 3 50 NaN 3.411414 2.371588 0.521001 0.521001 1.007945 0.659446 3.0 3 50 NaN 7.953236 2.072371 0.521001 0.521001 0.919839 0.665852 4.0 3 50 NaN 8.503696 1.937548 0.521001 0.521001 0.823425 0.636789 5.0 3 50 NaN 9.013576 1.871554 0.521001 0.521001 0.817610 0.630266 10.0 3 50 NaN 12.641237 1.761699 0.521001 0.521001 0.792941 0.700331 15.0 3 50 NaN 13.868945 1.729998 0.521001 0.521001 0.781636 0.720690 20.0 3 50 NaN 14.480582 1.708761 0.521001 0.521001 0.776870 0.728609 30.0 3 50 NaN 15.092759 1.687802 0.521001 0.521001 0.772400 0.736512 hsic 1.0 3 50 NaN 0.311456 3.637672 0.521001 0.521001 1.414238 0.021224 2.0 3 50 NaN 4.483172 2.371588 0.521001 0.521001 1.007945 0.018766 3.0 3 50 NaN 7.953236 2.072371 0.521001 0.521001 0.919839 0.018821 4.0 3 50 NaN 8.503696 1.937548 0.521001 0.521001 0.823425 0.018640 5.0 3 50 NaN 6.739547 1.871554 0.521001 0.521001 0.817610 0.018885 10.0 3 50 NaN 12.641237 1.761699 0.521001 0.521001 0.792941 0.018856 15.0 3 50 NaN 13.868945 1.729998 0.521001 0.521001 0.781636 0.018930 20.0 3 50 NaN 14.480582 1.708761 0.521001 0.521001 0.776870 0.018957 30.0 3 50 NaN 15.092759 1.687802 0.521001 0.521001 0.772400 0.018982 tka 1.0 3 50 NaN 0.000166 3.637672 0.521001 0.521001 1.414238 0.999635 2.0 3 50 NaN 0.000448 2.371588 0.521001 0.521001 1.007945 0.999753 3.0 3 50 NaN 0.000795 2.072371 0.521001 0.521001 0.919839 0.999907 4.0 3 50 NaN 0.000850 1.937548 0.521001 0.521001 0.823425 0.999460 5.0 3 50 NaN 0.000901 1.871554 0.521001 0.521001 0.817610 0.999566 10.0 3 50 NaN 0.001264 1.761699 0.521001 0.521001 0.792941 0.999915 15.0 3 50 NaN 0.001387 1.729998 0.521001 0.521001 0.781636 0.999941 20.0 3 50 NaN 0.001448 1.708761 0.521001 0.521001 0.776870 0.999949 30.0 3 50 NaN 0.001509 1.687802 0.521001 0.521001 0.772400 0.999956 t . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'nu' ]) . std () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } trial n_samples std gamma gamma_median gamma_silv gamma_scott gamma_belkin value dataset d_dimensions scorer nu tstudent 2 ctka 1.0 1.581139 0.0 NaN 0.961500 0.782348 0.0 0.0 0.371900 0.166620 2.0 1.581139 0.0 NaN 3.214027 0.304070 0.0 0.0 0.165151 0.050112 3.0 1.581139 0.0 NaN 1.950137 0.211945 0.0 0.0 0.140706 0.072745 4.0 1.581139 0.0 NaN 2.417514 0.172598 0.0 0.0 0.097211 0.046597 5.0 1.581139 0.0 NaN 2.490371 0.178211 0.0 0.0 0.096458 0.041736 10.0 1.581139 0.0 NaN 2.329043 0.139662 0.0 0.0 0.081018 0.044380 15.0 1.581139 0.0 NaN 2.218147 0.119495 0.0 0.0 0.072778 0.042949 20.0 1.581139 0.0 NaN 2.141577 0.111909 0.0 0.0 0.062929 0.041649 30.0 1.581139 0.0 NaN 2.040238 0.106456 0.0 0.0 0.056623 0.038702 hsic 1.0 1.581139 0.0 NaN 0.259527 0.782348 0.0 0.0 0.371900 0.004151 2.0 1.581139 0.0 NaN 1.872368 0.304070 0.0 0.0 0.165151 0.000259 3.0 1.581139 0.0 NaN 1.950137 0.211945 0.0 0.0 0.140706 0.000445 4.0 1.581139 0.0 NaN 2.417514 0.172598 0.0 0.0 0.097211 0.000505 5.0 1.581139 0.0 NaN 2.648875 0.178211 0.0 0.0 0.096458 0.000795 10.0 1.581139 0.0 NaN 2.329043 0.139662 0.0 0.0 0.081018 0.000337 15.0 1.581139 0.0 NaN 2.218147 0.119495 0.0 0.0 0.072778 0.000325 20.0 1.581139 0.0 NaN 2.141577 0.111909 0.0 0.0 0.062929 0.000315 30.0 1.581139 0.0 NaN 2.040238 0.106456 0.0 0.0 0.056623 0.000295 tka 1.0 1.581139 0.0 NaN 0.000181 0.782348 0.0 0.0 0.371900 0.000596 2.0 1.581139 0.0 NaN 0.000187 0.304070 0.0 0.0 0.165151 0.000179 3.0 1.581139 0.0 NaN 0.000195 0.211945 0.0 0.0 0.140706 0.000063 4.0 1.581139 0.0 NaN 0.000242 0.172598 0.0 0.0 0.097211 0.000904 5.0 1.581139 0.0 NaN 0.000249 0.178211 0.0 0.0 0.096458 0.000300 10.0 1.581139 0.0 NaN 0.000233 0.139662 0.0 0.0 0.081018 0.000033 15.0 1.581139 0.0 NaN 0.000222 0.119495 0.0 0.0 0.072778 0.000017 20.0 1.581139 0.0 NaN 0.000214 0.111909 0.0 0.0 0.062929 0.000012 30.0 1.581139 0.0 NaN 0.000204 0.106456 0.0 0.0 0.056623 0.000009","title":"4 visualize dimensions original"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions_original/#visualizing-hsic-measures","text":"import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # toy datasets from data.toy import generate_dependence_data # Kernel Dependency measure from models.dependence import HSIC from models.kernel import estimate_sigma , sigma_to_gamma , gamma_to_sigma , get_param_grid # RBIG IT measures from models.ite_algorithms import run_rbig_models import matplotlib import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 fig_path = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/\" save_path = f ' { cwd } /../../results/hsic/' save_name = 'dist_v2_belkin' cols = [ 'dataset' , 'trial' , 'n_samples' , 'd_dimensions' , 'nu' , 'std' , 'gamma' , 'gamma_median' , 'gamma_silv' , 'gamma_scott' , 'gamma_belkin' , 'scorer' , 'value' , 'mi_score' ] results_df = pd . read_csv ( f \" { save_path }{ save_name } .csv\" )[ cols ] results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial n_samples d_dimensions nu std gamma gamma_median gamma_silv gamma_scott gamma_belkin scorer value mi_score 7495 tstudent 5 5000 100 20.0 NaN 0.275053 11.709883 0.893117 0.921368 8.754526 tka 1.000000 8.098041 7496 tstudent 5 5000 100 20.0 NaN 0.275053 11.709883 0.893117 0.921368 8.754526 ctka 1.000000 8.098041 7497 tstudent 5 5000 100 30.0 NaN 0.005442 11.549000 0.893117 0.921368 8.718251 hsic 0.025679 7.993998 7498 tstudent 5 5000 100 30.0 NaN 0.281852 11.549000 0.893117 0.921368 8.718251 tka 1.000000 7.993998 7499 tstudent 5 5000 100 30.0 NaN 0.281852 11.549000 0.893117 0.921368 8.718251 ctka 1.000000 7.993998 res_samples = results_df [ 'n_samples' ] . unique () . tolist () res_dists = results_df [ 'dataset' ] . unique () . tolist () res_dimensions = results_df [ 'd_dimensions' ] . unique () . tolist () res_scorer = results_df [ 'scorer' ] . unique () . tolist ()","title":"Visualizing HSIC Measures"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions_original/#figure-i-gaussian-distribution","text":"results_gaussian = results_df [ results_df [ 'dataset' ] == 'gauss' ] results_gaussian . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial n_samples d_dimensions nu std gamma gamma_median gamma_silv gamma_scott gamma_belkin scorer value mi_score 4120 gauss 5 5000 100 NaN 0.9 0.285036 11.635845 0.893117 0.921368 9.328636 tka 1.000000 4.828360 4121 gauss 5 5000 100 NaN 0.9 0.285036 11.635845 0.893117 0.921368 9.328636 ctka 1.000000 4.828360 4122 gauss 5 5000 100 NaN 1.0 0.005679 11.299636 0.893117 0.921368 8.659846 hsic 0.026563 7.938746 4123 gauss 5 5000 100 NaN 1.0 0.294129 11.299636 0.893117 0.921368 8.659846 tka 1.000000 7.938746 4124 gauss 5 5000 100 NaN 1.0 0.294129 11.299636 0.893117 0.921368 8.659846 ctka 1.000000 7.938746","title":"Figure I - Gaussian Distribution"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions_original/#figure-i-t-student-distribution","text":"This first figure is to demonstrate how the mutual information compares with the amount of noise for each of the functions Linear , Sinusoidal , Circular , and Random . results_gaussian = results_df [ results_df [ 'dataset' ] == 'gauss' ] results_tstudent = results_df [ results_df [ 'dataset' ] == 'tstudent' ] results_tstudent . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial n_samples d_dimensions nu std gamma gamma_median gamma_silv gamma_scott gamma_belkin scorer value mi_score 4125 tstudent 1 50 2 1.0 NaN 0.244634 4.263675 0.521001 0.521001 1.915118 hsic 0.026925 0.302042 4126 tstudent 1 50 2 1.0 NaN 0.000193 4.263675 0.521001 0.521001 1.915118 tka 0.999865 0.302042 4127 tstudent 1 50 2 1.0 NaN 1.934087 4.263675 0.521001 0.521001 1.915118 ctka 0.630722 0.302042 4128 tstudent 1 50 2 2.0 NaN 4.484111 2.444370 0.521001 0.521001 1.049202 hsic 0.018855 0.136519 4129 tstudent 1 50 2 2.0 NaN 0.000448 2.444370 0.521001 0.521001 1.049202 tka 0.999888 0.136519","title":"Figure I - T-Student Distribution"},{"location":"notebooks/4_distributions/old/4_visualize_dimensions_original/#step-i-take-the-mean-wrt-the-experimental-parameters","text":"def average_trials ( res_df ): # Take the average of the trials cols = res_df . columns . tolist () # cols.remove('trial') # cols.remove('value') # cols.remove('gamma') return res_df . groupby ( cols ) . mean () . drop ( 'trial' , axis = 1 ) . reset_index () def variance_trials ( res_df ): # Take the average of the trials cols = res_df . columns . tolist () cols . remove ( 'trial' ) return res_df . groupby ( cols ) . std () . reset_index () . drop ( 'trial' , axis = 1 ) exp_vars = [ 'dataset' , 'trial' , 'n_samples' , 'd_dimensions' , 'nu' , 'std' , 'gamma' , 'gamma_median' , 'gamma_silv' , 'gamma_scott' , 'gamma_belkin' , 'scorer' , 'value' ] cols = results_tstudent . columns . tolist () # cols.remove('trial') # cols.remove('value') # cols.remove('gamma') res = average_trials ( results_tstudent ) res . head () --------------------------------------------------------------------------- DataError Traceback (most recent call last) <ipython-input-10-30ea35f40b59> in <module> 18 # cols.remove('value') 19 # cols.remove('gamma') ---> 20 res = average_trials ( results_tstudent ) 21 22 res . head ( ) <ipython-input-9-b503816a108f> in average_trials (res_df) 5 # cols.remove('value') 6 # cols.remove('gamma') ----> 7 return res_df . groupby ( cols ) . mean ( ) . drop ( 'trial' , axis = 1 ) . reset_index ( ) 8 9 def variance_trials ( res_df ) : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/groupby/groupby.py in mean (self, *args, **kwargs) 1203 try : 1204 return self._cython_agg_general( -> 1205 \"mean\" , alt = lambda x , axis : Series ( x ) . mean ( ** kwargs ) , ** kwargs 1206 ) 1207 except GroupByError : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/groupby/generic.py in _cython_agg_general (self, how, alt, numeric_only, min_count) 126 def _cython_agg_general ( self , how , alt = None , numeric_only = True , min_count = - 1 ) : 127 new_items, new_blocks = self._cython_agg_blocks( --> 128 how , alt = alt , numeric_only = numeric_only , min_count = min_count 129 ) 130 return self . _wrap_agged_blocks ( new_items , new_blocks ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/pandas/core/groupby/generic.py in _cython_agg_blocks (self, how, alt, numeric_only, min_count) 186 187 if len ( new_blocks ) == 0 : --> 188 raise DataError ( \"No numeric types to aggregate\" ) 189 190 # reset the locs in the blocks to correspond to our DataError : No numeric types to aggregate def plot_prepare ( res_df , dataset = 'gauss' ): # grab dataset attributes (fixed variables) d_dimensions = res_df [ 'd_dimensions' ] . unique () n_samples = res_df [ 'n_samples' ] . unique () dataset = res_df [ 'dataset' ] . unique () gamma_scott = res_df [ 'gamma_scott' ] . unique () gamma_silv = res_df [ 'gamma_silv' ] . unique () gamma_median = res_df [ 'gamma_median' ] . unique () gamma_belkin = res_df [ 'gamma_belkin' ] . unique () scorers = res_df [ 'scorer' ] . unique () . tolist () # print(gamma_median) # get fixed variables if dataset == 'gauss' : fixed_vars = { 'd_dimensions' : int ( d_dimensions ), 'n_samples' : int ( n_samples ), 'dataset' : dataset , 'scorer' : scorers , } elif dataset == 'tstudent' : fixed_vars = { 'd_dimensions' : int ( d_dimensions ), 'n_samples' : int ( n_samples ), 'dataset' : dataset , 'scorer' : scorers , } else : raise ValueError ( f 'Unrecognized distribution { dataset } ' ) return res_df , fixed_vars def plot_gauss ( res_df , fixed_vars , save = True ): for iscore in res_df . groupby ( 'scorer' ): # print(iscore[1].head()) mean_results = iscore [ 1 ] . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'std' ]) . median () std_results = iscore [ 1 ] . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'std' ]) . std () mean_results [ 'hsic_std' ] = std_results [ 'value' ] . values mean_results [ 'mi_std' ] = std_results [ 'mi_score' ] . values mean_results = mean_results . reset_index () # break # print(mean_results.head()) fig , ax = plt . subplots () pts = sns . scatterplot ( x = 'value' , y = 'mi_score' , data = mean_results , size = 'hsic_std' , sizes = ( 50 , 200 ), ax = ax , hue = 'gamma' , # hue_norm=matplotlib.colors.LogNorm(), label = iscore [ 0 ] . upper (), palette = 'Spectral' ) ax . legend ([ str ( iscore [ 0 ])]) ax . set_xlabel ( 'HSIC Value' ) ax . set_ylabel ( r 'Mutual Information' ) ax . set_title ( f \"D: { int ( fixed_vars [ 'd_dimensions' ]) } ,\" f \" N: { fixed_vars [ 'n_samples' ] } ,\" f \" { fixed_vars [ 'dataset' ][ 0 ] } \" ) # COLORBAR norm = matplotlib . colors . LogNorm ( mean_results . gamma . min (), mean_results . gamma . max ()) sm = plt . cm . ScalarMappable ( cmap = \"Spectral\" , norm = norm ) sm . set_array ([]) pts . figure . colorbar ( sm , label = r 'RBF Bandwidth, $\\gamma$' ) if not save : plt . show () else : save_name = \\ f \" { fixed_vars [ 'dataset' ][ 0 ] } _\" + \\ f \" { int ( fixed_vars [ 'n_samples' ]) } _\" + \\ f \" { int ( fixed_vars [ 'd_dimensions' ]) } _\" + \\ f \" { int ( fixed_vars [ 'std' ]) } _\" + \\ f \" { iscore [ 0 ] . upper () } \" + \\ \".png\" fig . savefig ( fig_path + save_name ) return None def plot_tstudent ( res_df , fixed_vars , save = True ): for iscore in res_df . groupby ( 'scorer' ): # print(iscore[1].head()) mean_results = iscore [ 1 ] . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'nu' ]) . median () std_results = iscore [ 1 ] . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'nu' ]) . std () mean_results [ 'hsic_std' ] = std_results [ 'value' ] . values mean_results [ 'mi_std' ] = std_results [ 'mi_score' ] . values mean_results = mean_results . reset_index () # break # print(mean_results.head()) fig , ax = plt . subplots () pts = sns . scatterplot ( x = 'value' , y = 'mi_score' , data = mean_results , size = 'hsic_std' , sizes = ( 50 , 200 ), ax = ax , hue = 'gamma' , # hue_norm=matplotlib.colors.LogNorm(), label = iscore [ 0 ] . upper (), palette = 'Spectral' ) ax . legend ([ str ( iscore [ 0 ])]) ax . set_xlabel ( 'HSIC Value' ) ax . set_ylabel ( r 'MI (nats)' ) ax . set_title ( f \"D: { int ( fixed_vars [ 'd_dimensions' ]) } ,\" f \" N: { fixed_vars [ 'n_samples' ] } ,\" f \" { fixed_vars [ 'dataset' ][ 0 ] } \" ) # COLORBAR norm = matplotlib . colors . LogNorm ( mean_results . gamma . min (), mean_results . gamma . max ()) sm = plt . cm . ScalarMappable ( cmap = \"Spectral\" , norm = norm ) sm . set_array ([]) pts . figure . colorbar ( sm , label = r 'RBF Bandwidth, $\\gamma$' ) if not save : plt . show () else : save_name = \\ f \" { fixed_vars [ 'dataset' ][ 0 ] } _\" + \\ f \" { int ( fixed_vars [ 'n_samples' ]) } _\" + \\ f \" { int ( fixed_vars [ 'd_dimensions' ]) } _\" + \\ f \" { int ( fixed_vars [ 'nu' ]) } _\" + \\ f \" { iscore [ 0 ] . upper () } \" + \\ \".png\" fig . savefig ( fig_path + save_name ) return None plot_groups = [ 'dataset' , 'n_samples' , 'd_dimensions' , 'dataset' , ] subres = results_tstudent . groupby ( plot_groups ) for igroup in subres : igroup , fixed_vars = plot_prepare ( igroup [ 1 ]) t = igroup plot_tstudent ( igroup , fixed_vars , save = False ) break plot_groups = [ 'dataset' , 'n_samples' , 'd_dimensions' , 'dataset' , ] subres = results_gaussian . groupby ( plot_groups ) for igroup in subres : igroup , fixed_vars = plot_prepare ( igroup [ 1 ]) t = igroup plot_gauss ( igroup , fixed_vars , save = False ) break for igroup in subres : igroup , fixed_vars = plot_prepare ( igroup [ 1 ]) t = igroup plot_tstudent ( igroup , fixed_vars , save = False ) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> --------------------------------------------------------------------------- ValueError Traceback (most recent call last) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2054 orientation = orientation , 2055 dryrun = True , -> 2056 **kwargs) 2057 renderer = self . figure . _cachedRenderer 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png (self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs) 525 526 else : --> 527 FigureCanvasAgg . draw ( self ) 528 renderer = self . get_renderer ( ) 529 with cbook . _setattr_cm ( renderer , dpi = self . figure . dpi ) , \\ ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw (self) 386 self . renderer = self . get_renderer ( cleared = True ) 387 with RendererAgg . lock : --> 388 self . figure . draw ( self . renderer ) 389 # A GUI class may be need to update a window using this draw, so 390 # don't forget to call the superclass. ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/figure.py in draw (self, renderer) 1707 self . patch . draw ( renderer ) 1708 mimage._draw_list_compositing_images( -> 1709 renderer, self, artists, self.suppressComposite) 1710 1711 renderer . close_group ( 'figure' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/axes/_base.py in draw (self, renderer, inframe) 2645 renderer . stop_rasterizing ( ) 2646 -> 2647 mimage . _draw_list_compositing_images ( renderer , self , artists ) 2648 2649 renderer . close_group ( 'axes' ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images (renderer, parent, artists, suppress_composite) 133 if not_composite or not has_images : 134 for a in artists : --> 135 a . draw ( renderer ) 136 else : 137 # Composite any adjacent images together ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper (artist, renderer, *args, **kwargs) 36 renderer . start_filter ( ) 37 ---> 38 return draw ( artist , renderer , * args , ** kwargs ) 39 finally : 40 if artist . get_agg_filter ( ) is not None : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in draw (self, renderer) 2015 offsets = np . column_stack ( [ xs , ys ] ) 2016 -> 2017 self . update_scalarmappable ( ) 2018 2019 if not transform . is_affine : ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/collections.py in update_scalarmappable (self) 761 return 762 if self . _is_filled : --> 763 self . _facecolors = self . to_rgba ( self . _A , self . _alpha ) 764 elif self . _is_stroked : 765 self . _edgecolors = self . to_rgba ( self . _A , self . _alpha ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/cm.py in to_rgba (self, x, alpha, bytes, norm) 287 x = ma . asarray ( x ) 288 if norm : --> 289 x = self . norm ( x ) 290 rgba = self . cmap ( x , alpha = alpha , bytes = bytes ) 291 return rgba ~/.conda/envs/it4dnn/lib/python3.6/site-packages/matplotlib/colors.py in __call__ (self, value, clip) 1094 raise ValueError ( \"minvalue must be less than or equal to maxvalue\" ) 1095 elif vmin <= 0 : -> 1096 raise ValueError ( \"values must all be positive\" ) 1097 elif vmin == vmax : 1098 result . fill ( 0 ) ValueError : values must all be positive <Figure size 432x288 with 2 Axes> plot_groups = [ 'dataset' , 'n_samples' , 'd_dimensions' , 'dataset' , ] subres = results_tstudent . groupby ( plot_groups ) np . linspace ( 1 , 100 , 5 ) array([ 1. , 25.75, 50.5 , 75.25, 100. ]) fixed_vars . keys () dict_keys(['d_dimensions', 'n_samples', 'dataset', 'scorer']) t . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'nu' ]) . mean () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } trial n_samples std gamma gamma_median gamma_silv gamma_scott gamma_belkin value dataset d_dimensions scorer nu tstudent 2 ctka 1.0 3 50 NaN 0.696469 3.637672 0.521001 0.521001 1.414238 0.783332 2.0 3 50 NaN 3.411414 2.371588 0.521001 0.521001 1.007945 0.659446 3.0 3 50 NaN 7.953236 2.072371 0.521001 0.521001 0.919839 0.665852 4.0 3 50 NaN 8.503696 1.937548 0.521001 0.521001 0.823425 0.636789 5.0 3 50 NaN 9.013576 1.871554 0.521001 0.521001 0.817610 0.630266 10.0 3 50 NaN 12.641237 1.761699 0.521001 0.521001 0.792941 0.700331 15.0 3 50 NaN 13.868945 1.729998 0.521001 0.521001 0.781636 0.720690 20.0 3 50 NaN 14.480582 1.708761 0.521001 0.521001 0.776870 0.728609 30.0 3 50 NaN 15.092759 1.687802 0.521001 0.521001 0.772400 0.736512 hsic 1.0 3 50 NaN 0.311456 3.637672 0.521001 0.521001 1.414238 0.021224 2.0 3 50 NaN 4.483172 2.371588 0.521001 0.521001 1.007945 0.018766 3.0 3 50 NaN 7.953236 2.072371 0.521001 0.521001 0.919839 0.018821 4.0 3 50 NaN 8.503696 1.937548 0.521001 0.521001 0.823425 0.018640 5.0 3 50 NaN 6.739547 1.871554 0.521001 0.521001 0.817610 0.018885 10.0 3 50 NaN 12.641237 1.761699 0.521001 0.521001 0.792941 0.018856 15.0 3 50 NaN 13.868945 1.729998 0.521001 0.521001 0.781636 0.018930 20.0 3 50 NaN 14.480582 1.708761 0.521001 0.521001 0.776870 0.018957 30.0 3 50 NaN 15.092759 1.687802 0.521001 0.521001 0.772400 0.018982 tka 1.0 3 50 NaN 0.000166 3.637672 0.521001 0.521001 1.414238 0.999635 2.0 3 50 NaN 0.000448 2.371588 0.521001 0.521001 1.007945 0.999753 3.0 3 50 NaN 0.000795 2.072371 0.521001 0.521001 0.919839 0.999907 4.0 3 50 NaN 0.000850 1.937548 0.521001 0.521001 0.823425 0.999460 5.0 3 50 NaN 0.000901 1.871554 0.521001 0.521001 0.817610 0.999566 10.0 3 50 NaN 0.001264 1.761699 0.521001 0.521001 0.792941 0.999915 15.0 3 50 NaN 0.001387 1.729998 0.521001 0.521001 0.781636 0.999941 20.0 3 50 NaN 0.001448 1.708761 0.521001 0.521001 0.776870 0.999949 30.0 3 50 NaN 0.001509 1.687802 0.521001 0.521001 0.772400 0.999956 t . groupby ([ 'dataset' , 'd_dimensions' , 'scorer' , 'nu' ]) . std () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } trial n_samples std gamma gamma_median gamma_silv gamma_scott gamma_belkin value dataset d_dimensions scorer nu tstudent 2 ctka 1.0 1.581139 0.0 NaN 0.961500 0.782348 0.0 0.0 0.371900 0.166620 2.0 1.581139 0.0 NaN 3.214027 0.304070 0.0 0.0 0.165151 0.050112 3.0 1.581139 0.0 NaN 1.950137 0.211945 0.0 0.0 0.140706 0.072745 4.0 1.581139 0.0 NaN 2.417514 0.172598 0.0 0.0 0.097211 0.046597 5.0 1.581139 0.0 NaN 2.490371 0.178211 0.0 0.0 0.096458 0.041736 10.0 1.581139 0.0 NaN 2.329043 0.139662 0.0 0.0 0.081018 0.044380 15.0 1.581139 0.0 NaN 2.218147 0.119495 0.0 0.0 0.072778 0.042949 20.0 1.581139 0.0 NaN 2.141577 0.111909 0.0 0.0 0.062929 0.041649 30.0 1.581139 0.0 NaN 2.040238 0.106456 0.0 0.0 0.056623 0.038702 hsic 1.0 1.581139 0.0 NaN 0.259527 0.782348 0.0 0.0 0.371900 0.004151 2.0 1.581139 0.0 NaN 1.872368 0.304070 0.0 0.0 0.165151 0.000259 3.0 1.581139 0.0 NaN 1.950137 0.211945 0.0 0.0 0.140706 0.000445 4.0 1.581139 0.0 NaN 2.417514 0.172598 0.0 0.0 0.097211 0.000505 5.0 1.581139 0.0 NaN 2.648875 0.178211 0.0 0.0 0.096458 0.000795 10.0 1.581139 0.0 NaN 2.329043 0.139662 0.0 0.0 0.081018 0.000337 15.0 1.581139 0.0 NaN 2.218147 0.119495 0.0 0.0 0.072778 0.000325 20.0 1.581139 0.0 NaN 2.141577 0.111909 0.0 0.0 0.062929 0.000315 30.0 1.581139 0.0 NaN 2.040238 0.106456 0.0 0.0 0.056623 0.000295 tka 1.0 1.581139 0.0 NaN 0.000181 0.782348 0.0 0.0 0.371900 0.000596 2.0 1.581139 0.0 NaN 0.000187 0.304070 0.0 0.0 0.165151 0.000179 3.0 1.581139 0.0 NaN 0.000195 0.211945 0.0 0.0 0.140706 0.000063 4.0 1.581139 0.0 NaN 0.000242 0.172598 0.0 0.0 0.097211 0.000904 5.0 1.581139 0.0 NaN 0.000249 0.178211 0.0 0.0 0.096458 0.000300 10.0 1.581139 0.0 NaN 0.000233 0.139662 0.0 0.0 0.081018 0.000033 15.0 1.581139 0.0 NaN 0.000222 0.119495 0.0 0.0 0.072778 0.000017 20.0 1.581139 0.0 NaN 0.000214 0.111909 0.0 0.0 0.062929 0.000012 30.0 1.581139 0.0 NaN 0.000204 0.106456 0.0 0.0 0.056623 0.000009","title":"Step I - Take the mean wrt the experimental parameters"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Code Review I - Different Sigma Scales \u00b6 This notebook features all of the functions necessary to estimate different length scales. We will look at 2 methods and break this review into two parts: The sigma estimator (scott, silverman, median, mean) The configuration (same length scales, separate length scales, one length scale per dimension) import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import numpy as np import pandas as pd from functools import partial # toy datasets from data.distribution import DataParams , Inputs # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-paper' ]) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) Part I - Estimate Sigma \u00b6 For this first part, we will need to look at how we estimate sigma. I will use the following methods: Silverman Scot Mean Median Data \u00b6 For this review, we will be using the distribution loader and we will take the T-Student distribution. We will look at 2 dimensions with 100 samples. Helper Functions \u00b6 2D Scatter Plot with Marginal distributions as histograms def plot_2d_data ( X ): fig = plt . figure () g = sns . jointplot ( x = X [:, 0 ], y = X [:, 1 ], ) plt . tight_layout () plt . show () def plot_1d_data ( X ): fig , ax = plt . subplots () ax . hist ( X ) We initialize a DataParameters namedtuple . It contains all of the parameters we need to generate our dataset. I chose a namedTuple because it is immutable so it won't be overwritten once we've called it within our functions. It also has a method to actually provide the data given the parameters, generate_data . # initialize the data generator dist_data = DataParams ( dataset = 'tstudent' , trial = 1 , std = 2 , nu = 7 , samples = 500 , dimensions = 2 ) inputs = dist_data . generate_data () # Plot the Distribution plot_1d_data ( inputs . X [:, 0 ]) plot_1d_data ( inputs . X [:, 1 ]) As we can see, these are clearly two different distributions and we would like to see how the different estimators work. Estimator I - Scotts Method \u00b6 \\text{scott} = N^{- \\frac{1}{D + 4}} \\text{scott} = N^{- \\frac{1}{D + 4}} where N N is the number of samples and D D is the number of data points. Source : Scipy Website According to the formula, we aren't actually calculating anything to do with the distance. So we will get the same value for both datasets. This is easy to calculate in numpy. def scotts_factor ( X : np . ndarray ) -> float : \"\"\"Scotts Method to estimate the length scale of the rbf kernel. factor = n**(-1./(d+4)) Parameters ---------- X : np.ndarry Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape return np . power ( n_samples , - 1 / ( n_features + 4. )) sigmas = {} sigmas [ 'scott' ] = ( scotts_factor ( inputs . X [:, 0 ][:, None ]), scotts_factor ( inputs . Y [:, 0 ][:, None ]) ) # check same value assert sigmas [ 'scott' ][ 0 ] == sigmas [ 'scott' ][ 1 ] print ( sigmas [ 'scott' ]) (0.2885399811814427, 0.2885399811814427) Estimator II - Silverman \u00b6 This is a slight different interpretation but very similar. $$ \\text{silverman} = \\left( \\frac{N * (D+2)}{4} \\right)^{- \\frac{1}{D + 4}} $$ def silvermans_factor ( X : np . ndarray ) -> float : \"\"\"Silvermans method used to estimate the length scale of the rbf kernel. factor = (n * (d + 2) / 4.)**(-1. / (d + 4)). Parameters ---------- X : np.ndarray, Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape base = ( n_samples * ( n_features + 2. ) ) / 4. return np . power ( base , - 1 / ( n_features + 4. )) sigmas = {} sigmas [ 'silverman' ] = ( silvermans_factor ( inputs . X [:, 0 ][:, None ]), silvermans_factor ( inputs . Y [:, 0 ][:, None ]) ) # check same value assert sigmas [ 'silverman' ][ 0 ] == sigmas [ 'silverman' ][ 1 ] print ( sigmas [ 'silverman' ]) (0.30562842716315974, 0.30562842716315974) Method III - Mean/Median Distance Heuristic \u00b6 The heuristic is the 'mean distance between the points of the domain'. The full formula is: \\nu = \\sqrt{\\frac{H_n}{2}} \\nu = \\sqrt{\\frac{H_n}{2}} where H_n = \\text{Med}\\left\\{ ||X_{n,i} - X_{n,j}||^2 | 1 \\leq i < j \\leq n \\right\\} H_n = \\text{Med}\\left\\{ ||X_{n,i} - X_{n,j}||^2 | 1 \\leq i < j \\leq n \\right\\} and \\text{Med} \\text{Med} is the empirical median. We can also use the Mean as well. We can obtain this by: Calculating the squareform euclidean distance of all points in our dataset Order them in increasing order Set H_n H_n to be the central element if n(n-1)/2 n(n-1)/2 is odd or the mean if n(n-1)/2 n(n-1)/2 is even. Note : some authors just use \\sqrt{H_n} \\sqrt{H_n} . Source : Large Sample Analysis of the Median Heuristic - Garreau et al. (2018) - PDF In particular, look at equation 2. They talk about how to find the heuristic as well as some asymptoptic properties. The Mean and Median Criterion for Automatic Kernel Bandwidth Selection for Support Vector Data Description - Chaudhuri et. al. (2017) - arxiv In other papers, they have defined others but I have yet to see too many people actually exploring the space of solutions. It's mostly swept under the rug. For our example, I have done the simple calculation of using squared euclidean distances. from scipy.spatial.distance import pdist , squareform # get the squared euclidean distances dists = np . sort ( pdist ( inputs . X [:, 0 ][:, None ], 'sqeuclidean' )) xs = np . linspace ( 0 , 1 , len ( dists )) fig , ax = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax [ 0 ] . plot ( dists ) # ax[0].plot(np.sort(dists.ravel())) bins = np . logspace ( np . log10 ( 1e-1 ), np . log10 ( 1e2 )) ax [ 1 ] . hist ( dists , bins = bins , range = ( 0 , 20 )) # ================ # Median Distance # ================ med_dist = np . median ( dists ) # Plot on graph idx = np . argwhere ( dists < med_dist )[ - 1 ] point = dists [ dists < med_dist ][ - 1 ] ax [ 0 ] . scatter ( idx , point , marker = '.' , s = 500 , color = 'black' , label = 'Median Distance' ) ax [ 1 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'black' , linestyle = 'dashed' , label = 'Median Distance' ) # ================ # Median Heuristic # ================ heuristic = np . sqrt ( med_dist / 2 ) idx = np . argwhere ( dists < heuristic )[ - 1 ] point = dists [ dists < heuristic ][ - 1 ] print ( med_dist , heuristic ) ax [ 0 ] . scatter ( idx , point , marker = 'x' , s = 300 , color = 'blue' , label = r 'Median Heuristic, $\\sqrt{\\frac{D^2} {2} }$' ) ax [ 1 ] . axvline ( heuristic , linewidth = 2 , zorder = 3 , color = 'blue' , linestyle = 'dashed' , label = 'Median Heuristic' ) # ================ # Mean Distance # ================ mean_dist = np . mean ( dists ) # Plot on graph idx = np . argwhere ( dists < mean_dist )[ - 1 ] point = dists [ dists < mean_dist ][ - 1 ] ax [ 0 ] . scatter ( idx , point , marker = '.' , s = 500 , color = 'red' , label = 'Mean Distance' ) ax [ 1 ] . axvline ( mean_dist , linewidth = 2 , zorder = 3 , color = 'red' , linestyle = 'dashed' , label = 'Mean Distance' ) # ================ # Mean Heuristic # ================ heuristic = np . sqrt ( mean_dist / 2 ) # Plot on graph idx = np . argwhere ( dists < heuristic )[ - 1 ] point = dists [ dists < heuristic ][ - 1 ] ax [ 0 ] . scatter ( idx , point , marker = 'x' , s = 300 , color = 'orange' , label = r 'Mean Heuristic, $\\sqrt{\\frac{D^2} {2} }$' ) ax [ 1 ] . axvline ( heuristic , linewidth = 2 , zorder = 3 , color = 'orange' , linestyle = 'dashed' , label = 'Mean Heuristic' ) ax [ 0 ] . set_yscale ( 'log' ) ax [ 1 ] . set_xscale ( 'log' ) ax [ 0 ] . legend ( fontsize = 12 ) ax [ 1 ] . legend ( fontsize = 12 ) 0.8120777689523777 0.6372118050351774 <matplotlib.legend.Legend at 0x7fa42064a550> Method III - Inherited Distance Measure \u00b6 This is a distance measure that is new to me. It is the median/mean of the distances to the k-th k-th neighbour of the dataset. So essentially, we take Calculate the squareform of the matrix Sort the matrix in ascending order Take the kth distance Take the median or mean of this columns def kth_distance ( dists : np . ndarray , percent : float ) -> np . ndarray : # kth distance calculation (50%) kth_sample = int ( percent * dists . shape [ 0 ]) # take the Kth neighbours of that distance k_dist = dists [:, kth_sample ] return k_dist # get the sorted square form of the squared euclidean distances dists1 = np . sort ( squareform ( pdist ( inputs . X [:, 0 ][:, None ], 'sqeuclidean' ))) dists2 = np . sort ( squareform ( pdist ( inputs . X [:, 1 ][:, None ], 'sqeuclidean' ))) # check the shape assert dists1 . shape [ 0 ] == inputs . X [:, 0 ] . shape [ 0 ] # np.testing.assert_array_almost_equal(dists, dists2) # kth distance calculation (50%) kth_sample = int ( 0.5 * dists1 . shape [ 0 ]) # take the Kth neighbour of that distance k_dist1 = dists1 [:, kth_sample ] k_dist2 = dists2 [:, kth_sample ] # take the mean or median distance median_dist1 = np . median ( k_dist1 ) median_dist2 = np . median ( k_dist2 ) Demo - Different K Distances \u00b6 fig , ax = plt . subplots ( nrows = 2 , ncols = 1 , figsize = ( 5 , 10 )) # ax[0].plot(np.sort(dists.ravel())) bins = np . logspace ( np . log10 ( 1e-2 ), np . log10 ( 1e3 )) ax [ 0 ] . hist ( dists1 . ravel (), bins = bins , density = True ) ax [ 1 ] . hist ( dists2 . ravel (), bins = bins , density = True ) # ============================== # Median Distance (50% Samples) # ============================== percent = 0.50 med_dist = np . median ( kth_distance ( dists1 , percent )) label = f \"50% Samples, { med_dist : .2f } \" ax [ 0 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'black' , linestyle = 'dashed' , label = label ) percent = 0.50 med_dist = np . median ( kth_distance ( dists2 , percent )) label = f \"50% Samples, { med_dist : .2f } \" ax [ 1 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'black' , linestyle = 'dashed' , label = label ) # ============================== # Median Distance (20% Samples) # ============================== percent = 0.20 med_dist = np . median ( kth_distance ( dists1 , percent )) label = f \"20% Samples, { med_dist : .2f } \" ax [ 0 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'blue' , linestyle = 'dashed' , label = label ) percent = 0.20 med_dist = np . median ( kth_distance ( dists2 , percent )) label = f \"20% Samples, { med_dist : .2f } \" ax [ 1 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'blue' , linestyle = 'dashed' , label = label ) # ============================== # Median Distance (80% Samples) # ============================== percent = 0.80 med_dist = np . median ( kth_distance ( dists1 , percent )) label = f \"80% Samples, { med_dist : .2f } \" ax [ 0 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'red' , linestyle = 'dashed' , label = label ) percent = 0.80 med_dist = np . median ( kth_distance ( dists2 , percent )) label = f \"80% Samples, { med_dist : .2f } \" ax [ 1 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'red' , linestyle = 'dashed' , label = label ) # ============================== # Median Distance (15% Samples) # ============================== percent = 0.15 med_dist = np . median ( kth_distance ( dists1 , percent )) label = f \"15% Samples, { med_dist : .2f } \" ax [ 0 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'orange' , linestyle = 'dashed' , label = label ) percent = 0.15 med_dist = np . median ( kth_distance ( dists2 , percent )) label = f \"15% Samples, { med_dist : .2f } \" ax [ 1 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'orange' , linestyle = 'dashed' , label = label ) ax [ 0 ] . set_xscale ( 'log' ) ax [ 1 ] . set_xscale ( 'log' ) ax [ 0 ] . legend ( fontsize = 12 ) ax [ 1 ] . legend ( fontsize = 12 ) <matplotlib.legend.Legend at 0x7fa420121fd0> Part II - Different Sigma Configurations \u00b6 So now, we will look at the different ways we can calculate the sigma values. The options are: 1 Sigma Value for both \\sigma_{XY} \\sigma_{XY} 1 Sigma Value per dataset \\sigma_X, \\sigma_Y \\sigma_X, \\sigma_Y 1 Sigma Value per dataset per dimension \\sigma_{X_d}, \\sigma_{Y_d} \\sigma_{X_d}, \\sigma_{Y_d} def sigma_estimate ( X : np . ndarray , method : str = 'scott' ): if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" ) Data \u00b6 We will revist the distribution except now we will look at the joint plot. # initialize the data generator dist_data = DataParams ( dataset = 'tstudent' , trial = 1 , std = 2 , nu = 7 , samples = 500 , dimensions = 2 ) inputs = dist_data . generate_data () # Plot the Distribution plot_2d_data ( inputs . X ) <Figure size 460.8x316.8 with 0 Axes> Scott n Silverman \u00b6 # scotts method sigmas = {} # 1 sigma per dataset sigma_x = sigma_estimate ( inputs . X , 'scott' ) sigma_y = sigma_estimate ( inputs . Y , 'scott' ) print ( f \"Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) # 1 sigma for both sigma_xy = np . mean ([ sigma_x , sigma_y ]) print ( f \"Sigma Same (XY): { sigma_xy : .4f } \" ) # 1 sigma per dimensions sigma_x = [ sigma_estimate ( ix . reshape ( - 1 , 1 ), 'scott' ) for ix in inputs . X . T ] sigma_y = [ sigma_estimate ( iy . reshape ( - 1 , 1 ), 'scott' ) for iy in inputs . Y . T ] print ( f \"Sigma Per Dimension (X,Y): \\n { sigma_x } , \\n { sigma_y } \" ) Sigma Per (X,Y): 0.3550,0.3550 Sigma Same (XY): 0.3550 Sigma Per Dimension (X,Y): [0.2885399811814427, 0.2885399811814427], [0.2885399811814427, 0.2885399811814427] This makes sense as we get the same \\sigma \\sigma value for both X,Y X,Y because they don't take into consideration any aspects of the individual datasets. Only the number of samples and dimensions. There is a difference between per dimension because we have changed the dimension parameter, but there is no difference between datasets. We expect to see the same thing for silverman # silvermans method # 1 sigma per dataset sigma_x = sigma_estimate ( inputs . X , 'silverman' ) sigma_y = sigma_estimate ( inputs . Y , 'silverman' ) print ( f \"Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) # 1 sigma for both sigma_xy = np . mean ([ sigma_x , sigma_y ]) print ( f \"Sigma Same (XY): { sigma_xy : .4f } \" ) # 1 sigma per dimensions sigma_x = [ sigma_estimate ( ix . reshape ( - 1 , 1 ), 'silverman' ) for ix in inputs . X . T ] sigma_y = [ sigma_estimate ( iy . reshape ( - 1 , 1 ), 'silverman' ) for iy in inputs . Y . T ] print ( f \"Sigma Per Dimension (X,Y): \\n { sigma_x } , \\n { sigma_y } \" ) Sigma Per (X,Y): 0.3550,0.3550 Sigma Same (XY): 0.3550 Sigma Per Dimension (X,Y): [0.30562842716315974, 0.30562842716315974], [0.30562842716315974, 0.30562842716315974] So the pattern is the same as scott: there are different values if we change the number of input dimensions, but we get the same values across datasets with the same number of samples and dimensions. Note : it looks a little fishy that the \\sigma_{XY} \\sigma_{XY} is the same for Scott and Silverman. But that's because in 2D, the measures are equivalent because the base factor of \\frac{N(D+2)}{4} \\frac{N(D+2)}{4} is equal to N N if D=2 D=2 . The exponent is the same for both estimators. Example in 3 dimensions: # initialize the data generator dist_data = DataParams ( dataset = 'tstudent' , trial = 1 , std = 2 , nu = 7 , samples = 500 , dimensions = 3 ) temp_input = dist_data . generate_data () # 1 sigma per dataset sigma_x = sigma_estimate ( temp_input . X , 'scott' ) sigma_y = sigma_estimate ( temp_input . Y , 'scott' ) print ( f \"Scott - Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) # 1 sigma per dataset sigma_x = sigma_estimate ( temp_input . X , 'silverman' ) sigma_y = sigma_estimate ( temp_input . Y , 'silverman' ) print ( f \"Silverman - Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) Scott - Sigma Per (X,Y): 0.4116,0.4116 Silverman - Sigma Per (X,Y): 0.3986,0.3986 We see that they are different. Median, Mean Heuristic \u00b6 So now I'm going to update my function so that we have the option to add the median and mean heuristic. def sigma_estimate ( X : np . ndarray , method : str = 'median' , heuristic : bool = False ): # get the squared euclidean distances if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) else : dists = np . sort ( pdist ( X , 'sqeuclidean' )) if method == 'median' : sigma = np . median ( dists ) elif method == 'mean' : sigma = np . mean ( dists ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" ) if heuristic : sigma = np . sqrt ( sigma / 2 ) return sigma # 1 sigma per dataset sigma_x = sigma_estimate ( inputs . X , 'mean' ) sigma_y = sigma_estimate ( inputs . Y , 'mean' ) print ( f \"Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) # 1 sigma for both sigma_xy = np . mean ([ sigma_x , sigma_y ]) print ( f \"Sigma Same (XY): { sigma_xy : .4f } \" ) # 1 sigma per dimensions sigma_x = [ sigma_estimate ( ix . reshape ( - 1 , 1 ), 'mean' ) for ix in inputs . X . T ] sigma_y = [ sigma_estimate ( iy . reshape ( - 1 , 1 ), 'mean' ) for iy in inputs . Y . T ] print ( f \"Sigma Per Dimension (X,Y): \\n { sigma_x } , \\n { sigma_y } \" ) Sigma Per (X,Y): 4.0080,4.0080 Sigma Same (XY): 4.0080 Sigma Per Dimension (X,Y): [2.004008016032065, 2.004008016032064], [2.0040080160320635, 2.0040080160320644] # 1 sigma per dataset sigma_x = sigma_estimate ( inputs . X , 'median' ) sigma_y = sigma_estimate ( inputs . Y , 'median' ) print ( f \"Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) # 1 sigma for both sigma_xy = np . mean ([ sigma_x , sigma_y ]) print ( f \"Sigma Same (XY): { sigma_xy : .4f } \" ) # 1 sigma per dimensions sigma_x = [ sigma_estimate ( ix . reshape ( - 1 , 1 ), 'median' ) for ix in inputs . X . T ] sigma_y = [ sigma_estimate ( iy . reshape ( - 1 , 1 ), 'median' ) for iy in inputs . Y . T ] print ( f \"Sigma Per Dimension (X,Y): \\n { sigma_x } , \\n { sigma_y } \" ) Sigma Per (X,Y): 2.5684,2.7045 Sigma Same (XY): 2.6364 Sigma Per Dimension (X,Y): [0.8120777689523777, 0.854339231759148], [0.90660872358859, 0.8619837864110205] So we see that the median distance does distinguish been the dimensions where as the mean does not. So if we want some differences, it might be worth it to go with the median as a heuristic.. Median - Kth Distance \u00b6 from typing import Optional def sigma_estimate ( X : np . ndarray , method : str = 'median' , percent : Optional [ int ] = None , heuristic : bool = False ) -> float : # get the squared euclidean distances if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) elif percent is not None : kth_sample = int (( percent / 100 ) * X . shape [ 0 ]) dists = np . sort ( squareform ( pdist ( X , 'sqeuclidean' )))[:, kth_sample ] # print(dists.shape, dists.min(), dists.max()) else : dists = np . sort ( pdist ( X , 'sqeuclidean' )) # print(dists.shape, dists.min(), dists.max()) if method == 'median' : sigma = np . median ( dists ) elif method == 'mean' : sigma = np . mean ( dists ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" ) if heuristic : sigma = np . sqrt ( sigma / 2 ) return sigma percentages = [ 15 , 20 , 50 , 80 ] results_df = pd . DataFrame () for ipercent in percentages : print ( f \" { ipercent } % Samples\" ) # 1 sigma per dataset sigma_x = sigma_estimate ( inputs . X , 'mean' , ipercent ) sigma_y = sigma_estimate ( inputs . Y , 'mean' , ipercent ) # 1 sigma for both sigma_xy = np . mean ([ sigma_x , sigma_y ]) # 1 sigma per dimensions sigma_x_d = [ sigma_estimate ( ix . reshape ( - 1 , 1 ), 'mean' , ipercent ) for ix in inputs . X . T ] sigma_y_d = [ sigma_estimate ( iy . reshape ( - 1 , 1 ), 'mean' , ipercent ) for iy in inputs . Y . T ] results_df = results_df . append ({ 'percent' : ipercent , 'sigma_xy' : sigma_xy , 'sigma_x' : sigma_x , 'sigma_y' : sigma_y , 'sigma_xd' : sigma_x_d , 'sigma_yd' : sigma_y_d , }, ignore_index = True ) 15% Samples 20% Samples 50% Samples 80% Samples results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } percent sigma_x sigma_xd sigma_xy sigma_y sigma_yd 0 15.0 1.020389 [0.24642895567240075, 0.23416783817803644] 1.017655 1.014922 [0.20299456942386293, 0.24035251603377777] 1 20.0 1.300021 [0.3523831447752424, 0.33390768867246945] 1.293269 1.286516 [0.3235887727904833, 0.3303919311440132] 2 50.0 3.074741 [1.2359792869486763, 1.2295046539405399] 3.089403 3.104064 [1.2550121778882104, 1.2382606065547748] 3 80.0 6.042370 [3.1447792239531553, 3.2164324641215707] 6.144976 6.247582 [3.2078125520953207, 3.147628845075649] And again, we get different values of that median estimate based on the 'knn' distance. And it changes depending upon the dimension as well.","title":"1.0 estimate sigma"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#code-review-i-different-sigma-scales","text":"This notebook features all of the functions necessary to estimate different length scales. We will look at 2 methods and break this review into two parts: The sigma estimator (scott, silverman, median, mean) The configuration (same length scales, separate length scales, one length scale per dimension) import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import numpy as np import pandas as pd from functools import partial # toy datasets from data.distribution import DataParams , Inputs # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-paper' ]) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path )","title":"Code Review I - Different Sigma Scales"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#part-i-estimate-sigma","text":"For this first part, we will need to look at how we estimate sigma. I will use the following methods: Silverman Scot Mean Median","title":"Part I - Estimate Sigma"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#data","text":"For this review, we will be using the distribution loader and we will take the T-Student distribution. We will look at 2 dimensions with 100 samples.","title":"Data"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#helper-functions","text":"2D Scatter Plot with Marginal distributions as histograms def plot_2d_data ( X ): fig = plt . figure () g = sns . jointplot ( x = X [:, 0 ], y = X [:, 1 ], ) plt . tight_layout () plt . show () def plot_1d_data ( X ): fig , ax = plt . subplots () ax . hist ( X ) We initialize a DataParameters namedtuple . It contains all of the parameters we need to generate our dataset. I chose a namedTuple because it is immutable so it won't be overwritten once we've called it within our functions. It also has a method to actually provide the data given the parameters, generate_data . # initialize the data generator dist_data = DataParams ( dataset = 'tstudent' , trial = 1 , std = 2 , nu = 7 , samples = 500 , dimensions = 2 ) inputs = dist_data . generate_data () # Plot the Distribution plot_1d_data ( inputs . X [:, 0 ]) plot_1d_data ( inputs . X [:, 1 ]) As we can see, these are clearly two different distributions and we would like to see how the different estimators work.","title":"Helper Functions"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#estimator-i-scotts-method","text":"\\text{scott} = N^{- \\frac{1}{D + 4}} \\text{scott} = N^{- \\frac{1}{D + 4}} where N N is the number of samples and D D is the number of data points. Source : Scipy Website According to the formula, we aren't actually calculating anything to do with the distance. So we will get the same value for both datasets. This is easy to calculate in numpy. def scotts_factor ( X : np . ndarray ) -> float : \"\"\"Scotts Method to estimate the length scale of the rbf kernel. factor = n**(-1./(d+4)) Parameters ---------- X : np.ndarry Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape return np . power ( n_samples , - 1 / ( n_features + 4. )) sigmas = {} sigmas [ 'scott' ] = ( scotts_factor ( inputs . X [:, 0 ][:, None ]), scotts_factor ( inputs . Y [:, 0 ][:, None ]) ) # check same value assert sigmas [ 'scott' ][ 0 ] == sigmas [ 'scott' ][ 1 ] print ( sigmas [ 'scott' ]) (0.2885399811814427, 0.2885399811814427)","title":"Estimator I - Scotts Method"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#estimator-ii-silverman","text":"This is a slight different interpretation but very similar. $$ \\text{silverman} = \\left( \\frac{N * (D+2)}{4} \\right)^{- \\frac{1}{D + 4}} $$ def silvermans_factor ( X : np . ndarray ) -> float : \"\"\"Silvermans method used to estimate the length scale of the rbf kernel. factor = (n * (d + 2) / 4.)**(-1. / (d + 4)). Parameters ---------- X : np.ndarray, Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape base = ( n_samples * ( n_features + 2. ) ) / 4. return np . power ( base , - 1 / ( n_features + 4. )) sigmas = {} sigmas [ 'silverman' ] = ( silvermans_factor ( inputs . X [:, 0 ][:, None ]), silvermans_factor ( inputs . Y [:, 0 ][:, None ]) ) # check same value assert sigmas [ 'silverman' ][ 0 ] == sigmas [ 'silverman' ][ 1 ] print ( sigmas [ 'silverman' ]) (0.30562842716315974, 0.30562842716315974)","title":"Estimator II - Silverman"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#method-iii-meanmedian-distance-heuristic","text":"The heuristic is the 'mean distance between the points of the domain'. The full formula is: \\nu = \\sqrt{\\frac{H_n}{2}} \\nu = \\sqrt{\\frac{H_n}{2}} where H_n = \\text{Med}\\left\\{ ||X_{n,i} - X_{n,j}||^2 | 1 \\leq i < j \\leq n \\right\\} H_n = \\text{Med}\\left\\{ ||X_{n,i} - X_{n,j}||^2 | 1 \\leq i < j \\leq n \\right\\} and \\text{Med} \\text{Med} is the empirical median. We can also use the Mean as well. We can obtain this by: Calculating the squareform euclidean distance of all points in our dataset Order them in increasing order Set H_n H_n to be the central element if n(n-1)/2 n(n-1)/2 is odd or the mean if n(n-1)/2 n(n-1)/2 is even. Note : some authors just use \\sqrt{H_n} \\sqrt{H_n} . Source : Large Sample Analysis of the Median Heuristic - Garreau et al. (2018) - PDF In particular, look at equation 2. They talk about how to find the heuristic as well as some asymptoptic properties. The Mean and Median Criterion for Automatic Kernel Bandwidth Selection for Support Vector Data Description - Chaudhuri et. al. (2017) - arxiv In other papers, they have defined others but I have yet to see too many people actually exploring the space of solutions. It's mostly swept under the rug. For our example, I have done the simple calculation of using squared euclidean distances. from scipy.spatial.distance import pdist , squareform # get the squared euclidean distances dists = np . sort ( pdist ( inputs . X [:, 0 ][:, None ], 'sqeuclidean' )) xs = np . linspace ( 0 , 1 , len ( dists )) fig , ax = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax [ 0 ] . plot ( dists ) # ax[0].plot(np.sort(dists.ravel())) bins = np . logspace ( np . log10 ( 1e-1 ), np . log10 ( 1e2 )) ax [ 1 ] . hist ( dists , bins = bins , range = ( 0 , 20 )) # ================ # Median Distance # ================ med_dist = np . median ( dists ) # Plot on graph idx = np . argwhere ( dists < med_dist )[ - 1 ] point = dists [ dists < med_dist ][ - 1 ] ax [ 0 ] . scatter ( idx , point , marker = '.' , s = 500 , color = 'black' , label = 'Median Distance' ) ax [ 1 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'black' , linestyle = 'dashed' , label = 'Median Distance' ) # ================ # Median Heuristic # ================ heuristic = np . sqrt ( med_dist / 2 ) idx = np . argwhere ( dists < heuristic )[ - 1 ] point = dists [ dists < heuristic ][ - 1 ] print ( med_dist , heuristic ) ax [ 0 ] . scatter ( idx , point , marker = 'x' , s = 300 , color = 'blue' , label = r 'Median Heuristic, $\\sqrt{\\frac{D^2} {2} }$' ) ax [ 1 ] . axvline ( heuristic , linewidth = 2 , zorder = 3 , color = 'blue' , linestyle = 'dashed' , label = 'Median Heuristic' ) # ================ # Mean Distance # ================ mean_dist = np . mean ( dists ) # Plot on graph idx = np . argwhere ( dists < mean_dist )[ - 1 ] point = dists [ dists < mean_dist ][ - 1 ] ax [ 0 ] . scatter ( idx , point , marker = '.' , s = 500 , color = 'red' , label = 'Mean Distance' ) ax [ 1 ] . axvline ( mean_dist , linewidth = 2 , zorder = 3 , color = 'red' , linestyle = 'dashed' , label = 'Mean Distance' ) # ================ # Mean Heuristic # ================ heuristic = np . sqrt ( mean_dist / 2 ) # Plot on graph idx = np . argwhere ( dists < heuristic )[ - 1 ] point = dists [ dists < heuristic ][ - 1 ] ax [ 0 ] . scatter ( idx , point , marker = 'x' , s = 300 , color = 'orange' , label = r 'Mean Heuristic, $\\sqrt{\\frac{D^2} {2} }$' ) ax [ 1 ] . axvline ( heuristic , linewidth = 2 , zorder = 3 , color = 'orange' , linestyle = 'dashed' , label = 'Mean Heuristic' ) ax [ 0 ] . set_yscale ( 'log' ) ax [ 1 ] . set_xscale ( 'log' ) ax [ 0 ] . legend ( fontsize = 12 ) ax [ 1 ] . legend ( fontsize = 12 ) 0.8120777689523777 0.6372118050351774 <matplotlib.legend.Legend at 0x7fa42064a550>","title":"Method III - Mean/Median Distance Heuristic"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#method-iii-inherited-distance-measure","text":"This is a distance measure that is new to me. It is the median/mean of the distances to the k-th k-th neighbour of the dataset. So essentially, we take Calculate the squareform of the matrix Sort the matrix in ascending order Take the kth distance Take the median or mean of this columns def kth_distance ( dists : np . ndarray , percent : float ) -> np . ndarray : # kth distance calculation (50%) kth_sample = int ( percent * dists . shape [ 0 ]) # take the Kth neighbours of that distance k_dist = dists [:, kth_sample ] return k_dist # get the sorted square form of the squared euclidean distances dists1 = np . sort ( squareform ( pdist ( inputs . X [:, 0 ][:, None ], 'sqeuclidean' ))) dists2 = np . sort ( squareform ( pdist ( inputs . X [:, 1 ][:, None ], 'sqeuclidean' ))) # check the shape assert dists1 . shape [ 0 ] == inputs . X [:, 0 ] . shape [ 0 ] # np.testing.assert_array_almost_equal(dists, dists2) # kth distance calculation (50%) kth_sample = int ( 0.5 * dists1 . shape [ 0 ]) # take the Kth neighbour of that distance k_dist1 = dists1 [:, kth_sample ] k_dist2 = dists2 [:, kth_sample ] # take the mean or median distance median_dist1 = np . median ( k_dist1 ) median_dist2 = np . median ( k_dist2 )","title":"Method III - Inherited Distance Measure"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#demo-different-k-distances","text":"fig , ax = plt . subplots ( nrows = 2 , ncols = 1 , figsize = ( 5 , 10 )) # ax[0].plot(np.sort(dists.ravel())) bins = np . logspace ( np . log10 ( 1e-2 ), np . log10 ( 1e3 )) ax [ 0 ] . hist ( dists1 . ravel (), bins = bins , density = True ) ax [ 1 ] . hist ( dists2 . ravel (), bins = bins , density = True ) # ============================== # Median Distance (50% Samples) # ============================== percent = 0.50 med_dist = np . median ( kth_distance ( dists1 , percent )) label = f \"50% Samples, { med_dist : .2f } \" ax [ 0 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'black' , linestyle = 'dashed' , label = label ) percent = 0.50 med_dist = np . median ( kth_distance ( dists2 , percent )) label = f \"50% Samples, { med_dist : .2f } \" ax [ 1 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'black' , linestyle = 'dashed' , label = label ) # ============================== # Median Distance (20% Samples) # ============================== percent = 0.20 med_dist = np . median ( kth_distance ( dists1 , percent )) label = f \"20% Samples, { med_dist : .2f } \" ax [ 0 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'blue' , linestyle = 'dashed' , label = label ) percent = 0.20 med_dist = np . median ( kth_distance ( dists2 , percent )) label = f \"20% Samples, { med_dist : .2f } \" ax [ 1 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'blue' , linestyle = 'dashed' , label = label ) # ============================== # Median Distance (80% Samples) # ============================== percent = 0.80 med_dist = np . median ( kth_distance ( dists1 , percent )) label = f \"80% Samples, { med_dist : .2f } \" ax [ 0 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'red' , linestyle = 'dashed' , label = label ) percent = 0.80 med_dist = np . median ( kth_distance ( dists2 , percent )) label = f \"80% Samples, { med_dist : .2f } \" ax [ 1 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'red' , linestyle = 'dashed' , label = label ) # ============================== # Median Distance (15% Samples) # ============================== percent = 0.15 med_dist = np . median ( kth_distance ( dists1 , percent )) label = f \"15% Samples, { med_dist : .2f } \" ax [ 0 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'orange' , linestyle = 'dashed' , label = label ) percent = 0.15 med_dist = np . median ( kth_distance ( dists2 , percent )) label = f \"15% Samples, { med_dist : .2f } \" ax [ 1 ] . axvline ( med_dist , linewidth = 2 , zorder = 3 , color = 'orange' , linestyle = 'dashed' , label = label ) ax [ 0 ] . set_xscale ( 'log' ) ax [ 1 ] . set_xscale ( 'log' ) ax [ 0 ] . legend ( fontsize = 12 ) ax [ 1 ] . legend ( fontsize = 12 ) <matplotlib.legend.Legend at 0x7fa420121fd0>","title":"Demo - Different K Distances"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#part-ii-different-sigma-configurations","text":"So now, we will look at the different ways we can calculate the sigma values. The options are: 1 Sigma Value for both \\sigma_{XY} \\sigma_{XY} 1 Sigma Value per dataset \\sigma_X, \\sigma_Y \\sigma_X, \\sigma_Y 1 Sigma Value per dataset per dimension \\sigma_{X_d}, \\sigma_{Y_d} \\sigma_{X_d}, \\sigma_{Y_d} def sigma_estimate ( X : np . ndarray , method : str = 'scott' ): if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" )","title":"Part II - Different Sigma Configurations"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#data_1","text":"We will revist the distribution except now we will look at the joint plot. # initialize the data generator dist_data = DataParams ( dataset = 'tstudent' , trial = 1 , std = 2 , nu = 7 , samples = 500 , dimensions = 2 ) inputs = dist_data . generate_data () # Plot the Distribution plot_2d_data ( inputs . X ) <Figure size 460.8x316.8 with 0 Axes>","title":"Data"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#scott-n-silverman","text":"# scotts method sigmas = {} # 1 sigma per dataset sigma_x = sigma_estimate ( inputs . X , 'scott' ) sigma_y = sigma_estimate ( inputs . Y , 'scott' ) print ( f \"Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) # 1 sigma for both sigma_xy = np . mean ([ sigma_x , sigma_y ]) print ( f \"Sigma Same (XY): { sigma_xy : .4f } \" ) # 1 sigma per dimensions sigma_x = [ sigma_estimate ( ix . reshape ( - 1 , 1 ), 'scott' ) for ix in inputs . X . T ] sigma_y = [ sigma_estimate ( iy . reshape ( - 1 , 1 ), 'scott' ) for iy in inputs . Y . T ] print ( f \"Sigma Per Dimension (X,Y): \\n { sigma_x } , \\n { sigma_y } \" ) Sigma Per (X,Y): 0.3550,0.3550 Sigma Same (XY): 0.3550 Sigma Per Dimension (X,Y): [0.2885399811814427, 0.2885399811814427], [0.2885399811814427, 0.2885399811814427] This makes sense as we get the same \\sigma \\sigma value for both X,Y X,Y because they don't take into consideration any aspects of the individual datasets. Only the number of samples and dimensions. There is a difference between per dimension because we have changed the dimension parameter, but there is no difference between datasets. We expect to see the same thing for silverman # silvermans method # 1 sigma per dataset sigma_x = sigma_estimate ( inputs . X , 'silverman' ) sigma_y = sigma_estimate ( inputs . Y , 'silverman' ) print ( f \"Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) # 1 sigma for both sigma_xy = np . mean ([ sigma_x , sigma_y ]) print ( f \"Sigma Same (XY): { sigma_xy : .4f } \" ) # 1 sigma per dimensions sigma_x = [ sigma_estimate ( ix . reshape ( - 1 , 1 ), 'silverman' ) for ix in inputs . X . T ] sigma_y = [ sigma_estimate ( iy . reshape ( - 1 , 1 ), 'silverman' ) for iy in inputs . Y . T ] print ( f \"Sigma Per Dimension (X,Y): \\n { sigma_x } , \\n { sigma_y } \" ) Sigma Per (X,Y): 0.3550,0.3550 Sigma Same (XY): 0.3550 Sigma Per Dimension (X,Y): [0.30562842716315974, 0.30562842716315974], [0.30562842716315974, 0.30562842716315974] So the pattern is the same as scott: there are different values if we change the number of input dimensions, but we get the same values across datasets with the same number of samples and dimensions. Note : it looks a little fishy that the \\sigma_{XY} \\sigma_{XY} is the same for Scott and Silverman. But that's because in 2D, the measures are equivalent because the base factor of \\frac{N(D+2)}{4} \\frac{N(D+2)}{4} is equal to N N if D=2 D=2 . The exponent is the same for both estimators. Example in 3 dimensions: # initialize the data generator dist_data = DataParams ( dataset = 'tstudent' , trial = 1 , std = 2 , nu = 7 , samples = 500 , dimensions = 3 ) temp_input = dist_data . generate_data () # 1 sigma per dataset sigma_x = sigma_estimate ( temp_input . X , 'scott' ) sigma_y = sigma_estimate ( temp_input . Y , 'scott' ) print ( f \"Scott - Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) # 1 sigma per dataset sigma_x = sigma_estimate ( temp_input . X , 'silverman' ) sigma_y = sigma_estimate ( temp_input . Y , 'silverman' ) print ( f \"Silverman - Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) Scott - Sigma Per (X,Y): 0.4116,0.4116 Silverman - Sigma Per (X,Y): 0.3986,0.3986 We see that they are different.","title":"Scott n Silverman"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#median-mean-heuristic","text":"So now I'm going to update my function so that we have the option to add the median and mean heuristic. def sigma_estimate ( X : np . ndarray , method : str = 'median' , heuristic : bool = False ): # get the squared euclidean distances if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) else : dists = np . sort ( pdist ( X , 'sqeuclidean' )) if method == 'median' : sigma = np . median ( dists ) elif method == 'mean' : sigma = np . mean ( dists ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" ) if heuristic : sigma = np . sqrt ( sigma / 2 ) return sigma # 1 sigma per dataset sigma_x = sigma_estimate ( inputs . X , 'mean' ) sigma_y = sigma_estimate ( inputs . Y , 'mean' ) print ( f \"Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) # 1 sigma for both sigma_xy = np . mean ([ sigma_x , sigma_y ]) print ( f \"Sigma Same (XY): { sigma_xy : .4f } \" ) # 1 sigma per dimensions sigma_x = [ sigma_estimate ( ix . reshape ( - 1 , 1 ), 'mean' ) for ix in inputs . X . T ] sigma_y = [ sigma_estimate ( iy . reshape ( - 1 , 1 ), 'mean' ) for iy in inputs . Y . T ] print ( f \"Sigma Per Dimension (X,Y): \\n { sigma_x } , \\n { sigma_y } \" ) Sigma Per (X,Y): 4.0080,4.0080 Sigma Same (XY): 4.0080 Sigma Per Dimension (X,Y): [2.004008016032065, 2.004008016032064], [2.0040080160320635, 2.0040080160320644] # 1 sigma per dataset sigma_x = sigma_estimate ( inputs . X , 'median' ) sigma_y = sigma_estimate ( inputs . Y , 'median' ) print ( f \"Sigma Per (X,Y): { sigma_x : .4f } , { sigma_y : .4f } \" ) # 1 sigma for both sigma_xy = np . mean ([ sigma_x , sigma_y ]) print ( f \"Sigma Same (XY): { sigma_xy : .4f } \" ) # 1 sigma per dimensions sigma_x = [ sigma_estimate ( ix . reshape ( - 1 , 1 ), 'median' ) for ix in inputs . X . T ] sigma_y = [ sigma_estimate ( iy . reshape ( - 1 , 1 ), 'median' ) for iy in inputs . Y . T ] print ( f \"Sigma Per Dimension (X,Y): \\n { sigma_x } , \\n { sigma_y } \" ) Sigma Per (X,Y): 2.5684,2.7045 Sigma Same (XY): 2.6364 Sigma Per Dimension (X,Y): [0.8120777689523777, 0.854339231759148], [0.90660872358859, 0.8619837864110205] So we see that the median distance does distinguish been the dimensions where as the mean does not. So if we want some differences, it might be worth it to go with the median as a heuristic..","title":"Median, Mean Heuristic"},{"location":"notebooks/code_reviews/1.0_estimate_sigma/#median-kth-distance","text":"from typing import Optional def sigma_estimate ( X : np . ndarray , method : str = 'median' , percent : Optional [ int ] = None , heuristic : bool = False ) -> float : # get the squared euclidean distances if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) elif percent is not None : kth_sample = int (( percent / 100 ) * X . shape [ 0 ]) dists = np . sort ( squareform ( pdist ( X , 'sqeuclidean' )))[:, kth_sample ] # print(dists.shape, dists.min(), dists.max()) else : dists = np . sort ( pdist ( X , 'sqeuclidean' )) # print(dists.shape, dists.min(), dists.max()) if method == 'median' : sigma = np . median ( dists ) elif method == 'mean' : sigma = np . mean ( dists ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" ) if heuristic : sigma = np . sqrt ( sigma / 2 ) return sigma percentages = [ 15 , 20 , 50 , 80 ] results_df = pd . DataFrame () for ipercent in percentages : print ( f \" { ipercent } % Samples\" ) # 1 sigma per dataset sigma_x = sigma_estimate ( inputs . X , 'mean' , ipercent ) sigma_y = sigma_estimate ( inputs . Y , 'mean' , ipercent ) # 1 sigma for both sigma_xy = np . mean ([ sigma_x , sigma_y ]) # 1 sigma per dimensions sigma_x_d = [ sigma_estimate ( ix . reshape ( - 1 , 1 ), 'mean' , ipercent ) for ix in inputs . X . T ] sigma_y_d = [ sigma_estimate ( iy . reshape ( - 1 , 1 ), 'mean' , ipercent ) for iy in inputs . Y . T ] results_df = results_df . append ({ 'percent' : ipercent , 'sigma_xy' : sigma_xy , 'sigma_x' : sigma_x , 'sigma_y' : sigma_y , 'sigma_xd' : sigma_x_d , 'sigma_yd' : sigma_y_d , }, ignore_index = True ) 15% Samples 20% Samples 50% Samples 80% Samples results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } percent sigma_x sigma_xd sigma_xy sigma_y sigma_yd 0 15.0 1.020389 [0.24642895567240075, 0.23416783817803644] 1.017655 1.014922 [0.20299456942386293, 0.24035251603377777] 1 20.0 1.300021 [0.3523831447752424, 0.33390768867246945] 1.293269 1.286516 [0.3235887727904833, 0.3303919311440132] 2 50.0 3.074741 [1.2359792869486763, 1.2295046539405399] 3.089403 3.104064 [1.2550121778882104, 1.2382606065547748] 3 80.0 6.042370 [3.1447792239531553, 3.2164324641215707] 6.144976 6.247582 [3.2078125520953207, 3.147628845075649] And again, we get different values of that median estimate based on the 'knn' distance. And it changes depending upon the dimension as well.","title":"Median - Kth Distance"},{"location":"notebooks/code_reviews/2.0_estimate_hsic/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Code Review II - Estimate HSIC \u00b6 This notebook features all of the functions necessary to estimate HSIC given different sigma estimation methods. We will look at the 3 methods: HSIC (centered kernel, unnormalized) Centered Kernel Alignment (CKA) (centered kernel, normalized) Kernel Alignment (KA) (uncentered kernel, unnormalized) And we will also look at how we calculate the kernel matrix: 1 RBF Kernel for both K_{XY} K_{XY} 1 RBF Kernel per datasets, K_X, K_Y K_X, K_Y 1 ARD Kernel per dataset, K_{X_d}, K_{Y_d} K_{X_d}, K_{Y_d} (an RBF kernel with a lengths scale per dimensions) import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import numpy as np import pandas as pd from functools import partial # toy datasets from data.distribution import DataParams , Inputs # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-paper' ]) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) Data \u00b6 def plot_2d_data ( X ): fig = plt . figure () g = sns . jointplot ( x = X [:, 0 ], y = X [:, 1 ], ) plt . tight_layout () plt . show () def plot_1d_data ( X ): fig , ax = plt . subplots () ax . hist ( X ) # initialize the data generator dist_data = DataParams ( dataset = 'tstudent' , trial = 1 , std = 2 , nu = 7 , samples = 500 , dimensions = 2 ) inputs = dist_data . generate_data () # Plot the Distribution plot_1d_data ( inputs . X [:, 0 ]) plot_1d_data ( inputs . X [:, 1 ]) Estimate Sigma \u00b6 I'll be using the same function that I developed in the last notebook which had the following methods available: from typing import Optional from scipy.spatial.distance import pdist , squareform def scotts_factor ( X : np . ndarray ) -> float : \"\"\"Scotts Method to estimate the length scale of the rbf kernel. factor = n**(-1./(d+4)) Parameters ---------- X : np.ndarry Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape return np . power ( n_samples , - 1 / ( n_features + 4. )) def silvermans_factor ( X : np . ndarray ) -> float : \"\"\"Silvermans method used to estimate the length scale of the rbf kernel. factor = (n * (d + 2) / 4.)**(-1. / (d + 4)). Parameters ---------- X : np.ndarray, Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape base = ( n_samples * ( n_features + 2. ) ) / 4. return np . power ( base , - 1 / ( n_features + 4. )) def kth_distance ( dists : np . ndarray , percent : float ) -> np . ndarray : # kth distance calculation (50%) kth_sample = int ( percent * dists . shape [ 0 ]) # take the Kth neighbours of that distance k_dist = dists [:, kth_sample ] return k_dist def sigma_estimate ( X : np . ndarray , method : str = 'median' , percent : Optional [ int ] = None , heuristic : bool = False ) -> float : # get the squared euclidean distances if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) elif percent is not None : kth_sample = int (( percent / 100 ) * X . shape [ 0 ]) dists = np . sort ( squareform ( pdist ( X , 'sqeuclidean' )))[:, kth_sample ] # print(dists.shape, dists.min(), dists.max()) else : dists = np . sort ( pdist ( X , 'sqeuclidean' )) # print(dists.shape, dists.min(), dists.max()) if method == 'median' : sigma = np . median ( dists ) elif method == 'mean' : sigma = np . mean ( dists ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" ) if heuristic : sigma = np . sqrt ( sigma / 2 ) return sigma RBF Kernel Matrix \u00b6 We define the generalized RBF kernel like so: K(\\mathbf{x,y}) = \\exp\\left(-\\frac{1}{2}\\left|\\left|\\frac{\\mathbf{x}}{\\sigma} - \\frac{\\mathbf{y}}{\\sigma}\\right|\\right|^2_2\\right) K(\\mathbf{x,y}) = \\exp\\left(-\\frac{1}{2}\\left|\\left|\\frac{\\mathbf{x}}{\\sigma} - \\frac{\\mathbf{y}}{\\sigma}\\right|\\right|^2_2\\right) where \\mathbf{x,y} \\in \\mathbb{R}^{D} \\mathbf{x,y} \\in \\mathbb{R}^{D} and \\sigma \\sigma can be either \\in \\mathbb{R} \\in \\mathbb{R} or \\in \\mathbb{R}^{D} \\in \\mathbb{R}^{D} . From scratch \u00b6 To calculate this from scratch efficiently, we can do the following: Divide each vector by the length scale We can divide each vector \\mathbf{x,y} \\mathbf{x,y} by the lengths scale \\sigma \\sigma before calculating the euclidean distance. Case I: \\sigma \\in \\mathbb{R} \\sigma \\in \\mathbb{R} - it will broadcast the vector across the samples and features, e.g. \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{1} = \\frac{N \\times D}{N \\times D} \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{1} = \\frac{N \\times D}{N \\times D} Case II: \\sigma \\in \\mathbb{R}^{D} \\sigma \\in \\mathbb{R}^{D} - it will broadcast the vector across the samples, e.g. \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{1 \\times D} = \\frac{N \\times D}{N \\times D} \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{1 \\times D} = \\frac{N \\times D}{N \\times D} Case III: \\sigma \\in \\mathbb{R}^{N} \\sigma \\in \\mathbb{R}^{N} - it will broadcast the vector across the features, e.g. \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{N \\times 1} = \\frac{N \\times D}{N \\times D} \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{N \\times 1} = \\frac{N \\times D}{N \\times D} So we can reuse the same code no matter which \\sigma \\sigma we give it. Any other case or size \\sigma \\sigma wil through up an error. # 0. Estimate sigma sigma_x = sigma_estimate ( inputs . X , method = 'median' , percent = None , heuristic = False ) sigma_y = sigma_estimate ( inputs . Y , method = 'median' , percent = None , heuristic = False ) sigma_xy = np . mean ([ sigma_x , sigma_y ]) # 1. Divide each vector by the length scale X_scaled = inputs . X / sigma_x 2. Calculate the squared euclidean distance between two the two vectors # 2. euclidean distance from sklearn.metrics.pairwise import euclidean_distances from scipy.spatial.distance import cdist dist = euclidean_distances ( X_scaled , X_scaled , squared = True ) dist_ = cdist ( X_scaled , X_scaled , metric = 'sqeuclidean' ) np . testing . assert_array_almost_equal ( dist , dist_ ) 3. Exponentiate the distances # 2. Exponential Kernel K_xy = np . exp ( - 0.5 * dist ) print ( K_xy . min (), K_xy . max ()) plt . imshow ( K_xy ) plt . colorbar () 0.006274266046377698 1.0 <matplotlib.colorbar.Colorbar at 0x7fc65009b1f0> Refactor \u00b6 Fortunately, there are people smarter than me and they already have a function that does the exact same thing. from sklearn.gaussian_process.kernels import RBF K_sk = RBF ( sigma_x )( inputs . X , inputs . X ) plt . imshow ( K_sk ) plt . colorbar () # check that they're the same np . testing . assert_array_almost_equal ( K_xy , K_sk ) Side Note - The Original Formula \u00b6 Most people write down this distance formula: K(\\mathbf{x,y}) = \\exp\\left(-\\frac{\\left|\\left|\\mathbf{x} - \\mathbf{y}\\right|\\right|^2_2}{2\\sigma^2}\\right) K(\\mathbf{x,y}) = \\exp\\left(-\\frac{\\left|\\left|\\mathbf{x} - \\mathbf{y}\\right|\\right|^2_2}{2\\sigma^2}\\right) This is equivalent to the formula I did above: $$ K(\\mathbf{x,y}) =\\exp\\left(-\\frac{\\left|\\left|\\mathbf{x} - \\mathbf{y}\\right|\\right| 2_2}{2\\sigma 2}\\right) = \\exp\\left(-\\left|\\left|\\frac{\\mathbf{x}}{\\sigma} - \\frac{\\mathbf{y}}{\\sigma}\\right|\\right|^2_2\\right) $$ # original # 1. Divide each vector by the length scale X_1d = inputs . X [:, 0 ] . reshape ( - 1 , 1 ) dist = euclidean_distances ( X_1d , X_1d , squared = True ) # 2. Exponential Kernel K_xy = np . exp ( - dist / ( 2 * sigma_x ** 2 )) # quicker K_sk = RBF ( sigma_x )( X_1d , X_1d ) np . testing . assert_array_almost_equal ( K_xy , K_sk ) Calculating HSIC \u00b6 Calculating HSIC is quite simple. Compute each kernel, K_x, K_y K_x, K_y Center the Kernel Matrix (or not) Compute the Trace Normalize or not # kernel matrices K_x = RBF ( sigma_x )( inputs . X ) K_y = RBF ( sigma_y )( inputs . Y ) # center the kernel matrices from sklearn.preprocessing import KernelCenterer K_xc = KernelCenterer () . fit_transform ( K_x ) K_yc = KernelCenterer () . fit_transform ( K_y ) # Compute the Trace hsic_score = np . sum ( K_xc * K_yc ) print ( 'HSIC:' , ( 1 / K_xc . shape [ 0 ] ** 2 ) * hsic_score ) # normalize by the norm cka_score = hsic_score / np . linalg . norm ( K_xc , ord = 'fro' ) / np . linalg . norm ( K_yc , ord = 'fro' ) print ( 'CKA:' , cka_score ) # Kernel Alignment, no centering ka_score = np . sum ( K_x * K_y ) / np . linalg . norm ( K_x , ord = 'fro' ) / np . linalg . norm ( K_y , ord = 'fro' ) print ( 'KA:' , ka_score ) HSIC: 0.0002787777096594028 CKA: 0.01807799077138073 KA: 0.9543875481010973 Refactor \u00b6 I already created a more complete function. from models.dependence import HSICModel hsic_clf = HSICModel ( kernel_X = RBF ( sigma_x ), kernel_Y = RBF ( sigma_y ), ) # hsic score hsic_score_ = hsic_clf . get_score ( inputs . X , inputs . Y , 'hsic' ) print ( 'HSIC:' , hsic_score_ ) # cka score cka_score_ = hsic_clf . get_score ( inputs . X , inputs . Y , 'cka' ) print ( 'HSIC:' , cka_score_ ) # ka score ka_score_ = hsic_clf . get_score ( inputs . X , inputs . Y , 'ka' ) print ( 'HSIC:' , ka_score_ ) HSIC: 0.0002787777096594028 HSIC: 0.01807799077138073 HSIC: 0.9543875481010973 Notice how the scores are all the same. Different Sigma Configurations \u00b6 So now, let's see how the scores change depending on how we estimate the sigma parameter. We're going to use a combination of the following scenarios: HSIC Scorer - HSIC, KA, CKA Estimator - Scott, Silverman, Median, Mean, Median Kth (15% samples) Sigma Config - Single, Per Dataset, Per Dataset+Dimension So let's gather all parameter combinations. parameters = { 'scorer' : [ 'hsic' , 'cka' , 'ka' ], 'estimator' : [ ( 'median' , 15 ), ( 'scott' , None ), ( 'silverman' , None ), ( 'median' , None ), ( 'mean' , None ), ], 'per_dataset' : [ True , False ], 'per_dimension' : [ True , False ] } And we're going to take the cartesian product so that we get all possible combinations. I have a dedicated function for that. from experiments.utils import dict_product , run_parallel_step # create a list of all param combinations parameters_list = list ( dict_product ( parameters )) n_params = len ( parameters_list ) print ( '# of Params:' , n_params ) # of Params: 60 So we have 60 combinations to look through just from this set of parameters. Now, let's create a look and go through all of the combinations. results = list () for iparams in parameters_list : # 0. Estimate sigma f_x = lambda x : sigma_estimate ( x , method = iparams [ 'estimator' ][ 0 ], percent = iparams [ 'estimator' ][ 1 ], heuristic = False ) # ======================== # Per Dimension # ======================== if iparams [ 'per_dimension' ]: sigma_X = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . X . T ] sigma_Y = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . Y . T ] else : sigma_X = f_x ( inputs . X ) sigma_Y = f_x ( inputs . Y ) # ========================= # Per Dataset # ========================= if not iparams [ 'per_dataset' ]: sigma_X = np . mean ([ sigma_X , sigma_Y ]) sigma_Y = np . copy ( sigma_X ) # ========================= # Estimate HSIC # ========================= hsic_clf = HSICModel ( kernel_X = RBF ( sigma_X ), kernel_Y = RBF ( sigma_Y ), ) score = hsic_clf . get_score ( inputs . X , inputs . Y , iparams [ 'scorer' ]) # Save Data results . append ( pd . DataFrame ({ 'score' : [ score ], 'scorer' : [ iparams [ 'scorer' ]], 'estimator' : [ iparams [ 'estimator' ]], 'sigma_Y' : [ sigma_Y ], 'sigma_X' : [ sigma_X ], 'per_dimension' : [ iparams [ 'per_dimension' ]], 'per_dataset' : [ iparams [ 'per_dataset' ]], })) results_df = pd . concat ( results ) results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } score scorer estimator sigma_Y sigma_X per_dimension per_dataset 0 0.001993 hsic (median, 15) [0.05111714688849182, 0.051362071720277146] [0.04721265098560398, 0.0582261233599152] True True 0 0.001777 hsic (median, 15) 0.618971 0.566652 False True 0 0.001993 hsic (median, 15) 0.051979498238572036 0.0519795 True False 0 0.001768 hsic (median, 15) 0.5928113701712288 0.592811 False False 0 0.001885 hsic (scott, None) [0.2885399811814427, 0.2885399811814427] [0.2885399811814427, 0.2885399811814427] True True 0 0.001836 hsic (scott, None) 0.354954 0.354954 False True 0 0.001885 hsic (scott, None) 0.2885399811814427 0.28854 True False 0 0.001836 hsic (scott, None) 0.35495366597555705 0.354954 False False 0 0.001871 hsic (silverman, None) [0.30562842716315974, 0.30562842716315974] [0.30562842716315974, 0.30562842716315974] True True 0 0.001836 hsic (silverman, None) 0.354954 0.354954 False True 0 0.001871 hsic (silverman, None) 0.30562842716315974 0.305628 True False 0 0.001836 hsic (silverman, None) 0.35495366597555705 0.354954 False False 0 0.001690 hsic (median, None) [0.90660872358859, 0.8619837864110205] [0.8120777689523777, 0.854339231759148] True True 0 0.000279 hsic (median, None) 2.70446 2.56843 False True 0 0.001686 hsic (median, None) 0.8587523776777841 0.858752 True False 0 0.000280 hsic (median, None) 2.636443482285435 2.63644 False False 0 0.000603 hsic (mean, None) [2.0040080160320635, 2.0040080160320644] [2.004008016032065, 2.004008016032064] True True 0 0.000066 hsic (mean, None) 4.00802 4.00802 False True 0 0.000603 hsic (mean, None) 2.0040080160320644 2.00401 True False 0 0.000066 hsic (mean, None) 4.008016032064129 4.00802 False False 0 0.736922 cka (median, 15) [0.05111714688849182, 0.051362071720277146] [0.04721265098560398, 0.0582261233599152] True True 0 0.035560 cka (median, 15) 0.618971 0.566652 False True 0 0.737589 cka (median, 15) 0.051979498238572036 0.0519795 True False 0 0.035332 cka (median, 15) 0.5928113701712288 0.592811 False False 0 0.091317 cka (scott, None) [0.2885399811814427, 0.2885399811814427] [0.2885399811814427, 0.2885399811814427] True True 0 0.065822 cka (scott, None) 0.354954 0.354954 False True 0 0.091317 cka (scott, None) 0.2885399811814427 0.28854 True False 0 0.065822 cka (scott, None) 0.35495366597555705 0.354954 False False 0 0.083200 cka (silverman, None) [0.30562842716315974, 0.30562842716315974] [0.30562842716315974, 0.30562842716315974] True True 0 0.065822 cka (silverman, None) 0.354954 0.354954 False True 0 0.083200 cka (silverman, None) 0.30562842716315974 0.305628 True False 0 0.065822 cka (silverman, None) 0.35495366597555705 0.354954 False False 0 0.028354 cka (median, None) [0.90660872358859, 0.8619837864110205] [0.8120777689523777, 0.854339231759148] True True 0 0.018078 cka (median, None) 2.70446 2.56843 False True 0 0.028297 cka (median, None) 0.8587523776777841 0.858752 True False 0 0.018147 cka (median, None) 2.636443482285435 2.63644 False False 0 0.021557 cka (mean, None) [2.0040080160320635, 2.0040080160320644] [2.004008016032065, 2.004008016032064] True True 0 0.013931 cka (mean, None) 4.00802 4.00802 False True 0 0.021557 cka (mean, None) 2.0040080160320644 2.00401 True False 0 0.013931 cka (mean, None) 4.008016032064129 4.00802 False False 0 0.737020 ka (median, 15) [0.05111714688849182, 0.051362071720277146] [0.04721265098560398, 0.0582261233599152] True True 0 0.333186 ka (median, 15) 0.618971 0.566652 False True 0 0.737686 ka (median, 15) 0.051979498238572036 0.0519795 True False 0 0.333453 ka (median, 15) 0.5928113701712288 0.592811 False False 0 0.170798 ka (scott, None) [0.2885399811814427, 0.2885399811814427] [0.2885399811814427, 0.2885399811814427] True True 0 0.187087 ka (scott, None) 0.354954 0.354954 False True 0 0.170798 ka (scott, None) 0.2885399811814427 0.28854 True False 0 0.187087 ka (scott, None) 0.35495366597555705 0.354954 False False 0 0.172871 ka (silverman, None) [0.30562842716315974, 0.30562842716315974] [0.30562842716315974, 0.30562842716315974] True True 0 0.187087 ka (silverman, None) 0.354954 0.354954 False True 0 0.172871 ka (silverman, None) 0.30562842716315974 0.305628 True False 0 0.187087 ka (silverman, None) 0.35495366597555705 0.354954 False False 0 0.518595 ka (median, None) [0.90660872358859, 0.8619837864110205] [0.8120777689523777, 0.854339231759148] True True 0 0.954388 ka (median, None) 2.70446 2.56843 False True 0 0.518887 ka (median, None) 0.8587523776777841 0.858752 True False 0 0.954562 ka (median, None) 2.636443482285435 2.63644 False False 0 0.901849 ka (mean, None) [2.0040080160320635, 2.0040080160320644] [2.004008016032065, 2.004008016032064] True True 0 0.988300 ka (mean, None) 4.00802 4.00802 False True 0 0.901849 ka (mean, None) 2.0040080160320644 2.00401 True False 0 0.988300 ka (mean, None) 4.008016032064129 4.00802 False False Evaluating how this all works is very difficult without any plots. So we'll skip ahead to the analysis code review in the next notebook.","title":"2.0 estimate hsic"},{"location":"notebooks/code_reviews/2.0_estimate_hsic/#code-review-ii-estimate-hsic","text":"This notebook features all of the functions necessary to estimate HSIC given different sigma estimation methods. We will look at the 3 methods: HSIC (centered kernel, unnormalized) Centered Kernel Alignment (CKA) (centered kernel, normalized) Kernel Alignment (KA) (uncentered kernel, unnormalized) And we will also look at how we calculate the kernel matrix: 1 RBF Kernel for both K_{XY} K_{XY} 1 RBF Kernel per datasets, K_X, K_Y K_X, K_Y 1 ARD Kernel per dataset, K_{X_d}, K_{Y_d} K_{X_d}, K_{Y_d} (an RBF kernel with a lengths scale per dimensions) import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) import numpy as np import pandas as pd from functools import partial # toy datasets from data.distribution import DataParams , Inputs # Plotting Procedures import matplotlib import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-paper' ]) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path )","title":"Code Review II - Estimate HSIC"},{"location":"notebooks/code_reviews/2.0_estimate_hsic/#data","text":"def plot_2d_data ( X ): fig = plt . figure () g = sns . jointplot ( x = X [:, 0 ], y = X [:, 1 ], ) plt . tight_layout () plt . show () def plot_1d_data ( X ): fig , ax = plt . subplots () ax . hist ( X ) # initialize the data generator dist_data = DataParams ( dataset = 'tstudent' , trial = 1 , std = 2 , nu = 7 , samples = 500 , dimensions = 2 ) inputs = dist_data . generate_data () # Plot the Distribution plot_1d_data ( inputs . X [:, 0 ]) plot_1d_data ( inputs . X [:, 1 ])","title":"Data"},{"location":"notebooks/code_reviews/2.0_estimate_hsic/#estimate-sigma","text":"I'll be using the same function that I developed in the last notebook which had the following methods available: from typing import Optional from scipy.spatial.distance import pdist , squareform def scotts_factor ( X : np . ndarray ) -> float : \"\"\"Scotts Method to estimate the length scale of the rbf kernel. factor = n**(-1./(d+4)) Parameters ---------- X : np.ndarry Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape return np . power ( n_samples , - 1 / ( n_features + 4. )) def silvermans_factor ( X : np . ndarray ) -> float : \"\"\"Silvermans method used to estimate the length scale of the rbf kernel. factor = (n * (d + 2) / 4.)**(-1. / (d + 4)). Parameters ---------- X : np.ndarray, Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape base = ( n_samples * ( n_features + 2. ) ) / 4. return np . power ( base , - 1 / ( n_features + 4. )) def kth_distance ( dists : np . ndarray , percent : float ) -> np . ndarray : # kth distance calculation (50%) kth_sample = int ( percent * dists . shape [ 0 ]) # take the Kth neighbours of that distance k_dist = dists [:, kth_sample ] return k_dist def sigma_estimate ( X : np . ndarray , method : str = 'median' , percent : Optional [ int ] = None , heuristic : bool = False ) -> float : # get the squared euclidean distances if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) elif percent is not None : kth_sample = int (( percent / 100 ) * X . shape [ 0 ]) dists = np . sort ( squareform ( pdist ( X , 'sqeuclidean' )))[:, kth_sample ] # print(dists.shape, dists.min(), dists.max()) else : dists = np . sort ( pdist ( X , 'sqeuclidean' )) # print(dists.shape, dists.min(), dists.max()) if method == 'median' : sigma = np . median ( dists ) elif method == 'mean' : sigma = np . mean ( dists ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" ) if heuristic : sigma = np . sqrt ( sigma / 2 ) return sigma","title":"Estimate Sigma"},{"location":"notebooks/code_reviews/2.0_estimate_hsic/#rbf-kernel-matrix","text":"We define the generalized RBF kernel like so: K(\\mathbf{x,y}) = \\exp\\left(-\\frac{1}{2}\\left|\\left|\\frac{\\mathbf{x}}{\\sigma} - \\frac{\\mathbf{y}}{\\sigma}\\right|\\right|^2_2\\right) K(\\mathbf{x,y}) = \\exp\\left(-\\frac{1}{2}\\left|\\left|\\frac{\\mathbf{x}}{\\sigma} - \\frac{\\mathbf{y}}{\\sigma}\\right|\\right|^2_2\\right) where \\mathbf{x,y} \\in \\mathbb{R}^{D} \\mathbf{x,y} \\in \\mathbb{R}^{D} and \\sigma \\sigma can be either \\in \\mathbb{R} \\in \\mathbb{R} or \\in \\mathbb{R}^{D} \\in \\mathbb{R}^{D} .","title":"RBF Kernel Matrix"},{"location":"notebooks/code_reviews/2.0_estimate_hsic/#from-scratch","text":"To calculate this from scratch efficiently, we can do the following: Divide each vector by the length scale We can divide each vector \\mathbf{x,y} \\mathbf{x,y} by the lengths scale \\sigma \\sigma before calculating the euclidean distance. Case I: \\sigma \\in \\mathbb{R} \\sigma \\in \\mathbb{R} - it will broadcast the vector across the samples and features, e.g. \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{1} = \\frac{N \\times D}{N \\times D} \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{1} = \\frac{N \\times D}{N \\times D} Case II: \\sigma \\in \\mathbb{R}^{D} \\sigma \\in \\mathbb{R}^{D} - it will broadcast the vector across the samples, e.g. \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{1 \\times D} = \\frac{N \\times D}{N \\times D} \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{1 \\times D} = \\frac{N \\times D}{N \\times D} Case III: \\sigma \\in \\mathbb{R}^{N} \\sigma \\in \\mathbb{R}^{N} - it will broadcast the vector across the features, e.g. \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{N \\times 1} = \\frac{N \\times D}{N \\times D} \\frac{\\mathbf{X}}{\\sigma} = \\frac{N \\times D}{N \\times 1} = \\frac{N \\times D}{N \\times D} So we can reuse the same code no matter which \\sigma \\sigma we give it. Any other case or size \\sigma \\sigma wil through up an error. # 0. Estimate sigma sigma_x = sigma_estimate ( inputs . X , method = 'median' , percent = None , heuristic = False ) sigma_y = sigma_estimate ( inputs . Y , method = 'median' , percent = None , heuristic = False ) sigma_xy = np . mean ([ sigma_x , sigma_y ]) # 1. Divide each vector by the length scale X_scaled = inputs . X / sigma_x 2. Calculate the squared euclidean distance between two the two vectors # 2. euclidean distance from sklearn.metrics.pairwise import euclidean_distances from scipy.spatial.distance import cdist dist = euclidean_distances ( X_scaled , X_scaled , squared = True ) dist_ = cdist ( X_scaled , X_scaled , metric = 'sqeuclidean' ) np . testing . assert_array_almost_equal ( dist , dist_ ) 3. Exponentiate the distances # 2. Exponential Kernel K_xy = np . exp ( - 0.5 * dist ) print ( K_xy . min (), K_xy . max ()) plt . imshow ( K_xy ) plt . colorbar () 0.006274266046377698 1.0 <matplotlib.colorbar.Colorbar at 0x7fc65009b1f0>","title":"From scratch"},{"location":"notebooks/code_reviews/2.0_estimate_hsic/#refactor","text":"Fortunately, there are people smarter than me and they already have a function that does the exact same thing. from sklearn.gaussian_process.kernels import RBF K_sk = RBF ( sigma_x )( inputs . X , inputs . X ) plt . imshow ( K_sk ) plt . colorbar () # check that they're the same np . testing . assert_array_almost_equal ( K_xy , K_sk )","title":"Refactor"},{"location":"notebooks/code_reviews/2.0_estimate_hsic/#side-note-the-original-formula","text":"Most people write down this distance formula: K(\\mathbf{x,y}) = \\exp\\left(-\\frac{\\left|\\left|\\mathbf{x} - \\mathbf{y}\\right|\\right|^2_2}{2\\sigma^2}\\right) K(\\mathbf{x,y}) = \\exp\\left(-\\frac{\\left|\\left|\\mathbf{x} - \\mathbf{y}\\right|\\right|^2_2}{2\\sigma^2}\\right) This is equivalent to the formula I did above: $$ K(\\mathbf{x,y}) =\\exp\\left(-\\frac{\\left|\\left|\\mathbf{x} - \\mathbf{y}\\right|\\right| 2_2}{2\\sigma 2}\\right) = \\exp\\left(-\\left|\\left|\\frac{\\mathbf{x}}{\\sigma} - \\frac{\\mathbf{y}}{\\sigma}\\right|\\right|^2_2\\right) $$ # original # 1. Divide each vector by the length scale X_1d = inputs . X [:, 0 ] . reshape ( - 1 , 1 ) dist = euclidean_distances ( X_1d , X_1d , squared = True ) # 2. Exponential Kernel K_xy = np . exp ( - dist / ( 2 * sigma_x ** 2 )) # quicker K_sk = RBF ( sigma_x )( X_1d , X_1d ) np . testing . assert_array_almost_equal ( K_xy , K_sk )","title":"Side Note - The Original Formula"},{"location":"notebooks/code_reviews/2.0_estimate_hsic/#calculating-hsic","text":"Calculating HSIC is quite simple. Compute each kernel, K_x, K_y K_x, K_y Center the Kernel Matrix (or not) Compute the Trace Normalize or not # kernel matrices K_x = RBF ( sigma_x )( inputs . X ) K_y = RBF ( sigma_y )( inputs . Y ) # center the kernel matrices from sklearn.preprocessing import KernelCenterer K_xc = KernelCenterer () . fit_transform ( K_x ) K_yc = KernelCenterer () . fit_transform ( K_y ) # Compute the Trace hsic_score = np . sum ( K_xc * K_yc ) print ( 'HSIC:' , ( 1 / K_xc . shape [ 0 ] ** 2 ) * hsic_score ) # normalize by the norm cka_score = hsic_score / np . linalg . norm ( K_xc , ord = 'fro' ) / np . linalg . norm ( K_yc , ord = 'fro' ) print ( 'CKA:' , cka_score ) # Kernel Alignment, no centering ka_score = np . sum ( K_x * K_y ) / np . linalg . norm ( K_x , ord = 'fro' ) / np . linalg . norm ( K_y , ord = 'fro' ) print ( 'KA:' , ka_score ) HSIC: 0.0002787777096594028 CKA: 0.01807799077138073 KA: 0.9543875481010973","title":"Calculating HSIC"},{"location":"notebooks/code_reviews/2.0_estimate_hsic/#refactor_1","text":"I already created a more complete function. from models.dependence import HSICModel hsic_clf = HSICModel ( kernel_X = RBF ( sigma_x ), kernel_Y = RBF ( sigma_y ), ) # hsic score hsic_score_ = hsic_clf . get_score ( inputs . X , inputs . Y , 'hsic' ) print ( 'HSIC:' , hsic_score_ ) # cka score cka_score_ = hsic_clf . get_score ( inputs . X , inputs . Y , 'cka' ) print ( 'HSIC:' , cka_score_ ) # ka score ka_score_ = hsic_clf . get_score ( inputs . X , inputs . Y , 'ka' ) print ( 'HSIC:' , ka_score_ ) HSIC: 0.0002787777096594028 HSIC: 0.01807799077138073 HSIC: 0.9543875481010973 Notice how the scores are all the same.","title":"Refactor"},{"location":"notebooks/code_reviews/2.0_estimate_hsic/#different-sigma-configurations","text":"So now, let's see how the scores change depending on how we estimate the sigma parameter. We're going to use a combination of the following scenarios: HSIC Scorer - HSIC, KA, CKA Estimator - Scott, Silverman, Median, Mean, Median Kth (15% samples) Sigma Config - Single, Per Dataset, Per Dataset+Dimension So let's gather all parameter combinations. parameters = { 'scorer' : [ 'hsic' , 'cka' , 'ka' ], 'estimator' : [ ( 'median' , 15 ), ( 'scott' , None ), ( 'silverman' , None ), ( 'median' , None ), ( 'mean' , None ), ], 'per_dataset' : [ True , False ], 'per_dimension' : [ True , False ] } And we're going to take the cartesian product so that we get all possible combinations. I have a dedicated function for that. from experiments.utils import dict_product , run_parallel_step # create a list of all param combinations parameters_list = list ( dict_product ( parameters )) n_params = len ( parameters_list ) print ( '# of Params:' , n_params ) # of Params: 60 So we have 60 combinations to look through just from this set of parameters. Now, let's create a look and go through all of the combinations. results = list () for iparams in parameters_list : # 0. Estimate sigma f_x = lambda x : sigma_estimate ( x , method = iparams [ 'estimator' ][ 0 ], percent = iparams [ 'estimator' ][ 1 ], heuristic = False ) # ======================== # Per Dimension # ======================== if iparams [ 'per_dimension' ]: sigma_X = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . X . T ] sigma_Y = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . Y . T ] else : sigma_X = f_x ( inputs . X ) sigma_Y = f_x ( inputs . Y ) # ========================= # Per Dataset # ========================= if not iparams [ 'per_dataset' ]: sigma_X = np . mean ([ sigma_X , sigma_Y ]) sigma_Y = np . copy ( sigma_X ) # ========================= # Estimate HSIC # ========================= hsic_clf = HSICModel ( kernel_X = RBF ( sigma_X ), kernel_Y = RBF ( sigma_Y ), ) score = hsic_clf . get_score ( inputs . X , inputs . Y , iparams [ 'scorer' ]) # Save Data results . append ( pd . DataFrame ({ 'score' : [ score ], 'scorer' : [ iparams [ 'scorer' ]], 'estimator' : [ iparams [ 'estimator' ]], 'sigma_Y' : [ sigma_Y ], 'sigma_X' : [ sigma_X ], 'per_dimension' : [ iparams [ 'per_dimension' ]], 'per_dataset' : [ iparams [ 'per_dataset' ]], })) results_df = pd . concat ( results ) results_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } score scorer estimator sigma_Y sigma_X per_dimension per_dataset 0 0.001993 hsic (median, 15) [0.05111714688849182, 0.051362071720277146] [0.04721265098560398, 0.0582261233599152] True True 0 0.001777 hsic (median, 15) 0.618971 0.566652 False True 0 0.001993 hsic (median, 15) 0.051979498238572036 0.0519795 True False 0 0.001768 hsic (median, 15) 0.5928113701712288 0.592811 False False 0 0.001885 hsic (scott, None) [0.2885399811814427, 0.2885399811814427] [0.2885399811814427, 0.2885399811814427] True True 0 0.001836 hsic (scott, None) 0.354954 0.354954 False True 0 0.001885 hsic (scott, None) 0.2885399811814427 0.28854 True False 0 0.001836 hsic (scott, None) 0.35495366597555705 0.354954 False False 0 0.001871 hsic (silverman, None) [0.30562842716315974, 0.30562842716315974] [0.30562842716315974, 0.30562842716315974] True True 0 0.001836 hsic (silverman, None) 0.354954 0.354954 False True 0 0.001871 hsic (silverman, None) 0.30562842716315974 0.305628 True False 0 0.001836 hsic (silverman, None) 0.35495366597555705 0.354954 False False 0 0.001690 hsic (median, None) [0.90660872358859, 0.8619837864110205] [0.8120777689523777, 0.854339231759148] True True 0 0.000279 hsic (median, None) 2.70446 2.56843 False True 0 0.001686 hsic (median, None) 0.8587523776777841 0.858752 True False 0 0.000280 hsic (median, None) 2.636443482285435 2.63644 False False 0 0.000603 hsic (mean, None) [2.0040080160320635, 2.0040080160320644] [2.004008016032065, 2.004008016032064] True True 0 0.000066 hsic (mean, None) 4.00802 4.00802 False True 0 0.000603 hsic (mean, None) 2.0040080160320644 2.00401 True False 0 0.000066 hsic (mean, None) 4.008016032064129 4.00802 False False 0 0.736922 cka (median, 15) [0.05111714688849182, 0.051362071720277146] [0.04721265098560398, 0.0582261233599152] True True 0 0.035560 cka (median, 15) 0.618971 0.566652 False True 0 0.737589 cka (median, 15) 0.051979498238572036 0.0519795 True False 0 0.035332 cka (median, 15) 0.5928113701712288 0.592811 False False 0 0.091317 cka (scott, None) [0.2885399811814427, 0.2885399811814427] [0.2885399811814427, 0.2885399811814427] True True 0 0.065822 cka (scott, None) 0.354954 0.354954 False True 0 0.091317 cka (scott, None) 0.2885399811814427 0.28854 True False 0 0.065822 cka (scott, None) 0.35495366597555705 0.354954 False False 0 0.083200 cka (silverman, None) [0.30562842716315974, 0.30562842716315974] [0.30562842716315974, 0.30562842716315974] True True 0 0.065822 cka (silverman, None) 0.354954 0.354954 False True 0 0.083200 cka (silverman, None) 0.30562842716315974 0.305628 True False 0 0.065822 cka (silverman, None) 0.35495366597555705 0.354954 False False 0 0.028354 cka (median, None) [0.90660872358859, 0.8619837864110205] [0.8120777689523777, 0.854339231759148] True True 0 0.018078 cka (median, None) 2.70446 2.56843 False True 0 0.028297 cka (median, None) 0.8587523776777841 0.858752 True False 0 0.018147 cka (median, None) 2.636443482285435 2.63644 False False 0 0.021557 cka (mean, None) [2.0040080160320635, 2.0040080160320644] [2.004008016032065, 2.004008016032064] True True 0 0.013931 cka (mean, None) 4.00802 4.00802 False True 0 0.021557 cka (mean, None) 2.0040080160320644 2.00401 True False 0 0.013931 cka (mean, None) 4.008016032064129 4.00802 False False 0 0.737020 ka (median, 15) [0.05111714688849182, 0.051362071720277146] [0.04721265098560398, 0.0582261233599152] True True 0 0.333186 ka (median, 15) 0.618971 0.566652 False True 0 0.737686 ka (median, 15) 0.051979498238572036 0.0519795 True False 0 0.333453 ka (median, 15) 0.5928113701712288 0.592811 False False 0 0.170798 ka (scott, None) [0.2885399811814427, 0.2885399811814427] [0.2885399811814427, 0.2885399811814427] True True 0 0.187087 ka (scott, None) 0.354954 0.354954 False True 0 0.170798 ka (scott, None) 0.2885399811814427 0.28854 True False 0 0.187087 ka (scott, None) 0.35495366597555705 0.354954 False False 0 0.172871 ka (silverman, None) [0.30562842716315974, 0.30562842716315974] [0.30562842716315974, 0.30562842716315974] True True 0 0.187087 ka (silverman, None) 0.354954 0.354954 False True 0 0.172871 ka (silverman, None) 0.30562842716315974 0.305628 True False 0 0.187087 ka (silverman, None) 0.35495366597555705 0.354954 False False 0 0.518595 ka (median, None) [0.90660872358859, 0.8619837864110205] [0.8120777689523777, 0.854339231759148] True True 0 0.954388 ka (median, None) 2.70446 2.56843 False True 0 0.518887 ka (median, None) 0.8587523776777841 0.858752 True False 0 0.954562 ka (median, None) 2.636443482285435 2.63644 False False 0 0.901849 ka (mean, None) [2.0040080160320635, 2.0040080160320644] [2.004008016032065, 2.004008016032064] True True 0 0.988300 ka (mean, None) 4.00802 4.00802 False True 0 0.901849 ka (mean, None) 2.0040080160320644 2.00401 True False 0 0.988300 ka (mean, None) 4.008016032064129 4.00802 False False Evaluating how this all works is very difficult without any plots. So we'll skip ahead to the analysis code review in the next notebook.","title":"Different Sigma Configurations"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Code Review III - Multivariate Distributions \u00b6 Now, the moment we've all be waiting for: How do these methods perform on multivariate distributions. So for this code review, I'll be walking through how these methods compare and I will try to have some telling plots where we outline exactly how each method performs when estimating multivariate distributions such as the Gaussian and T-Student. Recap \u00b6 So far we've seen how we can estimate sigma as well as how we can estimate the HSIC value. We've seen that this HSIC value depends on the sigma estimator method as well as how we configure the sigma parameter (per dataset, per dimension). So we have a set of methods, now we just need to see how these methods perform when we change the number of dimensions as well as the amount of samples. import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) import warnings from typing import Optional , Tuple from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.distribution import DataParams , Inputs # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from models.dependence import HSICModel # RBIG IT measures # from models.ite_algorithms import run_rbig_models # Plotting from visualization.distribution import plot_scorer # experiment helpers from experiments.utils import dict_product , run_parallel_step from tqdm import tqdm # Plotting Procedures import matplotlib sns . reset_defaults () # sns.set_style('whitegrid') #sns.set_context('talk') sns . set_context ( context = 'poster' , font_scale = 0.7 , rc = { 'font.family' : 'sans-serif' }) # sns.set(font='sans-serif') % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 --------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) <ipython-input-1-ab6dceaaaa93> in <module> 25 from sklearn . preprocessing import StandardScaler 26 from sklearn . gaussian_process . kernels import RBF ---> 27 from models . dependence import HSICModel 28 29 # RBIG IT measures ~/projects/2019_hsic_align/notebooks/code_reviews/../../src/models/dependence.py in <module> 12 from sklearn . utils import check_array , check_random_state 13 ---> 14 from src . models . utils import estimate_gamma 15 16 # Insert path to package,. ModuleNotFoundError : No module named 'src' ! pwd /home/emmanuel/projects/2019_hsic_align/notebooks/4_distributions FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/mutual_info/\" RES_PATH = \"/home/emmanuel/projects/2019_hsic_align/data/results/distributions/mutual_info/\" Experimental Parameters \u00b6 # initialize the holder for the parameters parameters = {} Case I - HSIC Estimator \u00b6 In this first part, we have 3 cases of HSIC as a combination of a centered kernel and whether or not we normalize the covariance term. The 3 \"scorers\" are as follows: HSIC HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F In this case, the kernels are centered , but the score is not normalized . Kernel Alignment (KA) TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} In this case, the kernels are not centered but the score is normalized . cTKA cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} In this case, the kernels are centered and the score is normalized . # def get_hsic( # X: np.ndarray, # Y: np.ndarray, # scorer: str, # sigma_X: Optional[float]=None, # sigma_Y: Optional[float]=None # ) -> float: # \"\"\"Estimates the HSIC value given some data, sigma and # the score.\"\"\" # # init hsic model class # hsic_model = HSICModel() # # hsic model params # if sigma_X is not None: # hsic_model.kernel_X = RBF(sigma_X) # hsic_model.kernel_Y = RBF(sigma_Y) # # get hsic score # hsic_val = hsic_model.get_score(X, Y, scorer) # return hsic_val # parameters parameters [ 'scorer' ] = [ 'hsic' , 'ka' , 'cka' ] Case II - Sigma Estimator \u00b6 For this parameter, we are interested in estimating a few things: We want to know which estimator to choose from. Kernel methods are great if the parameters of the kernel are correct. In supervised scenarios, we can simply learn the appropriate kernel parameters that best fit our data given some criteria. In unsupervised settings, we generally do not know which parameters to choose from. But there are many different ways to choose the parameters as every lab/researcher has their own method that \"they swear by\". I will choose some of the most common ones: Silverman Scott Mean Distance Median Distance Median Distance with the k^{th} k^{th} sample (or percent) of that distance matrix. Case III - Sigma Application \u00b6 We want to know the how we are applying the length scale. We have three cases to consider: One length scale for both datasets One length scale per dataset One length scale per dataset per dimension This is important as it could turn a good estimator into a bad estimator. Scott and Silverman work very well for univariate distributions but not very well for multivariate distributions. So if we have one scott/silverman estimate per feature, then this estimator might be a lot better and yield much better results. For the case of the RBF kernel, having one length scale per dimension corresponds to the ARD Kernel which assigns a length scale (or relevance values) per feature. We don't typically use the ARD kernel for kernel methods that we cannot optimize using some gradient function due to how expensive it is. But in this case, it isn't so expensive because we are choosing not to optimizing anything. from typing import Optional from scipy.spatial.distance import pdist , squareform from models.dependence import HSICModel def scotts_factor ( X : np . ndarray ) -> float : \"\"\"Scotts Method to estimate the length scale of the rbf kernel. factor = n**(-1./(d+4)) Parameters ---------- X : np.ndarry Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape return np . power ( n_samples , - 1 / ( n_features + 4. )) def silvermans_factor ( X : np . ndarray ) -> float : \"\"\"Silvermans method used to estimate the length scale of the rbf kernel. factor = (n * (d + 2) / 4.)**(-1. / (d + 4)). Parameters ---------- X : np.ndarray, Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape base = ( n_samples * ( n_features + 2. ) ) / 4. return np . power ( base , - 1 / ( n_features + 4. )) def kth_distance ( dists : np . ndarray , percent : float ) -> np . ndarray : # kth distance calculation (50%) kth_sample = int ( percent * dists . shape [ 0 ]) # take the Kth neighbours of that distance k_dist = dists [:, kth_sample ] return k_dist def sigma_estimate ( X : np . ndarray , method : str = 'median' , percent : Optional [ int ] = None , heuristic : bool = False ) -> float : # get the squared euclidean distances if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) elif percent is not None : kth_sample = int (( percent / 100 ) * X . shape [ 0 ]) dists = np . sort ( squareform ( pdist ( X , 'sqeuclidean' )))[:, kth_sample ] # print(dists.shape, dists.min(), dists.max()) else : dists = np . sort ( pdist ( X , 'sqeuclidean' )) # print(dists.shape, dists.min(), dists.max()) if method == 'median' : sigma = np . median ( dists ) elif method == 'mean' : sigma = np . mean ( dists ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" ) if heuristic : sigma = np . sqrt ( sigma / 2 ) return sigma # Parameters for the estimators parameters [ 'sigma_estimator' ] = [ ( 'median' , 15 ), ( 'median' , 20 ), ( 'median' , 50 ), ( 'median' , 80 ), ( 'scott' , None ), ( 'silverman' , None ), ( 'median' , None ), ] parameters [ 'separate_scales' ] = [ True ] parameters [ 'per_dimension' ] = [ True , False ] Case IV - Standardize or not Standardize \u00b6 This is a simple case but it can have drastic changes in the results of estimating the length scale. In ML, we tend to standardize our datasets because the algorithms do better with predictions with the ranges are contained. Datasets with massive values for certain features could have adverse affects on the representation and the predictions. The formula is given by: \\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} \\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} Note : this is scaling per feature and not per sample. # from typing import Tuple, Optional def standardize_data ( X : np . ndarray , Y : np . ndarray , standardize : bool = False ) -> Tuple [ np . ndarray , np . ndarray ]: X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) return X , Y # experimental parameters parameters [ 'standardize' ] = [ True , False ] Case V - Multivariate Datasets \u00b6 For this experiment, we have generated samples for two sets of multivariate distributions: the Gaussian and the T-Student. We have varied the parameters so that we get a variety of samples, dimensions and the amount of similarity (that we can analytically calculate) between them. For example, we can take a Gaussian distribution with a covariance and generate a similar Gaussian distribution with the same number of samples and variance with a covariance. We know the cross-covariance between them and the self-covariances, so we can analytically calculate the mutual information between the two. MI is absolute which is the dependence or similarity between the two datasets. Now, we will see how the HSIC scores will do versus this variation of dataset size and shape. We have the following parameters: Parameter Entry Samples 50, 100, 500, 1K, 5K Dimensions 2, 3, 10, 50, 100 Trials 1 \\rightarrow \\rightarrow 5 Distributions Gaussian, T-Student std (Gauss dist) 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 nu (T-Stu dist) 1, 2, 3, 4, 5, 6, 7, 8, 9 # example parameters for the dataset parameters [ 'dataset' ] = [ 'gauss' ] parameters [ 'std' ] = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 ] parameters [ 'nu' ] = [ 1 ] parameters [ 'trial' ] = [ 1 , 2 , 3 , 4 , 5 ] parameters [ 'dimensions' ] = [ 2 , 3 , 10 , 50 , 100 ] # Loop Params loop_params = {} loop_params [ \"samples\" ] = [ 50 , 100 , 500 , 1_000 , 5_000 ] # example parameters function example_params = DataParams () # generates a named tuple containing the inputs and the MI inputs = example_params . generate_data () Main Loop ( Update ) \u00b6 So it turns out just doing a blind parallel scheme ended up taking too much time. So I decided to break the problem up a bit. Do 1 Main Loop (Samples) I decided not to combine all of the combinations; I did all except for the number of samples. Everytime I was watching the progress bar, it would slow down every once in a while. That was because the bottleneck for kernel methods is the number of samples. We have cases of 1_000 which isn't too bad, but 5_000 samples is where the methods really start to slow down. In addition, there will be a lot of memory consumption. So I decided to do a main loop through the number of samples (starting from the smallest and ending with the largest). That way, we can get the easier datasets out of the way and then work on the larger datasets later. Controlling the number of jobs. As I mentioned before, the bottleneck is the number of samples. With 5_000, this starts to eat up a lot of memory when doing this in parallel. So to prevent this I set it up such that I control the number of cores doing the processing. Like so: # Samples Cores 50 28 100 28 500 28 1_000 16 5_000 8 Appending Data Because there was a lot of data being shifted around ( \\sim 297000 \\sim 297000 parameters), the resulting dataframe which stores the experimental results is going to be huge. So I decided that for every call to the main loop, I will run append those results to a csv file and then del that dataframe to free up memory. Experiment \u00b6 We have a lot of parameters. So we are going to run everything in parallel so that we can save time. We will do this by giving the cartesian product of our nD list of parameters. This will give us a list of tuples where each entry is a set of parameters to evaluate. The length of this list will be the total number of parameters. # create a list of all param combinations # shuffle parameters params = list ( dict_product ( parameters )) loop_params = list ( dict_product ( loop_params )) # parameters_list = list(dict_product(parameters)) n_params , n_loop_params = len ( params ), len ( loop_params ) print ( '# of Params:' , n_params , n_loop_params ) # of Params: 23100 5 from typing import Dict def step ( params : Dict , loop_param : Dict , ): # ================ # DATA # ================ dist_data = DataParams ( dataset = params [ \"dataset\" ], trial = params [ \"trial\" ], std = params [ \"std\" ], nu = params [ \"nu\" ], samples = loop_param [ \"samples\" ], dimensions = params [ \"dimensions\" ], ) # generate data inputs = dist_data . generate_data () # ======================== # Estimate Sigma # ======================== f_x = lambda x : sigma_estimate ( x , method = params [ 'sigma_estimator' ][ 0 ], percent = params [ 'sigma_estimator' ][ 1 ], heuristic = False ) # ======================== # Per Dimension # ======================== if params [ 'per_dimension' ]: sigma_X = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . X . T ] sigma_Y = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . Y . T ] else : sigma_X = f_x ( inputs . X ) sigma_Y = f_x ( inputs . Y ) # ========================= # Estimate HSIC # ========================= hsic_clf = HSICModel ( kernel_X = RBF ( sigma_X ), kernel_Y = RBF ( sigma_Y ), ) score = hsic_clf . get_score ( inputs . X , inputs . Y , params [ 'scorer' ]) # ==================== # Results # ==================== # append results to dataframe results_df = pd . DataFrame ( { # Data Params \"dataset\" : [ params [ \"dataset\" ]], \"trial\" : [ params [ \"trial\" ]], \"std\" : [ params [ \"std\" ]], \"nu\" : [ params [ \"nu\" ]], \"samples\" : [ loop_param [ \"samples\" ]], \"dimensions\" : [ params [ \"dimensions\" ]], # STANDARDIZE PARSM \"standardize\" : [ params [ \"standardize\" ]], # SIGMA FORMAT PARAMS \"per_dimension\" : [ params [ \"per_dimension\" ]], # SIGMA METHOD PARAMS \"sigma_method\" : [ params [ \"sigma_estimator\" ][ 0 ]], \"sigma_percent\" : [ params [ \"sigma_estimator\" ][ 1 ]], \"sigma_X\" : [ sigma_X ], \"sigma_Y\" : [ sigma_Y ], # HSIC Params \"scorer\" : [ params [ \"scorer\" ]], \"score\" : [ score ], \"mutual_info\" : [ inputs . mutual_info ], } ) return results_df Test - Single Step \u00b6 results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = loop_params [ 0 ], ) [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 3.8s [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 5.6s [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 7.7s [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 10.5s [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 13.8s [Parallel(n_jobs=-1)]: Done 3144 tasks | elapsed: 17.8s [Parallel(n_jobs=-1)]: Done 3994 tasks | elapsed: 22.3s [Parallel(n_jobs=-1)]: Done 4944 tasks | elapsed: 26.9s [Parallel(n_jobs=-1)]: Done 6640 tasks | elapsed: 32.8s [Parallel(n_jobs=-1)]: Done 8940 tasks | elapsed: 40.0s [Parallel(n_jobs=-1)]: Done 11440 tasks | elapsed: 47.6s --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) <ipython-input-35-3df2e8759391> in <module> ----> 1 results_df = run_parallel_step( 2 exp_step = step , 3 parameters = params , 4 n_jobs = - 1 , 5 verbose = 1 , ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/utils.py in run_parallel_step (exp_step, parameters, n_jobs, verbose, **kwargs) 96 97 # loop through parameters ---> 98 results = Parallel(n_jobs=n_jobs, verbose=verbose)( 99 delayed ( exp_step ) ( iparam , ** kwargs ) for iparam in parameters 100 ) ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py in __call__ (self, iterable) 1015 1016 with self . _backend . retrieval_context ( ) : -> 1017 self . retrieve ( ) 1018 # Make sure that we get a last message telling us we are done 1019 elapsed_time = time . time ( ) - self . _start_time ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py in retrieve (self) 907 try : 908 if getattr ( self . _backend , 'supports_timeout' , False ) : --> 909 self . _output . extend ( job . get ( timeout = self . timeout ) ) 910 else : 911 self . _output . extend ( job . get ( ) ) ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/_parallel_backends.py in wrap_future_result (future, timeout) 560 AsyncResults.get from multiprocessing.\"\"\" 561 try : --> 562 return future . result ( timeout = timeout ) 563 except LokyTimeoutError : 564 raise TimeoutError ( ) ~/.conda/envs/hsic_align/lib/python3.8/concurrent/futures/_base.py in result (self, timeout) 432 return self . __get_result ( ) 433 --> 434 self . _condition . wait ( timeout ) 435 436 if self . _state in [ CANCELLED , CANCELLED_AND_NOTIFIED ] : ~/.conda/envs/hsic_align/lib/python3.8/threading.py in wait (self, timeout) 300 try : # restore state no matter what (e.g., KeyboardInterrupt) 301 if timeout is None : --> 302 waiter . acquire ( ) 303 gotit = True 304 else : KeyboardInterrupt : results_df . tail () --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-36-5747df3a89d5> in <module> ----> 1 results_df . tail ( ) NameError : name 'results_df' is not defined # save results save_name = \"test\" dataset = 'gaussian' header = True mode = \"w\" with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) # get params # params, loop_params = get_parameters(args.dataset, njobs=args.njobs) save_name = \"test\" dataset = 'gaussian' # initialize datast header = True mode = \"w\" with tqdm ( loop_params ) as pbar : for iparam in pbar : pbar . set_description ( f \"# Samples: { iparam [ 'samples' ] } , Tasks: { len ( params ) } \" ) results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = iparam , ) # concat current results results_df = pd . concat ( results_df , ignore_index = True ) # save results with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) header = False mode = \"a\" del results_df break # Samples: 50, Tasks: 23100: 0%| | 0/5 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.0s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 4.8s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.5s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 10.7s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 14.7s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.4s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 24.9s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 30.6s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 37.5s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 43.8s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 51.4s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 50, Tasks: 23100: 0%| | 0/5 [01:27<?, ?it/s] step_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 0 gauss 1 1 1 50 2 True True True median 0.1 [0.1686566316684468, 0.14612229488391992] [0.1589719949193001, 0.1680410083908699] hsic 0.019091 0.0 Test - Full Loop \u00b6 # get params # params, loop_params = get_parameters(args.dataset, njobs=args.njobs) save_name = \"test_full\" dataset = 'gaussian' # initialize dataset header = True mode = \"w\" with tqdm ( loop_params ) as pbar : for iparam in pbar : pbar . set_description ( f \"# Samples: { iparam [ 'samples' ] } , Tasks: { len ( params ) } \" ) results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = iparam , ) # concat current results results_df = pd . concat ( results_df , ignore_index = True ) # save results with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) header = False mode = \"a\" # Samples: 50, Tasks: 23100: 0%| | 0/5 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.0s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 4.7s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.4s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 10.7s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 14.9s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.5s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 24.8s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 30.7s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 37.1s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 44.5s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 52.6s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 100, Tasks: 23100: 20%|\u2588\u2588 | 1/5 [01:27<05:51, 87.81s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.2s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.7s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 5.0s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.8s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 11.4s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 15.3s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.8s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 25.6s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 31.7s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 38.3s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 45.4s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 53.3s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 500, Tasks: 23100: 40%|\u2588\u2588\u2588\u2588 | 2/5 [02:57<04:24, 88.32s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 195 tasks | elapsed: 10.0s [Parallel(n_jobs=-1)]: Done 450 tasks | elapsed: 22.8s [Parallel(n_jobs=-1)]: Done 800 tasks | elapsed: 29.2s [Parallel(n_jobs=-1)]: Done 1250 tasks | elapsed: 38.5s [Parallel(n_jobs=-1)]: Done 1800 tasks | elapsed: 59.6s [Parallel(n_jobs=-1)]: Done 2450 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 3200 tasks | elapsed: 1.5min [Parallel(n_jobs=-1)]: Done 4050 tasks | elapsed: 2.0min [Parallel(n_jobs=-1)]: Done 5000 tasks | elapsed: 2.1min [Parallel(n_jobs=-1)]: Done 6050 tasks | elapsed: 2.2min [Parallel(n_jobs=-1)]: Done 7200 tasks | elapsed: 2.6min [Parallel(n_jobs=-1)]: Done 8450 tasks | elapsed: 3.2min [Parallel(n_jobs=-1)]: Done 9800 tasks | elapsed: 3.7min [Parallel(n_jobs=-1)]: Done 11250 tasks | elapsed: 4.4min [Parallel(n_jobs=-1)]: Done 12800 tasks | elapsed: 4.8min [Parallel(n_jobs=-1)]: Done 14450 tasks | elapsed: 5.0min [Parallel(n_jobs=-1)]: Done 16200 tasks | elapsed: 5.8min [Parallel(n_jobs=-1)]: Done 18050 tasks | elapsed: 6.7min [Parallel(n_jobs=-1)]: Done 20000 tasks | elapsed: 7.4min [Parallel(n_jobs=-1)]: Done 22050 tasks | elapsed: 7.6min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 8.0min finished # Samples: 1000, Tasks: 23100: 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 3/5 [11:14<07:01, 210.85s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 27.9s [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 1.3min [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 1.9min [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 2.3min [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 3.8min [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 4.6min [Parallel(n_jobs=-1)]: Done 3144 tasks | elapsed: 5.9min [Parallel(n_jobs=-1)]: Done 3994 tasks | elapsed: 7.8min [Parallel(n_jobs=-1)]: Done 4944 tasks | elapsed: 8.0min [Parallel(n_jobs=-1)]: Done 5994 tasks | elapsed: 8.2min [Parallel(n_jobs=-1)]: Done 7144 tasks | elapsed: 9.8min [Parallel(n_jobs=-1)]: Done 8394 tasks | elapsed: 11.8min [Parallel(n_jobs=-1)]: Done 9744 tasks | elapsed: 13.8min [Parallel(n_jobs=-1)]: Done 11194 tasks | elapsed: 16.5min [Parallel(n_jobs=-1)]: Done 12744 tasks | elapsed: 17.9min [Parallel(n_jobs=-1)]: Done 14394 tasks | elapsed: 18.3min [Parallel(n_jobs=-1)]: Done 16144 tasks | elapsed: 21.6min [Parallel(n_jobs=-1)]: Done 17994 tasks | elapsed: 25.0min [Parallel(n_jobs=-1)]: Done 19944 tasks | elapsed: 27.7min [Parallel(n_jobs=-1)]: Done 21994 tasks | elapsed: 28.0min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 29.7min finished # Samples: 5000, Tasks: 23100: 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 4/5 [41:13<11:27, 687.29s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 13.4min [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 37.4min [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 53.4min [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 65.1min [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 108.6min [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 130.8min results_df = pd . read_csv ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" ) results_df = results_df . loc [:, ~ results_df . columns . str . match ( 'Unnamed' )] results_df = results_df . astype ( object ) . replace ( np . nan , 'None' ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 115495 gauss 5 11 1 5000 2 False False median None 2.596209486629066 2.533566551925972 cka 0.408078 0.390005 115496 gauss 5 11 1 5000 3 False False median None 4.114994392992097 4.495821703399767 cka 0.453781 0.377389 115497 gauss 5 11 1 5000 10 False False median None 14.882197509532734 15.57776152697343 cka 0.752609 0.929178 115498 gauss 5 11 1 5000 50 False False median None 67.1011981827926 65.92873890142732 cka 0.969342 4.052644 115499 gauss 5 11 1 5000 100 False False median None 129.70371717695562 129.7259155663332 cka 0.985882 7.938746 results_df . sigma_percent . unique () . tolist () [15.0, 20.0, 50.0, 80.0, 'None'] Visualization \u00b6 Indiscrimenant Points - Dimensions, Samples Method - colors Standardize - type Correlation (MI, Score) Method I - Scott, Silverman \u00b6 # segment scott sub_df = results_df [ results_df [ \"sigma_method\" ] == 'silverman' ] # sub_df = sub_df[sub_df[\"sigma_percent\"] == 'None'] # dropcolumns with dimensions and samples sub_df = sub_df . drop ([ 'dimensions' , 'samples' , 'std' , 'nu' , 'trial' , 'dataset' , 'sigma_X' , 'sigma_Y' ], axis = 1 ) sub_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } standardize per_dimension sigma_method sigma_percent scorer score mutual_info 114395 False False silverman None cka 0.044627 0.390005 114396 False False silverman None cka 0.065012 0.377389 114397 False False silverman None cka 0.966685 0.929178 114398 False False silverman None cka 1.000000 4.052644 114399 False False silverman None cka 1.000000 7.938746 Convenience Functions \u00b6 I - Subsetting the DataFrame \u00b6 We want to be able to query the dataframe with multiple queries at a time. So I'll create a namedtuple which will hold the name of the column and the elements I want to access. Then I'll have a function that will take a list of these datastructures from typing import List , Optional , Union df_query = namedtuple ( 'df_query' , [ 'name' , 'elements' ]) def subset_dataframe ( df : pd . DataFrame , queries : List [ df_query ], ) -> pd . DataFrame : # copy dataframe to prevent overwriting sub_df = df . copy () # for iquery in queries : sub_df = sub_df [ sub_df [ iquery . name ] . isin ( iquery . elements )] return sub_df # subset dataframe scorer = 'hsic' hsic_data_df = subset_dataframe ( results_df , [ df_query ( 'scorer' , [ scorer ])]) hsic_data_df . head ( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 0 gauss 1 1 1 50 2 True True median 15 [0.05289913460722866, 0.046005156305852286] [0.0603301351143148, 0.06549625956610451] hsic 0.019532 0.0 1 gauss 1 1 1 50 3 True True median 15 [0.05289913460722866, 0.046005156305852286, 0.... [0.06549625956610451, 0.05939212909166344, 0.0... hsic 0.019590 0.0 # check for iscorer in [ 'hsic' , 'ka' , 'cka' ]: # subset dataframe sub_df = subset_dataframe ( results_df , [ df_query ( 'scorer' , [ iscorer ])]) # check that the only element is the one we query-ed assert sub_df . scorer . unique () . tolist () == [ iscorer ] II - Correlations \u00b6 I want to see the correlations between the mutual information and the score. So I'll make a dedicated function to handle that. I'll use a namedtuple to ensure that the results are a callable datastructure and immutable (cannot be overwritten). from scipy import stats from collections import namedtuple corr_stats = namedtuple ( 'corr_stats' , [ 'pearson' , 'spearman' ]) def get_correlations ( df : pd . DataFrame ): \"\"\"Inputs a dataframe and outputs the correlation between the mutual information and the score. Requires the 'mutual_info' and 'score' columns.\"\"\" # check that columns are in dataframe msg = \"No 'mutual_info' and/or 'score' column(s) found in dataframe\" assert { 'mutual_info' , \"score\" } . issubset ( df . columns ), msg # get pearson correlation corr_pear = stats . pearsonr ( df . score , df . mutual_info )[ 0 ] # get spearman correlation corr_spear = stats . spearmanr ( df . score , df . mutual_info )[ 0 ] return corr_stats ( corr_pear , corr_spear ) scorer = 'hsic' sub_df = subset_dataframe ( results_df , 'scorer' , [ scorer ]) test_corrs = get_correlations ( sub_df ) # check if output is named tuple assert isinstance ( test_corrs , corr_stats ) III - Plotting (score vs MI) \u00b6 I want to plot the score versus the mutual information. This will be the plot given the data we have. There are two competing factors that we need to address: per dimension and standardization . The plots were be per method and will either address whether per dimension makes sense or per standardize. def plot_score_vs_mi ( df : pd . DataFrame , scorer : Optional [ str ] = None , # methods: List[str]=['silverman'], # percent: Optional[List[str]]=None, compare : str = 'standard' ): # copy dataframe to prevent overwriting sub_df = df . copy () # segment method if scorer is not None : sub_df = subset_dataframe ( sub_df , [ df_query ( 'scorer' , [ scorer ])]) # # get percentage (if necessary) # if percent is not None: # sub_df = df[df[\"sigma_method\"].isin(percent)] # dropcolumns with dimensions and samples sub_df = sub_df . drop ([ 'dimensions' , 'samples' , 'std' , 'nu' , 'trial' , 'dataset' , 'sigma_X' , 'sigma_Y' ], axis = 1 ) if compare == 'standard' : true_df = sub_df [ sub_df [ 'standardize' ] == True ] true_corrs = get_correlations ( true_df ) true_label = f \"Standardized, (p: { true_corrs . pearson : .2f } , sp: { true_corrs . spearman : .2f } )\" false_df = sub_df [ sub_df [ 'standardize' ] == False ] false_corrs = get_correlations ( false_df ) false_label = f \"Non-Standardized, (p: { false_corrs . pearson : .2f } , sp: { false_corrs . spearman : .2f } )\" elif compare == 'dimension' : true_df = sub_df [ sub_df [ 'per_dimension' ] == True ] true_corrs = get_correlations ( true_df ) true_label = f \"Per Dimension, (p: { true_corrs . pearson : .2f } , sp: { true_corrs . spearman : .2f } )\" false_df = sub_df [ sub_df [ 'per_dimension' ] == False ] false_corrs = get_correlations ( false_df ) false_label = f \"Same, (p: { false_corrs . pearson : .2f } , sp: { false_corrs . spearman : .2f } )\" # plot fig , ax = plt . subplots () ax . scatter ( true_df . score , true_df . mutual_info , marker = 'o' , s = 30 , label = true_label ) ax . scatter ( false_df . score , false_df . mutual_info , marker = 'x' , s = 30 , label = false_label ) ax . legend () ax . set_yscale ( 'symlog' ) ax . set_xlabel ( 'Score' ) ax . set_ylabel ( 'Mutual Information' ) # ax.set_title(f\"{scorer.upper()}\") # ax.text(0.18, 0.18, r, {'color': 'C0', 'fontsize': 16}) return fig , ax Case I - Standardize or Not? \u00b6 # initialize list of queries queries = [] # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) # query dataframe for scott and silverman methods sigma_methods = [ 'scott' , 'silverman' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); Case II - Median (no percent) \u00b6 # initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 'None' ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); Case III - Median + Percent (50, 20, 60) \u00b6 # initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); Case IV - Median + Standardization \u00b6 # initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for hsic standardize = [ True ,] queries . append ( df_query ( 'standardize' , standardize )) sub_df = subset_dataframe ( results_df , queries ) print ( sub_df . shape ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); (24750, 15) Case IV - Median w/o Standardization \u00b6 # initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for hsic standardize = [ False ,] queries . append ( df_query ( 'standardize' , standardize )) sub_df = subset_dataframe ( results_df , queries ) print ( sub_df . shape ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); (24750, 15) import time t0 = time . time () df_ = pd . concat ( results_df , ignore_index = True ) t1 = time . time () - t0 print ( f \"Time Taken: { t1 : .2f } secs\" ) df_ . tail () Time Taken: 37.71 secs .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 59395 gauss 5 11 1 50 2 False False False median 0.9 2.88898 2.88898 cka 0.480297 0.390005 59396 gauss 5 11 1 50 3 False False False median 0.9 3.35418 3.35418 cka 0.530064 0.377389 59397 gauss 5 11 1 50 10 False False False median 0.9 5.687 5.687 cka 0.714579 0.929178 59398 gauss 5 11 1 50 50 False False False median 0.9 13.6425 13.6425 cka 0.975977 4.052644 59399 gauss 5 11 1 50 100 False False False median 0.9 19.2544 19.2544 cka 0.987792 7.938746 Note : This is another bottleneck. Appending to File \u00b6 We can use this simple pseudocode to append to a file. mode = 'a' header = False with open ( f \" { RES_PATH }{ save_name } .csv\" , mode ) as f : df . to_csv ( f , header = header ) header = True","title":"3.0 multivariate dists"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#code-review-iii-multivariate-distributions","text":"Now, the moment we've all be waiting for: How do these methods perform on multivariate distributions. So for this code review, I'll be walking through how these methods compare and I will try to have some telling plots where we outline exactly how each method performs when estimating multivariate distributions such as the Gaussian and T-Student.","title":"Code Review III - Multivariate Distributions"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#recap","text":"So far we've seen how we can estimate sigma as well as how we can estimate the HSIC value. We've seen that this HSIC value depends on the sigma estimator method as well as how we configure the sigma parameter (per dataset, per dimension). So we have a set of methods, now we just need to see how these methods perform when we change the number of dimensions as well as the amount of samples. import sys , os # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) import warnings from typing import Optional , Tuple from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from data.distribution import DataParams , Inputs # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from models.dependence import HSICModel # RBIG IT measures # from models.ite_algorithms import run_rbig_models # Plotting from visualization.distribution import plot_scorer # experiment helpers from experiments.utils import dict_product , run_parallel_step from tqdm import tqdm # Plotting Procedures import matplotlib sns . reset_defaults () # sns.set_style('whitegrid') #sns.set_context('talk') sns . set_context ( context = 'poster' , font_scale = 0.7 , rc = { 'font.family' : 'sans-serif' }) # sns.set(font='sans-serif') % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 --------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) <ipython-input-1-ab6dceaaaa93> in <module> 25 from sklearn . preprocessing import StandardScaler 26 from sklearn . gaussian_process . kernels import RBF ---> 27 from models . dependence import HSICModel 28 29 # RBIG IT measures ~/projects/2019_hsic_align/notebooks/code_reviews/../../src/models/dependence.py in <module> 12 from sklearn . utils import check_array , check_random_state 13 ---> 14 from src . models . utils import estimate_gamma 15 16 # Insert path to package,. ModuleNotFoundError : No module named 'src' ! pwd /home/emmanuel/projects/2019_hsic_align/notebooks/4_distributions FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/distribution_experiment/mutual_info/\" RES_PATH = \"/home/emmanuel/projects/2019_hsic_align/data/results/distributions/mutual_info/\"","title":"Recap"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#experimental-parameters","text":"# initialize the holder for the parameters parameters = {}","title":"Experimental Parameters"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#case-i-hsic-estimator","text":"In this first part, we have 3 cases of HSIC as a combination of a centered kernel and whether or not we normalize the covariance term. The 3 \"scorers\" are as follows: HSIC HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F HSIC = \\frac{1}{n(n-1)}\\langle K_xH,K_yH \\rangle_F In this case, the kernels are centered , but the score is not normalized . Kernel Alignment (KA) TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} TKA = \\frac{\\langle K_x,K_y \\rangle_F}{||K_x||_F||K_y||_F} In this case, the kernels are not centered but the score is normalized . cTKA cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} cTKA = \\frac{\\langle K_xH,K_yH \\rangle_F}{||K_xH||_F||K_yH||_F} In this case, the kernels are centered and the score is normalized . # def get_hsic( # X: np.ndarray, # Y: np.ndarray, # scorer: str, # sigma_X: Optional[float]=None, # sigma_Y: Optional[float]=None # ) -> float: # \"\"\"Estimates the HSIC value given some data, sigma and # the score.\"\"\" # # init hsic model class # hsic_model = HSICModel() # # hsic model params # if sigma_X is not None: # hsic_model.kernel_X = RBF(sigma_X) # hsic_model.kernel_Y = RBF(sigma_Y) # # get hsic score # hsic_val = hsic_model.get_score(X, Y, scorer) # return hsic_val # parameters parameters [ 'scorer' ] = [ 'hsic' , 'ka' , 'cka' ]","title":"Case I - HSIC Estimator"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#case-ii-sigma-estimator","text":"For this parameter, we are interested in estimating a few things: We want to know which estimator to choose from. Kernel methods are great if the parameters of the kernel are correct. In supervised scenarios, we can simply learn the appropriate kernel parameters that best fit our data given some criteria. In unsupervised settings, we generally do not know which parameters to choose from. But there are many different ways to choose the parameters as every lab/researcher has their own method that \"they swear by\". I will choose some of the most common ones: Silverman Scott Mean Distance Median Distance Median Distance with the k^{th} k^{th} sample (or percent) of that distance matrix.","title":"Case II - Sigma Estimator"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#case-iii-sigma-application","text":"We want to know the how we are applying the length scale. We have three cases to consider: One length scale for both datasets One length scale per dataset One length scale per dataset per dimension This is important as it could turn a good estimator into a bad estimator. Scott and Silverman work very well for univariate distributions but not very well for multivariate distributions. So if we have one scott/silverman estimate per feature, then this estimator might be a lot better and yield much better results. For the case of the RBF kernel, having one length scale per dimension corresponds to the ARD Kernel which assigns a length scale (or relevance values) per feature. We don't typically use the ARD kernel for kernel methods that we cannot optimize using some gradient function due to how expensive it is. But in this case, it isn't so expensive because we are choosing not to optimizing anything. from typing import Optional from scipy.spatial.distance import pdist , squareform from models.dependence import HSICModel def scotts_factor ( X : np . ndarray ) -> float : \"\"\"Scotts Method to estimate the length scale of the rbf kernel. factor = n**(-1./(d+4)) Parameters ---------- X : np.ndarry Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape return np . power ( n_samples , - 1 / ( n_features + 4. )) def silvermans_factor ( X : np . ndarray ) -> float : \"\"\"Silvermans method used to estimate the length scale of the rbf kernel. factor = (n * (d + 2) / 4.)**(-1. / (d + 4)). Parameters ---------- X : np.ndarray, Input array Returns ------- factor : float the length scale estimated \"\"\" n_samples , n_features = X . shape base = ( n_samples * ( n_features + 2. ) ) / 4. return np . power ( base , - 1 / ( n_features + 4. )) def kth_distance ( dists : np . ndarray , percent : float ) -> np . ndarray : # kth distance calculation (50%) kth_sample = int ( percent * dists . shape [ 0 ]) # take the Kth neighbours of that distance k_dist = dists [:, kth_sample ] return k_dist def sigma_estimate ( X : np . ndarray , method : str = 'median' , percent : Optional [ int ] = None , heuristic : bool = False ) -> float : # get the squared euclidean distances if method == 'silverman' : return silvermans_factor ( X ) elif method == 'scott' : return scotts_factor ( X ) elif percent is not None : kth_sample = int (( percent / 100 ) * X . shape [ 0 ]) dists = np . sort ( squareform ( pdist ( X , 'sqeuclidean' )))[:, kth_sample ] # print(dists.shape, dists.min(), dists.max()) else : dists = np . sort ( pdist ( X , 'sqeuclidean' )) # print(dists.shape, dists.min(), dists.max()) if method == 'median' : sigma = np . median ( dists ) elif method == 'mean' : sigma = np . mean ( dists ) else : raise ValueError ( f \"Unrecognized distance measure: { method } \" ) if heuristic : sigma = np . sqrt ( sigma / 2 ) return sigma # Parameters for the estimators parameters [ 'sigma_estimator' ] = [ ( 'median' , 15 ), ( 'median' , 20 ), ( 'median' , 50 ), ( 'median' , 80 ), ( 'scott' , None ), ( 'silverman' , None ), ( 'median' , None ), ] parameters [ 'separate_scales' ] = [ True ] parameters [ 'per_dimension' ] = [ True , False ]","title":"Case III - Sigma Application"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#case-iv-standardize-or-not-standardize","text":"This is a simple case but it can have drastic changes in the results of estimating the length scale. In ML, we tend to standardize our datasets because the algorithms do better with predictions with the ranges are contained. Datasets with massive values for certain features could have adverse affects on the representation and the predictions. The formula is given by: \\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} \\bar{x} = \\frac{x - \\mu_x}{\\sigma_x} Note : this is scaling per feature and not per sample. # from typing import Tuple, Optional def standardize_data ( X : np . ndarray , Y : np . ndarray , standardize : bool = False ) -> Tuple [ np . ndarray , np . ndarray ]: X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) return X , Y # experimental parameters parameters [ 'standardize' ] = [ True , False ]","title":"Case IV - Standardize or not Standardize"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#case-v-multivariate-datasets","text":"For this experiment, we have generated samples for two sets of multivariate distributions: the Gaussian and the T-Student. We have varied the parameters so that we get a variety of samples, dimensions and the amount of similarity (that we can analytically calculate) between them. For example, we can take a Gaussian distribution with a covariance and generate a similar Gaussian distribution with the same number of samples and variance with a covariance. We know the cross-covariance between them and the self-covariances, so we can analytically calculate the mutual information between the two. MI is absolute which is the dependence or similarity between the two datasets. Now, we will see how the HSIC scores will do versus this variation of dataset size and shape. We have the following parameters: Parameter Entry Samples 50, 100, 500, 1K, 5K Dimensions 2, 3, 10, 50, 100 Trials 1 \\rightarrow \\rightarrow 5 Distributions Gaussian, T-Student std (Gauss dist) 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 nu (T-Stu dist) 1, 2, 3, 4, 5, 6, 7, 8, 9 # example parameters for the dataset parameters [ 'dataset' ] = [ 'gauss' ] parameters [ 'std' ] = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 ] parameters [ 'nu' ] = [ 1 ] parameters [ 'trial' ] = [ 1 , 2 , 3 , 4 , 5 ] parameters [ 'dimensions' ] = [ 2 , 3 , 10 , 50 , 100 ] # Loop Params loop_params = {} loop_params [ \"samples\" ] = [ 50 , 100 , 500 , 1_000 , 5_000 ] # example parameters function example_params = DataParams () # generates a named tuple containing the inputs and the MI inputs = example_params . generate_data ()","title":"Case V - Multivariate Datasets"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#main-loop-update","text":"So it turns out just doing a blind parallel scheme ended up taking too much time. So I decided to break the problem up a bit. Do 1 Main Loop (Samples) I decided not to combine all of the combinations; I did all except for the number of samples. Everytime I was watching the progress bar, it would slow down every once in a while. That was because the bottleneck for kernel methods is the number of samples. We have cases of 1_000 which isn't too bad, but 5_000 samples is where the methods really start to slow down. In addition, there will be a lot of memory consumption. So I decided to do a main loop through the number of samples (starting from the smallest and ending with the largest). That way, we can get the easier datasets out of the way and then work on the larger datasets later. Controlling the number of jobs. As I mentioned before, the bottleneck is the number of samples. With 5_000, this starts to eat up a lot of memory when doing this in parallel. So to prevent this I set it up such that I control the number of cores doing the processing. Like so: # Samples Cores 50 28 100 28 500 28 1_000 16 5_000 8 Appending Data Because there was a lot of data being shifted around ( \\sim 297000 \\sim 297000 parameters), the resulting dataframe which stores the experimental results is going to be huge. So I decided that for every call to the main loop, I will run append those results to a csv file and then del that dataframe to free up memory.","title":"Main Loop (Update)"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#experiment","text":"We have a lot of parameters. So we are going to run everything in parallel so that we can save time. We will do this by giving the cartesian product of our nD list of parameters. This will give us a list of tuples where each entry is a set of parameters to evaluate. The length of this list will be the total number of parameters. # create a list of all param combinations # shuffle parameters params = list ( dict_product ( parameters )) loop_params = list ( dict_product ( loop_params )) # parameters_list = list(dict_product(parameters)) n_params , n_loop_params = len ( params ), len ( loop_params ) print ( '# of Params:' , n_params , n_loop_params ) # of Params: 23100 5 from typing import Dict def step ( params : Dict , loop_param : Dict , ): # ================ # DATA # ================ dist_data = DataParams ( dataset = params [ \"dataset\" ], trial = params [ \"trial\" ], std = params [ \"std\" ], nu = params [ \"nu\" ], samples = loop_param [ \"samples\" ], dimensions = params [ \"dimensions\" ], ) # generate data inputs = dist_data . generate_data () # ======================== # Estimate Sigma # ======================== f_x = lambda x : sigma_estimate ( x , method = params [ 'sigma_estimator' ][ 0 ], percent = params [ 'sigma_estimator' ][ 1 ], heuristic = False ) # ======================== # Per Dimension # ======================== if params [ 'per_dimension' ]: sigma_X = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . X . T ] sigma_Y = [ f_x ( ifeature . reshape ( - 1 , 1 )) for ifeature in inputs . Y . T ] else : sigma_X = f_x ( inputs . X ) sigma_Y = f_x ( inputs . Y ) # ========================= # Estimate HSIC # ========================= hsic_clf = HSICModel ( kernel_X = RBF ( sigma_X ), kernel_Y = RBF ( sigma_Y ), ) score = hsic_clf . get_score ( inputs . X , inputs . Y , params [ 'scorer' ]) # ==================== # Results # ==================== # append results to dataframe results_df = pd . DataFrame ( { # Data Params \"dataset\" : [ params [ \"dataset\" ]], \"trial\" : [ params [ \"trial\" ]], \"std\" : [ params [ \"std\" ]], \"nu\" : [ params [ \"nu\" ]], \"samples\" : [ loop_param [ \"samples\" ]], \"dimensions\" : [ params [ \"dimensions\" ]], # STANDARDIZE PARSM \"standardize\" : [ params [ \"standardize\" ]], # SIGMA FORMAT PARAMS \"per_dimension\" : [ params [ \"per_dimension\" ]], # SIGMA METHOD PARAMS \"sigma_method\" : [ params [ \"sigma_estimator\" ][ 0 ]], \"sigma_percent\" : [ params [ \"sigma_estimator\" ][ 1 ]], \"sigma_X\" : [ sigma_X ], \"sigma_Y\" : [ sigma_Y ], # HSIC Params \"scorer\" : [ params [ \"scorer\" ]], \"score\" : [ score ], \"mutual_info\" : [ inputs . mutual_info ], } ) return results_df","title":"Experiment"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#test-single-step","text":"results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = loop_params [ 0 ], ) [Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 3.8s [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 5.6s [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 7.7s [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 10.5s [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 13.8s [Parallel(n_jobs=-1)]: Done 3144 tasks | elapsed: 17.8s [Parallel(n_jobs=-1)]: Done 3994 tasks | elapsed: 22.3s [Parallel(n_jobs=-1)]: Done 4944 tasks | elapsed: 26.9s [Parallel(n_jobs=-1)]: Done 6640 tasks | elapsed: 32.8s [Parallel(n_jobs=-1)]: Done 8940 tasks | elapsed: 40.0s [Parallel(n_jobs=-1)]: Done 11440 tasks | elapsed: 47.6s --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) <ipython-input-35-3df2e8759391> in <module> ----> 1 results_df = run_parallel_step( 2 exp_step = step , 3 parameters = params , 4 n_jobs = - 1 , 5 verbose = 1 , ~/projects/2019_hsic_align/notebooks/4_distributions/../../src/experiments/utils.py in run_parallel_step (exp_step, parameters, n_jobs, verbose, **kwargs) 96 97 # loop through parameters ---> 98 results = Parallel(n_jobs=n_jobs, verbose=verbose)( 99 delayed ( exp_step ) ( iparam , ** kwargs ) for iparam in parameters 100 ) ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py in __call__ (self, iterable) 1015 1016 with self . _backend . retrieval_context ( ) : -> 1017 self . retrieve ( ) 1018 # Make sure that we get a last message telling us we are done 1019 elapsed_time = time . time ( ) - self . _start_time ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/parallel.py in retrieve (self) 907 try : 908 if getattr ( self . _backend , 'supports_timeout' , False ) : --> 909 self . _output . extend ( job . get ( timeout = self . timeout ) ) 910 else : 911 self . _output . extend ( job . get ( ) ) ~/.conda/envs/hsic_align/lib/python3.8/site-packages/joblib/_parallel_backends.py in wrap_future_result (future, timeout) 560 AsyncResults.get from multiprocessing.\"\"\" 561 try : --> 562 return future . result ( timeout = timeout ) 563 except LokyTimeoutError : 564 raise TimeoutError ( ) ~/.conda/envs/hsic_align/lib/python3.8/concurrent/futures/_base.py in result (self, timeout) 432 return self . __get_result ( ) 433 --> 434 self . _condition . wait ( timeout ) 435 436 if self . _state in [ CANCELLED , CANCELLED_AND_NOTIFIED ] : ~/.conda/envs/hsic_align/lib/python3.8/threading.py in wait (self, timeout) 300 try : # restore state no matter what (e.g., KeyboardInterrupt) 301 if timeout is None : --> 302 waiter . acquire ( ) 303 gotit = True 304 else : KeyboardInterrupt : results_df . tail () --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-36-5747df3a89d5> in <module> ----> 1 results_df . tail ( ) NameError : name 'results_df' is not defined # save results save_name = \"test\" dataset = 'gaussian' header = True mode = \"w\" with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) # get params # params, loop_params = get_parameters(args.dataset, njobs=args.njobs) save_name = \"test\" dataset = 'gaussian' # initialize datast header = True mode = \"w\" with tqdm ( loop_params ) as pbar : for iparam in pbar : pbar . set_description ( f \"# Samples: { iparam [ 'samples' ] } , Tasks: { len ( params ) } \" ) results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = iparam , ) # concat current results results_df = pd . concat ( results_df , ignore_index = True ) # save results with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) header = False mode = \"a\" del results_df break # Samples: 50, Tasks: 23100: 0%| | 0/5 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.0s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 4.8s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.5s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 10.7s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 14.7s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.4s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 24.9s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 30.6s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 37.5s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 43.8s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 51.4s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 50, Tasks: 23100: 0%| | 0/5 [01:27<?, ?it/s] step_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 0 gauss 1 1 1 50 2 True True True median 0.1 [0.1686566316684468, 0.14612229488391992] [0.1589719949193001, 0.1680410083908699] hsic 0.019091 0.0","title":"Test - Single Step"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#test-full-loop","text":"# get params # params, loop_params = get_parameters(args.dataset, njobs=args.njobs) save_name = \"test_full\" dataset = 'gaussian' # initialize dataset header = True mode = \"w\" with tqdm ( loop_params ) as pbar : for iparam in pbar : pbar . set_description ( f \"# Samples: { iparam [ 'samples' ] } , Tasks: { len ( params ) } \" ) results_df = run_parallel_step ( exp_step = step , parameters = params , n_jobs =- 1 , verbose = 1 , loop_param = iparam , ) # concat current results results_df = pd . concat ( results_df , ignore_index = True ) # save results with open ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" , mode ) as f : results_df . to_csv ( f , header = header ) header = False mode = \"a\" # Samples: 50, Tasks: 23100: 0%| | 0/5 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.0s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.6s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 4.7s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.4s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 10.7s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 14.9s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.5s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 24.8s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 30.7s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 37.1s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 44.5s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 52.6s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 100, Tasks: 23100: 20%|\u2588\u2588 | 1/5 [01:27<05:51, 87.81s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 232 tasks | elapsed: 1.2s [Parallel(n_jobs=-1)]: Done 732 tasks | elapsed: 2.7s [Parallel(n_jobs=-1)]: Done 1432 tasks | elapsed: 5.0s [Parallel(n_jobs=-1)]: Done 2332 tasks | elapsed: 7.8s [Parallel(n_jobs=-1)]: Done 3432 tasks | elapsed: 11.4s [Parallel(n_jobs=-1)]: Done 4732 tasks | elapsed: 15.3s [Parallel(n_jobs=-1)]: Done 6232 tasks | elapsed: 19.8s [Parallel(n_jobs=-1)]: Done 7932 tasks | elapsed: 25.6s [Parallel(n_jobs=-1)]: Done 9832 tasks | elapsed: 31.7s [Parallel(n_jobs=-1)]: Done 11932 tasks | elapsed: 38.3s [Parallel(n_jobs=-1)]: Done 14232 tasks | elapsed: 45.4s [Parallel(n_jobs=-1)]: Done 16732 tasks | elapsed: 53.3s [Parallel(n_jobs=-1)]: Done 19432 tasks | elapsed: 1.0min [Parallel(n_jobs=-1)]: Done 22332 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 1.2min finished # Samples: 500, Tasks: 23100: 40%|\u2588\u2588\u2588\u2588 | 2/5 [02:57<04:24, 88.32s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 195 tasks | elapsed: 10.0s [Parallel(n_jobs=-1)]: Done 450 tasks | elapsed: 22.8s [Parallel(n_jobs=-1)]: Done 800 tasks | elapsed: 29.2s [Parallel(n_jobs=-1)]: Done 1250 tasks | elapsed: 38.5s [Parallel(n_jobs=-1)]: Done 1800 tasks | elapsed: 59.6s [Parallel(n_jobs=-1)]: Done 2450 tasks | elapsed: 1.2min [Parallel(n_jobs=-1)]: Done 3200 tasks | elapsed: 1.5min [Parallel(n_jobs=-1)]: Done 4050 tasks | elapsed: 2.0min [Parallel(n_jobs=-1)]: Done 5000 tasks | elapsed: 2.1min [Parallel(n_jobs=-1)]: Done 6050 tasks | elapsed: 2.2min [Parallel(n_jobs=-1)]: Done 7200 tasks | elapsed: 2.6min [Parallel(n_jobs=-1)]: Done 8450 tasks | elapsed: 3.2min [Parallel(n_jobs=-1)]: Done 9800 tasks | elapsed: 3.7min [Parallel(n_jobs=-1)]: Done 11250 tasks | elapsed: 4.4min [Parallel(n_jobs=-1)]: Done 12800 tasks | elapsed: 4.8min [Parallel(n_jobs=-1)]: Done 14450 tasks | elapsed: 5.0min [Parallel(n_jobs=-1)]: Done 16200 tasks | elapsed: 5.8min [Parallel(n_jobs=-1)]: Done 18050 tasks | elapsed: 6.7min [Parallel(n_jobs=-1)]: Done 20000 tasks | elapsed: 7.4min [Parallel(n_jobs=-1)]: Done 22050 tasks | elapsed: 7.6min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 8.0min finished # Samples: 1000, Tasks: 23100: 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 3/5 [11:14<07:01, 210.85s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 27.9s [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 1.3min [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 1.9min [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 2.3min [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 3.8min [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 4.6min [Parallel(n_jobs=-1)]: Done 3144 tasks | elapsed: 5.9min [Parallel(n_jobs=-1)]: Done 3994 tasks | elapsed: 7.8min [Parallel(n_jobs=-1)]: Done 4944 tasks | elapsed: 8.0min [Parallel(n_jobs=-1)]: Done 5994 tasks | elapsed: 8.2min [Parallel(n_jobs=-1)]: Done 7144 tasks | elapsed: 9.8min [Parallel(n_jobs=-1)]: Done 8394 tasks | elapsed: 11.8min [Parallel(n_jobs=-1)]: Done 9744 tasks | elapsed: 13.8min [Parallel(n_jobs=-1)]: Done 11194 tasks | elapsed: 16.5min [Parallel(n_jobs=-1)]: Done 12744 tasks | elapsed: 17.9min [Parallel(n_jobs=-1)]: Done 14394 tasks | elapsed: 18.3min [Parallel(n_jobs=-1)]: Done 16144 tasks | elapsed: 21.6min [Parallel(n_jobs=-1)]: Done 17994 tasks | elapsed: 25.0min [Parallel(n_jobs=-1)]: Done 19944 tasks | elapsed: 27.7min [Parallel(n_jobs=-1)]: Done 21994 tasks | elapsed: 28.0min [Parallel(n_jobs=-1)]: Done 23100 out of 23100 | elapsed: 29.7min finished # Samples: 5000, Tasks: 23100: 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 4/5 [41:13<11:27, 687.29s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 28 concurrent workers. [Parallel(n_jobs=-1)]: Done 144 tasks | elapsed: 13.4min [Parallel(n_jobs=-1)]: Done 394 tasks | elapsed: 37.4min [Parallel(n_jobs=-1)]: Done 744 tasks | elapsed: 53.4min [Parallel(n_jobs=-1)]: Done 1194 tasks | elapsed: 65.1min [Parallel(n_jobs=-1)]: Done 1744 tasks | elapsed: 108.6min [Parallel(n_jobs=-1)]: Done 2394 tasks | elapsed: 130.8min results_df = pd . read_csv ( f \" { RES_PATH }{ save_name } _ { dataset } .csv\" ) results_df = results_df . loc [:, ~ results_df . columns . str . match ( 'Unnamed' )] results_df = results_df . astype ( object ) . replace ( np . nan , 'None' ) results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 115495 gauss 5 11 1 5000 2 False False median None 2.596209486629066 2.533566551925972 cka 0.408078 0.390005 115496 gauss 5 11 1 5000 3 False False median None 4.114994392992097 4.495821703399767 cka 0.453781 0.377389 115497 gauss 5 11 1 5000 10 False False median None 14.882197509532734 15.57776152697343 cka 0.752609 0.929178 115498 gauss 5 11 1 5000 50 False False median None 67.1011981827926 65.92873890142732 cka 0.969342 4.052644 115499 gauss 5 11 1 5000 100 False False median None 129.70371717695562 129.7259155663332 cka 0.985882 7.938746 results_df . sigma_percent . unique () . tolist () [15.0, 20.0, 50.0, 80.0, 'None']","title":"Test - Full Loop"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#visualization","text":"Indiscrimenant Points - Dimensions, Samples Method - colors Standardize - type Correlation (MI, Score)","title":"Visualization"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#method-i-scott-silverman","text":"# segment scott sub_df = results_df [ results_df [ \"sigma_method\" ] == 'silverman' ] # sub_df = sub_df[sub_df[\"sigma_percent\"] == 'None'] # dropcolumns with dimensions and samples sub_df = sub_df . drop ([ 'dimensions' , 'samples' , 'std' , 'nu' , 'trial' , 'dataset' , 'sigma_X' , 'sigma_Y' ], axis = 1 ) sub_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } standardize per_dimension sigma_method sigma_percent scorer score mutual_info 114395 False False silverman None cka 0.044627 0.390005 114396 False False silverman None cka 0.065012 0.377389 114397 False False silverman None cka 0.966685 0.929178 114398 False False silverman None cka 1.000000 4.052644 114399 False False silverman None cka 1.000000 7.938746","title":"Method I - Scott, Silverman"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#convenience-functions","text":"","title":"Convenience Functions"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#i-subsetting-the-dataframe","text":"We want to be able to query the dataframe with multiple queries at a time. So I'll create a namedtuple which will hold the name of the column and the elements I want to access. Then I'll have a function that will take a list of these datastructures from typing import List , Optional , Union df_query = namedtuple ( 'df_query' , [ 'name' , 'elements' ]) def subset_dataframe ( df : pd . DataFrame , queries : List [ df_query ], ) -> pd . DataFrame : # copy dataframe to prevent overwriting sub_df = df . copy () # for iquery in queries : sub_df = sub_df [ sub_df [ iquery . name ] . isin ( iquery . elements )] return sub_df # subset dataframe scorer = 'hsic' hsic_data_df = subset_dataframe ( results_df , [ df_query ( 'scorer' , [ scorer ])]) hsic_data_df . head ( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 0 gauss 1 1 1 50 2 True True median 15 [0.05289913460722866, 0.046005156305852286] [0.0603301351143148, 0.06549625956610451] hsic 0.019532 0.0 1 gauss 1 1 1 50 3 True True median 15 [0.05289913460722866, 0.046005156305852286, 0.... [0.06549625956610451, 0.05939212909166344, 0.0... hsic 0.019590 0.0 # check for iscorer in [ 'hsic' , 'ka' , 'cka' ]: # subset dataframe sub_df = subset_dataframe ( results_df , [ df_query ( 'scorer' , [ iscorer ])]) # check that the only element is the one we query-ed assert sub_df . scorer . unique () . tolist () == [ iscorer ]","title":"I - Subsetting the DataFrame"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#ii-correlations","text":"I want to see the correlations between the mutual information and the score. So I'll make a dedicated function to handle that. I'll use a namedtuple to ensure that the results are a callable datastructure and immutable (cannot be overwritten). from scipy import stats from collections import namedtuple corr_stats = namedtuple ( 'corr_stats' , [ 'pearson' , 'spearman' ]) def get_correlations ( df : pd . DataFrame ): \"\"\"Inputs a dataframe and outputs the correlation between the mutual information and the score. Requires the 'mutual_info' and 'score' columns.\"\"\" # check that columns are in dataframe msg = \"No 'mutual_info' and/or 'score' column(s) found in dataframe\" assert { 'mutual_info' , \"score\" } . issubset ( df . columns ), msg # get pearson correlation corr_pear = stats . pearsonr ( df . score , df . mutual_info )[ 0 ] # get spearman correlation corr_spear = stats . spearmanr ( df . score , df . mutual_info )[ 0 ] return corr_stats ( corr_pear , corr_spear ) scorer = 'hsic' sub_df = subset_dataframe ( results_df , 'scorer' , [ scorer ]) test_corrs = get_correlations ( sub_df ) # check if output is named tuple assert isinstance ( test_corrs , corr_stats )","title":"II - Correlations"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#iii-plotting-score-vs-mi","text":"I want to plot the score versus the mutual information. This will be the plot given the data we have. There are two competing factors that we need to address: per dimension and standardization . The plots were be per method and will either address whether per dimension makes sense or per standardize. def plot_score_vs_mi ( df : pd . DataFrame , scorer : Optional [ str ] = None , # methods: List[str]=['silverman'], # percent: Optional[List[str]]=None, compare : str = 'standard' ): # copy dataframe to prevent overwriting sub_df = df . copy () # segment method if scorer is not None : sub_df = subset_dataframe ( sub_df , [ df_query ( 'scorer' , [ scorer ])]) # # get percentage (if necessary) # if percent is not None: # sub_df = df[df[\"sigma_method\"].isin(percent)] # dropcolumns with dimensions and samples sub_df = sub_df . drop ([ 'dimensions' , 'samples' , 'std' , 'nu' , 'trial' , 'dataset' , 'sigma_X' , 'sigma_Y' ], axis = 1 ) if compare == 'standard' : true_df = sub_df [ sub_df [ 'standardize' ] == True ] true_corrs = get_correlations ( true_df ) true_label = f \"Standardized, (p: { true_corrs . pearson : .2f } , sp: { true_corrs . spearman : .2f } )\" false_df = sub_df [ sub_df [ 'standardize' ] == False ] false_corrs = get_correlations ( false_df ) false_label = f \"Non-Standardized, (p: { false_corrs . pearson : .2f } , sp: { false_corrs . spearman : .2f } )\" elif compare == 'dimension' : true_df = sub_df [ sub_df [ 'per_dimension' ] == True ] true_corrs = get_correlations ( true_df ) true_label = f \"Per Dimension, (p: { true_corrs . pearson : .2f } , sp: { true_corrs . spearman : .2f } )\" false_df = sub_df [ sub_df [ 'per_dimension' ] == False ] false_corrs = get_correlations ( false_df ) false_label = f \"Same, (p: { false_corrs . pearson : .2f } , sp: { false_corrs . spearman : .2f } )\" # plot fig , ax = plt . subplots () ax . scatter ( true_df . score , true_df . mutual_info , marker = 'o' , s = 30 , label = true_label ) ax . scatter ( false_df . score , false_df . mutual_info , marker = 'x' , s = 30 , label = false_label ) ax . legend () ax . set_yscale ( 'symlog' ) ax . set_xlabel ( 'Score' ) ax . set_ylabel ( 'Mutual Information' ) # ax.set_title(f\"{scorer.upper()}\") # ax.text(0.18, 0.18, r, {'color': 'C0', 'fontsize': 16}) return fig , ax","title":"III - Plotting (score vs MI)"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#case-i-standardize-or-not","text":"# initialize list of queries queries = [] # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) # query dataframe for scott and silverman methods sigma_methods = [ 'scott' , 'silverman' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' );","title":"Case I - Standardize or Not?"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#case-ii-median-no-percent","text":"# initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 'None' ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' );","title":"Case II - Median (no percent)"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#case-iii-median-percent-50-20-60","text":"# initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # # query dataframe for hsic # scorers = ['hsic',] # queries.append(df_query('scorer', scorers)) sub_df = subset_dataframe ( results_df , queries ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'standard' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'standard' ); # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' );","title":"Case III - Median + Percent (50, 20, 60)"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#case-iv-median-standardization","text":"# initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for hsic standardize = [ True ,] queries . append ( df_query ( 'standardize' , standardize )) sub_df = subset_dataframe ( results_df , queries ) print ( sub_df . shape ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); (24750, 15)","title":"Case IV - Median + Standardization"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#case-iv-median-wo-standardization","text":"# initialize list of queries queries = [] # query dataframe for scott and silverman methods sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20 , 50 , 80 ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for hsic standardize = [ False ,] queries . append ( df_query ( 'standardize' , standardize )) sub_df = subset_dataframe ( results_df , queries ) print ( sub_df . shape ) # plot - score vs mi plot_score_vs_mi ( sub_df , scorer = 'hsic' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'cka' , compare = 'dimension' ); plot_score_vs_mi ( sub_df , scorer = 'ka' , compare = 'dimension' ); (24750, 15) import time t0 = time . time () df_ = pd . concat ( results_df , ignore_index = True ) t1 = time . time () - t0 print ( f \"Time Taken: { t1 : .2f } secs\" ) df_ . tail () Time Taken: 37.71 secs .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 59395 gauss 5 11 1 50 2 False False False median 0.9 2.88898 2.88898 cka 0.480297 0.390005 59396 gauss 5 11 1 50 3 False False False median 0.9 3.35418 3.35418 cka 0.530064 0.377389 59397 gauss 5 11 1 50 10 False False False median 0.9 5.687 5.687 cka 0.714579 0.929178 59398 gauss 5 11 1 50 50 False False False median 0.9 13.6425 13.6425 cka 0.975977 4.052644 59399 gauss 5 11 1 50 100 False False False median 0.9 19.2544 19.2544 cka 0.987792 7.938746 Note : This is another bottleneck.","title":"Case IV - Median w/o Standardization"},{"location":"notebooks/code_reviews/3.0_multivariate_dists/#appending-to-file","text":"We can use this simple pseudocode to append to a file. mode = 'a' header = False with open ( f \" { RES_PATH }{ save_name } .csv\" , mode ) as f : df . to_csv ( f , header = header ) header = True","title":"Appending to File"},{"location":"notebooks/code_reviews/4.0_best_params/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Code Review IV - Best Parameters \u00b6 This is part two of the notebook before. Code Preamble \u00b6 # toy datasets import sys from pyprojroot import here sys . path . insert ( 0 , str ( here ())) import warnings from typing import Optional , Tuple from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from src.data.distribution import DataParams , Inputs # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from src.models.dependence import HSICModel # RBIG IT measures from src.features.utils import df_query , subset_dataframe # Plotting from src.visualization.distribution import plot_scorer , plot_score_vs_mi # experiment helpers from src.experiments.utils import dict_product , run_parallel_step from tqdm import tqdm # Plotting Procedures import seaborn as sns import matplotlib import matplotlib.pyplot as plt sns . reset_defaults () # sns.set_style('whitegrid') #sns.set_context('talk') sns . set_context ( context = 'poster' , font_scale = 0.7 , rc = { 'font.family' : 'sans-serif' }) # sns.set(font='sans-serif') % matplotlib inline % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload Query Data \u00b6 DATA_PATH = \"data/results/distributions/mutual_info/\" results_df = pd . concat ([ pd . read_csv ( here () / f \" { DATA_PATH } v5_gauss.csv\" ), pd . read_csv ( here () / f \" { DATA_PATH } v5_tstudent.csv\" ) ], axis = 1 ) results_df = results_df . loc [:, ~ results_df . columns . str . match ( 'Unnamed' )] results_df = results_df . astype ( object ) . replace ( np . nan , 'None' ) /home/emmanuel/.conda/envs/hsic_align/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (12,13) have mixed types.Specify dtype option on import or set low_memory=False. has_raised = await self.run_ast_nodes(code_ast.body, cell_name, Gaussian Distribution \u00b6 # initialize list of queries queries = [] # query dataframe for median dataset_methods = [ 'gauss' ] queries . append ( df_query ( 'dataset' , dataset_methods )) # query dataframe for median sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 40. , 50. , 60. ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for RBF Kernel dimension_query = [ False ] queries . append ( df_query ( 'per_dimension' , dimension_query )) # query dataframe for HSIC scorer_query = [ 'cka' ] queries . append ( df_query ( 'scorer' , scorer_query )) sub_df = subset_dataframe ( results_df , queries ) # # plot - score vs mi # plot_score_vs_mi(sub_df, scorer='cka', compare='dimension'); sub_df . head ( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 16500 gauss 1 1 1 50 2 True False True median 40 1.9787121467565072 1.9476870941963393 cka 0.066137 0.000000 16501 gauss 1 2 1 50 2 True False True median 40 2.0194286080222534 2.0089767519975203 cka 0.052168 0.002053 16502 gauss 1 3 1 50 2 True False True median 40 2.0088368919994264 2.006548619075144 cka 0.046326 0.007718 Extreme Values \u00b6 So there are a few extreme values (i.e. values that appear to fall outside of the trend). I would like to highlight in what settings they were found. # necessary columns for plotting columns = [ 'score' , 'mutual_info' , 'dimensions' , 'samples' ] sub_df = sub_df [ columns ] # change column types to categorical for plotting ind_cols = [ 'samples' , 'dimensions' ] sub_df [ ind_cols ] = sub_df [ ind_cols ] . astype ( 'category' ) # Plot fig , ax = plt . subplots ( ncols = 2 , figsize = ( 12 , 5 )) sns . scatterplot ( ax = ax [ 0 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'samples' , ) ax [ 0 ] . set_title ( \"Comparing Samples\" ) ax [ 0 ] . set_xlabel ( 'CKA Score' ) ax [ 0 ] . set_ylabel ( 'Mutual Information' ) ax [ 0 ] . set_yscale ( 'symlog' ) sns . scatterplot ( ax = ax [ 1 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'dimensions' , ) ax [ 1 ] . set_title ( \"Comparing Dimensions\" ) ax [ 1 ] . set_xlabel ( 'CKA Score' ) ax [ 1 ] . set_ylabel ( 'Mutual Information' ) ax [ 1 ] . set_yscale ( 'symlog' ) plt . tight_layout () plt . show () So it appears that our estimation is at it's worse when we have a setting where we have a low number of samples and a high number of dimensions when there is a low amount of mutual information. Note : I find this a bit funny because kernels are known for being good for situations with a high number of samples and a low number of dimensions. Exact Relation \u00b6 So there is a formula that describes the exact relationship between mutual information and the linear kernel for a Gaussian distribution. It's: I(\\mathbf{X;Y}) = - \\frac{1}{2} \\log(1-\\rho) I(\\mathbf{X;Y}) = - \\frac{1}{2} \\log(1-\\rho) where \\rho= \\frac{|C|}{|C_{XX}||C_{YY}|} \\rho= \\frac{|C|}{|C_{XX}||C_{YY}|} . This is essentially the closed form solution for the MI between two Gaussian distributions. And \\rho \\rho is the score that we should obtain. I didn't actually calculate the closed-form solution (although I could in the future). But I would like to see if the score that I estimated approximates the true score that we should obtain if we were to assume a Gaussian. So I'll solve this equation for \\rho \\rho and then plot my estimated \\hat{\\rho} \\hat{\\rho} . $$ \\rho = 1 - \\exp^{-2 I} $$ # calculate the real score based on the MI sub_df [ 'score_real' ] = 1 - np . exp ( - 2 * sub_df [ 'mutual_info' ]) # calculate the pearson, spearman between our estimate and the real score from scipy import stats p_score = stats . pearsonr ( sub_df [ 'score' ], sub_df [ 'score_real' ] )[ 0 ] sp_score = stats . spearmanr ( sub_df [ 'score' ], sub_df [ 'score_real' ] )[ 0 ] # Plot fig , ax = plt . subplots ( ncols = 1 , figsize = ( 7 , 7 )) sns . regplot ( ax = ax , x = 'score_real' , y = 'score' , data = sub_df , marker = '.' , color = 'black' , scatter_kws = { 'color' : 'lightblue' , 'label' : 'Points' } ) ax . set_title ( \"Approximate Relationship\" ) ax . set_xlabel ( 'CKA Score' ) ax . set_ylabel ( 'True Score' ) # ax.set_ylim([0.0, 8]) # Plot I # ax.plot(np.sort(sub_df['score']), sub_df['mi_kernel'], # linewidth=3, color='black', label='Fitted Curve') ax . legend ([ 'Regression Line' , 'Points' ]) ax . annotate ( f \"Pearson: { p_score : .2f } \\n Spearman: { sp_score : .2f } \" , ( - 0.025 , . 75 ), fontsize = 15 ) plt . show () So, there is clearly a relationship between the two curves. And you won't find any other curve with any other score. So for approximating mutual information, this would be the estimate that you would want to use. T-Student \u00b6 So I expect that the T-student will not necessarily be the best estimate. # initialize list of queries queries = [] # query dataframe for median dataset_methods = [ 'tstudent' ] queries . append ( df_query ( 'dataset' , dataset_methods )) # query dataframe for median sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20. ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for RBF Kernel dimension_query = [ True ] queries . append ( df_query ( 'per_dimension' , dimension_query )) # query dataframe for HSIC scorer_query = [ 'cka' ] queries . append ( df_query ( 'scorer' , scorer_query )) sub_df = subset_dataframe ( results_df , queries ) # # plot - score vs mi # plot_score_vs_mi(sub_df, scorer='cka', compare='dimension'); # necessary columns for plotting columns = [ 'score' , 'mutual_info' , 'dimensions' , 'samples' ] sub_df = sub_df [ columns ] # change column types to categorical for plotting ind_cols = [ 'samples' , 'dimensions' ] sub_df [ ind_cols ] = sub_df [ ind_cols ] . astype ( 'category' ) # Plot fig , ax = plt . subplots ( ncols = 2 , figsize = ( 12 , 5 )) sns . scatterplot ( ax = ax [ 0 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'samples' , ) ax [ 0 ] . set_title ( \"Comparing Samples\" ) ax [ 0 ] . set_xlabel ( 'CKA Score' ) ax [ 0 ] . set_ylabel ( 'Mutual Information' ) ax [ 0 ] . set_yscale ( 'symlog' ) sns . scatterplot ( ax = ax [ 1 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'dimensions' , ) ax [ 1 ] . set_title ( \"Comparing Dimensions\" ) ax [ 1 ] . set_xlabel ( 'CKA Score' ) ax [ 1 ] . set_ylabel ( 'Mutual Information' ) ax [ 1 ] . set_yscale ( 'symlog' ) plt . tight_layout () plt . show ()","title":"4.0 best params"},{"location":"notebooks/code_reviews/4.0_best_params/#code-review-iv-best-parameters","text":"This is part two of the notebook before.","title":"Code Review IV - Best Parameters"},{"location":"notebooks/code_reviews/4.0_best_params/#code-preamble","text":"# toy datasets import sys from pyprojroot import here sys . path . insert ( 0 , str ( here ())) import warnings from typing import Optional , Tuple from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from src.data.distribution import DataParams , Inputs # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from src.models.dependence import HSICModel # RBIG IT measures from src.features.utils import df_query , subset_dataframe # Plotting from src.visualization.distribution import plot_scorer , plot_score_vs_mi # experiment helpers from src.experiments.utils import dict_product , run_parallel_step from tqdm import tqdm # Plotting Procedures import seaborn as sns import matplotlib import matplotlib.pyplot as plt sns . reset_defaults () # sns.set_style('whitegrid') #sns.set_context('talk') sns . set_context ( context = 'poster' , font_scale = 0.7 , rc = { 'font.family' : 'sans-serif' }) # sns.set(font='sans-serif') % matplotlib inline % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload","title":"Code Preamble"},{"location":"notebooks/code_reviews/4.0_best_params/#query-data","text":"DATA_PATH = \"data/results/distributions/mutual_info/\" results_df = pd . concat ([ pd . read_csv ( here () / f \" { DATA_PATH } v5_gauss.csv\" ), pd . read_csv ( here () / f \" { DATA_PATH } v5_tstudent.csv\" ) ], axis = 1 ) results_df = results_df . loc [:, ~ results_df . columns . str . match ( 'Unnamed' )] results_df = results_df . astype ( object ) . replace ( np . nan , 'None' ) /home/emmanuel/.conda/envs/hsic_align/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (12,13) have mixed types.Specify dtype option on import or set low_memory=False. has_raised = await self.run_ast_nodes(code_ast.body, cell_name,","title":"Query Data"},{"location":"notebooks/code_reviews/4.0_best_params/#gaussian-distribution","text":"# initialize list of queries queries = [] # query dataframe for median dataset_methods = [ 'gauss' ] queries . append ( df_query ( 'dataset' , dataset_methods )) # query dataframe for median sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 40. , 50. , 60. ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for RBF Kernel dimension_query = [ False ] queries . append ( df_query ( 'per_dimension' , dimension_query )) # query dataframe for HSIC scorer_query = [ 'cka' ] queries . append ( df_query ( 'scorer' , scorer_query )) sub_df = subset_dataframe ( results_df , queries ) # # plot - score vs mi # plot_score_vs_mi(sub_df, scorer='cka', compare='dimension'); sub_df . head ( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 16500 gauss 1 1 1 50 2 True False True median 40 1.9787121467565072 1.9476870941963393 cka 0.066137 0.000000 16501 gauss 1 2 1 50 2 True False True median 40 2.0194286080222534 2.0089767519975203 cka 0.052168 0.002053 16502 gauss 1 3 1 50 2 True False True median 40 2.0088368919994264 2.006548619075144 cka 0.046326 0.007718","title":"Gaussian Distribution"},{"location":"notebooks/code_reviews/4.0_best_params/#extreme-values","text":"So there are a few extreme values (i.e. values that appear to fall outside of the trend). I would like to highlight in what settings they were found. # necessary columns for plotting columns = [ 'score' , 'mutual_info' , 'dimensions' , 'samples' ] sub_df = sub_df [ columns ] # change column types to categorical for plotting ind_cols = [ 'samples' , 'dimensions' ] sub_df [ ind_cols ] = sub_df [ ind_cols ] . astype ( 'category' ) # Plot fig , ax = plt . subplots ( ncols = 2 , figsize = ( 12 , 5 )) sns . scatterplot ( ax = ax [ 0 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'samples' , ) ax [ 0 ] . set_title ( \"Comparing Samples\" ) ax [ 0 ] . set_xlabel ( 'CKA Score' ) ax [ 0 ] . set_ylabel ( 'Mutual Information' ) ax [ 0 ] . set_yscale ( 'symlog' ) sns . scatterplot ( ax = ax [ 1 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'dimensions' , ) ax [ 1 ] . set_title ( \"Comparing Dimensions\" ) ax [ 1 ] . set_xlabel ( 'CKA Score' ) ax [ 1 ] . set_ylabel ( 'Mutual Information' ) ax [ 1 ] . set_yscale ( 'symlog' ) plt . tight_layout () plt . show () So it appears that our estimation is at it's worse when we have a setting where we have a low number of samples and a high number of dimensions when there is a low amount of mutual information. Note : I find this a bit funny because kernels are known for being good for situations with a high number of samples and a low number of dimensions.","title":"Extreme Values"},{"location":"notebooks/code_reviews/4.0_best_params/#exact-relation","text":"So there is a formula that describes the exact relationship between mutual information and the linear kernel for a Gaussian distribution. It's: I(\\mathbf{X;Y}) = - \\frac{1}{2} \\log(1-\\rho) I(\\mathbf{X;Y}) = - \\frac{1}{2} \\log(1-\\rho) where \\rho= \\frac{|C|}{|C_{XX}||C_{YY}|} \\rho= \\frac{|C|}{|C_{XX}||C_{YY}|} . This is essentially the closed form solution for the MI between two Gaussian distributions. And \\rho \\rho is the score that we should obtain. I didn't actually calculate the closed-form solution (although I could in the future). But I would like to see if the score that I estimated approximates the true score that we should obtain if we were to assume a Gaussian. So I'll solve this equation for \\rho \\rho and then plot my estimated \\hat{\\rho} \\hat{\\rho} . $$ \\rho = 1 - \\exp^{-2 I} $$ # calculate the real score based on the MI sub_df [ 'score_real' ] = 1 - np . exp ( - 2 * sub_df [ 'mutual_info' ]) # calculate the pearson, spearman between our estimate and the real score from scipy import stats p_score = stats . pearsonr ( sub_df [ 'score' ], sub_df [ 'score_real' ] )[ 0 ] sp_score = stats . spearmanr ( sub_df [ 'score' ], sub_df [ 'score_real' ] )[ 0 ] # Plot fig , ax = plt . subplots ( ncols = 1 , figsize = ( 7 , 7 )) sns . regplot ( ax = ax , x = 'score_real' , y = 'score' , data = sub_df , marker = '.' , color = 'black' , scatter_kws = { 'color' : 'lightblue' , 'label' : 'Points' } ) ax . set_title ( \"Approximate Relationship\" ) ax . set_xlabel ( 'CKA Score' ) ax . set_ylabel ( 'True Score' ) # ax.set_ylim([0.0, 8]) # Plot I # ax.plot(np.sort(sub_df['score']), sub_df['mi_kernel'], # linewidth=3, color='black', label='Fitted Curve') ax . legend ([ 'Regression Line' , 'Points' ]) ax . annotate ( f \"Pearson: { p_score : .2f } \\n Spearman: { sp_score : .2f } \" , ( - 0.025 , . 75 ), fontsize = 15 ) plt . show () So, there is clearly a relationship between the two curves. And you won't find any other curve with any other score. So for approximating mutual information, this would be the estimate that you would want to use.","title":"Exact Relation"},{"location":"notebooks/code_reviews/4.0_best_params/#t-student","text":"So I expect that the T-student will not necessarily be the best estimate. # initialize list of queries queries = [] # query dataframe for median dataset_methods = [ 'tstudent' ] queries . append ( df_query ( 'dataset' , dataset_methods )) # query dataframe for median sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 20. ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for RBF Kernel dimension_query = [ True ] queries . append ( df_query ( 'per_dimension' , dimension_query )) # query dataframe for HSIC scorer_query = [ 'cka' ] queries . append ( df_query ( 'scorer' , scorer_query )) sub_df = subset_dataframe ( results_df , queries ) # # plot - score vs mi # plot_score_vs_mi(sub_df, scorer='cka', compare='dimension'); # necessary columns for plotting columns = [ 'score' , 'mutual_info' , 'dimensions' , 'samples' ] sub_df = sub_df [ columns ] # change column types to categorical for plotting ind_cols = [ 'samples' , 'dimensions' ] sub_df [ ind_cols ] = sub_df [ ind_cols ] . astype ( 'category' ) # Plot fig , ax = plt . subplots ( ncols = 2 , figsize = ( 12 , 5 )) sns . scatterplot ( ax = ax [ 0 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'samples' , ) ax [ 0 ] . set_title ( \"Comparing Samples\" ) ax [ 0 ] . set_xlabel ( 'CKA Score' ) ax [ 0 ] . set_ylabel ( 'Mutual Information' ) ax [ 0 ] . set_yscale ( 'symlog' ) sns . scatterplot ( ax = ax [ 1 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'dimensions' , ) ax [ 1 ] . set_title ( \"Comparing Dimensions\" ) ax [ 1 ] . set_xlabel ( 'CKA Score' ) ax [ 1 ] . set_ylabel ( 'Mutual Information' ) ax [ 1 ] . set_yscale ( 'symlog' ) plt . tight_layout () plt . show ()","title":"T-Student"},{"location":"notebooks/code_reviews/5.0_fitting_mi/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Code Review V - Fitting MI \u00b6 In this code review, we're going to be reviewing how we can try to fit a curve for the relationship between mutual information and the centered kernel alignment (CKA) scorer. Code Preamble \u00b6 # toy datasets import sys from pyprojroot import here sys . path . insert ( 0 , str ( here ())) import warnings from typing import Optional , Tuple from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from src.data.distribution import DataParams , Inputs # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from src.models.dependence import HSICModel # RBIG IT measures from src.features.utils import df_query , subset_dataframe # Plotting from src.visualization.distribution import plot_scorer , plot_score_vs_mi # experiment helpers from src.experiments.utils import dict_product , run_parallel_step from tqdm import tqdm # Plotting Procedures import seaborn as sns import matplotlib import matplotlib.pyplot as plt sns . reset_defaults () # sns.set_style('whitegrid') #sns.set_context('talk') sns . set_context ( context = 'poster' , font_scale = 0.7 , rc = { 'font.family' : 'sans-serif' }) # sns.set(font='sans-serif') % matplotlib inline % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload Query Data \u00b6 DATA_PATH = \"data/results/distributions/mutual_info/\" results_df = pd . concat ([ pd . read_csv ( here () / f \" { DATA_PATH } v5_gauss.csv\" ), pd . read_csv ( here () / f \" { DATA_PATH } v5_tstudent.csv\" ) ], axis = 1 ) results_df = results_df . loc [:, ~ results_df . columns . str . match ( 'Unnamed' )] results_df = results_df . astype ( object ) . replace ( np . nan , 'None' ) /home/emmanuel/.conda/envs/hsic_align/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (12,13) have mixed types.Specify dtype option on import or set low_memory=False. has_raised = await self.run_ast_nodes(code_ast.body, cell_name, Gaussian Distribution \u00b6 # initialize list of queries queries = [] # query dataframe for median dataset_methods = [ 'gauss' ] queries . append ( df_query ( 'dataset' , dataset_methods )) # query dataframe for median sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 40. , 50. , 60. ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for RBF Kernel dimension_query = [ False ] queries . append ( df_query ( 'per_dimension' , dimension_query )) # query dataframe for HSIC scorer_query = [ 'cka' ] queries . append ( df_query ( 'scorer' , scorer_query )) sub_df = subset_dataframe ( results_df , queries ) # # plot - score vs mi # plot_score_vs_mi(sub_df, scorer='cka', compare='dimension'); sub_df . head ( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 16500 gauss 1 1 1 50 2 True False True median 40 1.9787121467565072 1.9476870941963393 cka 0.066137 0.000000 16501 gauss 1 2 1 50 2 True False True median 40 2.0194286080222534 2.0089767519975203 cka 0.052168 0.002053 16502 gauss 1 3 1 50 2 True False True median 40 2.0088368919994264 2.006548619075144 cka 0.046326 0.007718 Extreme Values \u00b6 So there are a few extreme values (i.e. values that appear to fall outside of the trend). I would like to highlight in what settings they were found. # necessary columns for plotting columns = [ 'score' , 'mutual_info' , 'dimensions' , 'samples' ] sub_df = sub_df [ columns ] # change column types to categorical for plotting ind_cols = [ 'samples' , 'dimensions' ] sub_df [ ind_cols ] = sub_df [ ind_cols ] . astype ( 'category' ) # Plot fig , ax = plt . subplots ( ncols = 2 , figsize = ( 12 , 5 )) sns . scatterplot ( ax = ax [ 0 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'samples' , ) ax [ 0 ] . set_title ( \"Comparing Samples\" ) ax [ 0 ] . set_xlabel ( 'CKA Score' ) ax [ 0 ] . set_ylabel ( 'Mutual Information' ) ax [ 0 ] . set_yscale ( 'symlog' ) sns . scatterplot ( ax = ax [ 1 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'dimensions' , ) ax [ 1 ] . set_title ( \"Comparing Dimensions\" ) ax [ 1 ] . set_xlabel ( 'CKA Score' ) ax [ 1 ] . set_ylabel ( 'Mutual Information' ) ax [ 1 ] . set_yscale ( 'symlog' ) plt . tight_layout () plt . show () So it appears that our estimation is at it's worse when we have a setting where we have a low number of samples and a high number of dimensions when there is a low amount of mutual information. Note : I find this a bit funny because kernels are known for being good for situations with a high number of samples and a low number of dimensions. Exact Relation \u00b6 So there is a formula that describes the exact relationship between mutual information and the linear kernel for a Gaussian distribution. It's: I(\\mathbf{X;Y}) = - \\frac{1}{2} \\log(1-\\rho) I(\\mathbf{X;Y}) = - \\frac{1}{2} \\log(1-\\rho) where \\rho= \\frac{|C|}{|C_{XX}||C_{YY}|} \\rho= \\frac{|C|}{|C_{XX}||C_{YY}|} . This is essentially the closed form solution for the MI between two Gaussian distributions. And \\rho \\rho is the score that we should obtain. I didn't actually calculate the closed-form solution (although I could in the future). But I would like to see if the score that I estimated approximates the true score that we should obtain if we were to assume a Gaussian. So I'll solve this equation for \\rho \\rho and then plot my estimated \\hat{\\rho} \\hat{\\rho} . $$ \\rho = 1 - \\exp^{-2 I} $$ # calculate the real score based on the MI sub_df [ 'score_real' ] = 1 - np . exp ( - 2 * sub_df [ 'mutual_info' ]) # calculate the pearson, spearman between our estimate and the real score from scipy import stats p_score = stats . pearsonr ( sub_df [ 'score' ], sub_df [ 'score_real' ] )[ 0 ] sp_score = stats . spearmanr ( sub_df [ 'score' ], sub_df [ 'score_real' ] )[ 0 ] # Plot fig , ax = plt . subplots ( ncols = 1 , figsize = ( 7 , 7 )) sns . regplot ( ax = ax , x = 'score_real' , y = 'score' , data = sub_df , marker = '.' , color = 'black' , scatter_kws = { 'color' : 'lightblue' , 'label' : 'Points' } ) ax . set_title ( \"Approximate Relationship\" ) ax . set_xlabel ( 'CKA Score' ) ax . set_ylabel ( 'True Score' ) # ax.set_ylim([0.0, 8]) # Plot I # ax.plot(np.sort(sub_df['score']), sub_df['mi_kernel'], # linewidth=3, color='black', label='Fitted Curve') ax . legend ([ 'Regression Line' , 'Points' ]) ax . annotate ( f \"Pearson: { p_score : .2f } \\n Spearman: { sp_score : .2f } \" , ( - 0.025 , . 75 ), fontsize = 15 ) plt . show () So, there is clearly a relationship between the two curves. And you won't find any other curve with any other score. So for approximating mutual information, this would be the estimate that you would want to use.","title":"5.0 fitting mi"},{"location":"notebooks/code_reviews/5.0_fitting_mi/#code-review-v-fitting-mi","text":"In this code review, we're going to be reviewing how we can try to fit a curve for the relationship between mutual information and the centered kernel alignment (CKA) scorer.","title":"Code Review V - Fitting MI"},{"location":"notebooks/code_reviews/5.0_fitting_mi/#code-preamble","text":"# toy datasets import sys from pyprojroot import here sys . path . insert ( 0 , str ( here ())) import warnings from typing import Optional , Tuple from tqdm import tqdm import random import pandas as pd import numpy as np import argparse from sklearn.utils import check_random_state # toy datasets from src.data.distribution import DataParams , Inputs # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from src.models.dependence import HSICModel # RBIG IT measures from src.features.utils import df_query , subset_dataframe # Plotting from src.visualization.distribution import plot_scorer , plot_score_vs_mi # experiment helpers from src.experiments.utils import dict_product , run_parallel_step from tqdm import tqdm # Plotting Procedures import seaborn as sns import matplotlib import matplotlib.pyplot as plt sns . reset_defaults () # sns.set_style('whitegrid') #sns.set_context('talk') sns . set_context ( context = 'poster' , font_scale = 0.7 , rc = { 'font.family' : 'sans-serif' }) # sns.set(font='sans-serif') % matplotlib inline % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload","title":"Code Preamble"},{"location":"notebooks/code_reviews/5.0_fitting_mi/#query-data","text":"DATA_PATH = \"data/results/distributions/mutual_info/\" results_df = pd . concat ([ pd . read_csv ( here () / f \" { DATA_PATH } v5_gauss.csv\" ), pd . read_csv ( here () / f \" { DATA_PATH } v5_tstudent.csv\" ) ], axis = 1 ) results_df = results_df . loc [:, ~ results_df . columns . str . match ( 'Unnamed' )] results_df = results_df . astype ( object ) . replace ( np . nan , 'None' ) /home/emmanuel/.conda/envs/hsic_align/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (12,13) have mixed types.Specify dtype option on import or set low_memory=False. has_raised = await self.run_ast_nodes(code_ast.body, cell_name,","title":"Query Data"},{"location":"notebooks/code_reviews/5.0_fitting_mi/#gaussian-distribution","text":"# initialize list of queries queries = [] # query dataframe for median dataset_methods = [ 'gauss' ] queries . append ( df_query ( 'dataset' , dataset_methods )) # query dataframe for median sigma_methods = [ 'median' ] queries . append ( df_query ( 'sigma_method' , sigma_methods )) # query dataframe for scott and silverman methods sigma_percents = [ 40. , 50. , 60. ] queries . append ( df_query ( 'sigma_percent' , sigma_percents )) # query dataframe for RBF Kernel dimension_query = [ False ] queries . append ( df_query ( 'per_dimension' , dimension_query )) # query dataframe for HSIC scorer_query = [ 'cka' ] queries . append ( df_query ( 'scorer' , scorer_query )) sub_df = subset_dataframe ( results_df , queries ) # # plot - score vs mi # plot_score_vs_mi(sub_df, scorer='cka', compare='dimension'); sub_df . head ( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset trial std nu samples dimensions standardize per_dimension separate_scales sigma_method sigma_percent sigma_X sigma_Y scorer score mutual_info 16500 gauss 1 1 1 50 2 True False True median 40 1.9787121467565072 1.9476870941963393 cka 0.066137 0.000000 16501 gauss 1 2 1 50 2 True False True median 40 2.0194286080222534 2.0089767519975203 cka 0.052168 0.002053 16502 gauss 1 3 1 50 2 True False True median 40 2.0088368919994264 2.006548619075144 cka 0.046326 0.007718","title":"Gaussian Distribution"},{"location":"notebooks/code_reviews/5.0_fitting_mi/#extreme-values","text":"So there are a few extreme values (i.e. values that appear to fall outside of the trend). I would like to highlight in what settings they were found. # necessary columns for plotting columns = [ 'score' , 'mutual_info' , 'dimensions' , 'samples' ] sub_df = sub_df [ columns ] # change column types to categorical for plotting ind_cols = [ 'samples' , 'dimensions' ] sub_df [ ind_cols ] = sub_df [ ind_cols ] . astype ( 'category' ) # Plot fig , ax = plt . subplots ( ncols = 2 , figsize = ( 12 , 5 )) sns . scatterplot ( ax = ax [ 0 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'samples' , ) ax [ 0 ] . set_title ( \"Comparing Samples\" ) ax [ 0 ] . set_xlabel ( 'CKA Score' ) ax [ 0 ] . set_ylabel ( 'Mutual Information' ) ax [ 0 ] . set_yscale ( 'symlog' ) sns . scatterplot ( ax = ax [ 1 ], x = 'score' , y = 'mutual_info' , data = sub_df , marker = '.' , hue = 'dimensions' , ) ax [ 1 ] . set_title ( \"Comparing Dimensions\" ) ax [ 1 ] . set_xlabel ( 'CKA Score' ) ax [ 1 ] . set_ylabel ( 'Mutual Information' ) ax [ 1 ] . set_yscale ( 'symlog' ) plt . tight_layout () plt . show () So it appears that our estimation is at it's worse when we have a setting where we have a low number of samples and a high number of dimensions when there is a low amount of mutual information. Note : I find this a bit funny because kernels are known for being good for situations with a high number of samples and a low number of dimensions.","title":"Extreme Values"},{"location":"notebooks/code_reviews/5.0_fitting_mi/#exact-relation","text":"So there is a formula that describes the exact relationship between mutual information and the linear kernel for a Gaussian distribution. It's: I(\\mathbf{X;Y}) = - \\frac{1}{2} \\log(1-\\rho) I(\\mathbf{X;Y}) = - \\frac{1}{2} \\log(1-\\rho) where \\rho= \\frac{|C|}{|C_{XX}||C_{YY}|} \\rho= \\frac{|C|}{|C_{XX}||C_{YY}|} . This is essentially the closed form solution for the MI between two Gaussian distributions. And \\rho \\rho is the score that we should obtain. I didn't actually calculate the closed-form solution (although I could in the future). But I would like to see if the score that I estimated approximates the true score that we should obtain if we were to assume a Gaussian. So I'll solve this equation for \\rho \\rho and then plot my estimated \\hat{\\rho} \\hat{\\rho} . $$ \\rho = 1 - \\exp^{-2 I} $$ # calculate the real score based on the MI sub_df [ 'score_real' ] = 1 - np . exp ( - 2 * sub_df [ 'mutual_info' ]) # calculate the pearson, spearman between our estimate and the real score from scipy import stats p_score = stats . pearsonr ( sub_df [ 'score' ], sub_df [ 'score_real' ] )[ 0 ] sp_score = stats . spearmanr ( sub_df [ 'score' ], sub_df [ 'score_real' ] )[ 0 ] # Plot fig , ax = plt . subplots ( ncols = 1 , figsize = ( 7 , 7 )) sns . regplot ( ax = ax , x = 'score_real' , y = 'score' , data = sub_df , marker = '.' , color = 'black' , scatter_kws = { 'color' : 'lightblue' , 'label' : 'Points' } ) ax . set_title ( \"Approximate Relationship\" ) ax . set_xlabel ( 'CKA Score' ) ax . set_ylabel ( 'True Score' ) # ax.set_ylim([0.0, 8]) # Plot I # ax.plot(np.sort(sub_df['score']), sub_df['mi_kernel'], # linewidth=3, color='black', label='Fitted Curve') ax . legend ([ 'Regression Line' , 'Points' ]) ax . annotate ( f \"Pearson: { p_score : .2f } \\n Spearman: { sp_score : .2f } \" , ( - 0.025 , . 75 ), fontsize = 15 ) plt . show () So, there is clearly a relationship between the two curves. And you won't find any other curve with any other score. So for approximating mutual information, this would be the estimate that you would want to use.","title":"Exact Relation"},{"location":"notebooks/demos/1_hsic-Copy1/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Demo I - Different Cases \u00b6 In this document, I will be looking at the motivation behind this study and why we would like to pursue this further. import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) # toy datasets from data.toy import generate_dependence_data from data.distribution import DataParams from dataclasses import dataclass # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from models.dependence import HSICModel from pysim.kernel.utils import get_init_gammas , get_gamma_grid , estimate_sigma import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-talk' ]) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/1d_dataset/demo/\" Estimating Sigma & HSIC \u00b6 def standardize_data ( X , Y , standardize : bool = False ): X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) return X , Y def get_sigma ( X , Y , method : str = 'silverman' , per_dimension : bool = False , separate_scales : bool = False ): # sigma parameters subsample = None percent = 0.20 random_state = 123 sigma_X = estimate_sigma ( X , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) sigma_Y = estimate_sigma ( Y , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) if separate_scales : sigma_X = np . mean ([ sigma_X , sigma_Y ]) sigma_Y = np . mean ([ sigma_X , sigma_Y ]) return sigma_X , sigma_Y def get_hsic ( X , Y , scorer : str , sigma_X = None , sigma_Y = None ): # init hsic model class hsic_model = HSICModel () # hsic model params if sigma_X is not None : hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( X , Y , scorer ) return hsic_val Data I - 1D Dataset \u00b6 # data params dataset = 'sine' num_points = 1000 seed = 123 noise = 0.1 # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise , noise_y = noise ) # plot fig , ax = plt . subplots () ax . scatter ( X [: 100 ,:], Y [: 100 ,:]) plt . tight_layout () fig . savefig ( FIG_PATH + f \"demo_ { dataset } .png\" ) plt . show () Let's take a simple 1D distribution: a sine curve. It is clear that there is a nonlinear relationship between them that cannot be captured (well) by linear methods. We are interested in looking at the dependence between X X and Y Y . We have the HSIC family of methods: HSIC, kernel alignment and centered kernel alignment. They are all very similar but there are some subtle differences. We will highlight them as we go through the overview. Let's take a generic approach and use the default HSIC, KA and CKA methods to try and estimate the dependence between X,Y X,Y . If we run the algorithm, we get the following results. Question I - Which Algorithm? \u00b6 results_df = pd . DataFrame () method = 'scott' per_dimension = False separate_scales = False # sigma_X, sigma_y = get_sigma( # X, Y, # method=method, # per_dimension=per_dimension, # separate_scales=separate_scales # ) method = 'default' sigma_X , sigma_Y = None , None scorer = 'hsic' results_df = results_df . append ( pd . DataFrame ({ \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q1' ]),) print ( results_df . to_markdown ()) | | hsic | ka | cka | |:---|----------:|---------:|---------:| | Q1 | 0.0582356 | 0.688475 | 0.588434 | Notice how all of the values are slightly difference. This is because of the composition of the methods. We can highlight the differences with a simple table. | **Method** | **Centered Kernel** | **Normalized** | | ------------------------- | ------------------- | -------------- | | HSIC | Yes | No | | Kernel Alignment | No | Yes | | Centered Kernel Alignment | Yes | No | So each method has a slightly different formulation but they are mostly the same. So now the next question is: how do we estimate the parameters of the kernel used? Well the default is simply \\sigma=1.0 \\sigma=1.0 but we know that this won't do as the kernel depends on the parameters of the kernel. In this case we are using the most commonly used kernel: the Radial Basis Function (RBF). Since this is a 1D example, I will use some generic estimators called the \"Silverman Rule\" and \"Scott Rule\". These are very commonly found in packages like scipy.stats.gaussian_kde or statsmodels.nonparametric.bandwidth . They are mostly used for the Kernel Density Estimation (KDE) where we need a decent parameter to approximate the kernel to get a decent density estimate. So what happens with the methods and the results? Question II - Which Parameter Estimator? \u00b6 methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = True results_df = pd . DataFrame () for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = per_dimension , separate_scales = separate_scales ) results_df = results_df . append ( pd . DataFrame ({ # \"sigma_x\": [sigma_X], # \"sigma_y\": [sigma_Y], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q2' ]),) print ( results_df . to_markdown ()) | | Estimator | hsic | ka | cka | |:---|:------------|----------:|---------:|---------:| | Q2 | scott | 0.0575482 | 0.660478 | 0.530685 | | Q2 | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q2 | median | 0.066173 | 0.702005 | 0.556274 | Question III - How do we estimate the length scale? \u00b6 Use the same length scale? Use different length scales? Use a length scale per dimension (D>1) methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] results_df = pd . DataFrame () for iscaler in separate_scales : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = per_dimension , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ # \"sigma_x\": [sigma_X], \"separate\" : [ iscaler ], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q3' ]),) print ( results_df . to_markdown ()) | | separate | Estimator | hsic | ka | cka | |:---|:-----------|:------------|----------:|---------:|---------:| | Q3 | True | scott | 0.0575482 | 0.660478 | 0.530685 | | Q3 | True | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q3 | True | median | 0.066173 | 0.702005 | 0.556274 | | Q3 | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q3 | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q3 | False | median | 0.0728568 | 0.739607 | 0.620757 | Question IV - Standardize Data? \u00b6 We could also standardize our data... This could actually change the size of each of the features which could eliminate the need to apply separate length scales. standardize = [ True , False ] methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] results_df = pd . DataFrame () for istandard in standardize : X_ , Y_ = standardize_data ( X , Y , istandard ) for iscaler in separate_scales : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X_ , Y_ , method = imethod , per_dimension = per_dimension , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"separate\" : [ iscaler ], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X_ , Y_ , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X_ , Y_ , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X_ , Y_ , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q4' ]),) print ( results_df . to_markdown ()) | | standardize | separate | Estimator | hsic | ka | cka | |:---|:--------------|:-----------|:------------|----------:|---------:|---------:| | Q4 | True | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | True | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q4 | False | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | False | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | False | median | 0.0728568 | 0.739607 | 0.620757 | Now we see that the values you get are quite different for all methods. What happens if we use different sigmas? Verdict \u00b6 Well, hard to say as it depends on the parameters. Every researcher I've met who dealt with kernel methods seems to have a suggestion that they swear by but I never know who to follow. My thoughts is that we should use dedicated sigma values per dataset however, that still leaves us with other methods that we may want to try. So we're going to repeat the same experiment but with a 2D dataset and we will see that the difficult will increase again. 2D Example \u00b6 For this experiment, we're going to take two 2D datasets each generated from a T-Student distribution. We will apply the same sequence as we did above and we will end the section by adding another option for picking the parameters. # initialize Data Params class dataset = 'tstudent' samples = 1_000 dimensions = 2 std = 5 nu = 8 trial = 1 standardize = False # initialize params example_params = DataParams ( dataset = dataset , samples = samples , dimensions = dimensions , std = std , nu = nu , trial = trial , standardize = standardize ) # generate some parameters inputs = example_params . generate_data () sns . jointplot ( x = inputs . X , y = inputs . Y ) plt . tight_layout () plt . savefig ( FIG_PATH + f \"demo_ { dataset } .png\" ) Fig I : An example 2D T-Student distribution. Question III (Revisited) - Different Length Scales? \u00b6 Now we can revisit this question because we actually could estimate a different length scale depending upon the dimensionality. One problem with scott or Silverman's method is that it takes into account the entire dataset instead of having one estimate per feature. methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] separate_dimensions = [ True , False ] results_df = pd . DataFrame () for iscaler in separate_scales : for idim in separate_dimensions : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = idim , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"Separate Dimensions\" : [ idim ], \"Separate Length Scales\" : [ iscaler ], 'Param Estimator' : [ imethod ], \"HSIC\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"KA\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"CKA\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q3' ]),) print ( results_df . to_markdown ()) Q1-Q4 \u00b6 So now, let's look at all questions for the 2D data distribution standardize = [ True , False ] methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] separate_dimensions = [ True , False ] results_df = pd . DataFrame () for istandard in standardize : X_ , Y_ = standardize_data ( X , Y , istandard ) for iscaler in separate_scales : for idim in separate_dimensions : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X_ , Y_ , method = imethod , per_dimension = idim , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"Separate Dimensions\" : [ idim ], \"Separate Length Scales\" : [ iscaler ], 'Param Estimator' : [ imethod ], \"HSIC\" : [ get_hsic ( X_ , Y_ , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"KA\" : [ get_hsic ( X_ , Y_ , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"CKA\" : [ get_hsic ( X_ , Y_ , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q4' ]),) print ( results_df . to_markdown ()) Verdict \u00b6 For the distributions, it seemed to be a little more consistent but with higher dimensions and more samples, these estimators start to fail. But then, we still don't have good alternative estimators. What Now? \u00b6 I will be looking at the following: Options Standardize Yes / No Parameter Estimator Mean, Median, Silverman, etc Center Kernel Yes / No Normalized Score Yes / No","title":"1 hsic Copy1"},{"location":"notebooks/demos/1_hsic-Copy1/#demo-i-different-cases","text":"In this document, I will be looking at the motivation behind this study and why we would like to pursue this further. import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) # toy datasets from data.toy import generate_dependence_data from data.distribution import DataParams from dataclasses import dataclass # Kernel Dependency measure from sklearn.preprocessing import StandardScaler from sklearn.gaussian_process.kernels import RBF from models.dependence import HSICModel from pysim.kernel.utils import get_init_gammas , get_gamma_grid , estimate_sigma import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-talk' ]) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload FIG_PATH = \"/home/emmanuel/projects/2019_hsic_align/results/figures/1d_dataset/demo/\"","title":"Demo I - Different Cases"},{"location":"notebooks/demos/1_hsic-Copy1/#estimating-sigma-hsic","text":"def standardize_data ( X , Y , standardize : bool = False ): X = StandardScaler () . fit_transform ( X ) Y = StandardScaler () . fit_transform ( Y ) return X , Y def get_sigma ( X , Y , method : str = 'silverman' , per_dimension : bool = False , separate_scales : bool = False ): # sigma parameters subsample = None percent = 0.20 random_state = 123 sigma_X = estimate_sigma ( X , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) sigma_Y = estimate_sigma ( Y , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) if separate_scales : sigma_X = np . mean ([ sigma_X , sigma_Y ]) sigma_Y = np . mean ([ sigma_X , sigma_Y ]) return sigma_X , sigma_Y def get_hsic ( X , Y , scorer : str , sigma_X = None , sigma_Y = None ): # init hsic model class hsic_model = HSICModel () # hsic model params if sigma_X is not None : hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( X , Y , scorer ) return hsic_val","title":"Estimating Sigma &amp; HSIC"},{"location":"notebooks/demos/1_hsic-Copy1/#data-i-1d-dataset","text":"# data params dataset = 'sine' num_points = 1000 seed = 123 noise = 0.1 # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise , noise_y = noise ) # plot fig , ax = plt . subplots () ax . scatter ( X [: 100 ,:], Y [: 100 ,:]) plt . tight_layout () fig . savefig ( FIG_PATH + f \"demo_ { dataset } .png\" ) plt . show () Let's take a simple 1D distribution: a sine curve. It is clear that there is a nonlinear relationship between them that cannot be captured (well) by linear methods. We are interested in looking at the dependence between X X and Y Y . We have the HSIC family of methods: HSIC, kernel alignment and centered kernel alignment. They are all very similar but there are some subtle differences. We will highlight them as we go through the overview. Let's take a generic approach and use the default HSIC, KA and CKA methods to try and estimate the dependence between X,Y X,Y . If we run the algorithm, we get the following results.","title":"Data I - 1D Dataset"},{"location":"notebooks/demos/1_hsic-Copy1/#question-i-which-algorithm","text":"results_df = pd . DataFrame () method = 'scott' per_dimension = False separate_scales = False # sigma_X, sigma_y = get_sigma( # X, Y, # method=method, # per_dimension=per_dimension, # separate_scales=separate_scales # ) method = 'default' sigma_X , sigma_Y = None , None scorer = 'hsic' results_df = results_df . append ( pd . DataFrame ({ \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q1' ]),) print ( results_df . to_markdown ()) | | hsic | ka | cka | |:---|----------:|---------:|---------:| | Q1 | 0.0582356 | 0.688475 | 0.588434 | Notice how all of the values are slightly difference. This is because of the composition of the methods. We can highlight the differences with a simple table. | **Method** | **Centered Kernel** | **Normalized** | | ------------------------- | ------------------- | -------------- | | HSIC | Yes | No | | Kernel Alignment | No | Yes | | Centered Kernel Alignment | Yes | No | So each method has a slightly different formulation but they are mostly the same. So now the next question is: how do we estimate the parameters of the kernel used? Well the default is simply \\sigma=1.0 \\sigma=1.0 but we know that this won't do as the kernel depends on the parameters of the kernel. In this case we are using the most commonly used kernel: the Radial Basis Function (RBF). Since this is a 1D example, I will use some generic estimators called the \"Silverman Rule\" and \"Scott Rule\". These are very commonly found in packages like scipy.stats.gaussian_kde or statsmodels.nonparametric.bandwidth . They are mostly used for the Kernel Density Estimation (KDE) where we need a decent parameter to approximate the kernel to get a decent density estimate. So what happens with the methods and the results?","title":"Question I - Which Algorithm?"},{"location":"notebooks/demos/1_hsic-Copy1/#question-ii-which-parameter-estimator","text":"methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = True results_df = pd . DataFrame () for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = per_dimension , separate_scales = separate_scales ) results_df = results_df . append ( pd . DataFrame ({ # \"sigma_x\": [sigma_X], # \"sigma_y\": [sigma_Y], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q2' ]),) print ( results_df . to_markdown ()) | | Estimator | hsic | ka | cka | |:---|:------------|----------:|---------:|---------:| | Q2 | scott | 0.0575482 | 0.660478 | 0.530685 | | Q2 | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q2 | median | 0.066173 | 0.702005 | 0.556274 |","title":"Question II - Which Parameter Estimator?"},{"location":"notebooks/demos/1_hsic-Copy1/#question-iii-how-do-we-estimate-the-length-scale","text":"Use the same length scale? Use different length scales? Use a length scale per dimension (D>1) methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] results_df = pd . DataFrame () for iscaler in separate_scales : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = per_dimension , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ # \"sigma_x\": [sigma_X], \"separate\" : [ iscaler ], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q3' ]),) print ( results_df . to_markdown ()) | | separate | Estimator | hsic | ka | cka | |:---|:-----------|:------------|----------:|---------:|---------:| | Q3 | True | scott | 0.0575482 | 0.660478 | 0.530685 | | Q3 | True | silverman | 0.0515751 | 0.6345 | 0.515583 | | Q3 | True | median | 0.066173 | 0.702005 | 0.556274 | | Q3 | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q3 | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q3 | False | median | 0.0728568 | 0.739607 | 0.620757 |","title":"Question III - How do we estimate the length scale?"},{"location":"notebooks/demos/1_hsic-Copy1/#question-iv-standardize-data","text":"We could also standardize our data... This could actually change the size of each of the features which could eliminate the need to apply separate length scales. standardize = [ True , False ] methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] results_df = pd . DataFrame () for istandard in standardize : X_ , Y_ = standardize_data ( X , Y , istandard ) for iscaler in separate_scales : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X_ , Y_ , method = imethod , per_dimension = per_dimension , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"separate\" : [ iscaler ], 'Estimator' : [ imethod ], \"hsic\" : [ get_hsic ( X_ , Y_ , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"ka\" : [ get_hsic ( X_ , Y_ , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"cka\" : [ get_hsic ( X_ , Y_ , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q4' ]),) print ( results_df . to_markdown ()) | | standardize | separate | Estimator | hsic | ka | cka | |:---|:--------------|:-----------|:------------|----------:|---------:|---------:| | Q4 | True | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | True | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | True | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | True | False | median | 0.0728568 | 0.739607 | 0.620757 | | Q4 | False | True | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | True | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | True | median | 0.0729923 | 0.74078 | 0.623443 | | Q4 | False | False | scott | 0.0601095 | 0.696988 | 0.596866 | | Q4 | False | False | silverman | 0.0524045 | 0.66827 | 0.577468 | | Q4 | False | False | median | 0.0728568 | 0.739607 | 0.620757 | Now we see that the values you get are quite different for all methods. What happens if we use different sigmas?","title":"Question IV - Standardize Data?"},{"location":"notebooks/demos/1_hsic-Copy1/#verdict","text":"Well, hard to say as it depends on the parameters. Every researcher I've met who dealt with kernel methods seems to have a suggestion that they swear by but I never know who to follow. My thoughts is that we should use dedicated sigma values per dataset however, that still leaves us with other methods that we may want to try. So we're going to repeat the same experiment but with a 2D dataset and we will see that the difficult will increase again.","title":"Verdict"},{"location":"notebooks/demos/1_hsic-Copy1/#2d-example","text":"For this experiment, we're going to take two 2D datasets each generated from a T-Student distribution. We will apply the same sequence as we did above and we will end the section by adding another option for picking the parameters. # initialize Data Params class dataset = 'tstudent' samples = 1_000 dimensions = 2 std = 5 nu = 8 trial = 1 standardize = False # initialize params example_params = DataParams ( dataset = dataset , samples = samples , dimensions = dimensions , std = std , nu = nu , trial = trial , standardize = standardize ) # generate some parameters inputs = example_params . generate_data () sns . jointplot ( x = inputs . X , y = inputs . Y ) plt . tight_layout () plt . savefig ( FIG_PATH + f \"demo_ { dataset } .png\" ) Fig I : An example 2D T-Student distribution.","title":"2D Example"},{"location":"notebooks/demos/1_hsic-Copy1/#question-iii-revisited-different-length-scales","text":"Now we can revisit this question because we actually could estimate a different length scale depending upon the dimensionality. One problem with scott or Silverman's method is that it takes into account the entire dataset instead of having one estimate per feature. methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] separate_dimensions = [ True , False ] results_df = pd . DataFrame () for iscaler in separate_scales : for idim in separate_dimensions : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X , Y , method = imethod , per_dimension = idim , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"Separate Dimensions\" : [ idim ], \"Separate Length Scales\" : [ iscaler ], 'Param Estimator' : [ imethod ], \"HSIC\" : [ get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"KA\" : [ get_hsic ( X , Y , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"CKA\" : [ get_hsic ( X , Y , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q3' ]),) print ( results_df . to_markdown ())","title":"Question III (Revisited) - Different Length Scales?"},{"location":"notebooks/demos/1_hsic-Copy1/#q1-q4","text":"So now, let's look at all questions for the 2D data distribution standardize = [ True , False ] methods = [ 'scott' , 'silverman' , 'median' ] per_dimension = False separate_scales = [ True , False ] separate_dimensions = [ True , False ] results_df = pd . DataFrame () for istandard in standardize : X_ , Y_ = standardize_data ( X , Y , istandard ) for iscaler in separate_scales : for idim in separate_dimensions : for imethod in methods : sigma_X , sigma_Y = get_sigma ( X_ , Y_ , method = imethod , per_dimension = idim , separate_scales = iscaler ) results_df = results_df . append ( pd . DataFrame ({ \"standardize\" : [ istandard ], \"Separate Dimensions\" : [ idim ], \"Separate Length Scales\" : [ iscaler ], 'Param Estimator' : [ imethod ], \"HSIC\" : [ get_hsic ( X_ , Y_ , 'hsic' , sigma_X , sigma_Y )], # Estimate HSIC \"KA\" : [ get_hsic ( X_ , Y_ , 'ka' , sigma_X , sigma_Y )], # Estimate KA \"CKA\" : [ get_hsic ( X_ , Y_ , 'cka' , sigma_X , sigma_Y )], # Estimate CKA }, index = [ 'Q4' ]),) print ( results_df . to_markdown ())","title":"Q1-Q4"},{"location":"notebooks/demos/1_hsic-Copy1/#verdict_1","text":"For the distributions, it seemed to be a little more consistent but with higher dimensions and more samples, these estimators start to fail. But then, we still don't have good alternative estimators.","title":"Verdict"},{"location":"notebooks/demos/1_hsic-Copy1/#what-now","text":"I will be looking at the following: Options Standardize Yes / No Parameter Estimator Mean, Median, Silverman, etc Center Kernel Yes / No Normalized Score Yes / No","title":"What Now?"},{"location":"notebooks/demos/2_estimate_sigma/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); HSIC and Tangent Kernel Alignment \u00b6 import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) # toy datasets from data.toy import generate_dependence_data from data.distribution import DataParams from dataclasses import dataclass # Kernel Dependency measure from models.dependence import HSICModel from pysim.kernel.utils import get_init_gammas , get_gamma_grid , estimate_sigma import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-talk' ]) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload Data I - 1D Dataset \u00b6 # data params dataset = 'sine' num_points = 1000 seed = 123 noise = 0.1 # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise , noise_y = noise ) # plot fig , ax = plt . subplots () ax . scatter ( X , Y ) plt . show () HSIC \u00b6 def get_hsic ( X , Y , scorer : str , sigma_X , sigma_Y ): # init hsic model class hsic_model = HSICModel () # hsic model params hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( inputs . X , inputs . Y , scorer ) return hsic_val Original HSIC \u00b6 # hsic value and kernel alignment score hsic_val = get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y ) print ( f \"HSIC: { hsic_val : .5f } \" ) HSIC: 0.00092 Kernel Tangent Alignment \u00b6 # hsic value and kernel alignment score tka_val = clf_hsic . score ( X , normalize = True ) print ( f \"TKA: { tka_val : .5f } \" ) TKA: 0.58843 Centered Kernel Tangent Alignment \u00b6 # hsic params kernel = 'rbf' scorer = 'ctka' subsample = None bias = True # initialize HSIC calculator clf_hsic = HSIC ( kernel = kernel , scorer = scorer , subsample = subsample , bias = bias ) # calculate HSIC return scorer clf_hsic . fit ( X , Y ); # hsic value and kernel alignment score tka_val = clf_hsic . hsic_value print ( f \"TKA: { tka_val : .5f } \" ) TKA: 0.89475 Length Scale \u00b6 from sklearn.gaussian_process.kernels import RBF def get_sigma ( X , Y , method : str = 'silverman' , per_dimension : bool = False ): # sigma parameters subsample = None percent = 0.20 random_state = 123 sigma_X = estimate_sigma ( X , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) sigma_Y = estimate_sigma ( Y , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) return sigma_X , sigma_Y # sigma parameters per_dimension = False method = 'silverman' sigma_X , sigma_Y = get_sigma ( method , per_dimension ) print ( f \"Estimated Sigma X: { sigma_X } \" ) print ( f \"Estimated Sigma Y: { sigma_Y } \" ) Estimated Sigma X: 0.06444718787975247 Estimated Sigma Y: 0.16119977831389598 The code below showcases an easy way to find the best kernel parameters by maximizing the HSIC value. This can be done with cross validation and the automatic training helper function found below. Data II - 2D Example \u00b6 # initialize Data Params class dataset = 'tstudent' samples = 1_000 dimensions = 2 std = 5 nu = 8 trial = 1 standardize = False # initialize params example_params = DataParams ( dataset = dataset , samples = samples , dimensions = dimensions , std = std , nu = nu , trial = trial , standardize = standardize ) # generate some parameters inputs = example_params . generate_data () sns . jointplot ( x = inputs . X , y = inputs . Y ) <seaborn.axisgrid.JointGrid at 0x7fbd90a73340> Sigma Estimation \u00b6 Case I - Same Length Scale \u00b6 # sigma parameters per_dimension = False method = 'silverman' sigma_X , sigma_Y = get_sigma ( inputs . X , inputs . Y , method , per_dimension ) sigma_mu = np . mean ([ sigma_X , sigma_Y ]) print ( f \"Estimated Sigma X: { sigma_X } \" ) print ( f \"Estimated Sigma Y: { sigma_Y } \" ) print ( f \"Estimated Sigma Y: { sigma_mu } \" ) Estimated Sigma X: 0.1949988419823719 Estimated Sigma Y: 0.19638960920405135 Estimated Sigma Y: 0.19569422559321165 # hsic value and kernel alignment score scorers = [ 'hsic' , 'ka' , 'cka' ] hsic_vals = [ get_hsic ( X , Y , iscorer , sigma_mu , sigma_mu ) for iscorer in scorers ] print ( f \"HSIC: { hsic_vals [ 0 ] : .5f } \" ) print ( f \"CKA: { hsic_vals [ 1 ] : .5f } \" ) print ( f \"KA: { hsic_vals [ 2 ] : .5f } \" ) HSIC: 0.00096 CKA: 0.13180 KA: 0.10091 Case II - Different Length Scale \u00b6 # sigma parameters per_dimension = False method = 'silverman' sigma_X , sigma_Y = get_sigma ( inputs . X , inputs . Y , method , per_dimension ) print ( f \"Estimated Sigma X: { sigma_X } \" ) print ( f \"Estimated Sigma Y: { sigma_Y } \" ) Estimated Sigma X: 0.1949988419823719 Estimated Sigma Y: 0.19638960920405135 # hsic value and kernel alignment score scorers = [ 'hsic' , 'ka' , 'cka' ] hsic_vals = [ get_hsic ( X , Y , iscorer , sigma_X , sigma_Y ) for iscorer in scorers ] print ( f \"HSIC: { hsic_vals [ 0 ] : .5f } \" ) print ( f \"CKA: { hsic_vals [ 1 ] : .5f } \" ) print ( f \"KA: { hsic_vals [ 2 ] : .5f } \" ) HSIC: 0.00096 CKA: 0.13180 KA: 0.10091 Case III - Different Length Scale Per Dimension \u00b6 # sigma parameters per_dimension = True method = 'scott' sigma_X , sigma_Y = get_sigma ( inputs . X , inputs . Y , method , per_dimension ) print ( f \"Estimated Sigma X: { sigma_X } \" ) print ( f \"Estimated Sigma Y: { sigma_Y } \" ) Estimated Sigma X: [0.26356727 0.26356727] Estimated Sigma Y: [0.26544708 0.26544708] # hsic value and kernel alignment score scorers = [ 'hsic' , 'ka' , 'cka' ] hsic_vals = [ get_hsic ( X , Y , iscorer , sigma_X , sigma_Y ) for iscorer in scorers ] print ( f \"HSIC: { hsic_vals [ 0 ] : .5f } \" ) print ( f \"CKA: { hsic_vals [ 1 ] : .5f } \" ) print ( f \"KA: { hsic_vals [ 2 ] : .5f } \" ) HSIC: 0.00094 CKA: 0.11962 KA: 0.06002 Standardize or Not Standardize the Data \u00b6","title":"2 estimate sigma"},{"location":"notebooks/demos/2_estimate_sigma/#hsic-and-tangent-kernel-alignment","text":"import sys , os import warnings import tqdm import random import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt # Insert path to model directory,. cwd = os . getcwd () path = f \" { cwd } /../../src\" sys . path . insert ( 0 , path ) # Insert path to package,. pysim_path = f \"/home/emmanuel/code/pysim/\" sys . path . insert ( 0 , pysim_path ) # toy datasets from data.toy import generate_dependence_data from data.distribution import DataParams from dataclasses import dataclass # Kernel Dependency measure from models.dependence import HSICModel from pysim.kernel.utils import get_init_gammas , get_gamma_grid , estimate_sigma import matplotlib.pyplot as plt import seaborn as sns plt . style . use ([ 'seaborn-talk' ]) % matplotlib inline warnings . filterwarnings ( 'ignore' ) # get rid of annoying warnings % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload","title":"HSIC and Tangent Kernel Alignment"},{"location":"notebooks/demos/2_estimate_sigma/#data-i-1d-dataset","text":"# data params dataset = 'sine' num_points = 1000 seed = 123 noise = 0.1 # get dataset X , Y = generate_dependence_data ( dataset = dataset , num_points = num_points , seed = seed , noise_x = noise , noise_y = noise ) # plot fig , ax = plt . subplots () ax . scatter ( X , Y ) plt . show ()","title":"Data I - 1D Dataset"},{"location":"notebooks/demos/2_estimate_sigma/#hsic","text":"def get_hsic ( X , Y , scorer : str , sigma_X , sigma_Y ): # init hsic model class hsic_model = HSICModel () # hsic model params hsic_model . kernel_X = RBF ( sigma_X ) hsic_model . kernel_Y = RBF ( sigma_Y ) # get hsic score hsic_val = hsic_model . get_score ( inputs . X , inputs . Y , scorer ) return hsic_val","title":"HSIC"},{"location":"notebooks/demos/2_estimate_sigma/#original-hsic","text":"# hsic value and kernel alignment score hsic_val = get_hsic ( X , Y , 'hsic' , sigma_X , sigma_Y ) print ( f \"HSIC: { hsic_val : .5f } \" ) HSIC: 0.00092","title":"Original HSIC"},{"location":"notebooks/demos/2_estimate_sigma/#kernel-tangent-alignment","text":"# hsic value and kernel alignment score tka_val = clf_hsic . score ( X , normalize = True ) print ( f \"TKA: { tka_val : .5f } \" ) TKA: 0.58843","title":"Kernel Tangent Alignment"},{"location":"notebooks/demos/2_estimate_sigma/#centered-kernel-tangent-alignment","text":"# hsic params kernel = 'rbf' scorer = 'ctka' subsample = None bias = True # initialize HSIC calculator clf_hsic = HSIC ( kernel = kernel , scorer = scorer , subsample = subsample , bias = bias ) # calculate HSIC return scorer clf_hsic . fit ( X , Y ); # hsic value and kernel alignment score tka_val = clf_hsic . hsic_value print ( f \"TKA: { tka_val : .5f } \" ) TKA: 0.89475","title":"Centered Kernel Tangent Alignment"},{"location":"notebooks/demos/2_estimate_sigma/#length-scale","text":"from sklearn.gaussian_process.kernels import RBF def get_sigma ( X , Y , method : str = 'silverman' , per_dimension : bool = False ): # sigma parameters subsample = None percent = 0.20 random_state = 123 sigma_X = estimate_sigma ( X , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) sigma_Y = estimate_sigma ( Y , subsample = subsample , method = method , percent = percent , random_state = random_state , per_dimension = per_dimension ) return sigma_X , sigma_Y # sigma parameters per_dimension = False method = 'silverman' sigma_X , sigma_Y = get_sigma ( method , per_dimension ) print ( f \"Estimated Sigma X: { sigma_X } \" ) print ( f \"Estimated Sigma Y: { sigma_Y } \" ) Estimated Sigma X: 0.06444718787975247 Estimated Sigma Y: 0.16119977831389598 The code below showcases an easy way to find the best kernel parameters by maximizing the HSIC value. This can be done with cross validation and the automatic training helper function found below.","title":"Length Scale"},{"location":"notebooks/demos/2_estimate_sigma/#data-ii-2d-example","text":"# initialize Data Params class dataset = 'tstudent' samples = 1_000 dimensions = 2 std = 5 nu = 8 trial = 1 standardize = False # initialize params example_params = DataParams ( dataset = dataset , samples = samples , dimensions = dimensions , std = std , nu = nu , trial = trial , standardize = standardize ) # generate some parameters inputs = example_params . generate_data () sns . jointplot ( x = inputs . X , y = inputs . Y ) <seaborn.axisgrid.JointGrid at 0x7fbd90a73340>","title":"Data II - 2D Example"},{"location":"notebooks/demos/2_estimate_sigma/#sigma-estimation","text":"","title":"Sigma Estimation"},{"location":"notebooks/demos/2_estimate_sigma/#case-i-same-length-scale","text":"# sigma parameters per_dimension = False method = 'silverman' sigma_X , sigma_Y = get_sigma ( inputs . X , inputs . Y , method , per_dimension ) sigma_mu = np . mean ([ sigma_X , sigma_Y ]) print ( f \"Estimated Sigma X: { sigma_X } \" ) print ( f \"Estimated Sigma Y: { sigma_Y } \" ) print ( f \"Estimated Sigma Y: { sigma_mu } \" ) Estimated Sigma X: 0.1949988419823719 Estimated Sigma Y: 0.19638960920405135 Estimated Sigma Y: 0.19569422559321165 # hsic value and kernel alignment score scorers = [ 'hsic' , 'ka' , 'cka' ] hsic_vals = [ get_hsic ( X , Y , iscorer , sigma_mu , sigma_mu ) for iscorer in scorers ] print ( f \"HSIC: { hsic_vals [ 0 ] : .5f } \" ) print ( f \"CKA: { hsic_vals [ 1 ] : .5f } \" ) print ( f \"KA: { hsic_vals [ 2 ] : .5f } \" ) HSIC: 0.00096 CKA: 0.13180 KA: 0.10091","title":"Case I - Same Length Scale"},{"location":"notebooks/demos/2_estimate_sigma/#case-ii-different-length-scale","text":"# sigma parameters per_dimension = False method = 'silverman' sigma_X , sigma_Y = get_sigma ( inputs . X , inputs . Y , method , per_dimension ) print ( f \"Estimated Sigma X: { sigma_X } \" ) print ( f \"Estimated Sigma Y: { sigma_Y } \" ) Estimated Sigma X: 0.1949988419823719 Estimated Sigma Y: 0.19638960920405135 # hsic value and kernel alignment score scorers = [ 'hsic' , 'ka' , 'cka' ] hsic_vals = [ get_hsic ( X , Y , iscorer , sigma_X , sigma_Y ) for iscorer in scorers ] print ( f \"HSIC: { hsic_vals [ 0 ] : .5f } \" ) print ( f \"CKA: { hsic_vals [ 1 ] : .5f } \" ) print ( f \"KA: { hsic_vals [ 2 ] : .5f } \" ) HSIC: 0.00096 CKA: 0.13180 KA: 0.10091","title":"Case II - Different Length Scale"},{"location":"notebooks/demos/2_estimate_sigma/#case-iii-different-length-scale-per-dimension","text":"# sigma parameters per_dimension = True method = 'scott' sigma_X , sigma_Y = get_sigma ( inputs . X , inputs . Y , method , per_dimension ) print ( f \"Estimated Sigma X: { sigma_X } \" ) print ( f \"Estimated Sigma Y: { sigma_Y } \" ) Estimated Sigma X: [0.26356727 0.26356727] Estimated Sigma Y: [0.26544708 0.26544708] # hsic value and kernel alignment score scorers = [ 'hsic' , 'ka' , 'cka' ] hsic_vals = [ get_hsic ( X , Y , iscorer , sigma_X , sigma_Y ) for iscorer in scorers ] print ( f \"HSIC: { hsic_vals [ 0 ] : .5f } \" ) print ( f \"CKA: { hsic_vals [ 1 ] : .5f } \" ) print ( f \"KA: { hsic_vals [ 2 ] : .5f } \" ) HSIC: 0.00094 CKA: 0.11962 KA: 0.06002","title":"Case III - Different Length Scale Per Dimension"},{"location":"notebooks/demos/2_estimate_sigma/#standardize-or-not-standardize-the-data","text":"","title":"Standardize or Not Standardize the Data"},{"location":"notebooks/ite_toolbox/0_demo/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Information Theory Measures using the ITE Toolbox \u00b6 Author: J. Emmanuel Johnson Email: jemanjohnson34@gmail.com Date: 4^{\\text{th}} 4^{\\text{th}} September, 2019 2019 This notebook will walk-through how one can calculate a few key Information theory (IT) measures using the ITE toolbox. We have done previous experiments with the MATLAB package but there is a python version that can be useful for Python users. It's a lot cleaner but some of the functionality may be difficult to follow. Resources \u00b6 Gael Implementation - Gist ITE sub imples - Github Literature Review (what we previous did) \u00b6 Entropy \u00b6 In our experiments, we were only looking at Shannon entropy. It is the general case of Renyi's entropy as \\alpha \\rightarrow 1 \\alpha \\rightarrow 1 . We chose not to look at Renyi's entropy because we did not want to go down a rabbit hole of measures that we cannont understand nor justify. So we stuck to the basics. It's also important to keep in mind that we were looking at measures that could calculate the joint entropy; i.e. for multivariate, multi-dimensional datasets. Algorithms \u00b6 KnnK \u00b6 This uses the KNN method to estimate the entropy. From what I understand, it's the simplest method that may have some issues at higher dimensions and large number of samples (normal with KNN estimators). In relation to the other standard methods of density estimation, it is the most robust in higher dimensions due to its adaptive-like binning. A new class of random vector entropy estimators and its applications in testing statistical hypotheses - Goria et. al. (2005) - Paper Nearest neighbor estimates of entropy - Singh et. al. (2003) - paper A statistical estimate for the entropy of a random vector - Kozachenko et. al. (1987) - paper KDP \u00b6 This is the logical progression from KnnK. It uses KD partitioning trees (KDTree) algorithm to speed up the calculations I presume. Fast multidimensional entropy estimation by k-d partitioning - Stowell & Plumbley (2009) - Paper expF \u00b6 This is the close-form expression for the Sharma-Mittal entropy calculation for expontial families. This estimates Y using the maximum likelihood estimation and then uses the analytical formula for the exponential family. A closed-form expression for the Sharma-Mittal entropy of exponential families - Nielsen & Nock (2012) - Paper vME \u00b6 This estimates the Shannon differential entropy (H) using the von Mises expansion. Nonparametric von Mises estimators for entropies, divergences and mutual informations - Kandasamy et. al. (2015) - Paper Ensemble \u00b6 Estimates the entropy from the average entropy estimations on groups of samples This is a simple implementation with the freedom to choose the estimator estimate_H . # split into groups for igroup in batches : H += estimate_H ( igroup ) H /= len ( batches ) High-dimensional mutual information estimation for image registration - Kybic (2004) - Paper Potential New Experiments \u00b6 Voronoi \u00b6 Estimates Shannon entropy using Voronoi regions. Apparently it is good for multi-dimensional densities. A new class of entropy estimators for multi-dimensional densities - Miller (2003) - Paper Mutual Information \u00b6 Total Correlation \u00b6 Code \u00b6 import sys , os cwd = os . getcwd () sys . path . insert ( 0 , f ' { cwd } /../../src' ) sys . path . insert ( 0 , f ' { cwd } /../../src/itetoolbox' ) import numpy as np import ite # from data.load_TishbyData import load_TishbyData % matplotlib inline % load_ext autoreload % autoreload 2 Data \u00b6 We will simulate some data X that is normally distributed and Y which is X that has been rotated by some random matrix A. 10 ** ( - 2 ) 0.01 np . random . seed ( 123 ) # reproducibility n_samples = 1000 d_dimensions = 3 # create dataset X X = np . random . randn ( n_samples , d_dimensions ) # do some random rotation A = np . random . rand ( d_dimensions , d_dimensions ) # create dataset Y Y = X @ A Entropy \u00b6 In our experiments, we were only looking at Shannon entropy. It is the general case of Renyi's entropy as \\alpha \\rightarrow 1 \\alpha \\rightarrow 1 . We chose not to look at Renyi's entropy because we did not want to go down a rabbit hole of measures that we cannont understand nor justify. So we stuck to the basics. It's also important to keep in mind that we were looking at measures that could calculate the joint entropy; i.e. for multivariate, multi-dimensional datasets. Algorithms \u00b6 KnnK \u00b6 This uses the KNN method to estimate the entropy. From what I understand, it's the simplest method that may have some issues at higher dimensions and large number of samples (normal with KNN estimators). A new class of random vector entropy estimators and its applications in testing statistical hypotheses - Goria et. al. (2005) - Paper Nearest neighbor estimates of entropy - Singh et. al. (2003) - paper A statistical estimate for the entropy of a random vector - Kozachenko et. al. (1987) - paper This method works by calculating the nearest neighbors formula KDP \u00b6 This is the logical progression from KnnK. It uses KD partitioning trees (KDTree) algorithm to speed up the calculations I presume. Fast multidimensional entropy estimation by k-d partitioning - Stowell & Plumbley (2009) - Paper Algorithm \u00b6 Calculate the KNN Distances using the distance matrix Calculate the Volume of the unit ball wrt d_dimensions Calculate the entropy measure H = \\log (N - 1) - \\psi(k) + \\log (v) + D * \\frac{1}{N} \\sum \\log D H = \\log (N - 1) - \\psi(k) + \\log (v) + D * \\frac{1}{N} \\sum \\log D <span><span class=\"MathJax_Preview\">H = \\log (N - 1) - \\psi(k) + \\log (v) + D * \\frac{1}{N} \\sum \\log D</span><script type=\"math/tex\">H = \\log (N - 1) - \\psi(k) + \\log (v) + D * \\frac{1}{N} \\sum \\log D def entropy_gaussian ( C ): ''' Entropy of a gaussian variable with covariance matrix C ''' if np . isscalar ( C ): # C is the variance return . 5 * ( 1 + np . log ( 2 * pi )) + . 5 * np . log ( C ) else : n = C . shape [ 0 ] # dimension return . 5 * n * ( 1 + np . log ( 2 * pi )) + . 5 * np . log ( abs ( det ( C ))) Shannon Entropy (KNN/KDP) \u00b6 from scipy.special import gamma from sklearn.neighbors import NearestNeighbors from typing import Optional # volume of unit ball def volume_unit_ball ( d_dimensions : int ) -> float : \"\"\"Volume of the d-dimensional unit ball Parameters ---------- d_dimensions : int Number of dimensions to estimate the volume Returns ------- vol : float The volume of the d-dimensional unit ball \"\"\" return ( np . pi ** ( . 5 * d_dimensions ) ) / gamma ( . 5 * d_dimensions + 1 ) # KNN Distances def knn_distance ( X : np . ndarray , n_neighbors : int = 20 , algorithm : str = 'brute' , n_jobs : int =- 1 , kwargs : Optional [ dict ] = None ) -> np . ndarray : \"\"\"Light wrapper around sklearn library. Parameters ---------- X : np.ndarray, (n_samples x d_dimensions) The data to find the nearest neighbors for. n_neighbors : int, default=20 The number of nearest neighbors to find. algorithm : str, default='brute', The knn algorithm to use. ('brute', 'ball_tree', 'kd_tree', 'auto') n_jobs : int, default=-1 The number of cores to use to find the nearest neighbors kwargs : dict, Optional Any extra keyword arguments. Returns ------- distances : np.ndarray, (n_samples x d_dimensions) \"\"\" if kwargs : clf_knn = NearestNeighbors ( n_neighbors = n_neighbors , algorithm = algorithm , n_jobs = n_jobs , ** kwargs ) else : clf_knn = NearestNeighbors ( n_neighbors = n_neighbors , algorithm = algorithm , n_jobs = n_jobs , ) clf_knn . fit ( X ); dists , _ = clf_knn . kneighbors ( X ) return dists from sklearn.base import BaseEstimator from sklearn.utils import gen_batches class Ensemble : def __init__ ( self ): pass def _fit_ensemble ( self , X : np . ndarray , batch_size : int = 100 ) -> float : Hs = list () for idx in gen_batches ( X . shape [ 0 ], batch_size , 10 ): Hs . append ( self . _fit ( X [ idx ])) return np . mean ( Hs ) class EntropyKNN ( BaseEstimator , Ensemble ): def __init__ ( self , n_neighbors : int = 20 , algorithm : str = 'brute' , n_jobs : int =- 1 , ensemble = False , batch_size = 100 , kwargs : Optional [ dict ] = None ) -> None : self . n_neighbors = n_neighbors self . algorithm = algorithm self . n_jobs = n_jobs self . ensemble = ensemble self . kwargs = kwargs self . batch_size = batch_size def fit ( self , X : np . ndarray ) -> BaseEstimator : self . vol = volume_unit_ball ( X . shape [ 1 ]) if self . ensemble : self . H_x = self . _fit_ensemble ( X , self . batch_size ) else : self . H_x = self . _fit ( X ) return self def _fit ( self , X : np . ndarray ) -> float : # 1. Calculate the K-nearest neighbors dist = knn_distance ( X , n_neighbors = self . n_neighbors , algorithm = self . algorithm , n_jobs = self . n_jobs , kwargs = self . kwargs ) return np . log ( n_samples - 1 ) - psi ( n_neighbors ) + np . log ( self . vol ) + ( d_dimensions / n_samples ) * np . log ( dist [:, n_neighbors - 1 ]) . sum () def score ( self , X ): return self . H_x # parameters (default) n_neighbors = 20 algorithm = 'brute' n_jobs = - 1 ensemble = False batch_size = 50 kwargs = { 'metric' : 'euclidean' } # initialize it estimator clf_knnK = EntropyKNN ( n_neighbors = n_neighbors , algorithm = algorithm , n_jobs = n_jobs , ensemble = ensemble , batch_size = batch_size , kwargs = kwargs , ) # estimate entropy H_x = clf_knnK . fit ( X ) . score ( X ) H_y = clf_knnK . fit ( Y ) . score ( Y ) print ( f \"H(X): { H_x : .3f } bits\" ) print ( f \"H(Y): { H_y : .3f } bits\" ) H(X): 4.077 bits H(Y): 2.131 bits Notice there are quite a lot of parameters we can change within the actual KNN estimation procedure. But the rest seems to be fairly consistent with not much tweaking we can do. ITE Toolbox implementation \u00b6 # parameters (default) mult = True knn_method = 'cKDTree' # fast version (slower version KNN) k_neighbors = 10 # free parameter eps = 0.1 # free parameter # initialize it estimator clf_knnK = ite . cost . BHShannon_KnnK ( mult = mult , knn_method = knn_method , k = k_neighbors , eps = eps ) # estimate entropy H_x = clf_knnK . estimation ( X ) H_y = clf_knnK . estimation ( Y ) print ( f \"H(X): { H_x : .3f } bits\" ) print ( f \"H(Y): { H_y : .3f } bits\" ) H(X): 4.132 bits H(Y): 2.208 bits It seems like the numbers we get are quite similar. Shannon Entropy: expF \u00b6 This is the close-form expression for the Sharma-Mittal entropy calculation for expontial families. The Sharma-Mittal entropy is a generalization of the Shannon, R\u00e9nyi and Tsallis entropy measurements. This estimates Y using the maximum likelihood estimation and then uses the analytical formula for the exponential family. A closed-form expression for the Sharma-Mittal entropy of exponential families - Nielsen & Nock (2012) - Paper Statistical exponential families: A digest with flash cards - Paper Source Parameters \\Lambda = (\\mu, \\Sigma) \\Lambda = (\\mu, \\Sigma) where \\mu \\in \\mathbb{R}^{d} \\mu \\in \\mathbb{R}^{d} and \\Sigma > 0 \\Sigma > 0 Parameters \\Theta = \\left( \\Sigma^{-1}\\mu, \\frac{1}{2}\\Sigma^{-1} \\right) \\Theta = \\left( \\Sigma^{-1}\\mu, \\frac{1}{2}\\Sigma^{-1} \\right) Log Normalizer F(\\Theta) = \\frac{1}{4} Tr( \\theta^\\top \\Theta^{-1} \\theta) - \\frac{1}{2} \\log|\\Theta| + \\frac{d}{2}\\log \\pi F(\\Theta) = \\frac{1}{4} Tr( \\theta^\\top \\Theta^{-1} \\theta) - \\frac{1}{2} \\log|\\Theta| + \\frac{d}{2}\\log \\pi Gradient Log Normalizer \\nabla F(\\Theta) = \\left( \\frac{1}{2} \\Theta^{-1}\\theta, -\\frac{1}{2} \\Theta^{-1}- \\frac{1}{4}(\\Theta^{-1}\\Theta)(\\Theta^{-1}\\Theta)^\\top \\right) \\nabla F(\\Theta) = \\left( \\frac{1}{2} \\Theta^{-1}\\theta, -\\frac{1}{2} \\Theta^{-1}- \\frac{1}{4}(\\Theta^{-1}\\Theta)(\\Theta^{-1}\\Theta)^\\top \\right) Final Entropy Calculation H = F(\\Theta) - \\langle F(\\Theta), \\nabla F(\\Theta) \\rangle H = F(\\Theta) - \\langle F(\\Theta), \\nabla F(\\Theta) \\rangle <span><span class=\"MathJax_Preview\">H = F(\\Theta) - \\langle F(\\Theta), \\nabla F(\\Theta) \\rangle</span><script type=\"math/tex\">H = F(\\Theta) - \\langle F(\\Theta), \\nabla F(\\Theta) \\rangle n_samples , n_dims = X . shape # source params, theta theta_1 = X . mean ( axis = 0 ) theta_2 = np . cov ( X . T ) print ( 'Source:' , theta_1 . shape , theta_2 . shape ) # natural params, eta eta_1 = np . linalg . inv ( theta_2 ) @ theta_1 [:, None ] eta_2 = . 5 * np . linalg . inv ( theta_2 ) print ( 'Natural:' , eta_1 . shape , eta_2 . shape ) # log-normalizer, F(eta) f_eta = . 25 * np . trace ( eta_1 . T @ np . linalg . inv ( eta_2 ) @ eta_1 ) - . 5 * np . linalg . slogdet ( eta_2 )[ 1 ] + ( n_dims / 2. ) * np . log ( np . pi ) print ( 'Log Norm:' , f_eta . shape ) # gradient log normalizer, dF(eta) df_eta_1 = . 5 * np . linalg . inv ( eta_2 ) @ eta_1 df_eta_2 = -. 5 * np . linalg . inv ( eta_2 ) - . 25 * ( np . linalg . inv ( eta_2 ) - eta_1 ) @ ( np . linalg . inv ( eta_2 ) - eta_1 ) . T print ( 'Grad Log Norm:' , df_eta_1 . shape , df_eta_2 . shape ) # outer product t2 = np . outer ( np . outer ( eta_1 , df_eta_1 ), np . outer ( eta_2 , df_eta_2 )) print ( t2 . shape ) def expF_entropy ( X ): # estimate Gaussian parameters mean = X . mean ( axis = 0 ) cov = np . cov ( X . T ) # make Gaussian distribution norm_dist = stats . multivariate_normal ( mean = mean , cov = cov , seed = seed ) # estimate the entropy from closed form solution H_x = norm_dist . entropy () return H_x H_x = expF_entropy ( X ) H_y = expF_entropy ( Y ) print ( f \"H(X): { H_x : .3f } bits\" ) print ( f \"H(Y): { H_y : .3f } bits\" ) H(X): 4.195 bits H(Y): 1.329 bits As you can see, it works well if the distribution is actuall Gaussian but it doesn't if it isn't. mean = X . mean ( axis = 0 ) cov = np . cov ( X . T ) seed = 1 norm_dist = stats . multivariate_normal ( mean = mean , cov = cov , seed = seed ) H_x = norm_dist . entropy () print ( f \"H(X): { H_x : .3f } bits\" ) H(X): 4.195 bits # 1. estimate the maximum likelihood params mean = X . mean ( axis = 0 )[:, None ] cov = np . cov ( X . T ) inv_cov = np . linalg . inv ( cov ) alpha = inv_cov @ mean sigma = inv_cov / 2 mean . shape , cov . shape , inv_cov . shape , t1 . shape , t2 . shape # Log Normalizer (Maximum Like) F = ( 1 / 4 ) * np . trace ( np . linalg . inv ( t2 ) @ t1 @ t1 . T ) - ( 1 / 2 ) * np . log ( np . linalg . det ( cov )) + ( X . shape [ 1 ] / 2 ) * np . log ( np . pi ) # Gradient Log Normalizer alpha_grad = File \"<ipython-input-79-af7a3dc7f9a4>\" , line 14 alpha_grad = ^ SyntaxError : invalid syntax mean . shape , cov . shape , inv_cov . shape , t1 . shape , t2 . shape ((3,), (3, 3), (3, 3), (3,), (3, 3)) vME \u00b6 This nonparametric method that estimates the Shannon differential entropy (H) using the von Mises expansion. This method has a fast convergence rate than the KDE and KNN methods. This algorithm does have and in addition the can be tuned using cross-validation techniques. It is also less expensive than the KDE in terms of the numerical integration whereas this method has closed form solutions for some families of von Mises expansions. Nonparametric von Mises estimators for entropies, divergences and mutual informations - Kandasamy et. al. (2015) - Paper Ensemble \u00b6 Estimates the entropy from the average entropy estimations on groups of samples This is a simple implementation with the freedom to choose the estimator estimate_H . # split into groups for igroup in batches : H += estimate_H ( igroup ) H /= len ( batches ) High-dimensional mutual information estimation for image registration - Kybic (2004) - Paper Potential New Experiments \u00b6 Voronoi \u00b6 Estimates Shannon entropy using Voronoi regions. Apparently it is good for multi-dimensional densities. A new class of entropy estimators for multi-dimensional densities - Miller (2003) - Paper Mutual Information \u00b6 The estimation was carried out using the following relationship. Let XY = [X, Y] \\in \\mathcal{R}^{N \\times D} XY = [X, Y] \\in \\mathcal{R}^{N \\times D} , where D=D_1+D_2 D=D_1+D_2 . I(XY) = \\sum_{d=1}^D H(XY) - H(XY) I(XY) = \\sum_{d=1}^D H(XY) - H(XY) The pseudo-code is fairly simple (in the MATLAB version). Organize the components XY = [ X , Y ] Estimate the joint entropy, H(XY) H(XY) H_xy = - estimate_H ( np . hstack ( XY ) # stack the vectors dimension-wise ) Estimate the marginals of XY; i.e. estimate X and Y individually, then sum them. H_x_y = np . sum ( # estimate the entropy for each marginal [ estimate_H ( imarginal ) for imarginal in XY ] ) Summation of the two quantities MI_XY = H_x_y + H_xy Naive \u00b6 class Ensemble : def _fit_ensemble ( self , X : np . ndarray , vol : float , batch_size : int = 100 ) -> float : Hs = list () for idx in gen_batches ( X . shape [ 0 ], batch_size , 10 ): Hs . append ( self . _fit ( X [ idx ], vol )) return np . mean ( Hs ) class MutualInfoKNN ( BaseEstimator ): def __init__ ( self , n_neighbors : int = 20 , algorithm : str = 'brute' , n_jobs : int =- 1 , kwargs : Optional [ dict ] = None ) -> None : self . n_neighbors = n_neighbors self . algorithm = algorithm self . n_jobs = n_jobs self . kwargs = kwargs def fit ( self , X : np . ndarray , Y : np . ndarray ) -> BaseEstimator : # Calculate Volumes vol_xy = volume_unit_ball ( X . shape [ 1 ] + Y . shape [ 1 ]) vol_x = volume_unit_ball ( X . shape [ 1 ]) vol_y = volume_unit_ball ( Y . shape [ 1 ]) # Calculate Joint Entropy H_xy = self . _fit ( np . vstack ([ X , Y ]), vol_xy ) # Calculate Marginal Probabilities H_x = self . _fit ( X , vol_x ) H_y = self . _fit ( Y , vol_y ) # Calculate Mutual Information self . MI = H_x + H_y - H_xy return self def _fit ( self , X : np . ndarray , vol : float ) -> float : # 1. Calculate the K-nearest neighbors dist = knn_distance ( X , n_neighbors = self . n_neighbors , algorithm = self . algorithm , n_jobs = self . n_jobs , kwargs = self . kwargs ) return np . log ( n_samples - 1 ) - psi ( n_neighbors ) + np . log ( vol ) + ( d_dimensions / n_samples ) * np . log ( dist [:, n_neighbors - 1 ]) . sum () def score ( self , X ): return self . MI # parameters (default) n_neighbors = 10 algorithm = 'brute' n_jobs = - 1 ensemble = False batch_size = 50 kwargs = { 'metric' : 'euclidean' } # initialize it estimator clf_knnK = MutualInfoKNN ( n_neighbors = n_neighbors , algorithm = algorithm , n_jobs = n_jobs , kwargs = kwargs , ) # estimate entropy MI_xy = clf_knnK . fit ( X , Y ) . score ( X ) print ( f \"H(X): { MI_xy : .3f } bits\" ) H(X): 6.427 bits ITE Toolbox \u00b6 # parameters (default) mult = True # ?? kl_co_name = 'BDKL_KnnK' # KLD calculator kl_co_pars = None # parameters for the KLD calculator # initialize it estimator clf_mi = ite . cost . MIShannon_DKL ( # mult=mult, # kl_co_name=kl_co_name, # kl_co_pars=kl_co_pars, ) # concat data XY = np . concatenate (( X , Y ), axis = 1 ) # individual dimensions per sub_dimensions = np . array ([ X . shape [ 1 ], Y . shape [ 1 ]]) # estimate mutual information mi_XY = clf_mi . estimation ( XY , sub_dimensions ) print ( f \"MI(X,Y): { mi_XY : .3f } bits\" ) MI(X,Y): 3.683 bits # parameters (default) mult = True # ?? kernel = { 'name' : 'RBF' , 'sigma' : 1 } # KLD calculator eta = 0.01 # parameters for the KLD calculator # initialize it estimator clf_mi = ite . cost . BIKGV ( # mult=mult, # kernel=kernel, # eta=eta, ) # concat data XY = np . concatenate (( X , Y ), axis = 1 ) # individual dimensions per sub_dimensions = np . array ([ X . shape [ 1 ], Y . shape [ 1 ]]) # estimate mutual information mi_XY = clf_mi . estimation ( XY , sub_dimensions ) print ( f \"MI(X,Y): { mi_XY : .3f } bits\" ) MI(X,Y): 2.062 bits I expect there to be some MI between X and Y since it is a rotation of the original distribution. Total Correlation (Multi-Information, Co-Information) \u00b6 The estimation was carried out using the following relationship: I(x_1, x_2, \\ldots, x_D) = \\sum_{d=1}^D H(x_d) - H(X) I(x_1, x_2, \\ldots, x_D) = \\sum_{d=1}^D H(x_d) - H(X) <span><span class=\"MathJax_Preview\">I(x_1, x_2, \\ldots, x_D) = \\sum_{d=1}^D H(x_d) - H(X)</span><script type=\"math/tex\">I(x_1, x_2, \\ldots, x_D) = \\sum_{d=1}^D H(x_d) - H(X) # parameters (default) mult = True kl_co_name = 'BDKL_KnnK' kl_co_pars = None # initialize it estimator clf_mi = ite . cost . MIShannon_DKL ( mult = mult , kl_co_name = kl_co_name , kl_co_pars = kl_co_pars , ) # concat data sub_dimensions = np . array ( range ( X . shape [ 1 ])) # estimate mutual information tc_X = clf_mi . estimation ( X , sub_dimensions ) tc_Y = clf_mi . estimation ( Y , sub_dimensions ) print ( f \"Shannon Total Correlation, TC(X): { tc_X : .3f } bits\" ) print ( f \"Shannon Total Correlation, TC(Y): { tc_Y : .3f } bits\" ) Shannon Total Correlation, TC(X): -0.002 bits Shannon Total Correlation, TC(Y): 2.365 bits This makes since given that the original distribution X X should have no correlations between dimensions because it is Gaussian. The rotation of X X by some random matrix A A , Y=AX^{\\top} Y=AX^{\\top} , means that we have added some correlations between dimensions. We see that as the TC is higher.","title":"0 demo"},{"location":"notebooks/ite_toolbox/0_demo/#information-theory-measures-using-the-ite-toolbox","text":"Author: J. Emmanuel Johnson Email: jemanjohnson34@gmail.com Date: 4^{\\text{th}} 4^{\\text{th}} September, 2019 2019 This notebook will walk-through how one can calculate a few key Information theory (IT) measures using the ITE toolbox. We have done previous experiments with the MATLAB package but there is a python version that can be useful for Python users. It's a lot cleaner but some of the functionality may be difficult to follow.","title":"Information Theory Measures using the ITE Toolbox"},{"location":"notebooks/ite_toolbox/0_demo/#resources","text":"Gael Implementation - Gist ITE sub imples - Github","title":"Resources"},{"location":"notebooks/ite_toolbox/0_demo/#literature-review-what-we-previous-did","text":"","title":"Literature Review (what we previous did)"},{"location":"notebooks/ite_toolbox/0_demo/#entropy","text":"In our experiments, we were only looking at Shannon entropy. It is the general case of Renyi's entropy as \\alpha \\rightarrow 1 \\alpha \\rightarrow 1 . We chose not to look at Renyi's entropy because we did not want to go down a rabbit hole of measures that we cannont understand nor justify. So we stuck to the basics. It's also important to keep in mind that we were looking at measures that could calculate the joint entropy; i.e. for multivariate, multi-dimensional datasets.","title":"Entropy"},{"location":"notebooks/ite_toolbox/0_demo/#algorithms","text":"","title":"Algorithms"},{"location":"notebooks/ite_toolbox/0_demo/#knnk","text":"This uses the KNN method to estimate the entropy. From what I understand, it's the simplest method that may have some issues at higher dimensions and large number of samples (normal with KNN estimators). In relation to the other standard methods of density estimation, it is the most robust in higher dimensions due to its adaptive-like binning. A new class of random vector entropy estimators and its applications in testing statistical hypotheses - Goria et. al. (2005) - Paper Nearest neighbor estimates of entropy - Singh et. al. (2003) - paper A statistical estimate for the entropy of a random vector - Kozachenko et. al. (1987) - paper","title":"KnnK"},{"location":"notebooks/ite_toolbox/0_demo/#kdp","text":"This is the logical progression from KnnK. It uses KD partitioning trees (KDTree) algorithm to speed up the calculations I presume. Fast multidimensional entropy estimation by k-d partitioning - Stowell & Plumbley (2009) - Paper","title":"KDP"},{"location":"notebooks/ite_toolbox/0_demo/#expf","text":"This is the close-form expression for the Sharma-Mittal entropy calculation for expontial families. This estimates Y using the maximum likelihood estimation and then uses the analytical formula for the exponential family. A closed-form expression for the Sharma-Mittal entropy of exponential families - Nielsen & Nock (2012) - Paper","title":"expF"},{"location":"notebooks/ite_toolbox/0_demo/#vme","text":"This estimates the Shannon differential entropy (H) using the von Mises expansion. Nonparametric von Mises estimators for entropies, divergences and mutual informations - Kandasamy et. al. (2015) - Paper","title":"vME"},{"location":"notebooks/ite_toolbox/0_demo/#ensemble","text":"Estimates the entropy from the average entropy estimations on groups of samples This is a simple implementation with the freedom to choose the estimator estimate_H . # split into groups for igroup in batches : H += estimate_H ( igroup ) H /= len ( batches ) High-dimensional mutual information estimation for image registration - Kybic (2004) - Paper","title":"Ensemble"},{"location":"notebooks/ite_toolbox/0_demo/#potential-new-experiments","text":"","title":"Potential New Experiments"},{"location":"notebooks/ite_toolbox/0_demo/#voronoi","text":"Estimates Shannon entropy using Voronoi regions. Apparently it is good for multi-dimensional densities. A new class of entropy estimators for multi-dimensional densities - Miller (2003) - Paper","title":"Voronoi"},{"location":"notebooks/ite_toolbox/0_demo/#mutual-information","text":"","title":"Mutual Information"},{"location":"notebooks/ite_toolbox/0_demo/#total-correlation","text":"","title":"Total Correlation"},{"location":"notebooks/ite_toolbox/0_demo/#code","text":"import sys , os cwd = os . getcwd () sys . path . insert ( 0 , f ' { cwd } /../../src' ) sys . path . insert ( 0 , f ' { cwd } /../../src/itetoolbox' ) import numpy as np import ite # from data.load_TishbyData import load_TishbyData % matplotlib inline % load_ext autoreload % autoreload 2","title":"Code"},{"location":"notebooks/ite_toolbox/0_demo/#data","text":"We will simulate some data X that is normally distributed and Y which is X that has been rotated by some random matrix A. 10 ** ( - 2 ) 0.01 np . random . seed ( 123 ) # reproducibility n_samples = 1000 d_dimensions = 3 # create dataset X X = np . random . randn ( n_samples , d_dimensions ) # do some random rotation A = np . random . rand ( d_dimensions , d_dimensions ) # create dataset Y Y = X @ A","title":"Data"},{"location":"notebooks/ite_toolbox/0_demo/#entropy_1","text":"In our experiments, we were only looking at Shannon entropy. It is the general case of Renyi's entropy as \\alpha \\rightarrow 1 \\alpha \\rightarrow 1 . We chose not to look at Renyi's entropy because we did not want to go down a rabbit hole of measures that we cannont understand nor justify. So we stuck to the basics. It's also important to keep in mind that we were looking at measures that could calculate the joint entropy; i.e. for multivariate, multi-dimensional datasets.","title":"Entropy"},{"location":"notebooks/ite_toolbox/0_demo/#algorithms_1","text":"","title":"Algorithms"},{"location":"notebooks/ite_toolbox/0_demo/#knnk_1","text":"This uses the KNN method to estimate the entropy. From what I understand, it's the simplest method that may have some issues at higher dimensions and large number of samples (normal with KNN estimators). A new class of random vector entropy estimators and its applications in testing statistical hypotheses - Goria et. al. (2005) - Paper Nearest neighbor estimates of entropy - Singh et. al. (2003) - paper A statistical estimate for the entropy of a random vector - Kozachenko et. al. (1987) - paper This method works by calculating the nearest neighbors formula","title":"KnnK"},{"location":"notebooks/ite_toolbox/0_demo/#kdp_1","text":"This is the logical progression from KnnK. It uses KD partitioning trees (KDTree) algorithm to speed up the calculations I presume. Fast multidimensional entropy estimation by k-d partitioning - Stowell & Plumbley (2009) - Paper","title":"KDP"},{"location":"notebooks/ite_toolbox/0_demo/#algorithm","text":"Calculate the KNN Distances using the distance matrix Calculate the Volume of the unit ball wrt d_dimensions Calculate the entropy measure H = \\log (N - 1) - \\psi(k) + \\log (v) + D * \\frac{1}{N} \\sum \\log D H = \\log (N - 1) - \\psi(k) + \\log (v) + D * \\frac{1}{N} \\sum \\log D <span><span class=\"MathJax_Preview\">H = \\log (N - 1) - \\psi(k) + \\log (v) + D * \\frac{1}{N} \\sum \\log D</span><script type=\"math/tex\">H = \\log (N - 1) - \\psi(k) + \\log (v) + D * \\frac{1}{N} \\sum \\log D def entropy_gaussian ( C ): ''' Entropy of a gaussian variable with covariance matrix C ''' if np . isscalar ( C ): # C is the variance return . 5 * ( 1 + np . log ( 2 * pi )) + . 5 * np . log ( C ) else : n = C . shape [ 0 ] # dimension return . 5 * n * ( 1 + np . log ( 2 * pi )) + . 5 * np . log ( abs ( det ( C )))","title":"Algorithm"},{"location":"notebooks/ite_toolbox/0_demo/#shannon-entropy-knnkdp","text":"from scipy.special import gamma from sklearn.neighbors import NearestNeighbors from typing import Optional # volume of unit ball def volume_unit_ball ( d_dimensions : int ) -> float : \"\"\"Volume of the d-dimensional unit ball Parameters ---------- d_dimensions : int Number of dimensions to estimate the volume Returns ------- vol : float The volume of the d-dimensional unit ball \"\"\" return ( np . pi ** ( . 5 * d_dimensions ) ) / gamma ( . 5 * d_dimensions + 1 ) # KNN Distances def knn_distance ( X : np . ndarray , n_neighbors : int = 20 , algorithm : str = 'brute' , n_jobs : int =- 1 , kwargs : Optional [ dict ] = None ) -> np . ndarray : \"\"\"Light wrapper around sklearn library. Parameters ---------- X : np.ndarray, (n_samples x d_dimensions) The data to find the nearest neighbors for. n_neighbors : int, default=20 The number of nearest neighbors to find. algorithm : str, default='brute', The knn algorithm to use. ('brute', 'ball_tree', 'kd_tree', 'auto') n_jobs : int, default=-1 The number of cores to use to find the nearest neighbors kwargs : dict, Optional Any extra keyword arguments. Returns ------- distances : np.ndarray, (n_samples x d_dimensions) \"\"\" if kwargs : clf_knn = NearestNeighbors ( n_neighbors = n_neighbors , algorithm = algorithm , n_jobs = n_jobs , ** kwargs ) else : clf_knn = NearestNeighbors ( n_neighbors = n_neighbors , algorithm = algorithm , n_jobs = n_jobs , ) clf_knn . fit ( X ); dists , _ = clf_knn . kneighbors ( X ) return dists from sklearn.base import BaseEstimator from sklearn.utils import gen_batches class Ensemble : def __init__ ( self ): pass def _fit_ensemble ( self , X : np . ndarray , batch_size : int = 100 ) -> float : Hs = list () for idx in gen_batches ( X . shape [ 0 ], batch_size , 10 ): Hs . append ( self . _fit ( X [ idx ])) return np . mean ( Hs ) class EntropyKNN ( BaseEstimator , Ensemble ): def __init__ ( self , n_neighbors : int = 20 , algorithm : str = 'brute' , n_jobs : int =- 1 , ensemble = False , batch_size = 100 , kwargs : Optional [ dict ] = None ) -> None : self . n_neighbors = n_neighbors self . algorithm = algorithm self . n_jobs = n_jobs self . ensemble = ensemble self . kwargs = kwargs self . batch_size = batch_size def fit ( self , X : np . ndarray ) -> BaseEstimator : self . vol = volume_unit_ball ( X . shape [ 1 ]) if self . ensemble : self . H_x = self . _fit_ensemble ( X , self . batch_size ) else : self . H_x = self . _fit ( X ) return self def _fit ( self , X : np . ndarray ) -> float : # 1. Calculate the K-nearest neighbors dist = knn_distance ( X , n_neighbors = self . n_neighbors , algorithm = self . algorithm , n_jobs = self . n_jobs , kwargs = self . kwargs ) return np . log ( n_samples - 1 ) - psi ( n_neighbors ) + np . log ( self . vol ) + ( d_dimensions / n_samples ) * np . log ( dist [:, n_neighbors - 1 ]) . sum () def score ( self , X ): return self . H_x # parameters (default) n_neighbors = 20 algorithm = 'brute' n_jobs = - 1 ensemble = False batch_size = 50 kwargs = { 'metric' : 'euclidean' } # initialize it estimator clf_knnK = EntropyKNN ( n_neighbors = n_neighbors , algorithm = algorithm , n_jobs = n_jobs , ensemble = ensemble , batch_size = batch_size , kwargs = kwargs , ) # estimate entropy H_x = clf_knnK . fit ( X ) . score ( X ) H_y = clf_knnK . fit ( Y ) . score ( Y ) print ( f \"H(X): { H_x : .3f } bits\" ) print ( f \"H(Y): { H_y : .3f } bits\" ) H(X): 4.077 bits H(Y): 2.131 bits Notice there are quite a lot of parameters we can change within the actual KNN estimation procedure. But the rest seems to be fairly consistent with not much tweaking we can do.","title":"Shannon Entropy (KNN/KDP)"},{"location":"notebooks/ite_toolbox/0_demo/#ite-toolbox-implementation","text":"# parameters (default) mult = True knn_method = 'cKDTree' # fast version (slower version KNN) k_neighbors = 10 # free parameter eps = 0.1 # free parameter # initialize it estimator clf_knnK = ite . cost . BHShannon_KnnK ( mult = mult , knn_method = knn_method , k = k_neighbors , eps = eps ) # estimate entropy H_x = clf_knnK . estimation ( X ) H_y = clf_knnK . estimation ( Y ) print ( f \"H(X): { H_x : .3f } bits\" ) print ( f \"H(Y): { H_y : .3f } bits\" ) H(X): 4.132 bits H(Y): 2.208 bits It seems like the numbers we get are quite similar.","title":"ITE Toolbox implementation"},{"location":"notebooks/ite_toolbox/0_demo/#shannon-entropy-expf","text":"This is the close-form expression for the Sharma-Mittal entropy calculation for expontial families. The Sharma-Mittal entropy is a generalization of the Shannon, R\u00e9nyi and Tsallis entropy measurements. This estimates Y using the maximum likelihood estimation and then uses the analytical formula for the exponential family. A closed-form expression for the Sharma-Mittal entropy of exponential families - Nielsen & Nock (2012) - Paper Statistical exponential families: A digest with flash cards - Paper Source Parameters \\Lambda = (\\mu, \\Sigma) \\Lambda = (\\mu, \\Sigma) where \\mu \\in \\mathbb{R}^{d} \\mu \\in \\mathbb{R}^{d} and \\Sigma > 0 \\Sigma > 0 Parameters \\Theta = \\left( \\Sigma^{-1}\\mu, \\frac{1}{2}\\Sigma^{-1} \\right) \\Theta = \\left( \\Sigma^{-1}\\mu, \\frac{1}{2}\\Sigma^{-1} \\right) Log Normalizer F(\\Theta) = \\frac{1}{4} Tr( \\theta^\\top \\Theta^{-1} \\theta) - \\frac{1}{2} \\log|\\Theta| + \\frac{d}{2}\\log \\pi F(\\Theta) = \\frac{1}{4} Tr( \\theta^\\top \\Theta^{-1} \\theta) - \\frac{1}{2} \\log|\\Theta| + \\frac{d}{2}\\log \\pi Gradient Log Normalizer \\nabla F(\\Theta) = \\left( \\frac{1}{2} \\Theta^{-1}\\theta, -\\frac{1}{2} \\Theta^{-1}- \\frac{1}{4}(\\Theta^{-1}\\Theta)(\\Theta^{-1}\\Theta)^\\top \\right) \\nabla F(\\Theta) = \\left( \\frac{1}{2} \\Theta^{-1}\\theta, -\\frac{1}{2} \\Theta^{-1}- \\frac{1}{4}(\\Theta^{-1}\\Theta)(\\Theta^{-1}\\Theta)^\\top \\right) Final Entropy Calculation H = F(\\Theta) - \\langle F(\\Theta), \\nabla F(\\Theta) \\rangle H = F(\\Theta) - \\langle F(\\Theta), \\nabla F(\\Theta) \\rangle <span><span class=\"MathJax_Preview\">H = F(\\Theta) - \\langle F(\\Theta), \\nabla F(\\Theta) \\rangle</span><script type=\"math/tex\">H = F(\\Theta) - \\langle F(\\Theta), \\nabla F(\\Theta) \\rangle n_samples , n_dims = X . shape # source params, theta theta_1 = X . mean ( axis = 0 ) theta_2 = np . cov ( X . T ) print ( 'Source:' , theta_1 . shape , theta_2 . shape ) # natural params, eta eta_1 = np . linalg . inv ( theta_2 ) @ theta_1 [:, None ] eta_2 = . 5 * np . linalg . inv ( theta_2 ) print ( 'Natural:' , eta_1 . shape , eta_2 . shape ) # log-normalizer, F(eta) f_eta = . 25 * np . trace ( eta_1 . T @ np . linalg . inv ( eta_2 ) @ eta_1 ) - . 5 * np . linalg . slogdet ( eta_2 )[ 1 ] + ( n_dims / 2. ) * np . log ( np . pi ) print ( 'Log Norm:' , f_eta . shape ) # gradient log normalizer, dF(eta) df_eta_1 = . 5 * np . linalg . inv ( eta_2 ) @ eta_1 df_eta_2 = -. 5 * np . linalg . inv ( eta_2 ) - . 25 * ( np . linalg . inv ( eta_2 ) - eta_1 ) @ ( np . linalg . inv ( eta_2 ) - eta_1 ) . T print ( 'Grad Log Norm:' , df_eta_1 . shape , df_eta_2 . shape ) # outer product t2 = np . outer ( np . outer ( eta_1 , df_eta_1 ), np . outer ( eta_2 , df_eta_2 )) print ( t2 . shape ) def expF_entropy ( X ): # estimate Gaussian parameters mean = X . mean ( axis = 0 ) cov = np . cov ( X . T ) # make Gaussian distribution norm_dist = stats . multivariate_normal ( mean = mean , cov = cov , seed = seed ) # estimate the entropy from closed form solution H_x = norm_dist . entropy () return H_x H_x = expF_entropy ( X ) H_y = expF_entropy ( Y ) print ( f \"H(X): { H_x : .3f } bits\" ) print ( f \"H(Y): { H_y : .3f } bits\" ) H(X): 4.195 bits H(Y): 1.329 bits As you can see, it works well if the distribution is actuall Gaussian but it doesn't if it isn't. mean = X . mean ( axis = 0 ) cov = np . cov ( X . T ) seed = 1 norm_dist = stats . multivariate_normal ( mean = mean , cov = cov , seed = seed ) H_x = norm_dist . entropy () print ( f \"H(X): { H_x : .3f } bits\" ) H(X): 4.195 bits # 1. estimate the maximum likelihood params mean = X . mean ( axis = 0 )[:, None ] cov = np . cov ( X . T ) inv_cov = np . linalg . inv ( cov ) alpha = inv_cov @ mean sigma = inv_cov / 2 mean . shape , cov . shape , inv_cov . shape , t1 . shape , t2 . shape # Log Normalizer (Maximum Like) F = ( 1 / 4 ) * np . trace ( np . linalg . inv ( t2 ) @ t1 @ t1 . T ) - ( 1 / 2 ) * np . log ( np . linalg . det ( cov )) + ( X . shape [ 1 ] / 2 ) * np . log ( np . pi ) # Gradient Log Normalizer alpha_grad = File \"<ipython-input-79-af7a3dc7f9a4>\" , line 14 alpha_grad = ^ SyntaxError : invalid syntax mean . shape , cov . shape , inv_cov . shape , t1 . shape , t2 . shape ((3,), (3, 3), (3, 3), (3,), (3, 3))","title":"Shannon Entropy: expF"},{"location":"notebooks/ite_toolbox/0_demo/#vme_1","text":"This nonparametric method that estimates the Shannon differential entropy (H) using the von Mises expansion. This method has a fast convergence rate than the KDE and KNN methods. This algorithm does have and in addition the can be tuned using cross-validation techniques. It is also less expensive than the KDE in terms of the numerical integration whereas this method has closed form solutions for some families of von Mises expansions. Nonparametric von Mises estimators for entropies, divergences and mutual informations - Kandasamy et. al. (2015) - Paper","title":"vME"},{"location":"notebooks/ite_toolbox/0_demo/#ensemble_1","text":"Estimates the entropy from the average entropy estimations on groups of samples This is a simple implementation with the freedom to choose the estimator estimate_H . # split into groups for igroup in batches : H += estimate_H ( igroup ) H /= len ( batches ) High-dimensional mutual information estimation for image registration - Kybic (2004) - Paper","title":"Ensemble"},{"location":"notebooks/ite_toolbox/0_demo/#potential-new-experiments_1","text":"","title":"Potential New Experiments"},{"location":"notebooks/ite_toolbox/0_demo/#voronoi_1","text":"Estimates Shannon entropy using Voronoi regions. Apparently it is good for multi-dimensional densities. A new class of entropy estimators for multi-dimensional densities - Miller (2003) - Paper","title":"Voronoi"},{"location":"notebooks/ite_toolbox/0_demo/#mutual-information_1","text":"The estimation was carried out using the following relationship. Let XY = [X, Y] \\in \\mathcal{R}^{N \\times D} XY = [X, Y] \\in \\mathcal{R}^{N \\times D} , where D=D_1+D_2 D=D_1+D_2 . I(XY) = \\sum_{d=1}^D H(XY) - H(XY) I(XY) = \\sum_{d=1}^D H(XY) - H(XY) The pseudo-code is fairly simple (in the MATLAB version). Organize the components XY = [ X , Y ] Estimate the joint entropy, H(XY) H(XY) H_xy = - estimate_H ( np . hstack ( XY ) # stack the vectors dimension-wise ) Estimate the marginals of XY; i.e. estimate X and Y individually, then sum them. H_x_y = np . sum ( # estimate the entropy for each marginal [ estimate_H ( imarginal ) for imarginal in XY ] ) Summation of the two quantities MI_XY = H_x_y + H_xy","title":"Mutual Information"},{"location":"notebooks/ite_toolbox/0_demo/#naive","text":"class Ensemble : def _fit_ensemble ( self , X : np . ndarray , vol : float , batch_size : int = 100 ) -> float : Hs = list () for idx in gen_batches ( X . shape [ 0 ], batch_size , 10 ): Hs . append ( self . _fit ( X [ idx ], vol )) return np . mean ( Hs ) class MutualInfoKNN ( BaseEstimator ): def __init__ ( self , n_neighbors : int = 20 , algorithm : str = 'brute' , n_jobs : int =- 1 , kwargs : Optional [ dict ] = None ) -> None : self . n_neighbors = n_neighbors self . algorithm = algorithm self . n_jobs = n_jobs self . kwargs = kwargs def fit ( self , X : np . ndarray , Y : np . ndarray ) -> BaseEstimator : # Calculate Volumes vol_xy = volume_unit_ball ( X . shape [ 1 ] + Y . shape [ 1 ]) vol_x = volume_unit_ball ( X . shape [ 1 ]) vol_y = volume_unit_ball ( Y . shape [ 1 ]) # Calculate Joint Entropy H_xy = self . _fit ( np . vstack ([ X , Y ]), vol_xy ) # Calculate Marginal Probabilities H_x = self . _fit ( X , vol_x ) H_y = self . _fit ( Y , vol_y ) # Calculate Mutual Information self . MI = H_x + H_y - H_xy return self def _fit ( self , X : np . ndarray , vol : float ) -> float : # 1. Calculate the K-nearest neighbors dist = knn_distance ( X , n_neighbors = self . n_neighbors , algorithm = self . algorithm , n_jobs = self . n_jobs , kwargs = self . kwargs ) return np . log ( n_samples - 1 ) - psi ( n_neighbors ) + np . log ( vol ) + ( d_dimensions / n_samples ) * np . log ( dist [:, n_neighbors - 1 ]) . sum () def score ( self , X ): return self . MI # parameters (default) n_neighbors = 10 algorithm = 'brute' n_jobs = - 1 ensemble = False batch_size = 50 kwargs = { 'metric' : 'euclidean' } # initialize it estimator clf_knnK = MutualInfoKNN ( n_neighbors = n_neighbors , algorithm = algorithm , n_jobs = n_jobs , kwargs = kwargs , ) # estimate entropy MI_xy = clf_knnK . fit ( X , Y ) . score ( X ) print ( f \"H(X): { MI_xy : .3f } bits\" ) H(X): 6.427 bits","title":"Naive"},{"location":"notebooks/ite_toolbox/0_demo/#ite-toolbox","text":"# parameters (default) mult = True # ?? kl_co_name = 'BDKL_KnnK' # KLD calculator kl_co_pars = None # parameters for the KLD calculator # initialize it estimator clf_mi = ite . cost . MIShannon_DKL ( # mult=mult, # kl_co_name=kl_co_name, # kl_co_pars=kl_co_pars, ) # concat data XY = np . concatenate (( X , Y ), axis = 1 ) # individual dimensions per sub_dimensions = np . array ([ X . shape [ 1 ], Y . shape [ 1 ]]) # estimate mutual information mi_XY = clf_mi . estimation ( XY , sub_dimensions ) print ( f \"MI(X,Y): { mi_XY : .3f } bits\" ) MI(X,Y): 3.683 bits # parameters (default) mult = True # ?? kernel = { 'name' : 'RBF' , 'sigma' : 1 } # KLD calculator eta = 0.01 # parameters for the KLD calculator # initialize it estimator clf_mi = ite . cost . BIKGV ( # mult=mult, # kernel=kernel, # eta=eta, ) # concat data XY = np . concatenate (( X , Y ), axis = 1 ) # individual dimensions per sub_dimensions = np . array ([ X . shape [ 1 ], Y . shape [ 1 ]]) # estimate mutual information mi_XY = clf_mi . estimation ( XY , sub_dimensions ) print ( f \"MI(X,Y): { mi_XY : .3f } bits\" ) MI(X,Y): 2.062 bits I expect there to be some MI between X and Y since it is a rotation of the original distribution.","title":"ITE Toolbox"},{"location":"notebooks/ite_toolbox/0_demo/#total-correlation-multi-information-co-information","text":"The estimation was carried out using the following relationship: I(x_1, x_2, \\ldots, x_D) = \\sum_{d=1}^D H(x_d) - H(X) I(x_1, x_2, \\ldots, x_D) = \\sum_{d=1}^D H(x_d) - H(X) <span><span class=\"MathJax_Preview\">I(x_1, x_2, \\ldots, x_D) = \\sum_{d=1}^D H(x_d) - H(X)</span><script type=\"math/tex\">I(x_1, x_2, \\ldots, x_D) = \\sum_{d=1}^D H(x_d) - H(X) # parameters (default) mult = True kl_co_name = 'BDKL_KnnK' kl_co_pars = None # initialize it estimator clf_mi = ite . cost . MIShannon_DKL ( mult = mult , kl_co_name = kl_co_name , kl_co_pars = kl_co_pars , ) # concat data sub_dimensions = np . array ( range ( X . shape [ 1 ])) # estimate mutual information tc_X = clf_mi . estimation ( X , sub_dimensions ) tc_Y = clf_mi . estimation ( Y , sub_dimensions ) print ( f \"Shannon Total Correlation, TC(X): { tc_X : .3f } bits\" ) print ( f \"Shannon Total Correlation, TC(Y): { tc_Y : .3f } bits\" ) Shannon Total Correlation, TC(X): -0.002 bits Shannon Total Correlation, TC(Y): 2.365 bits This makes since given that the original distribution X X should have no correlations between dimensions because it is Gaussian. The rotation of X X by some random matrix A A , Y=AX^{\\top} Y=AX^{\\top} , means that we have added some correlations between dimensions. We see that as the TC is higher.","title":"Total Correlation (Multi-Information, Co-Information)"},{"location":"notebooks/ite_toolbox/1_fake_distributions/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Simulated Distributions \u00b6 In this notebook, I will walk through some of the distributions we used in order to generate some fake data. import sys , os cwd = os . getcwd () sys . path . insert ( 0 , f ' { cwd } /../../src' ) sys . path . insert ( 0 , f ' { cwd } /../../src/itetoolbox' ) import numpy as np import ite from sklearn.utils import check_random_state from data.toy import entropy_marginal % matplotlib inline % load_ext autoreload % autoreload 2 Analytical Values \u00b6 Uniform Distribution \u00b6 x \\sim \\mathcal{U}(a, b) x \\sim \\mathcal{U}(a, b) where a,b a,b are the support for the distribution. We can measure the entropy as: H(x) = \\ln(b-a) H(x) = \\ln(b-a) Additionally, if we want to measure the entropy of x x that is generated by some random transformation A A then we have: H(Ax) = \\ln(b-a)+ \\ln \\left| A \\right| H(Ax) = \\ln(b-a)+ \\ln \\left| A \\right| where |\\cdot| |\\cdot| is the determinant operator. Multivariate Uniform Distribution Note : I saw in the code that they do the prod of the support and then calculate the log function. Because every dimension is independent so we can perhaps just sum them. But I'm not sure about the product. ??? ( b - a ) 2 a = - 1 b = 1 loc = - 1 scale = ( b - a ) uni_var = stats . uniform . rvs ( loc = loc , scale = scale , size = ( 10 , 2 ), random_state = 123 ) stats . uniform . entropy ( loc = a , scale = ( b - a )) array(0.69314718) from scipy import stats np . random . seed ( 123 ) d_dimensions = 2 support_a = - np . random . rand ( 1 , d_dimensions ) support_b = np . random . rand ( 1 , d_dimensions ) # random rotation matrix A = np . random . rand ( d_dimensions , d_dimensions ) # Compute entropy of uniform dist H_uni = np . log ( np . prod ( support_b - support_a )) # computer entropy of linear transformation H_A = np . linalg . slogdet ( A )[ 1 ] print ( H_uni ) -0.2571675347021572 Gaussian Distribution \u00b6 H = \\frac{1}{2} \\log\\left( 2 \\pi \\exp(1)\\right)^{D} \\left| \\Sigma \\right| H = \\frac{1}{2} \\log\\left( 2 \\pi \\exp(1)\\right)^{D} \\left| \\Sigma \\right| <span><span class=\"MathJax_Preview\">H = \\frac{1}{2} \\log\\left( 2 \\pi \\exp(1)\\right)^{D} \\left| \\Sigma \\right|</span><script type=\"math/tex\">H = \\frac{1}{2} \\log\\left( 2 \\pi \\exp(1)\\right)^{D} \\left| \\Sigma \\right| cov = np . array ([[ 1 , 0.9 ], [ 0.9 , 1 ]]) print ( cov . shape ) mu = [ 0.0 , 0.0 ] seed = 123 n_samples = 100 , d_dimensions = 2 norm_dist = stats . multivariate_normal ( mean = mu , cov = cov , seed = seed ) # norm_dist.entropy() (2, 2) norm_dist <scipy.stats._multivariate.multivariate_normal_frozen at 0x7f5d3b091a58> Dirichlet Distribution \u00b6 alpha = 0.1 seed = 123 diri_dist = stats . dirichlet . rvs ( alpha = alpha , size = ( 3 , 1 ), random_state = seed ) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) <ipython-input-145-67b2f0e5f6c9> in <module> 2 seed = 123 3 ----> 4 diri_dist = stats . dirichlet . rvs ( alpha = alpha , size = ( 3 , 1 ) , random_state = seed ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/scipy/stats/_multivariate.py in rvs (self, alpha, size, random_state) 1557 1558 \"\"\" -> 1559 alpha = _dirichlet_check_parameters ( alpha ) 1560 random_state = self . _get_random_state ( random_state ) 1561 return random_state . dirichlet ( alpha , size = size ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/scipy/stats/_multivariate.py in _dirichlet_check_parameters (alpha) 1230 elif alpha . ndim != 1 : 1231 raise ValueError(\"Parameter vector 'a' must be one dimensional, \" -> 1232 \"but a.shape = %s.\" % (alpha.shape, )) 1233 return alpha 1234 ValueError : Parameter vector 'a' must be one dimensional, but a.shape = (). T-Student Distribution \u00b6 Distribution \u00b6 Multivariate $$\\frac{\\Gamma \\left[ \\frac{(\\nu + p)}{2} \\right]} {\\Gamma \\left(\\frac{\\nu}{2} \\right)\\nu^{\\frac{p}{2}} \\pi^{\\frac{p}{2}} \\left|\\Sigma \\right|^{\\frac{1}{2}}} \\left[ 1 + \\frac{1}{\\nu} (x - \\mu)^\\top \\Sigma^{-1}(x - \\mu) \\right]^{- \\frac{(\\nu + p}{2}} $$ Entropy The differential entropy of the multivariate student-t distribution when the covariance matrix is the identity. h = - \\log \\frac{\\Gamma \\left( \\frac{\\nu + d}{2} \\right)}{\\Gamma \\left( \\frac{\\nu}{2} \\right)(\\nu \\pi)^{d/2}} + \\left( \\frac{\\nu + d}{2} \\right) \\left( \\Psi \\left(\\frac{\\nu + d}{2} \\right) - \\Psi\\left( \\frac{\\nu}{2} \\right)\\right) h = - \\log \\frac{\\Gamma \\left( \\frac{\\nu + d}{2} \\right)}{\\Gamma \\left( \\frac{\\nu}{2} \\right)(\\nu \\pi)^{d/2}} + \\left( \\frac{\\nu + d}{2} \\right) \\left( \\Psi \\left(\\frac{\\nu + d}{2} \\right) - \\Psi\\left( \\frac{\\nu}{2} \\right)\\right) where: \\Psi \\Psi is the digamma function \\Gamma \\Gamma is the gamma function If we have the case where we have a covariance matrix \\Sigma \\Sigma , we can use the relationship: y = \\mu + Lx y = \\mu + Lx where: * x x is the standard Student-t random vector * \\mu \\mu is the mean * \\Sigma=LL^\\top \\Sigma=LL^\\top is the covariance matrix We know the properties of differential entropy yields the following equation: h(Ax) = h(x) + \\log |A| h(Ax) = h(x) + \\log |A| So we can rewrite the Student-t distribution with a mean \\mu \\mu and a covariance matrix \\Sigma \\Sigma as the additive product of the original distribution with a covariance I I and the change of variables: h(x) = h_{\\Sigma=I} + \\frac{1}{2} \\log |\\Sigma| h(x) = h_{\\Sigma=I} + \\frac{1}{2} \\log |\\Sigma| Source StackOverFlow Wiki Distribution Class Generator \u00b6 class DistData : def __init__ ( self , n_samples : int = 1000 , d_dimensions : int = 3 , distribution : str = \"gauss\" , mu : float = 0.0 , sigma : float = 1.0 , weight : float = 2.0 , bias : float = 0.5 , nu : float = 1.0 , gauss_state : int = 123 , dim_state : int = 111 , trans_state : int = 123 , ) -> None : self . n_samples = n_samples self . d_dimensions = d_dimensions self . distribution = distribution self . mu = mu self . sigma = sigma self . weight = weight self . bias = bias self . nu = nu self . gauss = check_random_state ( gauss_state ) self . dim_state = check_random_state ( dim_state ) self . trans_state = check_random_state ( trans_state ) def data ( self ): if self . distribution == \"gauss\" : # generate data Gaussian data self . samples = self . mu + self . sigma * self . gauss . randn ( self . n_samples , self . d_dimensions ) # random rotation (uniformly distributed) self . A = self . trans_state . rand ( self . d_dimensions , self . d_dimensions ) # output data self . X = self . samples @ self . A elif self . distribution == 'linear' : # generate data from normal dist self . samples = self . mu + self . sigma * self . gauss . randn ( self . n_samples , self . d_dimensions ) # random rotation (uniformly distributed) d_rot = self . dim_state . randn ( 1 , self . d_dimensions ) # linear transformation on all dimensions for idim in range ( self . d_dimensions ): exponent = self . weight * d_rot [:, idim ] + self . bias self . samples [:, idim ] = np . sign ( self . samples [:, idim ]) * np . abs ( self . samples [:, idim ]) ** exponent # random rotation (uniformly distributed) self . A = self . trans_state . rand ( self . d_dimensions , self . d_dimensions ) self . X = self . samples @ self . A else : raise ValueError ( \"Unrecognized distribution...\" ) return self . X def entropy ( self ): if self . distribution == \"gauss\" : # calculate entropy return entropy_marginal ( self . X ) . sum () + np . linalg . slogdet ( self . A )[ 1 ] if self . distribution == \"linear\" : # calculate entropy return entropy_marginal ( self . X ) . sum () + np . linalg . slogdet ( self . A )[ 1 ] else : raise ValueError ( \"Unrecognized distribution...\" ) Distribution I - Rotated Gaussian Dataset \u00b6 random_state = 123 mu = 0.0 sigma = 1.0 n_samples = 10000 d_dimensions = 100 distribution = 'gauss' # initialize class clf_datadist = DistData ( n_samples = n_samples , mu = mu , sigma = sigma , d_dimensions = d_dimensions ) # generate samples X = clf_datadist . data () # calculate entropy H_x = clf_datadist . entropy () print ( f \"Entropy: { H_x : .4f } \" ) Entropy: 518.0578 Distribution II - Rotated Linear Dataset \u00b6 random_state = 123 mu = 0.0 sigma = 1.0 n_samples = 10000 d_dimensions = 100 distribution = 'linear' # initialize class clf_datadist = DistData ( n_samples = n_samples , mu = mu , sigma = sigma , d_dimensions = d_dimensions , distribution = distribution ) # generate samples X = clf_datadist . data () # calculate entropy H_x = clf_datadist . entropy () print ( f \"Entropy: { H_x : .4f } \" ) Entropy: 4602.8497","title":"1 fake distributions"},{"location":"notebooks/ite_toolbox/1_fake_distributions/#simulated-distributions","text":"In this notebook, I will walk through some of the distributions we used in order to generate some fake data. import sys , os cwd = os . getcwd () sys . path . insert ( 0 , f ' { cwd } /../../src' ) sys . path . insert ( 0 , f ' { cwd } /../../src/itetoolbox' ) import numpy as np import ite from sklearn.utils import check_random_state from data.toy import entropy_marginal % matplotlib inline % load_ext autoreload % autoreload 2","title":"Simulated Distributions"},{"location":"notebooks/ite_toolbox/1_fake_distributions/#analytical-values","text":"","title":"Analytical Values"},{"location":"notebooks/ite_toolbox/1_fake_distributions/#uniform-distribution","text":"x \\sim \\mathcal{U}(a, b) x \\sim \\mathcal{U}(a, b) where a,b a,b are the support for the distribution. We can measure the entropy as: H(x) = \\ln(b-a) H(x) = \\ln(b-a) Additionally, if we want to measure the entropy of x x that is generated by some random transformation A A then we have: H(Ax) = \\ln(b-a)+ \\ln \\left| A \\right| H(Ax) = \\ln(b-a)+ \\ln \\left| A \\right| where |\\cdot| |\\cdot| is the determinant operator. Multivariate Uniform Distribution Note : I saw in the code that they do the prod of the support and then calculate the log function. Because every dimension is independent so we can perhaps just sum them. But I'm not sure about the product. ??? ( b - a ) 2 a = - 1 b = 1 loc = - 1 scale = ( b - a ) uni_var = stats . uniform . rvs ( loc = loc , scale = scale , size = ( 10 , 2 ), random_state = 123 ) stats . uniform . entropy ( loc = a , scale = ( b - a )) array(0.69314718) from scipy import stats np . random . seed ( 123 ) d_dimensions = 2 support_a = - np . random . rand ( 1 , d_dimensions ) support_b = np . random . rand ( 1 , d_dimensions ) # random rotation matrix A = np . random . rand ( d_dimensions , d_dimensions ) # Compute entropy of uniform dist H_uni = np . log ( np . prod ( support_b - support_a )) # computer entropy of linear transformation H_A = np . linalg . slogdet ( A )[ 1 ] print ( H_uni ) -0.2571675347021572","title":"Uniform Distribution"},{"location":"notebooks/ite_toolbox/1_fake_distributions/#gaussian-distribution","text":"H = \\frac{1}{2} \\log\\left( 2 \\pi \\exp(1)\\right)^{D} \\left| \\Sigma \\right| H = \\frac{1}{2} \\log\\left( 2 \\pi \\exp(1)\\right)^{D} \\left| \\Sigma \\right| <span><span class=\"MathJax_Preview\">H = \\frac{1}{2} \\log\\left( 2 \\pi \\exp(1)\\right)^{D} \\left| \\Sigma \\right|</span><script type=\"math/tex\">H = \\frac{1}{2} \\log\\left( 2 \\pi \\exp(1)\\right)^{D} \\left| \\Sigma \\right| cov = np . array ([[ 1 , 0.9 ], [ 0.9 , 1 ]]) print ( cov . shape ) mu = [ 0.0 , 0.0 ] seed = 123 n_samples = 100 , d_dimensions = 2 norm_dist = stats . multivariate_normal ( mean = mu , cov = cov , seed = seed ) # norm_dist.entropy() (2, 2) norm_dist <scipy.stats._multivariate.multivariate_normal_frozen at 0x7f5d3b091a58>","title":"Gaussian Distribution"},{"location":"notebooks/ite_toolbox/1_fake_distributions/#dirichlet-distribution","text":"alpha = 0.1 seed = 123 diri_dist = stats . dirichlet . rvs ( alpha = alpha , size = ( 3 , 1 ), random_state = seed ) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) <ipython-input-145-67b2f0e5f6c9> in <module> 2 seed = 123 3 ----> 4 diri_dist = stats . dirichlet . rvs ( alpha = alpha , size = ( 3 , 1 ) , random_state = seed ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/scipy/stats/_multivariate.py in rvs (self, alpha, size, random_state) 1557 1558 \"\"\" -> 1559 alpha = _dirichlet_check_parameters ( alpha ) 1560 random_state = self . _get_random_state ( random_state ) 1561 return random_state . dirichlet ( alpha , size = size ) ~/.conda/envs/it4dnn/lib/python3.6/site-packages/scipy/stats/_multivariate.py in _dirichlet_check_parameters (alpha) 1230 elif alpha . ndim != 1 : 1231 raise ValueError(\"Parameter vector 'a' must be one dimensional, \" -> 1232 \"but a.shape = %s.\" % (alpha.shape, )) 1233 return alpha 1234 ValueError : Parameter vector 'a' must be one dimensional, but a.shape = ().","title":"Dirichlet Distribution"},{"location":"notebooks/ite_toolbox/1_fake_distributions/#t-student-distribution","text":"","title":"T-Student Distribution"},{"location":"notebooks/ite_toolbox/1_fake_distributions/#distribution","text":"Multivariate $$\\frac{\\Gamma \\left[ \\frac{(\\nu + p)}{2} \\right]} {\\Gamma \\left(\\frac{\\nu}{2} \\right)\\nu^{\\frac{p}{2}} \\pi^{\\frac{p}{2}} \\left|\\Sigma \\right|^{\\frac{1}{2}}} \\left[ 1 + \\frac{1}{\\nu} (x - \\mu)^\\top \\Sigma^{-1}(x - \\mu) \\right]^{- \\frac{(\\nu + p}{2}} $$ Entropy The differential entropy of the multivariate student-t distribution when the covariance matrix is the identity. h = - \\log \\frac{\\Gamma \\left( \\frac{\\nu + d}{2} \\right)}{\\Gamma \\left( \\frac{\\nu}{2} \\right)(\\nu \\pi)^{d/2}} + \\left( \\frac{\\nu + d}{2} \\right) \\left( \\Psi \\left(\\frac{\\nu + d}{2} \\right) - \\Psi\\left( \\frac{\\nu}{2} \\right)\\right) h = - \\log \\frac{\\Gamma \\left( \\frac{\\nu + d}{2} \\right)}{\\Gamma \\left( \\frac{\\nu}{2} \\right)(\\nu \\pi)^{d/2}} + \\left( \\frac{\\nu + d}{2} \\right) \\left( \\Psi \\left(\\frac{\\nu + d}{2} \\right) - \\Psi\\left( \\frac{\\nu}{2} \\right)\\right) where: \\Psi \\Psi is the digamma function \\Gamma \\Gamma is the gamma function If we have the case where we have a covariance matrix \\Sigma \\Sigma , we can use the relationship: y = \\mu + Lx y = \\mu + Lx where: * x x is the standard Student-t random vector * \\mu \\mu is the mean * \\Sigma=LL^\\top \\Sigma=LL^\\top is the covariance matrix We know the properties of differential entropy yields the following equation: h(Ax) = h(x) + \\log |A| h(Ax) = h(x) + \\log |A| So we can rewrite the Student-t distribution with a mean \\mu \\mu and a covariance matrix \\Sigma \\Sigma as the additive product of the original distribution with a covariance I I and the change of variables: h(x) = h_{\\Sigma=I} + \\frac{1}{2} \\log |\\Sigma| h(x) = h_{\\Sigma=I} + \\frac{1}{2} \\log |\\Sigma| Source StackOverFlow Wiki","title":"Distribution"},{"location":"notebooks/ite_toolbox/1_fake_distributions/#distribution-class-generator","text":"class DistData : def __init__ ( self , n_samples : int = 1000 , d_dimensions : int = 3 , distribution : str = \"gauss\" , mu : float = 0.0 , sigma : float = 1.0 , weight : float = 2.0 , bias : float = 0.5 , nu : float = 1.0 , gauss_state : int = 123 , dim_state : int = 111 , trans_state : int = 123 , ) -> None : self . n_samples = n_samples self . d_dimensions = d_dimensions self . distribution = distribution self . mu = mu self . sigma = sigma self . weight = weight self . bias = bias self . nu = nu self . gauss = check_random_state ( gauss_state ) self . dim_state = check_random_state ( dim_state ) self . trans_state = check_random_state ( trans_state ) def data ( self ): if self . distribution == \"gauss\" : # generate data Gaussian data self . samples = self . mu + self . sigma * self . gauss . randn ( self . n_samples , self . d_dimensions ) # random rotation (uniformly distributed) self . A = self . trans_state . rand ( self . d_dimensions , self . d_dimensions ) # output data self . X = self . samples @ self . A elif self . distribution == 'linear' : # generate data from normal dist self . samples = self . mu + self . sigma * self . gauss . randn ( self . n_samples , self . d_dimensions ) # random rotation (uniformly distributed) d_rot = self . dim_state . randn ( 1 , self . d_dimensions ) # linear transformation on all dimensions for idim in range ( self . d_dimensions ): exponent = self . weight * d_rot [:, idim ] + self . bias self . samples [:, idim ] = np . sign ( self . samples [:, idim ]) * np . abs ( self . samples [:, idim ]) ** exponent # random rotation (uniformly distributed) self . A = self . trans_state . rand ( self . d_dimensions , self . d_dimensions ) self . X = self . samples @ self . A else : raise ValueError ( \"Unrecognized distribution...\" ) return self . X def entropy ( self ): if self . distribution == \"gauss\" : # calculate entropy return entropy_marginal ( self . X ) . sum () + np . linalg . slogdet ( self . A )[ 1 ] if self . distribution == \"linear\" : # calculate entropy return entropy_marginal ( self . X ) . sum () + np . linalg . slogdet ( self . A )[ 1 ] else : raise ValueError ( \"Unrecognized distribution...\" )","title":"Distribution Class Generator"},{"location":"notebooks/ite_toolbox/1_fake_distributions/#distribution-i-rotated-gaussian-dataset","text":"random_state = 123 mu = 0.0 sigma = 1.0 n_samples = 10000 d_dimensions = 100 distribution = 'gauss' # initialize class clf_datadist = DistData ( n_samples = n_samples , mu = mu , sigma = sigma , d_dimensions = d_dimensions ) # generate samples X = clf_datadist . data () # calculate entropy H_x = clf_datadist . entropy () print ( f \"Entropy: { H_x : .4f } \" ) Entropy: 518.0578","title":"Distribution I - Rotated Gaussian Dataset"},{"location":"notebooks/ite_toolbox/1_fake_distributions/#distribution-ii-rotated-linear-dataset","text":"random_state = 123 mu = 0.0 sigma = 1.0 n_samples = 10000 d_dimensions = 100 distribution = 'linear' # initialize class clf_datadist = DistData ( n_samples = n_samples , mu = mu , sigma = sigma , d_dimensions = d_dimensions , distribution = distribution ) # generate samples X = clf_datadist . data () # calculate entropy H_x = clf_datadist . entropy () print ( f \"Entropy: { H_x : .4f } \" ) Entropy: 4602.8497","title":"Distribution II - Rotated Linear Dataset"},{"location":"notebooks/ite_toolbox/Untitled/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Rotation Matrices \u00b6 import sys , os cwd = os . getcwd () sys . path . insert ( 0 , f ' { cwd } /../../src' ) sys . path . insert ( 0 , f ' { cwd } /../../src/itetoolbox' ) import numpy as np import ite from sklearn.utils import check_random_state from data.toy import entropy_marginal from scipy import stats % matplotlib inline % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload Random Rotation \u00b6 d_dimensions = 2 seed = 123 A_rand = stats . special_ortho_group . rvs ( dim = d_dimensions , random_state = seed ) print ( A_rand . shape ) # Calculate the log determinant np . linalg . slogdet ( A_rand )[ 1 ] (2, 2) 1.6653345369377348e-16 Random Orthogonal Matrix \u00b6 d_dimensions = 2 seed = 123 A_ortho = stats . ortho_group . rvs ( dim = d_dimensions , random_state = seed ) A_ortho . shape # Calculate the log determinant np . linalg . slogdet ( A_ortho )[ 1 ] 4.996003610813204e-16 Random Unitary Matrix \u00b6 d_dimensions = 2 seed = 123 A_unitary = stats . unitary_group . rvs ( dim = d_dimensions , random_state = seed ) A_unitary . shape # Calculate the log determinant np . linalg . slogdet ( A_unitary )[ 1 ] -4.163336342344337e-16 Random Correlation Matrix \u00b6 d_dimensions = 2 seed = 123 eigs = np . array ([ 1.2 , 0.8 ]) A_corr = stats . random_correlation . rvs ( eigs = eigs , random_state = seed ) A_corr . shape # Calculate the log determinant np . linalg . slogdet ( A_corr )[ 1 ] -0.04082199452025481 PCA Transformation \u00b6 # generate complete random matrix n_samples = 100 d_dimensions = 2 X = np . random . rand ( n_samples , d_dimensions ) from sklearn.decomposition import PCA pca_model = PCA () . fit ( X ) # get components, V V = pca_model . components_ # find log determinant transform of components np . linalg . slogdet ( V )[ 1 ] 1.1102230246251565e-16 ICA Transformation \u00b6 # generate complete random matrix n_samples = 100 d_dimensions = 2 X = np . random . rand ( n_samples , d_dimensions ) from sklearn.decomposition import FastICA ica_model = FastICA ( whiten = True , random_state = seed ) . fit ( X ) # get components, V V = ica_model . components_ # find log determinant transform of components np . linalg . slogdet ( V )[ 1 ] -2.094808661664451 Orthogonal Constraint \u00b6 So we need to ensure that the ICA performs under the orthogonal constraint. So for this we can use the Picard-O algorithm. The software can be found here ( docs ). #!pip install picard from picard import picard ortho = True seed = 123 K , W , Y = picard ( X , ortho = True , random_state = 123 , whiten = True ) components = W @ K print ( components . shape ) X_trans = X @ components . T # find log determinant transform of components # np.linalg.slogdet(W @ K)[1] (2, 100) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) <ipython-input-17-2206cfc7d55f> in <module> 8 components = W @ K 9 print ( components . shape ) ---> 10 X_trans = X @ components . T 11 # find log determinant transform of components 12 # np.linalg.slogdet(W @ K)[1] ValueError : matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 100 is different from 2) X_trans . shape , components . shape , W . shape --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-18-deeb8cb2cac6> in <module> ----> 1 X_trans . shape , components . shape , W . shape NameError : name 'X_trans' is not defined np . linalg . slogdet ( W )[ 1 ] 9.020562075079397e-16 Can we go back?? # can we go back? X_ori = ( W @ X_trans ) . T --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-21-9e4215dfa4ae> in <module> 1 # can we go back? ----> 2 X_ori = ( W @ X_trans ) . T NameError : name 'X_trans' is not defined X_ori . shape --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-22-36430365f080> in <module> ----> 1 X_ori . shape NameError : name 'X_ori' is not defined","title":"Untitled"},{"location":"notebooks/ite_toolbox/Untitled/#rotation-matrices","text":"import sys , os cwd = os . getcwd () sys . path . insert ( 0 , f ' { cwd } /../../src' ) sys . path . insert ( 0 , f ' { cwd } /../../src/itetoolbox' ) import numpy as np import ite from sklearn.utils import check_random_state from data.toy import entropy_marginal from scipy import stats % matplotlib inline % load_ext autoreload % autoreload 2 The autoreload extension is already loaded. To reload it, use: %reload_ext autoreload","title":"Rotation Matrices"},{"location":"notebooks/ite_toolbox/Untitled/#random-rotation","text":"d_dimensions = 2 seed = 123 A_rand = stats . special_ortho_group . rvs ( dim = d_dimensions , random_state = seed ) print ( A_rand . shape ) # Calculate the log determinant np . linalg . slogdet ( A_rand )[ 1 ] (2, 2) 1.6653345369377348e-16","title":"Random Rotation"},{"location":"notebooks/ite_toolbox/Untitled/#random-orthogonal-matrix","text":"d_dimensions = 2 seed = 123 A_ortho = stats . ortho_group . rvs ( dim = d_dimensions , random_state = seed ) A_ortho . shape # Calculate the log determinant np . linalg . slogdet ( A_ortho )[ 1 ] 4.996003610813204e-16","title":"Random Orthogonal Matrix"},{"location":"notebooks/ite_toolbox/Untitled/#random-unitary-matrix","text":"d_dimensions = 2 seed = 123 A_unitary = stats . unitary_group . rvs ( dim = d_dimensions , random_state = seed ) A_unitary . shape # Calculate the log determinant np . linalg . slogdet ( A_unitary )[ 1 ] -4.163336342344337e-16","title":"Random Unitary Matrix"},{"location":"notebooks/ite_toolbox/Untitled/#random-correlation-matrix","text":"d_dimensions = 2 seed = 123 eigs = np . array ([ 1.2 , 0.8 ]) A_corr = stats . random_correlation . rvs ( eigs = eigs , random_state = seed ) A_corr . shape # Calculate the log determinant np . linalg . slogdet ( A_corr )[ 1 ] -0.04082199452025481","title":"Random Correlation Matrix"},{"location":"notebooks/ite_toolbox/Untitled/#pca-transformation","text":"# generate complete random matrix n_samples = 100 d_dimensions = 2 X = np . random . rand ( n_samples , d_dimensions ) from sklearn.decomposition import PCA pca_model = PCA () . fit ( X ) # get components, V V = pca_model . components_ # find log determinant transform of components np . linalg . slogdet ( V )[ 1 ] 1.1102230246251565e-16","title":"PCA Transformation"},{"location":"notebooks/ite_toolbox/Untitled/#ica-transformation","text":"# generate complete random matrix n_samples = 100 d_dimensions = 2 X = np . random . rand ( n_samples , d_dimensions ) from sklearn.decomposition import FastICA ica_model = FastICA ( whiten = True , random_state = seed ) . fit ( X ) # get components, V V = ica_model . components_ # find log determinant transform of components np . linalg . slogdet ( V )[ 1 ] -2.094808661664451","title":"ICA Transformation"},{"location":"notebooks/ite_toolbox/Untitled/#orthogonal-constraint","text":"So we need to ensure that the ICA performs under the orthogonal constraint. So for this we can use the Picard-O algorithm. The software can be found here ( docs ). #!pip install picard from picard import picard ortho = True seed = 123 K , W , Y = picard ( X , ortho = True , random_state = 123 , whiten = True ) components = W @ K print ( components . shape ) X_trans = X @ components . T # find log determinant transform of components # np.linalg.slogdet(W @ K)[1] (2, 100) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) <ipython-input-17-2206cfc7d55f> in <module> 8 components = W @ K 9 print ( components . shape ) ---> 10 X_trans = X @ components . T 11 # find log determinant transform of components 12 # np.linalg.slogdet(W @ K)[1] ValueError : matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 100 is different from 2) X_trans . shape , components . shape , W . shape --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-18-deeb8cb2cac6> in <module> ----> 1 X_trans . shape , components . shape , W . shape NameError : name 'X_trans' is not defined np . linalg . slogdet ( W )[ 1 ] 9.020562075079397e-16 Can we go back?? # can we go back? X_ori = ( W @ X_trans ) . T --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-21-9e4215dfa4ae> in <module> 1 # can we go back? ----> 2 X_ori = ( W @ X_trans ) . T NameError : name 'X_trans' is not defined X_ori . shape --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-22-36430365f080> in <module> ----> 1 X_ori . shape NameError : name 'X_ori' is not defined","title":"Orthogonal Constraint"}]}